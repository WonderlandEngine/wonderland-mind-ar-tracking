var __defProp = Object.defineProperty;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __export = (target, all4) => {
  for (var name in all4)
    __defProp(target, name, { get: all4[name], enumerable: true });
};
var __publicField = (obj, key, value) => {
  __defNormalProp(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};

// node_modules/@wonderlandengine/api/dist/index.js
var dist_exports = {};
__export(dist_exports, {
  APIVersion: () => APIVersion,
  Alignment: () => Alignment,
  Animation: () => Animation,
  AnimationComponent: () => AnimationComponent,
  AnimationState: () => AnimationState,
  BrokenComponent: () => BrokenComponent,
  Collider: () => Collider,
  CollisionComponent: () => CollisionComponent,
  CollisionEventType: () => CollisionEventType,
  Component: () => Component,
  DestroyedComponentInstance: () => DestroyedComponentInstance,
  DestroyedObjectInstance: () => DestroyedObjectInstance,
  DestroyedTextureInstance: () => DestroyedTextureInstance,
  Emitter: () => Emitter,
  ForceMode: () => ForceMode,
  I18N: () => I18N,
  InputComponent: () => InputComponent,
  InputType: () => InputType,
  Justification: () => Justification,
  LightComponent: () => LightComponent,
  LightType: () => LightType,
  LockAxis: () => LockAxis,
  Material: () => Material,
  MaterialParamType: () => MaterialParamType,
  Mesh: () => Mesh,
  MeshAttribute: () => MeshAttribute,
  MeshAttributeAccessor: () => MeshAttributeAccessor,
  MeshComponent: () => MeshComponent,
  MeshIndexType: () => MeshIndexType,
  MeshSkinningType: () => MeshSkinningType,
  Object: () => Object3D,
  Object3D: () => Object3D,
  PhysXComponent: () => PhysXComponent,
  Physics: () => Physics,
  Property: () => Property,
  RayHit: () => RayHit,
  RetainEmitter: () => RetainEmitter,
  Scene: () => Scene,
  Shape: () => Shape,
  Skin: () => Skin,
  TextComponent: () => TextComponent,
  TextEffect: () => TextEffect,
  Texture: () => Texture,
  TextureManager: () => TextureManager,
  Type: () => Type,
  ViewComponent: () => ViewComponent,
  WASM: () => WASM,
  WonderlandEngine: () => WonderlandEngine,
  XR: () => XR,
  checkRuntimeCompatibility: () => checkRuntimeCompatibility,
  inheritProperties: () => inheritProperties,
  loadRuntime: () => loadRuntime,
  math: () => math
});

// node_modules/wasm-feature-detect/dist/esm/index.js
var simd = async () => WebAssembly.validate(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 5, 1, 96, 0, 1, 123, 3, 2, 1, 0, 10, 10, 1, 8, 0, 65, 0, 253, 15, 253, 98, 11]));
var threads = () => (async (e) => {
  try {
    return "undefined" != typeof MessageChannel && new MessageChannel().port1.postMessage(new SharedArrayBuffer(1)), WebAssembly.validate(e);
  } catch (e2) {
    return false;
  }
})(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 4, 1, 96, 0, 0, 3, 2, 1, 0, 5, 4, 1, 3, 1, 1, 10, 11, 1, 9, 0, 65, 0, 254, 16, 2, 0, 26, 11]));

// node_modules/@wonderlandengine/api/dist/property.js
var Type;
(function(Type2) {
  Type2[Type2["Native"] = 1] = "Native";
  Type2[Type2["Bool"] = 2] = "Bool";
  Type2[Type2["Int"] = 4] = "Int";
  Type2[Type2["Float"] = 8] = "Float";
  Type2[Type2["String"] = 16] = "String";
  Type2[Type2["Enum"] = 32] = "Enum";
  Type2[Type2["Object"] = 64] = "Object";
  Type2[Type2["Mesh"] = 128] = "Mesh";
  Type2[Type2["Texture"] = 256] = "Texture";
  Type2[Type2["Material"] = 512] = "Material";
  Type2[Type2["Animation"] = 1024] = "Animation";
  Type2[Type2["Skin"] = 2048] = "Skin";
  Type2[Type2["Color"] = 4096] = "Color";
})(Type || (Type = {}));
var Property = {
  /**
   * Create an boolean property.
   *
   * @param defaultValue The default value. If not provided, defaults to `false`.
   */
  bool(defaultValue = false) {
    return { type: Type.Bool, default: defaultValue };
  },
  /**
   * Create an integer property.
   *
   * @param defaultValue The default value. If not provided, defaults to `0`.
   */
  int(defaultValue = 0) {
    return { type: Type.Int, default: defaultValue };
  },
  /**
   * Create an float property.
   *
   * @param defaultValue The default value. If not provided, defaults to `0.0`.
   */
  float(defaultValue = 0) {
    return { type: Type.Float, default: defaultValue };
  },
  /**
   * Create an string property.
   *
   * @param defaultValue The default value. If not provided, defaults to `''`.
   */
  string(defaultValue = "") {
    return { type: Type.String, default: defaultValue };
  },
  /**
   * Create an enumeration property.
   *
   * @param values The list of values.
   * @param defaultValue The default value. Can be a string or an index into
   *     `values`. If not provided, defaults to the first element.
   */
  enum(values, defaultValue) {
    return { type: Type.Enum, values, default: defaultValue };
  },
  /** Create an {@link Object3D} reference property. */
  object(opts) {
    return { type: Type.Object, default: null, required: opts?.required ?? false };
  },
  /** Create a {@link Mesh} reference property. */
  mesh(opts) {
    return { type: Type.Mesh, default: null, required: opts?.required ?? false };
  },
  /** Create a {@link Texture} reference property. */
  texture(opts) {
    return { type: Type.Texture, default: null, required: opts?.required ?? false };
  },
  /** Create a {@link Material} reference property. */
  material(opts) {
    return { type: Type.Material, default: null, required: opts?.required ?? false };
  },
  /** Create an {@link Animation} reference property. */
  animation(opts) {
    return { type: Type.Animation, default: null, required: opts?.required ?? false };
  },
  /** Create a {@link Skin} reference property. */
  skin(opts) {
    return { type: Type.Skin, default: null, required: opts?.required ?? false };
  },
  /**
   * Create a color property.
   *
   * @param r The red component, in the range [0; 1].
   * @param g The green component, in the range [0; 1].
   * @param b The blue component, in the range [0; 1].
   * @param a The alpha component, in the range [0; 1].
   */
  color(r = 0, g = 0, b = 0, a = 1) {
    return { type: Type.Color, default: [r, g, b, a] };
  }
};

// node_modules/@wonderlandengine/api/dist/decorators.js
function propertyDecorator(data) {
  return function(target, propertyKey) {
    const ctor = target.constructor;
    ctor.Properties = ctor.hasOwnProperty("Properties") ? ctor.Properties : {};
    ctor.Properties[propertyKey] = data;
  };
}
function enumerable() {
  return function(_, __, descriptor) {
    descriptor.enumerable = true;
  };
}
function nativeProperty() {
  return function(target, propertyKey, descriptor) {
    enumerable()(target, propertyKey, descriptor);
    propertyDecorator({ type: Type.Native })(target, propertyKey);
  };
}
var property = {};
for (const name in Property) {
  property[name] = (...args) => {
    const functor = Property[name];
    return propertyDecorator(functor(...args));
  };
}

// node_modules/@wonderlandengine/api/dist/utils/object.js
function isString(value) {
  if (value === "")
    return true;
  return value && (typeof value === "string" || value.constructor === String);
}
function isNumber(value) {
  if (value === null || value === void 0)
    return false;
  return typeof value === "number" || value.constructor === Number;
}

// node_modules/@wonderlandengine/api/dist/utils/event.js
var Emitter = class {
  /**
   * List of listeners to trigger when `notify` is called.
   *
   * @hidden
   */
  _listeners = [];
  /**
   * Register a new listener to be triggered on {@link Emitter.notify}.
   *
   * Basic usage:
   *
   * ```js
   * emitter.add((data) => {
   *     console.log('event received!');
   *     console.log(data);
   * });
   * ```
   *
   * Automatically remove the listener when an event is received:
   *
   * ```js
   * emitter.add((data) => {
   *     console.log('event received!');
   *     console.log(data);
   * }, {once: true});
   * ```
   *
   * @param listener The callback to register.
   * @param opts The listener options. For more information, please have a look
   *     at the {@link ListenerOptions} interface.
   *
   * @returns Reference to self (for method chaining)
   */
  add(listener, opts = {}) {
    const { once = false, id = void 0 } = opts;
    this._listeners.push({ id, once, callback: listener });
    return this;
  }
  /**
   * Equivalent to {@link Emitter.add}.
   *
   * @param listeners The callback(s) to register.
   * @returns Reference to self (for method chaining).
   *
   * @deprecated Please use {@link Emitter.add} instead.
   */
  push(...listeners) {
    for (const cb of listeners)
      this.add(cb);
    return this;
  }
  /**
   * Register a new listener to be triggered on {@link Emitter.notify}.
   *
   * Once notified, the listener will be automatically removed.
   *
   * The method is equivalent to calling {@link Emitter.add} with:
   *
   * ```js
   * emitter.add(listener, {once: true});
   * ```
   *
   * @param listener The callback to register.
   *
   * @returns Reference to self (for method chaining).
   */
  once(listener) {
    return this.add(listener, { once: true });
  }
  /**
   * Remove a registered listener.
   *
   * Usage with a callback:
   *
   * ```js
   * const listener = (data) => console.log(data);
   * emitter.add(listener);
   *
   * // Remove using the callback reference:
   * emitter.remove(listener);
   * ```
   *
   * Usage with an id:
   *
   * ```js
   * emitter.add((data) => console.log(data), {id: 'my-callback'});
   *
   * // Remove using the id:
   * emitter.remove('my-callback');
   * ```
   *
   * Using identifiers, you will need to ensure your value is unique to avoid
   * removing listeners from other libraries, e.g.,:
   *
   * ```js
   * emitter.add((data) => console.log(data), {id: 'non-unique'});
   * // This second listener could be added by a third-party library.
   * emitter.add((data) => console.log('Hello From Library!'), {id: 'non-unique'});
   *
   * // Ho Snap! This also removed the library listener!
   * emitter.remove('non-unique');
   * ```
   *
   * The identifier can be any type. However, remember that the comparison will be
   * by-value for primitive types (string, number), but by reference for objects.
   *
   * Example:
   *
   * ```js
   * emitter.add(() => console.log('Hello'), {id: {value: 42}});
   * emitter.add(() => console.log('World!'), {id: {value: 42}});
   * emitter.remove({value: 42}); // None of the above listeners match!
   * emitter.notify(); // Prints 'Hello' and 'World!'.
   * ```
   *
   * Here, both emitters have id `{value: 42}`, but the comparison is made by reference. Thus,
   * the `remove()` call has no effect. We can make it work by doing:
   *
   * ```js
   * const id = {value: 42};
   * emitter.add(() => console.log('Hello'), {id});
   * emitter.add(() => console.log('World!'), {id});
   * emitter.remove(id); // Same reference, it works!
   * emitter.notify(); // Doesn't print.
   * ```
   *
   * @param listener The registered callback or a value representing the `id`.
   *
   * @returns Reference to self (for method chaining)
   */
  remove(listener) {
    const listeners = this._listeners;
    for (let i = 0; i < listeners.length; ++i) {
      const target = listeners[i];
      if (target.callback === listener || target.id === listener) {
        listeners.splice(i--, 1);
      }
    }
    return this;
  }
  /**
   * Check whether the listener is registered.
   *
   * @note This method performs a linear search.
   *
   * @param listener The registered callback or a value representing the `id`.
   * @returns `true` if the handle is found, `false` otherwise.
   */
  has(listener) {
    const listeners = this._listeners;
    for (let i = 0; i < listeners.length; ++i) {
      const target = listeners[i];
      if (target.callback === listener || target.id === listener)
        return true;
    }
    return false;
  }
  /**
   * Notify listeners with the given data object.
   *
   * @note This method ensures all listeners are called even if
   * an exception is thrown. For (possibly) faster notification,
   * please use {@link Emitter.notifyUnsafe}.
   *
   * @param data The data to pass to listener when invoked.
   */
  notify(...data) {
    const listeners = this._listeners;
    for (let i = 0; i < listeners.length; ++i) {
      const listener = listeners[i];
      if (listener.once)
        listeners.splice(i--, 1);
      try {
        listener.callback(...data);
      } catch (e) {
        console.error(e);
      }
    }
  }
  /**
   * Notify listeners with the given data object.
   *
   * @note Because this method doesn't catch exceptions, some listeners
   * will be skipped on a throw. Please use {@link Emitter.notify} for safe
   * notification.
   *
   * @param data The data to pass to listener when invoked.
   */
  notifyUnsafe(...data) {
    const listeners = this._listeners;
    for (let i = 0; i < listeners.length; ++i) {
      const listener = listeners[i];
      if (listener.once)
        listeners.splice(i--, 1);
      listener.callback(...data);
    }
  }
  /**
   * Return a promise that will resolve on the next event.
   *
   * @note The promise might never resolve if no event is sent.
   *
   * @returns A promise that resolves with the data passed to
   *     {@link Emitter.notify}.
   */
  promise() {
    return new Promise((res, _) => {
      this.once((...args) => {
        if (args.length > 1) {
          res(args);
        } else {
          res(args[0]);
        }
      });
    });
  }
  /** Number of listeners. */
  get listenerCount() {
    return this._listeners.length;
  }
  /** `true` if it has no listeners, `false` otherwise. */
  get isEmpty() {
    return this.listenerCount === 0;
  }
};
var RetainEmitterUndefined = {};
var RetainEmitter = class extends Emitter {
  /** Pre-resolved data. @hidden */
  _event = RetainEmitterUndefined;
  /**
   * Emitter target used to reset the state of this emitter.
   *
   * @hidden
   */
  _reset;
  /** @override */
  add(listener, opts) {
    const immediate = opts?.immediate ?? true;
    if (this._event !== RetainEmitterUndefined && immediate) {
      listener(...this._event);
    }
    super.add(listener, opts);
    return this;
  }
  /**
   * @override
   *
   * @param listener The callback to register.
   * @param immediate If `true`, directly resolves if the emitter retains a value.
   *
   * @returns Reference to self (for method chaining).
   */
  once(listener, immediate) {
    return this.add(listener, { once: true, immediate });
  }
  /** @override */
  notify(...data) {
    this._event = data;
    super.notify(...data);
  }
  /** @override */
  notifyUnsafe(...data) {
    this._event = data;
    super.notifyUnsafe(...data);
  }
  /**
   * Reset the state of the emitter.
   *
   * Further call to {@link Emitter.add} will not automatically resolve,
   * until a new call to {@link Emitter.notify} is performed.
   *
   * @returns Reference to self (for method chaining)
   */
  reset() {
    this._event = RetainEmitterUndefined;
    return this;
  }
  /** Returns the retained data, or `undefined` if no data was retained. */
  get data() {
    return this.isDataRetained ? this._event : void 0;
  }
  /** `true` if data is retained from the last event, `false` otherwise. */
  get isDataRetained() {
    return this._event !== RetainEmitterUndefined;
  }
};

// node_modules/@wonderlandengine/api/dist/wonderland.js
var __decorate = function(decorators, target, key, desc) {
  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
  if (typeof Reflect === "object" && typeof Reflect.decorate === "function")
    r = Reflect.decorate(decorators, target, key, desc);
  else
    for (var i = decorators.length - 1; i >= 0; i--)
      if (d = decorators[i])
        r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
  return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var Collider;
(function(Collider2) {
  Collider2[Collider2["Sphere"] = 0] = "Sphere";
  Collider2[Collider2["AxisAlignedBox"] = 1] = "AxisAlignedBox";
  Collider2[Collider2["Box"] = 2] = "Box";
})(Collider || (Collider = {}));
var Alignment;
(function(Alignment2) {
  Alignment2[Alignment2["Left"] = 0] = "Left";
  Alignment2[Alignment2["Center"] = 1] = "Center";
  Alignment2[Alignment2["Right"] = 2] = "Right";
})(Alignment || (Alignment = {}));
var Justification;
(function(Justification2) {
  Justification2[Justification2["Line"] = 0] = "Line";
  Justification2[Justification2["Middle"] = 1] = "Middle";
  Justification2[Justification2["Top"] = 2] = "Top";
  Justification2[Justification2["Bottom"] = 3] = "Bottom";
})(Justification || (Justification = {}));
var TextEffect;
(function(TextEffect2) {
  TextEffect2[TextEffect2["None"] = 0] = "None";
  TextEffect2[TextEffect2["Outline"] = 1] = "Outline";
})(TextEffect || (TextEffect = {}));
var InputType;
(function(InputType2) {
  InputType2[InputType2["Head"] = 0] = "Head";
  InputType2[InputType2["EyeLeft"] = 1] = "EyeLeft";
  InputType2[InputType2["EyeRight"] = 2] = "EyeRight";
  InputType2[InputType2["ControllerLeft"] = 3] = "ControllerLeft";
  InputType2[InputType2["ControllerRight"] = 4] = "ControllerRight";
  InputType2[InputType2["RayLeft"] = 5] = "RayLeft";
  InputType2[InputType2["RayRight"] = 6] = "RayRight";
})(InputType || (InputType = {}));
var LightType;
(function(LightType2) {
  LightType2[LightType2["Point"] = 0] = "Point";
  LightType2[LightType2["Spot"] = 1] = "Spot";
  LightType2[LightType2["Sun"] = 2] = "Sun";
})(LightType || (LightType = {}));
var AnimationState;
(function(AnimationState2) {
  AnimationState2[AnimationState2["Playing"] = 0] = "Playing";
  AnimationState2[AnimationState2["Paused"] = 1] = "Paused";
  AnimationState2[AnimationState2["Stopped"] = 2] = "Stopped";
})(AnimationState || (AnimationState = {}));
var ForceMode;
(function(ForceMode2) {
  ForceMode2[ForceMode2["Force"] = 0] = "Force";
  ForceMode2[ForceMode2["Impulse"] = 1] = "Impulse";
  ForceMode2[ForceMode2["VelocityChange"] = 2] = "VelocityChange";
  ForceMode2[ForceMode2["Acceleration"] = 3] = "Acceleration";
})(ForceMode || (ForceMode = {}));
var CollisionEventType;
(function(CollisionEventType2) {
  CollisionEventType2[CollisionEventType2["Touch"] = 0] = "Touch";
  CollisionEventType2[CollisionEventType2["TouchLost"] = 1] = "TouchLost";
  CollisionEventType2[CollisionEventType2["TriggerTouch"] = 2] = "TriggerTouch";
  CollisionEventType2[CollisionEventType2["TriggerTouchLost"] = 3] = "TriggerTouchLost";
})(CollisionEventType || (CollisionEventType = {}));
var Shape;
(function(Shape2) {
  Shape2[Shape2["None"] = 0] = "None";
  Shape2[Shape2["Sphere"] = 1] = "Sphere";
  Shape2[Shape2["Capsule"] = 2] = "Capsule";
  Shape2[Shape2["Box"] = 3] = "Box";
  Shape2[Shape2["Plane"] = 4] = "Plane";
  Shape2[Shape2["ConvexMesh"] = 5] = "ConvexMesh";
  Shape2[Shape2["TriangleMesh"] = 6] = "TriangleMesh";
})(Shape || (Shape = {}));
var MeshAttribute;
(function(MeshAttribute2) {
  MeshAttribute2[MeshAttribute2["Position"] = 0] = "Position";
  MeshAttribute2[MeshAttribute2["Tangent"] = 1] = "Tangent";
  MeshAttribute2[MeshAttribute2["Normal"] = 2] = "Normal";
  MeshAttribute2[MeshAttribute2["TextureCoordinate"] = 3] = "TextureCoordinate";
  MeshAttribute2[MeshAttribute2["Color"] = 4] = "Color";
  MeshAttribute2[MeshAttribute2["JointId"] = 5] = "JointId";
  MeshAttribute2[MeshAttribute2["JointWeight"] = 6] = "JointWeight";
})(MeshAttribute || (MeshAttribute = {}));
var MaterialParamType;
(function(MaterialParamType2) {
  MaterialParamType2[MaterialParamType2["UnsignedInt"] = 0] = "UnsignedInt";
  MaterialParamType2[MaterialParamType2["Int"] = 1] = "Int";
  MaterialParamType2[MaterialParamType2["Float"] = 2] = "Float";
  MaterialParamType2[MaterialParamType2["Sampler"] = 3] = "Sampler";
  MaterialParamType2[MaterialParamType2["Font"] = 4] = "Font";
})(MaterialParamType || (MaterialParamType = {}));
function createDestroyedProxy(type) {
  return new Proxy({}, {
    get(_, param) {
      if (param === "isDestroyed")
        return true;
      throw new Error(`Canno't read '${param}' of destroyed ${type}`);
    },
    set(_, param) {
      throw new Error(`Canno't write '${param}' of destroyed ${type}`);
    }
  });
}
var DestroyedObjectInstance = createDestroyedProxy("object");
var DestroyedComponentInstance = createDestroyedProxy("component");
var DestroyedTextureInstance = createDestroyedProxy("texture");
function isMeshShape(shape) {
  return shape === Shape.ConvexMesh || shape === Shape.TriangleMesh;
}
function isBaseComponentClass(value) {
  return !!value && value.hasOwnProperty("_isBaseComponent") && value._isBaseComponent;
}
var UP_VECTOR = [0, 1, 0];
var SQRT_3 = Math.sqrt(3);
var Component = class {
  /**
   * Allows to inherit properties directly inside the editor.
   *
   * @note Do not use directly, prefer using {@link inheritProperties}.
   *
   * @hidden
   */
  static _inheritProperties() {
    inheritProperties(this);
  }
  /** Manager index. @hidden */
  _manager;
  /** Instance index. @hidden */
  _id;
  /**
   * Object containing this object.
   *
   * **Note**: This is cached for faster retrieval.
   *
   * @hidden
   */
  _object;
  /** Wonderland Engine instance. @hidden */
  _engine;
  /**
   * Create a new instance
   *
   * @param engine The engine instance.
   * @param manager Index of the manager.
   * @param id WASM component instance index.
   *
   * @hidden
   */
  constructor(engine3, manager = -1, id = -1) {
    this._engine = engine3;
    this._manager = manager;
    this._id = id;
    this._object = null;
  }
  /** Hosting engine instance. */
  get engine() {
    return this._engine;
  }
  /** The name of this component's type */
  get type() {
    const ctor = this.constructor;
    return ctor.TypeName ?? this._engine.wasm._typeNameFor(this._manager);
  }
  /** The object this component is attached to. */
  get object() {
    if (!this._object) {
      const objectId = this._engine.wasm._wl_component_get_object(this._manager, this._id);
      this._object = this._engine.wrapObject(objectId);
    }
    return this._object;
  }
  /**
   * Set whether this component is active.
   *
   * Activating/deactivating a component comes at a small cost of reordering
   * components in the respective component manager. This function therefore
   * is not a trivial assignment.
   *
   * Does nothing if the component is already activated/deactivated.
   *
   * @param active New active state.
   */
  set active(active) {
    this._engine.wasm._wl_component_setActive(this._manager, this._id, active);
  }
  /**
   * Whether this component is active
   */
  get active() {
    return this._engine.wasm._wl_component_isActive(this._manager, this._id) != 0;
  }
  /**
   * Copy all the properties from `src` into this instance.
   *
   * @note Only properties are copied. If a component needs to
   * copy extra data, it needs to override this method.
   *
   * #### Example
   *
   * ```js
   * class MyComponent extends Component {
   *     nonPropertyData = 'Hello World';
   *
   *     copy(src) {
   *         super.copy(src);
   *         this.nonPropertyData = src.nonPropertyData;
   *         return this;
   *     }
   * }
   * ```
   *
   * @note This method is called by {@link Object3D.clone}. Do not attempt to:
   *     - Create new component
   *     - Read references to other objects
   *
   * When cloning via {@link Object3D.clone}, this method will be called before
   * {@link Component.start}.
   *
   * @note JavaScript component properties aren't retargeted. Thus, references
   * inside the source object will not be retargeted to the destination object,
   * at the exception of the skin data on {@link MeshComponent} and {@link AnimationComponent}.
   *
   * @param src The source component to copy from.
   *
   * @returns Reference to self (for method chaining).
   */
  copy(src) {
    const ctor = this.constructor;
    for (const name in ctor.Properties) {
      const value = src[name];
      if (value !== void 0) {
        this[name] = value;
      }
    }
    return this;
  }
  /**
   * Remove this component from its objects and destroy it.
   *
   * It is best practice to set the component to `null` after,
   * to ensure it does not get used later.
   *
   * ```js
   *    c.destroy();
   *    c = null;
   * ```
   * @since 0.9.0
   */
  destroy() {
    const manager = this._manager;
    if (manager < 0 || this._id < 0)
      return;
    const jsManager = this.engine.wasm._jsManagerIndex;
    this._engine.wasm._wl_component_remove(manager, this._id);
    if (manager !== jsManager)
      this._triggerOnDestroy();
  }
  /**
   * Checks equality by comparing whether the wrapped native component ids
   * and component manager types are equal.
   *
   * @param otherComponent Component to check equality with.
   * @returns Whether this component equals the given component.
   */
  equals(otherComponent) {
    if (!otherComponent)
      return false;
    return this._manager == otherComponent._manager && this._id == otherComponent._id;
  }
  /**
   * Reset the component properties to default.
   *
   * @note This is automatically called during the component instantiation.
   *
   * @returns Reference to self (for method chaining).
   */
  resetProperties() {
    const ctor = this.constructor;
    const properties = ctor.Properties;
    if (!properties)
      return this;
    for (const name in properties) {
      this[name] = properties[name].default;
    }
    return this;
  }
  /** @deprecated Use {@link Component.resetProperties} instead. */
  reset() {
    return this.resetProperties();
  }
  /**
   * Validate the properties on this instance.
   *
   * @throws If any of the required properties isn't initialized
   * on this instance.
   */
  validateProperties() {
    const ctor = this.constructor;
    if (!ctor.Properties)
      return;
    for (const name in ctor.Properties) {
      if (!ctor.Properties[name].required)
        continue;
      if (!this[name]) {
        throw new Error(`Property '${name}' is required but was not initialized`);
      }
    }
  }
  /**
   * `true` if the component is destroyed, `false` otherwise.
   *
   * If {@link WonderlandEngine.erasePrototypeOnDestroy} is `true`,
   * reading a custom property will not work:
   *
   * ```js
   * engine.erasePrototypeOnDestroy = true;
   *
   * const comp = obj.addComponent('mesh');
   * comp.customParam = 'Hello World!';
   *
   * console.log(comp.isDestroyed); // Prints `false`
   * comp.destroy();
   * console.log(comp.isDestroyed); // Prints `true`
   * console.log(comp.customParam); // Throws an error
   * ```
   *
   * @since 1.1.1
   */
  get isDestroyed() {
    return this._id < 0;
  }
  /**
   * Trigger the component {@link Component.init} method.
   *
   * @note Use this method instead of directly calling {@link Component.init},
   * because this method creates an handler for the {@link Component.start}.
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _triggerInit() {
    if (this.init) {
      try {
        this.init();
      } catch (e) {
        console.error(`Exception during ${this.type} init() on object ${this.object.name}`);
        console.error(e);
      }
    }
    const oldActivate = this.onActivate;
    this.onActivate = function() {
      this.onActivate = oldActivate;
      let failed = false;
      try {
        this.validateProperties();
      } catch (e) {
        console.error(`Exception during ${this.type} validateProperties() on object ${this.object.name}`);
        console.error(e);
        failed = true;
      }
      try {
        this.start?.();
      } catch (e) {
        console.error(`Exception during ${this.type} start() on object ${this.object.name}`);
        console.error(e);
        failed = true;
      }
      if (failed) {
        this.active = false;
        return;
      }
      if (!this.onActivate)
        return;
      try {
        this.onActivate();
      } catch (e) {
        console.error(`Exception during ${this.type} onActivate() on object ${this.object.name}`);
        console.error(e);
      }
    };
  }
  /**
   * Trigger the component {@link Component.update} method.
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _triggerUpdate(dt) {
    if (!this.update)
      return;
    try {
      this.update(dt);
    } catch (e) {
      console.error(`Exception during ${this.type} update() on object ${this.object.name}`);
      console.error(e);
      if (this._engine.wasm._deactivate_component_on_error) {
        this.active = false;
      }
    }
  }
  /**
   * Trigger the component {@link Component.onActivate} method.
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _triggerOnActivate() {
    if (!this.onActivate)
      return;
    try {
      this.onActivate();
    } catch (e) {
      console.error(`Exception during ${this.type} onActivate() on object ${this.object.name}`);
      console.error(e);
    }
  }
  /**
   * Trigger the component {@link Component.onDeactivate} method.
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _triggerOnDeactivate() {
    if (!this.onDeactivate)
      return;
    try {
      this.onDeactivate();
    } catch (e) {
      console.error(`Exception during ${this.type} onDeactivate() on object ${this.object.name}`);
      console.error(e);
    }
  }
  /**
   * Trigger the component {@link Component.onDestroy} method.
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _triggerOnDestroy() {
    try {
      if (this.onDestroy)
        this.onDestroy();
    } catch (e) {
      console.error(`Exception during ${this.type} onDestroy() on object ${this.object.name}`);
      console.error(e);
    }
    this._engine._destroyComponent(this);
  }
};
/**
 * `true` for every class inheriting from this class.
 *
 * @note This is a workaround for `instanceof` to prevent issues
 * that could arise when an application ends up using multiple API versions.
 *
 * @hidden
 */
__publicField(Component, "_isBaseComponent", true);
/**
 * Unique identifier for this component class.
 *
 * This is used to register, add, and retrieve components of a given type.
 */
__publicField(Component, "TypeName");
/**
 * Properties of this component class.
 *
 * Properties are public attributes that can be configured via the
 * Wonderland Editor.
 *
 * Example:
 *
 * ```js
 * import { Component, Type } from '@wonderlandengine/api';
 * class MyComponent extends Component {
 *     static TypeName = 'my-component';
 *     static Properties = {
 *         myBoolean: { type: Type.Boolean, default: false },
 *         myFloat: { type: Type.Float, default: false },
 *         myTexture: { type: Type.Texture, default: null },
 *     };
 * }
 * ```
 *
 * Properties are automatically added to each component instance, and are
 * accessible like any JS attribute:
 *
 * ```js
 * // Creates a new component and set each properties value:
 * const myComponent = object.addComponent(MyComponent, {
 *     myBoolean: true,
 *     myFloat: 42.0,
 *     myTexture: null
 * });
 *
 * // You can also override the properties on the instance:
 * myComponent.myBoolean = false;
 * myComponent.myFloat = -42.0;
 * ```
 *
 * #### References
 *
 * Reference types (i.e., mesh, object, etc...) can also be listed as **required**:
 *
 * ```js
 * import {Component, Property} from '@wonderlandengine/api';
 *
 * class MyComponent extends Component {
 *     static Properties = {
 *         myObject: Property.object({required: true}),
 *         myAnimation: Property.animation({required: true}),
 *         myTexture: Property.texture({required: true}),
 *         myMesh: Property.mesh({required: true}),
 *     }
 * }
 * ```
 *
 * Please note that references are validated **once** before the call to {@link Component.start} only,
 * via the {@link Component.validateProperties} method.
 */
__publicField(Component, "Properties");
/**
 * When set to `true`, the child class inherits from the parent
 * properties, as shown in the following example:
 *
 * ```js
 * import {Component, Property} from '@wonderlandengine/api';
 *
 * class Parent extends Component {
 *     static TypeName = 'parent';
 *     static Properties = {parentName: Property.string('parent')}
 * }
 *
 * class Child extends Parent {
 *     static TypeName = 'child';
 *     static Properties = {name: Property.string('child')}
 *     static InheritProperties = true;
 *
 *     start() {
 *         // Works because `InheritProperties` is `true`.
 *         console.log(`${this.name} inherits from ${this.parentName}`);
 *     }
 * }
 * ```
 *
 * @note Properties defined in descendant classes will override properties
 * with the same name defined in ancestor classes.
 *
 * Defaults to `true`.
 */
__publicField(Component, "InheritProperties");
/**
 * Called when this component class is registered.
 *
 * @example
 *
 * This callback can be used to register dependencies of a component,
 * e.g., component classes that need to be registered in order to add
 * them at runtime with {@link Object3D.addComponent}, independent of whether
 * they are used in the editor.
 *
 * ```js
 * class Spawner extends Component {
 *     static TypeName = 'spawner';
 *
 *     static onRegister(engine) {
 *         engine.registerComponent(SpawnedComponent);
 *     }
 *
 *     // You can now use addComponent with SpawnedComponent
 * }
 * ```
 *
 * @example
 *
 * This callback can be used to register different implementations of a
 * component depending on client features or API versions.
 *
 * ```js
 * // Properties need to be the same for all implementations!
 * const SharedProperties = {};
 *
 * class Anchor extends Component {
 *     static TypeName = 'spawner';
 *     static Properties = SharedProperties;
 *
 *     static onRegister(engine) {
 *         if(navigator.xr === undefined) {
 *             /* WebXR unsupported, keep this dummy component *\/
 *             return;
 *         }
 *         /* WebXR supported! Override already registered dummy implementation
 *          * with one depending on hit-test API support *\/
 *         engine.registerComponent(window.HitTestSource === undefined ?
 *             AnchorWithoutHitTest : AnchorWithHitTest);
 *     }
 *
 *     // This one implements no functions
 * }
 * ```
 */
__publicField(Component, "onRegister");
var BrokenComponent = class extends Component {
};
__publicField(BrokenComponent, "TypeName", "__broken-component__");
function inheritProperties(target) {
  if (!target.TypeName)
    return;
  const chain = [];
  let curr = target;
  while (curr && !isBaseComponentClass(curr)) {
    const comp = curr;
    const needsMerge = comp.hasOwnProperty("InheritProperties") ? comp.InheritProperties : true;
    if (!needsMerge)
      break;
    if (comp.TypeName && comp.hasOwnProperty("Properties")) {
      chain.push(comp.Properties);
    }
    curr = Object.getPrototypeOf(curr);
  }
  if (chain.length <= 1)
    return;
  const merged = {};
  for (let i = chain.length - 1; i >= 0; --i) {
    Object.assign(merged, chain[i]);
  }
  target.Properties = merged;
}
var _CollisionComponent = class extends Component {
  /** Collision component collider */
  get collider() {
    return this._engine.wasm._wl_collision_component_get_collider(this._id);
  }
  /**
   * Set collision component collider.
   *
   * @param collider Collider of the collision component.
   */
  set collider(collider) {
    this._engine.wasm._wl_collision_component_set_collider(this._id, collider);
  }
  /**
   * Collision component extents.
   *
   * If {@link collider} returns {@link Collider.Sphere}, only the first
   * component of the returned vector is used.
   */
  get extents() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_collision_component_get_extents(this._id), 3);
  }
  /**
   * Set collision component extents.
   *
   * If {@link collider} returns {@link Collider.Sphere}, only the first
   * component of the passed vector is used.
   *
   * Example:
   *
   * ```js
   * // Spans 1 unit on the x-axis, 2 on the y-axis, 3 on the z-axis.
   * collision.extent = [1, 2, 3];
   * ```
   *
   * @param extents Extents of the collision component, expects a
   *      3 component array.
   */
  set extents(extents) {
    this.extents.set(extents);
  }
  /**
   * Get collision component radius.
   *
   * @note If {@link collider} is not {@link Collider.Sphere}, the returned value
   * corresponds to the radius of a sphere enclosing the shape.
   *
   * Example:
   * ```js
   * sphere.radius = 3.0;
   * console.log(sphere.radius); // 3.0
   *
   * box.extents = [2.0, 2.0, 2.0];
   * console.log(box.radius); // 1.732...
   * ```
   *
   */
  get radius() {
    const wasm = this._engine.wasm;
    if (this.collider === Collider.Sphere)
      return wasm.HEAPF32[wasm._wl_collision_component_get_extents(this._id) >> 2];
    const extents = new Float32Array(wasm.HEAPF32.buffer, wasm._wl_collision_component_get_extents(this._id), 3);
    const x2 = extents[0] * extents[0];
    const y2 = extents[1] * extents[1];
    const z2 = extents[2] * extents[2];
    return Math.sqrt(x2 + y2 + z2) / 2;
  }
  /**
   * Set collision component radius.
   *
   * @param radius Radius of the collision component
   *
   * @note If {@link collider} is not {@link Collider.Sphere},
   * the extents are set to form a square that fits a sphere with the provided radius.
   *
   * Example:
   * ```js
   * aabbCollision.radius = 2.0; // AABB fits a sphere of radius 2.0
   * boxCollision.radius = 3.0; // Box now fits a sphere of radius 3.0, keeping orientation
   * ```
   *
   */
  set radius(radius) {
    const length5 = this.collider === Collider.Sphere ? radius : 2 * radius / SQRT_3;
    this.extents.set([length5, length5, length5]);
  }
  /**
   * Collision component group.
   *
   * The groups is a bitmask that is compared to other components in {@link CollisionComponent#queryOverlaps}
   * or the group in {@link Scene#rayCast}.
   *
   * Colliders that have no common groups will not overlap with each other. If a collider
   * has none of the groups set for {@link Scene#rayCast}, the ray will not hit it.
   *
   * Each bit represents belonging to a group, see example.
   *
   * ```js
   *    // c belongs to group 2
   *    c.group = (1 << 2);
   *
   *    // c belongs to group 0
   *    c.group = (1 << 0);
   *
   *    // c belongs to group 0 *and* 2
   *    c.group = (1 << 0) | (1 << 2);
   *
   *    (c.group & (1 << 2)) != 0; // true
   *    (c.group & (1 << 7)) != 0; // false
   * ```
   */
  get group() {
    return this._engine.wasm._wl_collision_component_get_group(this._id);
  }
  /**
   * Set collision component group.
   *
   * @param group Group mask of the collision component.
   */
  set group(group) {
    this._engine.wasm._wl_collision_component_set_group(this._id, group);
  }
  /**
   * Query overlapping objects.
   *
   * Usage:
   *
   * ```js
   * const collision = object.getComponent('collision');
   * const overlaps = collision.queryOverlaps();
   * for(const otherCollision of overlaps) {
   *     const otherObject = otherCollision.object;
   *     console.log(`Collision with object ${otherObject.objectId}`);
   * }
   * ```
   *
   * @returns Collision components overlapping this collider.
   */
  queryOverlaps() {
    const count2 = this._engine.wasm._wl_collision_component_query_overlaps(this._id, this._engine.wasm._tempMem, this._engine.wasm._tempMemSize >> 1);
    const overlaps = new Array(count2);
    for (let i = 0; i < count2; ++i) {
      overlaps[i] = new _CollisionComponent(this._engine, this._manager, this._engine.wasm._tempMemUint16[i]);
    }
    return overlaps;
  }
};
var CollisionComponent = _CollisionComponent;
/** @override */
__publicField(CollisionComponent, "TypeName", "collision");
__decorate([
  nativeProperty()
], CollisionComponent.prototype, "collider", null);
__decorate([
  nativeProperty()
], CollisionComponent.prototype, "extents", null);
__decorate([
  nativeProperty()
], CollisionComponent.prototype, "group", null);
var TextComponent = class extends Component {
  /** Text component alignment. */
  get alignment() {
    return this._engine.wasm._wl_text_component_get_horizontal_alignment(this._id);
  }
  /**
   * Set text component alignment.
   *
   * @param alignment Alignment for the text component.
   */
  set alignment(alignment) {
    this._engine.wasm._wl_text_component_set_horizontal_alignment(this._id, alignment);
  }
  /** Text component justification. */
  get justification() {
    return this._engine.wasm._wl_text_component_get_vertical_alignment(this._id);
  }
  /**
   * Set text component justification.
   *
   * @param justification Justification for the text component.
   */
  set justification(justification) {
    this._engine.wasm._wl_text_component_set_vertical_alignment(this._id, justification);
  }
  /** Text component character spacing. */
  get characterSpacing() {
    return this._engine.wasm._wl_text_component_get_character_spacing(this._id);
  }
  /**
   * Set text component character spacing.
   *
   * @param spacing Character spacing for the text component.
   */
  set characterSpacing(spacing) {
    this._engine.wasm._wl_text_component_set_character_spacing(this._id, spacing);
  }
  /** Text component line spacing. */
  get lineSpacing() {
    return this._engine.wasm._wl_text_component_get_line_spacing(this._id);
  }
  /**
   * Set text component line spacing
   *
   * @param spacing Line spacing for the text component
   */
  set lineSpacing(spacing) {
    this._engine.wasm._wl_text_component_set_line_spacing(this._id, spacing);
  }
  /** Text component effect. */
  get effect() {
    return this._engine.wasm._wl_text_component_get_effect(this._id);
  }
  /**
   * Set text component effect
   *
   * @param effect Effect for the text component
   */
  set effect(effect) {
    this._engine.wasm._wl_text_component_set_effect(this._id, effect);
  }
  /** Text component text. */
  get text() {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_text_component_get_text(this._id);
    return wasm.UTF8ToString(ptr);
  }
  /**
   * Set text component text.
   *
   * @param text Text of the text component.
   */
  set text(text) {
    const wasm = this._engine.wasm;
    wasm._wl_text_component_set_text(this._id, wasm.tempUTF8(text.toString()));
  }
  /**
   * Set material to render the text with.
   *
   * @param material New material.
   */
  set material(material) {
    const matIndex = material ? material._index : 0;
    this._engine.wasm._wl_text_component_set_material(this._id, matIndex);
  }
  /** Material used to render the text. */
  get material() {
    const id = this._engine.wasm._wl_text_component_get_material(this._id);
    return id > 0 ? new Material(this._engine, id) : null;
  }
};
/** @override */
__publicField(TextComponent, "TypeName", "text");
__decorate([
  nativeProperty()
], TextComponent.prototype, "alignment", null);
__decorate([
  nativeProperty()
], TextComponent.prototype, "justification", null);
__decorate([
  nativeProperty()
], TextComponent.prototype, "characterSpacing", null);
__decorate([
  nativeProperty()
], TextComponent.prototype, "lineSpacing", null);
__decorate([
  nativeProperty()
], TextComponent.prototype, "effect", null);
__decorate([
  nativeProperty()
], TextComponent.prototype, "text", null);
__decorate([
  nativeProperty()
], TextComponent.prototype, "material", null);
var ViewComponent = class extends Component {
  /** Projection matrix. */
  get projectionMatrix() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_view_component_get_projection_matrix(this._id), 16);
  }
  /** ViewComponent near clipping plane value. */
  get near() {
    return this._engine.wasm._wl_view_component_get_near(this._id);
  }
  /**
   * Set near clipping plane distance for the view.
   *
   * If an XR session is active, the change will apply in the
   * following frame, otherwise the change is immediate.
   *
   * @param near Near depth value.
   */
  set near(near) {
    this._engine.wasm._wl_view_component_set_near(this._id, near);
  }
  /** Far clipping plane value. */
  get far() {
    return this._engine.wasm._wl_view_component_get_far(this._id);
  }
  /**
   * Set far clipping plane distance for the view.
   *
   * If an XR session is active, the change will apply in the
   * following frame, otherwise the change is immediate.
   *
   * @param far Near depth value.
   */
  set far(far) {
    this._engine.wasm._wl_view_component_set_far(this._id, far);
  }
  /**
   * Get the horizontal field of view for the view, **in degrees**.
   *
   * If an XR session is active, this returns the field of view reported by
   * the device, regardless of the fov that was set.
   */
  get fov() {
    return this._engine.wasm._wl_view_component_get_fov(this._id);
  }
  /**
   * Set the horizontal field of view for the view, **in degrees**.
   *
   * If an XR session is active, the field of view reported by the device is
   * used and this value is ignored. After the XR session ends, the new value
   * is applied.
   *
   * @param fov Horizontal field of view, **in degrees**.
   */
  set fov(fov) {
    this._engine.wasm._wl_view_component_set_fov(this._id, fov);
  }
};
/** @override */
__publicField(ViewComponent, "TypeName", "view");
__decorate([
  enumerable()
], ViewComponent.prototype, "projectionMatrix", null);
__decorate([
  nativeProperty()
], ViewComponent.prototype, "near", null);
__decorate([
  nativeProperty()
], ViewComponent.prototype, "far", null);
__decorate([
  nativeProperty()
], ViewComponent.prototype, "fov", null);
var InputComponent = class extends Component {
  /** Input component type */
  get inputType() {
    return this._engine.wasm._wl_input_component_get_type(this._id);
  }
  /**
   * Set input component type.
   *
   * @params New input component type.
   */
  set inputType(type) {
    this._engine.wasm._wl_input_component_set_type(this._id, type);
  }
  /**
   * WebXR Device API input source associated with this input component,
   * if type {@link InputType.ControllerLeft} or {@link InputType.ControllerRight}.
   */
  get xrInputSource() {
    const xrSession = this._engine.xrSession;
    if (xrSession) {
      for (let inputSource of xrSession.inputSources) {
        if (inputSource.handedness == this.handedness) {
          return inputSource;
        }
      }
    }
    return null;
  }
  /**
   * 'left', 'right' or `null` depending on the {@link InputComponent#inputType}.
   */
  get handedness() {
    const inputType = this.inputType;
    if (inputType == InputType.ControllerRight || inputType == InputType.RayRight || inputType == InputType.EyeRight)
      return "right";
    if (inputType == InputType.ControllerLeft || inputType == InputType.RayLeft || inputType == InputType.EyeLeft)
      return "left";
    return null;
  }
};
/** @override */
__publicField(InputComponent, "TypeName", "input");
__decorate([
  nativeProperty()
], InputComponent.prototype, "inputType", null);
__decorate([
  enumerable()
], InputComponent.prototype, "xrInputSource", null);
__decorate([
  enumerable()
], InputComponent.prototype, "handedness", null);
var LightComponent = class extends Component {
  getColor(out = new Float32Array(3)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_light_component_get_color(this._id) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    return out;
  }
  /**
   * Set light color.
   *
   * @param c New color array/vector, expected to have at least 3 elements.
   * @since 1.0.0
   */
  setColor(c) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_light_component_get_color(this._id) / 4;
    wasm.HEAPF32[ptr] = c[0];
    wasm.HEAPF32[ptr + 1] = c[1];
    wasm.HEAPF32[ptr + 2] = c[2];
  }
  /**
   * View on the light color.
   *
   * @note Prefer to use {@link getColor} in performance-critical code.
   */
  get color() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_light_component_get_color(this._id), 3);
  }
  /**
   * Set light color.
   *
   * @param c Color of the light component.
   *
   * @note Prefer to use {@link setColor} in performance-critical code.
   */
  set color(c) {
    this.color.set(c);
  }
  /** Light type. */
  get lightType() {
    return this._engine.wasm._wl_light_component_get_type(this._id);
  }
  /**
   * Set light type.
   *
   * @param lightType Type of the light component.
   */
  set lightType(t) {
    this._engine.wasm._wl_light_component_set_type(this._id, t);
  }
  /**
   * Light intensity.
   * @since 1.0.0
   */
  get intensity() {
    return this._engine.wasm._wl_light_component_get_intensity(this._id);
  }
  /**
   * Set light intensity.
   *
   * @param intensity Intensity of the light component.
   * @since 1.0.0
   */
  set intensity(intensity) {
    this._engine.wasm._wl_light_component_set_intensity(this._id, intensity);
  }
  /**
   * Outer angle for spot lights, in degrees.
   * @since 1.0.0
   */
  get outerAngle() {
    return this._engine.wasm._wl_light_component_get_outerAngle(this._id);
  }
  /**
   * Set outer angle for spot lights.
   *
   * @param angle Outer angle, in degrees.
   * @since 1.0.0
   */
  set outerAngle(angle2) {
    this._engine.wasm._wl_light_component_set_outerAngle(this._id, angle2);
  }
  /**
   * Inner angle for spot lights, in degrees.
   * @since 1.0.0
   */
  get innerAngle() {
    return this._engine.wasm._wl_light_component_get_innerAngle(this._id);
  }
  /**
   * Set inner angle for spot lights.
   *
   * @param angle Inner angle, in degrees.
   * @since 1.0.0
   */
  set innerAngle(angle2) {
    this._engine.wasm._wl_light_component_set_innerAngle(this._id, angle2);
  }
  /**
   * Whether the light casts shadows.
   * @since 1.0.0
   */
  get shadows() {
    return !!this._engine.wasm._wl_light_component_get_shadows(this._id);
  }
  /**
   * Set whether the light casts shadows.
   *
   * @param b Whether the light casts shadows.
   * @since 1.0.0
   */
  set shadows(b) {
    this._engine.wasm._wl_light_component_set_shadows(this._id, b);
  }
  /**
   * Range for shadows.
   * @since 1.0.0
   */
  get shadowRange() {
    return this._engine.wasm._wl_light_component_get_shadowRange(this._id);
  }
  /**
   * Set range for shadows.
   *
   * @param range Range for shadows.
   * @since 1.0.0
   */
  set shadowRange(range5) {
    this._engine.wasm._wl_light_component_set_shadowRange(this._id, range5);
  }
  /**
   * Bias value for shadows.
   * @since 1.0.0
   */
  get shadowBias() {
    return this._engine.wasm._wl_light_component_get_shadowBias(this._id);
  }
  /**
   * Set bias value for shadows.
   *
   * @param bias Bias for shadows.
   * @since 1.0.0
   */
  set shadowBias(bias) {
    this._engine.wasm._wl_light_component_set_shadowBias(this._id, bias);
  }
  /**
   * Normal bias value for shadows.
   * @since 1.0.0
   */
  get shadowNormalBias() {
    return this._engine.wasm._wl_light_component_get_shadowNormalBias(this._id);
  }
  /**
   * Set normal bias value for shadows.
   *
   * @param bias Normal bias for shadows.
   * @since 1.0.0
   */
  set shadowNormalBias(bias) {
    this._engine.wasm._wl_light_component_set_shadowNormalBias(this._id, bias);
  }
  /**
   * Texel size for shadows.
   * @since 1.0.0
   */
  get shadowTexelSize() {
    return this._engine.wasm._wl_light_component_get_shadowTexelSize(this._id);
  }
  /**
   * Set texel size for shadows.
   *
   * @param size Texel size for shadows.
   * @since 1.0.0
   */
  set shadowTexelSize(size) {
    this._engine.wasm._wl_light_component_set_shadowTexelSize(this._id, size);
  }
  /**
   * Cascade count for {@link LightType.Sun} shadows.
   * @since 1.0.0
   */
  get cascadeCount() {
    return this._engine.wasm._wl_light_component_get_cascadeCount(this._id);
  }
  /**
   * Set cascade count for {@link LightType.Sun} shadows.
   *
   * @param count Cascade count.
   * @since 1.0.0
   */
  set cascadeCount(count2) {
    this._engine.wasm._wl_light_component_set_cascadeCount(this._id, count2);
  }
};
/** @override */
__publicField(LightComponent, "TypeName", "light");
__decorate([
  nativeProperty()
], LightComponent.prototype, "color", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "lightType", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "intensity", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "outerAngle", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "innerAngle", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "shadows", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "shadowRange", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "shadowBias", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "shadowNormalBias", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "shadowTexelSize", null);
__decorate([
  nativeProperty()
], LightComponent.prototype, "cascadeCount", null);
var AnimationComponent = class extends Component {
  /**
   * Set animation to play.
   *
   * Make sure to {@link Animation#retarget} the animation to affect the
   * right objects.
   *
   * @param anim Animation to play.
   */
  set animation(anim) {
    this._engine.wasm._wl_animation_component_set_animation(this._id, anim ? anim._index : 0);
  }
  /** Animation set for this component */
  get animation() {
    const id = this._engine.wasm._wl_animation_component_get_animation(this._id);
    return id > 0 ? new Animation(this._engine, id) : null;
  }
  /**
   * Set play count. Set to `0` to loop indefinitely.
   *
   * @param playCount Number of times to repeat the animation.
   */
  set playCount(playCount) {
    this._engine.wasm._wl_animation_component_set_playCount(this._id, playCount);
  }
  /** Number of times the animation is played. */
  get playCount() {
    return this._engine.wasm._wl_animation_component_get_playCount(this._id);
  }
  /**
   * Set speed. Set to negative values to run the animation backwards.
   *
   * Setting speed has an immediate effect for the current frame's update
   * and will continue with the speed from the current point in the animation.
   *
   * @param speed New speed at which to play the animation.
   * @since 0.8.10
   */
  set speed(speed) {
    this._engine.wasm._wl_animation_component_set_speed(this._id, speed);
  }
  /**
   * Speed factor at which the animation is played.
   *
   * @since 0.8.10
   */
  get speed() {
    return this._engine.wasm._wl_animation_component_get_speed(this._id);
  }
  /** Current playing state of the animation */
  get state() {
    return this._engine.wasm._wl_animation_component_state(this._id);
  }
  /**
   * Play animation.
   *
   * If the animation is currently paused, resumes from that position. If the
   * animation is already playing, does nothing.
   *
   * To restart the animation, {@link AnimationComponent#stop} it first.
   */
  play() {
    this._engine.wasm._wl_animation_component_play(this._id);
  }
  /** Stop animation. */
  stop() {
    this._engine.wasm._wl_animation_component_stop(this._id);
  }
  /** Pause animation. */
  pause() {
    this._engine.wasm._wl_animation_component_pause(this._id);
  }
};
/** @override */
__publicField(AnimationComponent, "TypeName", "animation");
__decorate([
  nativeProperty()
], AnimationComponent.prototype, "animation", null);
__decorate([
  nativeProperty()
], AnimationComponent.prototype, "playCount", null);
__decorate([
  nativeProperty()
], AnimationComponent.prototype, "speed", null);
__decorate([
  enumerable()
], AnimationComponent.prototype, "state", null);
var MeshComponent = class extends Component {
  /**
   * Set material to render the mesh with.
   *
   * @param material Material to render the mesh with.
   */
  set material(material) {
    this._engine.wasm._wl_mesh_component_set_material(this._id, material ? material._index : 0);
  }
  /** Material used to render the mesh. */
  get material() {
    const id = this._engine.wasm._wl_mesh_component_get_material(this._id);
    return id > 0 ? new Material(this._engine, id) : null;
  }
  /** Mesh rendered by this component. */
  get mesh() {
    const id = this._engine.wasm._wl_mesh_component_get_mesh(this._id);
    return id > 0 ? new Mesh(this._engine, id) : null;
  }
  /**
   * Set mesh to rendered with this component.
   *
   * @param mesh Mesh rendered by this component.
   */
  set mesh(mesh) {
    this._engine.wasm._wl_mesh_component_set_mesh(this._id, mesh ? mesh._index : 0);
  }
  /** Skin for this mesh component. */
  get skin() {
    const id = this._engine.wasm._wl_mesh_component_get_skin(this._id);
    return id > 0 ? new Skin(this._engine, id) : null;
  }
  /**
   * Set skin to transform this mesh component.
   *
   * @param skin Skin to use for rendering skinned meshes.
   */
  set skin(skin) {
    this._engine.wasm._wl_mesh_component_set_skin(this._id, skin ? skin._index : 0);
  }
};
/** @override */
__publicField(MeshComponent, "TypeName", "mesh");
__decorate([
  nativeProperty()
], MeshComponent.prototype, "material", null);
__decorate([
  nativeProperty()
], MeshComponent.prototype, "mesh", null);
__decorate([
  nativeProperty()
], MeshComponent.prototype, "skin", null);
var LockAxis;
(function(LockAxis2) {
  LockAxis2[LockAxis2["None"] = 0] = "None";
  LockAxis2[LockAxis2["X"] = 1] = "X";
  LockAxis2[LockAxis2["Y"] = 2] = "Y";
  LockAxis2[LockAxis2["Z"] = 4] = "Z";
})(LockAxis || (LockAxis = {}));
var PhysXComponent = class extends Component {
  getTranslationOffset(out = new Float32Array(3)) {
    const wasm = this._engine.wasm;
    wasm._wl_physx_component_get_offsetTranslation(this._id, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  getRotationOffset(out = new Float32Array(4)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_physx_component_get_offsetTransform(this._id) >> 2;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    out[3] = wasm.HEAPF32[ptr + 3];
    return out;
  }
  /**
   * Set whether this rigid body is static.
   *
   * Setting this property only takes effect once the component
   * switches from inactive to active.
   *
   * @param b Whether the rigid body should be static.
   */
  set static(b) {
    this._engine.wasm._wl_physx_component_set_static(this._id, b);
  }
  /**
   * Whether this rigid body is static.
   *
   * This property returns whether the rigid body is *effectively*
   * static. If static property was set while the rigid body was
   * active, it will not take effect until the rigid body is set
   * inactive and active again. Until the component is set inactive,
   * this getter will return whether the rigid body is actually
   * static.
   */
  get static() {
    return !!this._engine.wasm._wl_physx_component_get_static(this._id);
  }
  /**
   * Equivalent to {@link PhysXComponent.getTranslationOffset}.
   *
   * Gives a quick view of the offset in a debugger.
   *
   * @note Prefer to use {@link PhysXComponent.getTranslationOffset} for performance.
   *
   * @since 1.1.1
   */
  get translationOffset() {
    return this.getTranslationOffset();
  }
  /**
   * Set the offset translation.
   *
   * The array must be a vector of at least **3** elements.
   *
   * @note The component must be re-activated to apply the change.
   *
   * @since 1.1.1
   */
  set translationOffset(offset) {
    const wasm = this._engine.wasm;
    wasm._wl_physx_component_set_offsetTranslation(this._id, offset[0], offset[1], offset[2]);
  }
  /**
   * Equivalent to {@link PhysXComponent.getRotationOffset}.
   *
   * Gives a quick view of the offset in a debugger.
   *
   * @note Prefer to use {@link PhysXComponent.getRotationOffset} for performance.
   *
   * @since 1.1.1
   */
  get rotationOffset() {
    return this.getRotationOffset();
  }
  /**
   * Set the offset rotation.
   *
   * The array must be a quaternion of at least **4** elements.
   *
   * @note The component must be re-activated to apply the change.
   *
   * @since 1.1.1
   */
  set rotationOffset(offset) {
    const wasm = this._engine.wasm;
    wasm._wl_physx_component_set_offsetRotation(this._id, offset[0], offset[1], offset[2], offset[3]);
  }
  /**
   * Set whether this rigid body is kinematic.
   *
   * @param b Whether the rigid body should be kinematic.
   */
  set kinematic(b) {
    this._engine.wasm._wl_physx_component_set_kinematic(this._id, b);
  }
  /**
   * Whether this rigid body is kinematic.
   */
  get kinematic() {
    return !!this._engine.wasm._wl_physx_component_get_kinematic(this._id);
  }
  /**
   * Set whether this rigid body's gravity is enabled.
   *
   * @param b Whether the rigid body's gravity should be enabled.
   */
  set gravity(b) {
    this._engine.wasm._wl_physx_component_set_gravity(this._id, b);
  }
  /**
   * Whether this rigid body's gravity flag is enabled.
   */
  get gravity() {
    return !!this._engine.wasm._wl_physx_component_get_gravity(this._id);
  }
  /**
   * Set whether this rigid body's simulate flag is enabled.
   *
   * @param b Whether the rigid body's simulate flag should be enabled.
   */
  set simulate(b) {
    this._engine.wasm._wl_physx_component_set_simulate(this._id, b);
  }
  /**
   * Whether this rigid body's simulate flag is enabled.
   */
  get simulate() {
    return !!this._engine.wasm._wl_physx_component_get_simulate(this._id);
  }
  /**
   * Set whether to allow simulation of this rigid body.
   *
   * {@link allowSimulation} and {@link trigger} can not be enabled at the
   * same time. Enabling {@link allowSimulation} while {@link trigger} is enabled
   * will disable {@link trigger}.
   *
   * @param b Whether to allow simulation of this rigid body.
   */
  set allowSimulation(b) {
    this._engine.wasm._wl_physx_component_set_allowSimulation(this._id, b);
  }
  /**
   * Whether to allow simulation of this rigid body.
   */
  get allowSimulation() {
    return !!this._engine.wasm._wl_physx_component_get_allowSimulation(this._id);
  }
  /**
   * Set whether this rigid body may be queried in ray casts.
   *
   * @param b Whether this rigid body may be queried in ray casts.
   */
  set allowQuery(b) {
    this._engine.wasm._wl_physx_component_set_allowQuery(this._id, b);
  }
  /**
   * Whether this rigid body may be queried in ray casts.
   */
  get allowQuery() {
    return !!this._engine.wasm._wl_physx_component_get_allowQuery(this._id);
  }
  /**
   * Set whether this physics body is a trigger.
   *
   * {@link allowSimulation} and {@link trigger} can not be enabled at the
   * same time. Enabling trigger while {@link allowSimulation} is enabled,
   * will disable {@link allowSimulation}.
   *
   * @param b Whether this physics body is a trigger.
   */
  set trigger(b) {
    this._engine.wasm._wl_physx_component_set_trigger(this._id, b);
  }
  /**
   * Whether this physics body is a trigger.
   */
  get trigger() {
    return !!this._engine.wasm._wl_physx_component_get_trigger(this._id);
  }
  /**
   * Set the shape for collision detection.
   *
   * @param s New shape.
   * @since 0.8.5
   */
  set shape(s) {
    this._engine.wasm._wl_physx_component_set_shape(this._id, s);
  }
  /** The shape for collision detection. */
  get shape() {
    return this._engine.wasm._wl_physx_component_get_shape(this._id);
  }
  /**
   * Set additional data for the shape.
   *
   * Retrieved only from {@link PhysXComponent#shapeData}.
   * @since 0.8.10
   */
  set shapeData(d) {
    if (d == null || !isMeshShape(this.shape))
      return;
    this._engine.wasm._wl_physx_component_set_shape_data(this._id, d.index);
  }
  /**
   * Additional data for the shape.
   *
   * `null` for {@link Shape} values: `None`, `Sphere`, `Capsule`, `Box`, `Plane`.
   * `{index: n}` for `TriangleMesh` and `ConvexHull`.
   *
   * This data is currently only for passing onto or creating other {@link PhysXComponent}.
   * @since 0.8.10
   */
  get shapeData() {
    if (!isMeshShape(this.shape))
      return null;
    return {
      index: this._engine.wasm._wl_physx_component_get_shape_data(this._id)
    };
  }
  /**
   * Set the shape extents for collision detection.
   *
   * @param e New extents for the shape.
   * @since 0.8.5
   */
  set extents(e) {
    this.extents.set(e);
  }
  /**
   * The shape extents for collision detection.
   */
  get extents() {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_physx_component_get_extents(this._id);
    return new Float32Array(wasm.HEAPF32.buffer, ptr, 3);
  }
  /**
   * Get staticFriction.
   */
  get staticFriction() {
    return this._engine.wasm._wl_physx_component_get_staticFriction(this._id);
  }
  /**
   * Set staticFriction.
   * @param v New staticFriction.
   */
  set staticFriction(v) {
    this._engine.wasm._wl_physx_component_set_staticFriction(this._id, v);
  }
  /**
   * Get dynamicFriction.
   */
  get dynamicFriction() {
    return this._engine.wasm._wl_physx_component_get_dynamicFriction(this._id);
  }
  /**
   * Set dynamicFriction
   * @param v New dynamicDamping.
   */
  set dynamicFriction(v) {
    this._engine.wasm._wl_physx_component_set_dynamicFriction(this._id, v);
  }
  /**
   * Get bounciness.
   * @since 0.9.0
   */
  get bounciness() {
    return this._engine.wasm._wl_physx_component_get_bounciness(this._id);
  }
  /**
   * Set bounciness.
   * @param v New bounciness.
   * @since 0.9.0
   */
  set bounciness(v) {
    this._engine.wasm._wl_physx_component_set_bounciness(this._id, v);
  }
  /**
   * Get linearDamping/
   */
  get linearDamping() {
    return this._engine.wasm._wl_physx_component_get_linearDamping(this._id);
  }
  /**
   * Set linearDamping.
   * @param v New linearDamping.
   */
  set linearDamping(v) {
    this._engine.wasm._wl_physx_component_set_linearDamping(this._id, v);
  }
  /** Get angularDamping. */
  get angularDamping() {
    return this._engine.wasm._wl_physx_component_get_angularDamping(this._id);
  }
  /**
   * Set angularDamping.
   * @param v New angularDamping.
   */
  set angularDamping(v) {
    this._engine.wasm._wl_physx_component_set_angularDamping(this._id, v);
  }
  /**
   * Set linear velocity.
   *
   * [PhysX Manual - "Velocity"](https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Manual/RigidBodyDynamics.html#velocity)
   *
   * Has no effect, if the component is not active.
   *
   * @param v New linear velocity.
   */
  set linearVelocity(v) {
    this._engine.wasm._wl_physx_component_set_linearVelocity(this._id, v[0], v[1], v[2]);
  }
  /** Linear velocity or `[0, 0, 0]` if the component is not active. */
  get linearVelocity() {
    const wasm = this._engine.wasm;
    wasm._wl_physx_component_get_linearVelocity(this._id, wasm._tempMem);
    return new Float32Array(wasm.HEAPF32.buffer, wasm._tempMem, 3);
  }
  /**
   * Set angular velocity
   *
   * [PhysX Manual - "Velocity"](https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Manual/RigidBodyDynamics.html#velocity)
   *
   * Has no effect, if the component is not active.
   *
   * @param v New angular velocity
   */
  set angularVelocity(v) {
    this._engine.wasm._wl_physx_component_set_angularVelocity(this._id, v[0], v[1], v[2]);
  }
  /** Angular velocity or `[0, 0, 0]` if the component is not active. */
  get angularVelocity() {
    const wasm = this._engine.wasm;
    wasm._wl_physx_component_get_angularVelocity(this._id, wasm._tempMem);
    return new Float32Array(wasm.HEAPF32.buffer, wasm._tempMem, 3);
  }
  /**
   * Set the components groups mask.
   *
   * @param flags New flags that need to be set.
   */
  set groupsMask(flags) {
    this._engine.wasm._wl_physx_component_set_groupsMask(this._id, flags);
  }
  /**
   * Get the components groups mask flags.
   *
   * Each bit represents membership to group, see example.
   *
   * ```js
   * // Assign c to group 2
   * c.groupsMask = (1 << 2);
   *
   * // Assign c to group 0
   * c.groupsMask  = (1 << 0);
   *
   * // Assign c to group 0 and 2
   * c.groupsMask = (1 << 0) | (1 << 2);
   *
   * (c.groupsMask & (1 << 2)) != 0; // true
   * (c.groupsMask & (1 << 7)) != 0; // false
   * ```
   */
  get groupsMask() {
    return this._engine.wasm._wl_physx_component_get_groupsMask(this._id);
  }
  /**
   * Set the components blocks mask.
   *
   * @param flags New flags that need to be set.
   */
  set blocksMask(flags) {
    this._engine.wasm._wl_physx_component_set_blocksMask(this._id, flags);
  }
  /**
   * Get the components blocks mask flags.
   *
   * Each bit represents membership to the block, see example.
   *
   * ```js
   * // Block overlap with any objects in group 2
   * c.blocksMask = (1 << 2);
   *
   * // Block overlap with any objects in group 0
   * c.blocksMask  = (1 << 0)
   *
   * // Block overlap with any objects in group 0 and 2
   * c.blocksMask = (1 << 0) | (1 << 2);
   *
   * (c.blocksMask & (1 << 2)) != 0; // true
   * (c.blocksMask & (1 << 7)) != 0; // false
   * ```
   */
  get blocksMask() {
    return this._engine.wasm._wl_physx_component_get_blocksMask(this._id);
  }
  /**
   * Set axes to lock for linear velocity.
   *
   * @param lock The Axis that needs to be set.
   *
   * Combine flags with Bitwise OR.
   * ```js
   * body.linearLockAxis = LockAxis.X | LockAxis.Y; // x and y set
   * body.linearLockAxis = LockAxis.X; // y unset
   * ```
   *
   * @note This has no effect if the component is static.
   */
  set linearLockAxis(lock) {
    this._engine.wasm._wl_physx_component_set_linearLockAxis(this._id, lock);
  }
  /**
   * Get the linear lock axes flags.
   *
   * To get the state of a specific flag, Bitwise AND with the LockAxis needed.
   *
   * ```js
   * if(body.linearLockAxis & LockAxis.Y) {
   *     console.log("The Y flag was set!");
   * }
   * ```
   *
   * @return axes that are currently locked for linear movement.
   */
  get linearLockAxis() {
    return this._engine.wasm._wl_physx_component_get_linearLockAxis(this._id);
  }
  /**
   * Set axes to lock for angular velocity.
   *
   * @param lock The Axis that needs to be set.
   *
   * ```js
   * body.angularLockAxis = LockAxis.X | LockAxis.Y; // x and y set
   * body.angularLockAxis = LockAxis.X; // y unset
   * ```
   *
   * @note This has no effect if the component is static.
   */
  set angularLockAxis(lock) {
    this._engine.wasm._wl_physx_component_set_angularLockAxis(this._id, lock);
  }
  /**
   * Get the angular lock axes flags.
   *
   * To get the state of a specific flag, Bitwise AND with the LockAxis needed.
   *
   * ```js
   * if(body.angularLockAxis & LockAxis.Y) {
   *     console.log("The Y flag was set!");
   * }
   * ```
   *
   * @return axes that are currently locked for angular movement.
   */
  get angularLockAxis() {
    return this._engine.wasm._wl_physx_component_get_angularLockAxis(this._id);
  }
  /**
   * Set mass.
   *
   * [PhysX Manual - "Mass Properties"](https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Manual/RigidBodyDynamics.html#mass-properties)
   *
   * @param m New mass.
   */
  set mass(m) {
    this._engine.wasm._wl_physx_component_set_mass(this._id, m);
  }
  /** Mass */
  get mass() {
    return this._engine.wasm._wl_physx_component_get_mass(this._id);
  }
  /**
   * Set mass space interia tensor.
   *
   * [PhysX Manual - "Mass Properties"](https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Manual/RigidBodyDynamics.html#mass-properties)
   *
   * Has no effect, if the component is not active.
   *
   * @param v New mass space interatia tensor.
   */
  set massSpaceInteriaTensor(v) {
    this._engine.wasm._wl_physx_component_set_massSpaceInertiaTensor(this._id, v[0], v[1], v[2]);
  }
  /**
   * Apply a force.
   *
   * [PhysX Manual - "Applying Forces and Torques"](https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Manual/RigidBodyDynamics.html#applying-forces-and-torques)
   *
   * Has no effect, if the component is not active.
   *
   * @param f Force vector.
   * @param m Force mode, see {@link ForceMode}, default `Force`.
   * @param localForce Whether the force vector is in local space, default `false`.
   * @param p Position to apply force at, default is center of mass.
   * @param local Whether position is in local space, default `false`.
   */
  addForce(f, m = ForceMode.Force, localForce = false, p2, local = false) {
    const wasm = this._engine.wasm;
    if (!p2) {
      wasm._wl_physx_component_addForce(this._id, f[0], f[1], f[2], m, localForce);
      return;
    }
    wasm._wl_physx_component_addForceAt(this._id, f[0], f[1], f[2], m, localForce, p2[0], p2[1], p2[2], local);
  }
  /**
   * Apply torque.
   *
   * [PhysX Manual - "Applying Forces and Torques"](https://gameworksdocs.nvidia.com/PhysX/4.1/documentation/physxguide/Manual/RigidBodyDynamics.html#applying-forces-and-torques)
   *
   * Has no effect, if the component is not active.
   *
   * @param f Force vector.
   * @param m Force mode, see {@link ForceMode}, default `Force`.
   */
  addTorque(f, m = ForceMode.Force) {
    this._engine.wasm._wl_physx_component_addTorque(this._id, f[0], f[1], f[2], m);
  }
  /**
   * Add on collision callback.
   *
   * @param callback Function to call when this rigid body (un)collides with any other.
   *
   * ```js
   *  let rigidBody = this.object.getComponent('physx');
   *  rigidBody.onCollision(function(type, other) {
   *      // Ignore uncollides
   *      if(type == CollisionEventType.TouchLost) return;
   *
   *      // Take damage on collision with enemies
   *      if(other.object.name.startsWith("enemy-")) {
   *          this.applyDamage(10);
   *      }
   *  }.bind(this));
   * ```
   *
   * @returns Id of the new callback for use with {@link PhysXComponent#removeCollisionCallback}.
   */
  onCollision(callback) {
    return this.onCollisionWith(this, callback);
  }
  /**
   * Add filtered on collision callback.
   *
   * @param otherComp Component for which callbacks will
   *        be triggered. If you pass this component, the method is equivalent to.
   *        {@link PhysXComponent#onCollision}.
   * @param callback Function to call when this rigid body
   *        (un)collides with `otherComp`.
   * @returns Id of the new callback for use with {@link PhysXComponent#removeCollisionCallback}.
   */
  onCollisionWith(otherComp, callback) {
    const physics = this._engine.physics;
    physics._callbacks[this._id] = physics._callbacks[this._id] || [];
    physics._callbacks[this._id].push(callback);
    return this._engine.wasm._wl_physx_component_addCallback(this._id, otherComp._id || this._id);
  }
  /**
   * Remove a collision callback added with {@link PhysXComponent#onCollision} or {@link PhysXComponent#onCollisionWith}.
   *
   * @param callbackId Callback id as returned by {@link PhysXComponent#onCollision} or {@link PhysXComponent#onCollisionWith}.
   * @throws When the callback does not belong to the component.
   * @throws When the callback does not exist.
   */
  removeCollisionCallback(callbackId) {
    const physics = this._engine.physics;
    const r = this._engine.wasm._wl_physx_component_removeCallback(this._id, callbackId);
    if (r)
      physics._callbacks[this._id].splice(-r);
  }
};
/** @override */
__publicField(PhysXComponent, "TypeName", "physx");
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "static", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "translationOffset", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "rotationOffset", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "kinematic", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "gravity", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "simulate", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "allowSimulation", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "allowQuery", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "trigger", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "shape", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "shapeData", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "extents", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "staticFriction", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "dynamicFriction", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "bounciness", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "linearDamping", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "angularDamping", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "linearVelocity", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "angularVelocity", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "groupsMask", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "blocksMask", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "linearLockAxis", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "angularLockAxis", null);
__decorate([
  nativeProperty()
], PhysXComponent.prototype, "mass", null);
var Physics = class {
  /**
   * @hidden
   *
   * **Note**: This is public to emulate a `friend` accessor.
   */
  _callbacks;
  /** Wonderland Engine instance */
  _engine;
  /** Ray Hit */
  _rayHit;
  /** Hit. */
  _hit;
  constructor(engine3) {
    this._engine = engine3;
    this._rayHit = engine3.wasm._malloc(4 * (3 * 4 + 3 * 4 + 4 + 2) + 4);
    this._hit = new RayHit(this._engine, this._rayHit);
    this._callbacks = {};
  }
  /**
   * Cast a ray through the physics scene and find intersecting objects.
   *
   * The resulting ray hit will contain **up to 4** closest ray hits,
   * sorted by increasing distance.
   *
   * @param o Ray origin.
   * @param d Ray direction.
   * @param group Collision group to filter by: only objects that are
   *        part of given group are considered for raycast.
   * @param maxDistance Maximum ray distance, default `100.0`.
   *
   * @returns The RayHit instance, belonging to this class.
   *
   * @note The returned {@link RayHit} object is owned by the Physics instance and
   *       will be reused with the next {@link Physics#rayCast} call.
   */
  rayCast(o, d, group, maxDistance = 100) {
    this._engine.wasm._wl_physx_ray_cast(o[0], o[1], o[2], d[0], d[1], d[2], group, maxDistance, this._rayHit);
    return this._hit;
  }
};
var MeshIndexType;
(function(MeshIndexType2) {
  MeshIndexType2[MeshIndexType2["UnsignedByte"] = 1] = "UnsignedByte";
  MeshIndexType2[MeshIndexType2["UnsignedShort"] = 2] = "UnsignedShort";
  MeshIndexType2[MeshIndexType2["UnsignedInt"] = 4] = "UnsignedInt";
})(MeshIndexType || (MeshIndexType = {}));
var MeshSkinningType;
(function(MeshSkinningType2) {
  MeshSkinningType2[MeshSkinningType2["None"] = 0] = "None";
  MeshSkinningType2[MeshSkinningType2["FourJoints"] = 1] = "FourJoints";
  MeshSkinningType2[MeshSkinningType2["EightJoints"] = 2] = "EightJoints";
})(MeshSkinningType || (MeshSkinningType = {}));
var Mesh = class {
  /**
   * Index of the mesh in the manager.
   *
   * @hidden
   */
  _index = -1;
  /** Wonderland Engine instance. @hidden */
  _engine;
  /**
   * Create a new instance.
   *
   * @param params Either a mesh index to wrap or set of parameters to create a new mesh.
   *    For more information, please have a look at the {@link MeshParameters} interface.
   */
  constructor(engine3, params) {
    this._engine = engine3 ?? WL;
    this._index = -1;
    if (isNumber(params)) {
      this._index = params;
      return;
    }
    if (!params.vertexCount)
      throw new Error("Missing parameter 'vertexCount'");
    const wasm = this._engine.wasm;
    let indexData = 0;
    let indexType = 0;
    let indexDataSize = 0;
    if (params.indexData) {
      indexType = params.indexType || MeshIndexType.UnsignedShort;
      indexDataSize = params.indexData.length * indexType;
      indexData = wasm._malloc(indexDataSize);
      switch (indexType) {
        case MeshIndexType.UnsignedByte:
          wasm.HEAPU8.set(params.indexData, indexData);
          break;
        case MeshIndexType.UnsignedShort:
          wasm.HEAPU16.set(params.indexData, indexData >> 1);
          break;
        case MeshIndexType.UnsignedInt:
          wasm.HEAPU32.set(params.indexData, indexData >> 2);
          break;
      }
    }
    const { skinningType = MeshSkinningType.None } = params;
    this._index = wasm._wl_mesh_create(indexData, indexDataSize, indexType, params.vertexCount, skinningType);
  }
  /** Number of vertices in this mesh. */
  get vertexCount() {
    return this._engine.wasm._wl_mesh_get_vertexCount(this._index);
  }
  /** Index data (read-only) or `null` if the mesh is not indexed. */
  get indexData() {
    const wasm = this._engine.wasm;
    const tempMem = wasm._tempMem;
    const ptr = wasm._wl_mesh_get_indexData(this._index, tempMem, tempMem + 4);
    if (ptr === null)
      return null;
    const indexCount = wasm.HEAPU32[tempMem / 4];
    const indexSize = wasm.HEAPU32[tempMem / 4 + 1];
    switch (indexSize) {
      case MeshIndexType.UnsignedByte:
        return new Uint8Array(wasm.HEAPU8.buffer, ptr, indexCount);
      case MeshIndexType.UnsignedShort:
        return new Uint16Array(wasm.HEAPU16.buffer, ptr, indexCount);
      case MeshIndexType.UnsignedInt:
        return new Uint32Array(wasm.HEAPU32.buffer, ptr, indexCount);
    }
    return null;
  }
  /** Hosting engine instance. */
  get engine() {
    return this._engine;
  }
  /**
   * Apply changes to {@link attribute | vertex attributes}.
   *
   * Uploads the updated vertex attributes to the GPU and updates the bounding
   * sphere to match the new vertex positions.
   *
   * Since this is an expensive operation, call it only once you have performed
   * all modifications on a mesh and avoid calling if you did not perform any
   * modifications at all.
   */
  update() {
    this._engine.wasm._wl_mesh_update(this._index);
  }
  getBoundingSphere(out = new Float32Array(4)) {
    const tempMemFloat = this._engine.wasm._tempMemFloat;
    this._engine.wasm._wl_mesh_get_boundingSphere(this._index, this._engine.wasm._tempMem);
    out[0] = tempMemFloat[0];
    out[1] = tempMemFloat[1];
    out[2] = tempMemFloat[2];
    out[3] = tempMemFloat[3];
    return out;
  }
  attribute(attr) {
    if (typeof attr != "number")
      throw new TypeError("Expected number, but got " + typeof attr);
    const tempMemUint32 = this._engine.wasm._tempMemUint32;
    this._engine.wasm._wl_mesh_get_attribute(this._index, attr, this._engine.wasm._tempMem);
    if (tempMemUint32[0] == 255)
      return null;
    const arraySize = tempMemUint32[5];
    return new MeshAttributeAccessor(this._engine, {
      attribute: tempMemUint32[0],
      offset: tempMemUint32[1],
      stride: tempMemUint32[2],
      formatSize: tempMemUint32[3],
      componentCount: tempMemUint32[4],
      /* The WASM API returns `0` for a scalar value. We clamp it to 1 as we strictly use it as a multiplier for get/set operations */
      arraySize: arraySize ? arraySize : 1,
      length: this.vertexCount,
      bufferType: attr !== MeshAttribute.JointId ? Float32Array : Uint16Array
    });
  }
  /**
   * Destroy and free the meshes memory.
   *
   * It is best practice to set the mesh variable to `null` after calling
   * destroy to prevent accidental use:
   *
   * ```js
   *   mesh.destroy();
   *   mesh = null;
   * ```
   *
   * Accessing the mesh after destruction behaves like accessing an empty
   * mesh.
   *
   * @since 0.9.0
   */
  destroy() {
    this._engine.wasm._wl_mesh_destroy(this._index);
  }
  /**
   * Checks equality by comparing whether the wrapped native mesh ids are
   * equal.
   *
   * @param otherMesh Mesh to check equality with.
   * @returns Whether this mesh equals the given mesh.
   *
   * @since 1.0.0
   */
  equals(otherMesh) {
    if (!otherMesh)
      return false;
    return this._index === otherMesh._index;
  }
};
var MeshAttributeAccessor = class {
  /** Max number of elements. */
  length = 0;
  /** Wonderland Engine instance. @hidden */
  _engine;
  /** Attribute index. @hidden */
  _attribute = -1;
  /** Attribute offset. @hidden */
  _offset = 0;
  /** Attribute stride. @hidden */
  _stride = 0;
  /** Format size native enum. @hidden */
  _formatSize = 0;
  /** Number of components per vertex. @hidden */
  _componentCount = 0;
  /** Number of values per vertex. @hidden */
  _arraySize = 1;
  /**
   * Class to instantiate an ArrayBuffer to get/set values.
   */
  _bufferType;
  /**
   * Function to allocate temporary WASM memory. It is cached in the accessor to avoid
   * conditionals during get/set.
   */
  _tempBufferGetter;
  /**
   * Create a new instance.
   *
   * @note Please use {@link Mesh.attribute} to create a new instance.
   *
   * @param options Contains information about how to read the data.
   * @note Do not use this constructor. Instead, please use the {@link Mesh.attribute} method.
   *
   * @hidden
   */
  constructor(engine3, options) {
    this._engine = engine3;
    const wasm = this._engine.wasm;
    this._attribute = options.attribute;
    this._offset = options.offset;
    this._stride = options.stride;
    this._formatSize = options.formatSize;
    this._componentCount = options.componentCount;
    this._arraySize = options.arraySize;
    this._bufferType = options.bufferType;
    this.length = options.length;
    this._tempBufferGetter = this._bufferType === Float32Array ? wasm.getTempBufferF32.bind(wasm) : wasm.getTempBufferU16.bind(wasm);
  }
  /**
   * Create a new TypedArray to hold this attribute's values.
   *
   * This method is useful to create a view to hold the data to
   * pass to {@link get} and {@link set}
   *
   * Example:
   *
   * ```js
   * const vertexCount = 4;
   * const positionAttribute = mesh.attribute(MeshAttribute.Position);
   *
   * // A position has 3 floats per vertex. Thus, positions has length 3 * 4.
   * const positions = positionAttribute.createArray(vertexCount);
   * ```
   *
   * @param count The number of **vertices** expected.
   * @returns A TypedArray with the appropriate format to access the data
   */
  createArray(count2 = 1) {
    count2 = count2 > this.length ? this.length : count2;
    return new this._bufferType(count2 * this._componentCount * this._arraySize);
  }
  get(index, out = this.createArray()) {
    if (out.length % this._componentCount !== 0) {
      throw new Error(`out.length, ${out.length} is not a multiple of the attribute vector components, ${this._componentCount}`);
    }
    const dest = this._tempBufferGetter(out.length);
    const elementSize = this._bufferType.BYTES_PER_ELEMENT;
    const destSize = elementSize * out.length;
    const srcFormatSize = this._formatSize * this._arraySize;
    const destFormatSize = this._componentCount * elementSize * this._arraySize;
    this._engine.wasm._wl_mesh_get_attribute_values(this._attribute, srcFormatSize, this._offset + index * this._stride, this._stride, destFormatSize, dest.byteOffset, destSize);
    for (let i = 0; i < out.length; ++i)
      out[i] = dest[i];
    return out;
  }
  /**
   * Set attribute element.
   *
   * @param i Index
   * @param v Value to set the element to
   *
   * `v.length` needs to be a multiple of the attributes component count, see
   * {@link MeshAttribute}. If `v.length` is more than one multiple, it will be
   * filled with the next n attribute elements, which can reduce overhead
   * of this call.
   *
   * @returns Reference to self (for method chaining)
   */
  set(i, v) {
    if (v.length % this._componentCount !== 0)
      throw new Error(`out.length, ${v.length} is not a multiple of the attribute vector components, ${this._componentCount}`);
    const elementSize = this._bufferType.BYTES_PER_ELEMENT;
    const srcSize = elementSize * v.length;
    const srcFormatSize = this._componentCount * elementSize * this._arraySize;
    const destFormatSize = this._formatSize * this._arraySize;
    const wasm = this._engine.wasm;
    if (v.buffer != wasm.HEAPU8.buffer) {
      const dest = this._tempBufferGetter(v.length);
      dest.set(v);
      v = dest;
    }
    wasm._wl_mesh_set_attribute_values(this._attribute, srcFormatSize, v.byteOffset, srcSize, destFormatSize, this._offset + i * this._stride, this._stride);
    return this;
  }
};
var Material = class {
  /**
   * Index of this material in the manager.
   *
   * @hidden
   */
  _index;
  /**
   * Material definition index in the scene.
   *
   * @hidden
   */
  _definition;
  /** Wonderland Engine instance. @hidden */
  _engine;
  /**
   * Create a new Material.
   *
   * @note Creating material is expensive. Please use {@link Material#clone} to clone a material.
   * @note Do not use this constructor directly with an index, this is reserved for internal purposes.
   */
  constructor(engine3, params) {
    this._engine = engine3;
    if (typeof params !== "number") {
      if (!params?.pipeline)
        throw new Error("Missing parameter 'pipeline'");
      const wasm = this._engine.wasm;
      const pipeline = params.pipeline;
      this._index = wasm._wl_material_create(wasm.tempUTF8(pipeline));
      if (this._index < 0)
        throw new Error(`No such pipeline '${pipeline}'`);
    } else {
      this._index = params;
    }
    this._definition = this._engine.wasm._wl_material_get_definition(this._index);
    if (!this._engine.wasm._materialDefinitions[this._definition])
      throw new Error(`Material Definition ${this._definition} not found for material with index ${this._index}`);
    return new Proxy(this, {
      get(target, prop) {
        const wasm = engine3.wasm;
        const definition = wasm._materialDefinitions[target._definition];
        const param = definition.get(prop);
        if (!param)
          return target[prop];
        if (wasm._wl_material_get_param_value(target._index, param.index, wasm._tempMem)) {
          const type = param.type;
          switch (type.type) {
            case MaterialParamType.UnsignedInt:
              return type.componentCount == 1 ? wasm._tempMemUint32[0] : new Uint32Array(wasm.HEAPU32.buffer, wasm._tempMem, type.componentCount);
            case MaterialParamType.Int:
              return type.componentCount == 1 ? wasm._tempMemInt[0] : new Int32Array(wasm.HEAP32.buffer, wasm._tempMem, type.componentCount);
            case MaterialParamType.Float:
              return type.componentCount == 1 ? wasm._tempMemFloat[0] : new Float32Array(wasm.HEAPF32.buffer, wasm._tempMem, type.componentCount);
            case MaterialParamType.Sampler:
              return engine3.textures.wrap(wasm._tempMemInt[0]);
            default:
              throw new Error(`Invalid type ${type.type} on parameter ${param.index} for material ${target._index}`);
          }
        }
      },
      set(target, prop, value) {
        const wasm = engine3.wasm;
        const definition = wasm._materialDefinitions[target._definition];
        const param = definition.get(prop);
        if (!param) {
          target[prop] = value;
          return true;
        }
        const type = param.type;
        switch (type.type) {
          case MaterialParamType.UnsignedInt:
          case MaterialParamType.Int:
          case MaterialParamType.Sampler:
            const v = value.id ?? value;
            wasm._wl_material_set_param_value_uint(target._index, param.index, v);
            break;
          case MaterialParamType.Float:
            let count2 = 1;
            if (typeof value === "number") {
              wasm._tempMemFloat[0] = value;
            } else {
              count2 = value.length;
              for (let i = 0; i < count2; ++i)
                wasm._tempMemFloat[i] = value[i];
            }
            wasm._wl_material_set_param_value_float(target._index, param.index, wasm._tempMem, count2);
            break;
          case MaterialParamType.Font:
            throw new Error("Setting font properties is currently unsupported.");
        }
        return true;
      }
    });
  }
  /** @deprecated Use {@link #pipeline} instead. */
  get shader() {
    return this.pipeline;
  }
  /** Name of the pipeline used by this material. */
  get pipeline() {
    const wasm = this._engine.wasm;
    return wasm.UTF8ToString(wasm._wl_material_get_pipeline(this._index));
  }
  /** Hosting engine instance. */
  get engine() {
    return this._engine;
  }
  /**
   * Create a copy of the underlying native material.
   *
   * @returns Material clone.
   */
  clone() {
    const id = this._engine.wasm._wl_material_clone(this._index);
    return id > 0 ? new Material(this._engine, id) : null;
  }
  /**
   * Checks equality by comparing whether the wrapped native material ids are
   * equal.
   *
   * @param otherMaterial Material to check equality with.
   * @returns Whether this material equals the given material.
   *
   * @since 1.0.0
   */
  equals(otherMaterial) {
    if (!otherMaterial)
      return false;
    return this._index === otherMaterial._index;
  }
  /**
   * Wrap a native material index.
   *
   * @param engine Engine instance.
   * @param index The index.
   * @returns Material instance or `null` if index <= 0.
   *
   * @deprecated Please use `new Material()` instead.
   */
  static wrap(engine3, index) {
    return index > 0 ? new Material(engine3, index) : null;
  }
};
var temp2d = null;
var Texture = class {
  /** Wonderland Engine instance. @hidden */
  _engine;
  /** Index in the manager. @hidden */
  _id = 0;
  /** HTML image index. @hidden */
  _imageIndex = null;
  /**
   * @param engine The engine instance
   * @param param HTML media element to create texture from or texture id to wrap.
   */
  constructor(engine3, param) {
    this._engine = engine3 ?? WL;
    const wasm = engine3.wasm;
    if (param instanceof HTMLImageElement || param instanceof HTMLVideoElement || param instanceof HTMLCanvasElement) {
      const index = wasm._images.length;
      wasm._images.push(param);
      this._imageIndex = index;
      this._id = this._engine.wasm._wl_renderer_addImage(index);
    } else {
      this._id = param;
    }
    this._engine.textures._set(this);
  }
  /** Whether this texture is valid. */
  get valid() {
    return this._id >= 0;
  }
  /** Index in this manager. */
  get id() {
    return this._id;
  }
  /** Update the texture to match the HTML element (e.g. reflect the current frame of a video). */
  update() {
    if (!this.valid || this._imageIndex === null)
      return;
    this._engine.wasm._wl_renderer_updateImage(this._id, this._imageIndex);
  }
  /** Width of the texture. */
  get width() {
    return this._engine.wasm._wl_texture_width(this._id);
  }
  /** Height of the texture. */
  get height() {
    return this._engine.wasm._wl_texture_height(this._id);
  }
  /** Hosting engine instance. */
  get engine() {
    return this._engine;
  }
  /**
   * Update a subrange on the texture to match the HTML element (e.g. reflect the current frame of a video).
   *
   * Usage:
   *
   * ```js
   * // Copies rectangle of pixel starting from (10, 20)
   * texture.updateSubImage(10, 20, 600, 400);
   * ```
   *
   * @param x x offset
   * @param y y offset
   * @param w width
   * @param h height
   */
  updateSubImage(x, y, w, h) {
    if (!this.valid || this._imageIndex === null)
      return;
    if (!temp2d) {
      const canvas = document.createElement("canvas");
      const ctx = canvas.getContext("2d");
      if (!ctx) {
        throw new Error("Texture.updateSubImage(): Failed to obtain CanvasRenderingContext2D.");
      }
      temp2d = {
        canvas,
        ctx
      };
    }
    const wasm = this._engine.wasm;
    const img = wasm._images[this._imageIndex];
    if (!img)
      return;
    temp2d.canvas.width = w;
    temp2d.canvas.height = h;
    temp2d.ctx.drawImage(img, x, y, w, h, 0, 0, w, h);
    const yOffset = (img.videoHeight ?? img.height) - y - h;
    wasm._images[this._imageIndex] = temp2d.canvas;
    wasm._wl_renderer_updateImage(this._id, this._imageIndex, x, yOffset);
    wasm._images[this._imageIndex] = img;
  }
  /**
   * Destroy and free the texture's texture altas space and memory.
   *
   * It is best practice to set the texture variable to `null` after calling
   * destroy to prevent accidental use of the invalid texture:
   *
   * ```js
   *   texture.destroy();
   *   texture = null;
   * ```
   *
   * @since 0.9.0
   */
  destroy() {
    this.engine._destroyTexture(this);
    this._id = -1;
    this._imageIndex = null;
  }
  /**
   * Checks equality by comparing whether the wrapped native texture ids are
   * equal.
   *
   * @param otherTexture Texture to check equality with.
   * @returns Whether this texture equals the given texture.
   *
   * @since 1.0.0
   */
  equals(otherTexture) {
    if (!otherTexture)
      return false;
    return this._id === otherTexture._id;
  }
};
var Animation = class {
  /** Index of the mesh in the manager. @hidden */
  _index;
  /** Wonderland Engine instance. @hidden */
  _engine;
  /**
   * @param index Index in the manager
   */
  constructor(engine3 = WL, index) {
    this._engine = engine3;
    this._index = index;
  }
  /** Duration of this animation. */
  get duration() {
    return this._engine.wasm._wl_animation_get_duration(this._index);
  }
  /** Number of tracks in this animation. */
  get trackCount() {
    return this._engine.wasm._wl_animation_get_trackCount(this._index);
  }
  /**
   * Clone this animation retargeted to a new set of objects.
   *
   * The clone shares most of the data with the original and is therefore
   * light-weight.
   *
   * **Experimental:** This API might change in upcoming versions.
   *
   * If retargeting to {@link Skin}, the join names will be used to determine a mapping
   * from the previous skin to the new skin. The source skin will be retrieved from
   * the first track in the animation that targets a joint.
   *
   * @param newTargets New targets per track. Expected to have
   *      {@link Animation#trackCount} elements or to be a {@link Skin}.
   * @returns The retargeted clone of this animation.
   */
  retarget(newTargets) {
    const wasm = this._engine.wasm;
    if (newTargets instanceof Skin) {
      const animId2 = wasm._wl_animation_retargetToSkin(this._index, newTargets._index);
      return new Animation(this._engine, animId2);
    }
    if (newTargets.length != this.trackCount) {
      throw Error("Expected " + this.trackCount.toString() + " targets, but got " + newTargets.length.toString());
    }
    const ptr = wasm._malloc(2 * newTargets.length);
    for (let i = 0; i < newTargets.length; ++i) {
      wasm.HEAPU16[ptr >> 1 + i] = newTargets[i].objectId;
    }
    const animId = wasm._wl_animation_retarget(this._index, ptr);
    wasm._free(ptr);
    return new Animation(this._engine, animId);
  }
  /**
   * Checks equality by comparing whether the wrapped native animation ids
   * are equal.
   *
   * @param otherAnimation Animation to check equality with.
   * @returns Whether this animation equals the given animation.
   *
   * @since 1.0.0
   */
  equals(otherAnimation) {
    if (!otherAnimation)
      return false;
    return this._index === otherAnimation._index;
  }
};
var Object3D = class {
  /**
   * Object index in the manager.
   *
   * @hidden
   */
  _objectId = -1;
  /** Wonderland Engine instance. @hidden */
  _engine;
  /**
   * @param o Object id to wrap
   *
   * For performance reasons, please use {@link WonderlandEngine.wrapObject}
   */
  constructor(engine3, o) {
    this._objectId = o;
    this._engine = engine3;
  }
  /**
   * Name of the object.
   *
   * Useful for identifying objects during debugging.
   */
  get name() {
    const wasm = this._engine.wasm;
    return wasm.UTF8ToString(wasm._wl_object_name(this.objectId));
  }
  /**
   * Set the object's name.
   *
   * @param newName The new name to set.
   */
  set name(newName) {
    const wasm = this._engine.wasm;
    wasm._wl_object_set_name(this.objectId, wasm.tempUTF8(newName));
  }
  /**
   * Parent of this object or `null` if parented to root.
   */
  get parent() {
    const p2 = this._engine.wasm._wl_object_parent(this.objectId);
    return p2 === 0 ? null : this._engine.wrapObject(p2);
  }
  /**
   * Children of this object.
   *
   * @note Child order is **undefined**. No assumptions should be made
   * about the index of a specific object.
   *
   * If you need to access a specific child of this object, you can
   * use {@link Object3D.findByName}.
   *
   * When the object exists in the scene at editor time, prefer passing it as
   * a component property.
   */
  get children() {
    const childrenCount = this._engine.wasm._wl_object_get_children_count(this.objectId);
    if (childrenCount === 0)
      return [];
    const wasm = this._engine.wasm;
    wasm.requireTempMem(childrenCount * 2);
    this._engine.wasm._wl_object_get_children(this.objectId, wasm._tempMem, wasm._tempMemSize >> 1);
    const children = new Array(childrenCount);
    for (let i = 0; i < childrenCount; ++i) {
      children[i] = this._engine.wrapObject(wasm._tempMemUint16[i]);
    }
    return children;
  }
  /**
   * Reparent object to given object.
   *
   * @note Reparenting is not trivial and might have a noticeable performance impact.
   *
   * @param newParent New parent or `null` to parent to root
   */
  set parent(newParent) {
    this._engine.wasm._wl_object_set_parent(this.objectId, newParent == null ? 0 : newParent.objectId);
  }
  /** Object index in the manager. */
  get objectId() {
    return this._objectId;
  }
  /** Hosting engine instance. */
  get engine() {
    return this._engine;
  }
  /**
   * Clone this hierarchy into a new one.
   *
   * Cloning copies the hierarchy structure, object names,
   * as well as components.
   *
   * JavaScript components are cloned using {@link Component.copy}. You can
   * override this method in your components.
   *
   * @param parent The parent for the cloned hierarchy. Defaults
   *     to the scene root.
   *
   * @returns The clone of this object.
   */
  clone(parent) {
    const engine3 = this._engine;
    const id = engine3.wasm._wl_object_clone(this._objectId, parent?._objectId ?? 0);
    return engine3.wrapObject(id);
  }
  /**
   * Reset local transformation (translation, rotation and scaling) to identity.
   *
   * @returns Reference to self (for method chaining).
   */
  resetTransform() {
    this._engine.wasm._wl_object_reset_translation_rotation(this.objectId);
    this._engine.wasm._wl_object_reset_scaling(this.objectId);
    return this;
  }
  /**
   * Reset local position and rotation to identity.
   *
   * @returns Reference to self (for method chaining).
   */
  resetPositionRotation() {
    this._engine.wasm._wl_object_reset_translation_rotation(this.objectId);
    return this;
  }
  /** @deprecated Please use {@link Object3D.resetPositionRotation} instead. */
  resetTranslationRotation() {
    return this.resetPositionRotation();
  }
  /**
   * Reset local rotation, keep translation.
   *
   * @note To reset both rotation and translation, prefer
   *       {@link resetTranslationRotation}.
   *
   * @returns Reference to self (for method chaining).
   */
  resetRotation() {
    this._engine.wasm._wl_object_reset_rotation(this.objectId);
    return this;
  }
  /**
   * Reset local translation, keep rotation.
   *
   * @note To reset both rotation and translation, prefer
   *       {@link resetTranslationRotation}.
   *
   * @returns Reference to self (for method chaining).
   */
  resetPosition() {
    this._engine.wasm._wl_object_reset_translation(this.objectId);
    return this;
  }
  /** @deprecated Please use {@link Object3D.resetPosition} instead. */
  resetTranslation() {
    return this.resetPosition();
  }
  /**
   * Reset local scaling to identity (``[1.0, 1.0, 1.0]``).
   *
   * @returns Reference to self (for method chaining).
   */
  resetScaling() {
    this._engine.wasm._wl_object_reset_scaling(this.objectId);
    return this;
  }
  /** @deprecated Please use {@link Object3D.translateLocal} instead. */
  translate(v) {
    return this.translateLocal(v);
  }
  /**
   * Translate object by a vector in the parent's space.
   *
   * @param v Vector to translate by.
   *
   * @returns Reference to self (for method chaining).
   */
  translateLocal(v) {
    this._engine.wasm._wl_object_translate(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  /**
   * Translate object by a vector in object space.
   *
   * @param v Vector to translate by.
   *
   * @returns Reference to self (for method chaining).
   */
  translateObject(v) {
    this._engine.wasm._wl_object_translate_obj(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  /**
   * Translate object by a vector in world space.
   *
   * @param v Vector to translate by.
   *
   * @returns Reference to self (for method chaining).
   */
  translateWorld(v) {
    this._engine.wasm._wl_object_translate_world(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  /** @deprecated Please use {@link Object3D.rotateAxisAngleDegLocal} instead. */
  rotateAxisAngleDeg(a, d) {
    this.rotateAxisAngleDegLocal(a, d);
    return this;
  }
  /**
   * Rotate around given axis by given angle (degrees) in local space.
   *
   * @param a Vector representing the rotation axis.
   * @param d Angle in degrees.
   *
   * @note If the object is translated the rotation will be around
   *     the parent. To rotate around the object origin, use
   *     {@link rotateAxisAngleDegObject}
   *
   * @see {@link rotateAxisAngleRad}
   *
   * @returns Reference to self (for method chaining).
   */
  rotateAxisAngleDegLocal(a, d) {
    this._engine.wasm._wl_object_rotate_axis_angle(this.objectId, a[0], a[1], a[2], d);
    return this;
  }
  /** @deprecated Please use {@link Object3D.rotateAxisAngleRadLocal} instead. */
  rotateAxisAngleRad(a, d) {
    return this.rotateAxisAngleRadLocal(a, d);
  }
  /**
   * Rotate around given axis by given angle (radians) in local space.
   *
   * @param a Vector representing the rotation axis.
   * @param d Angle in radians.
   *
   * @note If the object is translated the rotation will be around
   *     the parent. To rotate around the object origin, use
   *     {@link rotateAxisAngleDegObject}
   *
   * @see {@link rotateAxisAngleDeg}
   *
   * @returns Reference to self (for method chaining).
   */
  rotateAxisAngleRadLocal(a, d) {
    this._engine.wasm._wl_object_rotate_axis_angle_rad(this.objectId, a[0], a[1], a[2], d);
    return this;
  }
  /**
   * Rotate around given axis by given angle (degrees) in object space.
   *
   * @param a Vector representing the rotation axis.
   * @param d Angle in degrees.
   *
   * Equivalent to prepending a rotation quaternion to the object's
   * local transformation.
   *
   * @see {@link rotateAxisAngleRadObject}
   *
   * @returns Reference to self (for method chaining).
   */
  rotateAxisAngleDegObject(a, d) {
    this._engine.wasm._wl_object_rotate_axis_angle_obj(this.objectId, a[0], a[1], a[2], d);
    return this;
  }
  /**
   * Rotate around given axis by given angle (radians) in object space
   * Equivalent to prepending a rotation quaternion to the object's
   * local transformation.
   *
   * @param a Vector representing the rotation axis
   * @param d Angle in degrees
   *
   * @see {@link rotateAxisAngleDegObject}
   *
   * @returns Reference to self (for method chaining).
   */
  rotateAxisAngleRadObject(a, d) {
    this._engine.wasm._wl_object_rotate_axis_angle_rad_obj(this.objectId, a[0], a[1], a[2], d);
    return this;
  }
  /** @deprecated Please use {@link Object3D.rotateLocal} instead. */
  rotate(q) {
    this.rotateLocal(q);
    return this;
  }
  /**
   * Rotate by a quaternion.
   *
   * @param q the Quaternion to rotate by.
   *
   * @returns Reference to self (for method chaining).
   */
  rotateLocal(q) {
    this._engine.wasm._wl_object_rotate_quat(this.objectId, q[0], q[1], q[2], q[3]);
    return this;
  }
  /**
   * Rotate by a quaternion in object space.
   *
   * Equivalent to prepending a rotation quaternion to the object's
   * local transformation.
   *
   * @param q the Quaternion to rotate by.
   *
   * @returns Reference to self (for method chaining).
   */
  rotateObject(q) {
    this._engine.wasm._wl_object_rotate_quat_obj(this.objectId, q[0], q[1], q[2], q[3]);
    return this;
  }
  /** @deprecated Please use {@link Object3D.scaleLocal} instead. */
  scale(v) {
    this.scaleLocal(v);
    return this;
  }
  /**
   * Scale object by a vector in object space.
   *
   * @param v Vector to scale by.
   *
   * @returns Reference to self (for method chaining).
   */
  scaleLocal(v) {
    this._engine.wasm._wl_object_scale(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  getPositionLocal(out = new Float32Array(3)) {
    const wasm = this._engine.wasm;
    wasm._wl_object_get_translation_local(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  getTranslationLocal(out = new Float32Array(3)) {
    return this.getPositionLocal(out);
  }
  getPositionWorld(out = new Float32Array(3)) {
    const wasm = this._engine.wasm;
    wasm._wl_object_get_translation_world(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  getTranslationWorld(out = new Float32Array(3)) {
    return this.getPositionWorld(out);
  }
  /**
   * Set local / object space position.
   *
   * Concatenates a new translation dual quaternion onto the existing rotation.
   *
   * @param v New local position array/vector, expected to have at least 3 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setPositionLocal(v) {
    this._engine.wasm._wl_object_set_translation_local(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  /** @deprecated Please use {@link Object3D.setPositionLocal} instead. */
  setTranslationLocal(v) {
    return this.setPositionLocal(v);
  }
  /**
   * Set world space position.
   *
   * Applies the inverse parent transform with a new translation dual quaternion
   * which is concatenated onto the existing rotation.
   *
   * @param v New world position array/vector, expected to have at least 3 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setPositionWorld(v) {
    this._engine.wasm._wl_object_set_translation_world(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  /** @deprecated Please use {@link Object3D.setPositionWorld} instead. */
  setTranslationWorld(v) {
    return this.setPositionWorld(v);
  }
  getScalingLocal(out = new Float32Array(3)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_scaling_local(this.objectId) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    return out;
  }
  /**
   * Set local / object space scaling.
   *
   * @param v New local scaling array/vector, expected to have at least 3 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setScalingLocal(v) {
    this._engine.wasm._wl_object_set_scaling_local(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  getScalingWorld(out = new Float32Array(3)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_scaling_world(this.objectId) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    return out;
  }
  /**
   * Set World space scaling.
   *
   * @param v New world scaling array/vector, expected to have at least 3 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setScalingWorld(v) {
    this._engine.wasm._wl_object_set_scaling_world(this.objectId, v[0], v[1], v[2]);
    return this;
  }
  getRotationLocal(out = new Float32Array(4)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_trans_local(this.objectId) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    out[3] = wasm.HEAPF32[ptr + 3];
    return out;
  }
  /**
   * Set local space rotation.
   *
   * @param v New world rotation array/vector, expected to have at least 4 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setRotationLocal(v) {
    this._engine.wasm._wl_object_set_rotation_local(this.objectId, v[0], v[1], v[2], v[3]);
    return this;
  }
  getRotationWorld(out = new Float32Array(4)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_trans_world(this.objectId) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    out[3] = wasm.HEAPF32[ptr + 3];
    return out;
  }
  /**
   * Set local space rotation.
   *
   * @param v New world rotation array/vector, expected to have at least 4 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setRotationWorld(v) {
    this._engine.wasm._wl_object_set_rotation_world(this.objectId, v[0], v[1], v[2], v[3]);
    return this;
  }
  getTransformLocal(out = new Float32Array(8)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_trans_local(this.objectId) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    out[3] = wasm.HEAPF32[ptr + 3];
    out[4] = wasm.HEAPF32[ptr + 4];
    out[5] = wasm.HEAPF32[ptr + 5];
    out[6] = wasm.HEAPF32[ptr + 6];
    out[7] = wasm.HEAPF32[ptr + 7];
    return out;
  }
  /**
   * Set local space rotation.
   *
   * @param v New local transform array, expected to have at least 8 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setTransformLocal(v) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_trans_local(this.objectId) / 4;
    wasm.HEAPF32[ptr] = v[0];
    wasm.HEAPF32[ptr + 1] = v[1];
    wasm.HEAPF32[ptr + 2] = v[2];
    wasm.HEAPF32[ptr + 3] = v[3];
    wasm.HEAPF32[ptr + 4] = v[4];
    wasm.HEAPF32[ptr + 5] = v[5];
    wasm.HEAPF32[ptr + 6] = v[6];
    wasm.HEAPF32[ptr + 7] = v[7];
    this.setDirty();
    return this;
  }
  getTransformWorld(out = new Float32Array(8)) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_trans_world(this.objectId) / 4;
    out[0] = wasm.HEAPF32[ptr];
    out[1] = wasm.HEAPF32[ptr + 1];
    out[2] = wasm.HEAPF32[ptr + 2];
    out[3] = wasm.HEAPF32[ptr + 3];
    out[4] = wasm.HEAPF32[ptr + 4];
    out[5] = wasm.HEAPF32[ptr + 5];
    out[6] = wasm.HEAPF32[ptr + 6];
    out[7] = wasm.HEAPF32[ptr + 7];
    return out;
  }
  /**
   * Set world space rotation.
   *
   * @param v New world transform array, expected to have at least 8 elements.
   *
   * @returns Reference to self (for method chaining).
   */
  setTransformWorld(v) {
    const wasm = this._engine.wasm;
    const ptr = wasm._wl_object_trans_world(this.objectId) / 4;
    wasm.HEAPF32[ptr] = v[0];
    wasm.HEAPF32[ptr + 1] = v[1];
    wasm.HEAPF32[ptr + 2] = v[2];
    wasm.HEAPF32[ptr + 3] = v[3];
    wasm.HEAPF32[ptr + 4] = v[4];
    wasm.HEAPF32[ptr + 5] = v[5];
    wasm.HEAPF32[ptr + 6] = v[6];
    wasm.HEAPF32[ptr + 7] = v[7];
    this._engine.wasm._wl_object_trans_world_to_local(this.objectId);
    return this;
  }
  /**
   * Local space transformation.
   *
   * @deprecated Please use {@link Object3D.setTransformLocal} and
   * {@link Object3D.getTransformLocal} instead.
   */
  get transformLocal() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_object_trans_local(this.objectId), 8);
  }
  /**
   * Set local transform.
   *
   * @param t Local space transformation.
   *
   * @since 0.8.5
   *
   * @deprecated Please use {@link Object3D.setTransformLocal} and
   * {@link Object3D.getTransformLocal} instead.
   */
  set transformLocal(t) {
    this.transformLocal.set(t);
    this.setDirty();
  }
  /**
   * Global / world space transformation.
   *
   * May recompute transformations of the hierarchy of this object,
   * if they were changed by JavaScript components this frame.
   *
   * @deprecated Please use {@link Object3D.setTransformWorld} and
   * {@link Object3D.getTransformWorld} instead.
   */
  get transformWorld() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_object_trans_world(this.objectId), 8);
  }
  /**
   * Set world transform.
   *
   * @param t Global / world space transformation.
   *
   * @since 0.8.5
   *
   * @deprecated Please use {@link Object3D.setTransformWorld} and
   * {@link Object3D.getTransformWorld} instead.
   */
  set transformWorld(t) {
    this.transformWorld.set(t);
    this._engine.wasm._wl_object_trans_world_to_local(this.objectId);
  }
  /**
   * Local / object space scaling.
   *
   * @deprecated Please use {@link Object3D.setScalingLocal} and
   * {@link Object3D.getScalingLocal} instead.
   */
  get scalingLocal() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_object_scaling_local(this.objectId), 3);
  }
  /**
   * Set local space scaling.
   *
   * @param s Local space scaling.
   *
   * @since 0.8.7
   *
   * @deprecated Please use {@link Object3D.setScalingLocal} and
   * {@link Object3D.getScalingLocal} instead.
   */
  set scalingLocal(s) {
    this.scalingLocal.set(s);
    this.setDirty();
  }
  /**
   * Global / world space scaling.
   *
   * May recompute transformations of the hierarchy of this object,
   * if they were changed by JavaScript components this frame.
   *
   * @deprecated Please use {@link Object3D.setScalingWorld} and
   * {@link Object3D.getScalingWorld} instead.
   */
  get scalingWorld() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_object_scaling_world(this.objectId), 3);
  }
  /**
   * Set world space scaling.
   *
   * @param t World space scaling.
   *
   * @since 0.8.7
   *
   * @deprecated Please use {@link Object3D.setScalingWorld} and
   * {@link Object3D.getScalingWorld} instead.
   */
  set scalingWorld(s) {
    this.scalingWorld.set(s);
    this._engine.wasm._wl_object_scaling_world_to_local(this.objectId);
  }
  /**
   * Local space rotation.
   *
   * @since 0.8.7
   *
   * @deprecated Please use {@link Object3D.getRotationLocal} and
   * {@link Object3D.setRotationLocal} instead.
   */
  get rotationLocal() {
    return this.transformLocal.subarray(0, 4);
  }
  /**
   * Global / world space rotation
   *
   * @since 0.8.7
   *
   * @deprecated Please use {@link Object3D.getRotationWorld} and
   * {@link Object3D.setRotationWorld} instead.
   */
  get rotationWorld() {
    return this.transformWorld.subarray(0, 4);
  }
  /**
   * Set local space rotation.
   *
   * @param r Local space rotation
   *
   * @since 0.8.7
   *
   * @deprecated Please use {@link Object3D.getRotationLocal} and
   * {@link Object3D.setRotationLocal} instead.
   */
  set rotationLocal(r) {
    this._engine.wasm._wl_object_set_rotation_local(this.objectId, r[0], r[1], r[2], r[3]);
  }
  /**
   * Set world space rotation.
   *
   * @param r Global / world space rotation.
   *
   * @since 0.8.7
   *
   * @deprecated Please use {@link Object3D.getRotationWorld} and
   * {@link Object3D.setRotationWorld} instead.
   */
  set rotationWorld(r) {
    this._engine.wasm._wl_object_set_rotation_world(this.objectId, r[0], r[1], r[2], r[3]);
  }
  /** @deprecated Please use {@link Object3D.getForwardWorld} instead. */
  getForward(out) {
    return this.getForwardWorld(out);
  }
  /**
   * Compute the object's forward facing world space vector.
   *
   * The forward vector in object space is along the negative z-axis, i.e.,
   * `[0, 0, -1]`.
   *
   * @param out Destination array/vector, expected to have at least 3 elements.
   * @return The `out` parameter.
   */
  getForwardWorld(out) {
    out[0] = 0;
    out[1] = 0;
    out[2] = -1;
    this.transformVectorWorld(out);
    return out;
  }
  /** @deprecated Please use {@link Object3D.getUpWorld} instead. */
  getUp(out) {
    return this.getUpWorld(out);
  }
  /**
   * Compute the object's up facing world space vector.
   *
   * @param out Destination array/vector, expected to have at least 3 elements.
   * @return The `out` parameter.
   */
  getUpWorld(out) {
    out[0] = 0;
    out[1] = 1;
    out[2] = 0;
    this.transformVectorWorld(out);
    return out;
  }
  /** @deprecated Please use {@link Object3D.getRightWorld} instead. */
  getRight(out) {
    return this.getRightWorld(out);
  }
  /**
   * Compute the object's right facing world space vector.
   *
   * @param out Destination array/vector, expected to have at least 3 elements.
   * @return The `out` parameter.
   */
  getRightWorld(out) {
    out[0] = 1;
    out[1] = 0;
    out[2] = 0;
    this.transformVectorWorld(out);
    return out;
  }
  /**
   * Transform a vector by this object's world transform.
   *
   * @param out Out vector
   * @param v Vector to transform, default `out`
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformVectorWorld(out, v = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = v[0];
    wasm._tempMemFloat[1] = v[1];
    wasm._tempMemFloat[2] = v[2];
    wasm._wl_object_transformVectorWorld(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a vector by this object's local transform.
   *
   * @param out Out vector
   * @param v Vector to transform, default `out`
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformVectorLocal(out, v = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = v[0];
    wasm._tempMemFloat[1] = v[1];
    wasm._tempMemFloat[2] = v[2];
    wasm._wl_object_transformVectorLocal(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a point by this object's world transform.
   *
   * @param out Out point.
   * @param p Point to transform, default `out`.
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformPointWorld(out, p2 = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = p2[0];
    wasm._tempMemFloat[1] = p2[1];
    wasm._tempMemFloat[2] = p2[2];
    wasm._wl_object_transformPointWorld(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a point by this object's local transform.
   *
   * @param out Out point.
   * @param p Point to transform, default `out`.
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformPointLocal(out, p2 = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = p2[0];
    wasm._tempMemFloat[1] = p2[1];
    wasm._tempMemFloat[2] = p2[2];
    wasm._wl_object_transformPointLocal(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a vector by this object's inverse world transform.
   *
   * @param out Out vector.
   * @param v Vector to transform, default `out`.
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformVectorInverseWorld(out, v = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = v[0];
    wasm._tempMemFloat[1] = v[1];
    wasm._tempMemFloat[2] = v[2];
    wasm._wl_object_transformVectorInverseWorld(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a vector by this object's inverse local transform.
   *
   * @param out Out vector
   * @param v Vector to transform, default `out`
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformVectorInverseLocal(out, v = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = v[0];
    wasm._tempMemFloat[1] = v[1];
    wasm._tempMemFloat[2] = v[2];
    wasm._wl_object_transformVectorInverseLocal(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a point by this object's inverse world transform.
   *
   * @param out Out point.
   * @param p Point to transform, default `out`.
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformPointInverseWorld(out, p2 = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat[0] = p2[0];
    wasm._tempMemFloat[1] = p2[1];
    wasm._tempMemFloat[2] = p2[2];
    wasm._wl_object_transformPointInverseWorld(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform a point by this object's inverse local transform.
   *
   * @param out Out point.
   * @param p Point to transform, default `out`.
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  transformPointInverseLocal(out, p2 = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat.set(p2);
    wasm._wl_object_transformPointInverseLocal(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    return out;
  }
  /**
   * Transform an object space dual quaternion into world space.
   *
   * @param out Out transformation.
   * @param q Local space transformation, default `out`.
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  toWorldSpaceTransform(out, q = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat.set(q);
    wasm._wl_object_toWorldSpaceTransform(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    out[3] = wasm._tempMemFloat[3];
    out[4] = wasm._tempMemFloat[4];
    out[5] = wasm._tempMemFloat[5];
    out[6] = wasm._tempMemFloat[6];
    out[7] = wasm._tempMemFloat[7];
    return out;
  }
  /**
   * Transform a world space dual quaternion into local space.
   *
   * @param out Out transformation
   * @param q World space transformation, default `out`
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  toLocalSpaceTransform(out, q = out) {
    const p2 = this.parent;
    if (p2) {
      p2.toObjectSpaceTransform(out, q);
      return out;
    }
    if (out !== q) {
      out[0] = q[0];
      out[1] = q[1];
      out[2] = q[2];
      out[3] = q[3];
      out[4] = q[4];
      out[5] = q[5];
      out[6] = q[6];
      out[7] = q[7];
    }
    return out;
  }
  /**
   * Transform a world space dual quaternion into object space.
   *
   * @param out Out transformation.
   * @param q World space transformation, default `out`
   * @return The `out` parameter.
   *
   * @since 0.8.7
   */
  toObjectSpaceTransform(out, q = out) {
    const wasm = this._engine.wasm;
    wasm._tempMemFloat.set(q);
    wasm._wl_object_toObjectSpaceTransform(this.objectId, wasm._tempMem);
    out[0] = wasm._tempMemFloat[0];
    out[1] = wasm._tempMemFloat[1];
    out[2] = wasm._tempMemFloat[2];
    out[3] = wasm._tempMemFloat[3];
    out[4] = wasm._tempMemFloat[4];
    out[5] = wasm._tempMemFloat[5];
    out[6] = wasm._tempMemFloat[6];
    out[7] = wasm._tempMemFloat[7];
    return out;
  }
  /**
   * Turn towards / look at target.
   *
   * Rotates the object so that its forward vector faces towards the target
   * position. The `up` vector acts as a hint to uniquely orient the object's
   * up direction. When orienting a view component, the projected `up` vector
   * faces upwards on the viewing plane.
   *
   * @param p Target position to turn towards, in world space.
   * @param up Up vector to align object with, in world space. Default is `[0, 1, 0]`.
   *
   * @returns Reference to self (for method chaining).
   */
  lookAt(p2, up = UP_VECTOR) {
    this._engine.wasm._wl_object_lookAt(this.objectId, p2[0], p2[1], p2[2], up[0], up[1], up[2]);
    return this;
  }
  /** Destroy the object with all of its components and remove it from the scene */
  destroy() {
    if (this._objectId < 0)
      return;
    this.engine.wasm._wl_scene_remove_object(this._objectId);
    this.engine._destroyObject(this);
  }
  /**
   * Mark transformation dirty.
   *
   * Causes an eventual recalculation of {@link transformWorld}, either
   * on next {@link getTranslationWorld}, {@link transformWorld} or
   * {@link scalingWorld} or the beginning of next frame, whichever
   * happens first.
   */
  setDirty() {
    this._engine.wasm._wl_object_set_dirty(this.objectId);
  }
  /**
   * Disable/enable all components of this object.
   *
   * @param b New state for the components.
   *
   * @since 0.8.5
   */
  set active(b) {
    const comps = this.getComponents();
    for (let c of comps) {
      c.active = b;
    }
  }
  getComponent(typeOrClass, index = 0) {
    const type = isString(typeOrClass) ? typeOrClass : typeOrClass.TypeName;
    const wasm = this._engine.wasm;
    const componentType = wasm._wl_get_component_manager_index(wasm.tempUTF8(type));
    if (componentType < 0) {
      const typeIndex = wasm._componentTypeIndices[type];
      if (typeIndex === void 0)
        return null;
      const jsIndex = wasm._wl_get_js_component_index(this.objectId, typeIndex, index);
      if (jsIndex < 0)
        return null;
      const component = this._engine.wasm._components[jsIndex];
      return component.constructor !== BrokenComponent ? component : null;
    }
    const componentId = this._engine.wasm._wl_get_component_id(this.objectId, componentType, index);
    return this._engine._wrapComponent(type, componentType, componentId);
  }
  getComponents(typeOrClass) {
    const wasm = this._engine.wasm;
    let componentType = null;
    let type = null;
    if (typeOrClass) {
      type = isString(typeOrClass) ? typeOrClass : typeOrClass.TypeName;
      componentType = wasm._typeIndexFor(type);
    }
    const components = [];
    const maxComps = Math.floor(wasm._tempMemSize / 3 * 2);
    const componentsCount = wasm._wl_object_get_components(this.objectId, wasm._tempMem, maxComps);
    const offset = 2 * componentsCount;
    wasm._wl_object_get_component_types(this.objectId, wasm._tempMem + offset, maxComps);
    const jsManagerIndex = wasm._jsManagerIndex;
    for (let i = 0; i < componentsCount; ++i) {
      const t = wasm._tempMemUint8[i + offset];
      const componentId = wasm._tempMemUint16[i];
      if (t == jsManagerIndex) {
        const typeIndex = wasm._wl_get_js_component_index_for_id(componentId);
        const comp = wasm._components[typeIndex];
        const matches = componentType === null || comp.type == type;
        if (comp.constructor !== BrokenComponent && matches) {
          components.push(comp);
        }
        continue;
      }
      if (componentType === null) {
        const managerName = wasm._typeNameFor(t);
        components.push(this._engine._wrapComponent(managerName, t, componentId));
      } else if (t == componentType) {
        components.push(this._engine._wrapComponent(type, componentType, componentId));
      }
    }
    return components;
  }
  addComponent(typeOrClass, params) {
    const wasm = this._engine.wasm;
    const type = isString(typeOrClass) ? typeOrClass : typeOrClass.TypeName;
    const componentType = wasm._typeIndexFor(type);
    let component = null;
    let componentIndex = null;
    if (componentType < 0) {
      if (!(type in wasm._componentTypeIndices)) {
        throw new TypeError("Unknown component type '" + type + "'");
      }
      const componentId = wasm._wl_object_add_js_component(this.objectId, wasm._componentTypeIndices[type]);
      componentIndex = wasm._wl_get_js_component_index_for_id(componentId);
      component = wasm._components[componentIndex];
    } else {
      const componentId = wasm._wl_object_add_component(this.objectId, componentType);
      component = this._engine._wrapComponent(type, componentType, componentId);
    }
    if (params !== void 0)
      component.copy(params);
    if (componentType < 0) {
      wasm._wljs_component_init(componentIndex);
    }
    if (!params || !("active" in params && !params.active)) {
      component.active = true;
    }
    return component;
  }
  /**
   * Search for descendants matching the name.
   *
   * This method is a wrapper around {@link Object3D.findByNameDirect} and
   * {@link Object3D.findByNameRecursive}.
   *
   * @param name The name to search for.
   * @param recursive If `true`, the method will look at all the descendants of this object.
   *     If `false`, this method will only perform the search in direct children.
   * @returns An array of {@link Object3D} matching the name.
   *
   * @since 1.1.0
   */
  findByName(name, recursive = false) {
    return recursive ? this.findByNameRecursive(name) : this.findByNameDirect(name);
  }
  /**
   * Search for all **direct** children matching the name.
   *
   * @note Even though this method is heavily optimized, it does perform
   * a linear search to find the objects. Do not use in a hot path.
   *
   * @param name The name to search for.
   * @returns An array of {@link Object3D} matching the name.
   *
   * @since 1.1.0
   */
  findByNameDirect(name) {
    const wasm = this._engine.wasm;
    const id = this._objectId;
    const tempSizeU16 = wasm._tempMemSize >> 2;
    const maxCount = tempSizeU16 - 2;
    const buffer2 = wasm._tempMemUint16;
    buffer2[maxCount] = 0;
    buffer2[maxCount + 1] = 0;
    const bufferPtr = wasm._tempMem;
    const indexPtr = bufferPtr + maxCount * 2;
    const childCountPtr = bufferPtr + maxCount * 2 + 2;
    const namePtr = wasm.tempUTF8(name, (maxCount + 2) * 2);
    const result = [];
    let read = 0;
    while (read = wasm._wl_object_findByName(id, namePtr, indexPtr, childCountPtr, bufferPtr, maxCount)) {
      for (let i = 0; i < read; ++i)
        result.push(this.engine.wrapObject(buffer2[i]));
    }
    return result;
  }
  /**
   * Search for **all descendants** matching the name.
   *
   * @note Even though this method is heavily optimized, it does perform
   * a linear search to find the objects. Do not use in a hot path.
   *
   * @param name The name to search for.
   * @returns An array of {@link Object3D} matching the name.
   */
  findByNameRecursive(name) {
    const wasm = this._engine.wasm;
    const id = this._objectId;
    const tempSizeU16 = wasm._tempMemSize >> 2;
    const maxCount = tempSizeU16 - 1;
    const buffer2 = wasm._tempMemUint16;
    buffer2[maxCount] = 0;
    const bufferPtr = wasm._tempMem;
    const indexPtr = bufferPtr + maxCount * 2;
    const namePtr = wasm.tempUTF8(name, (maxCount + 1) * 2);
    let read = 0;
    const result = [];
    while (read = wasm._wl_object_findByNameRecursive(id, namePtr, indexPtr, bufferPtr, maxCount)) {
      for (let i = 0; i < read; ++i)
        result.push(this.engine.wrapObject(buffer2[i]));
    }
    return result;
  }
  /**
   * Whether given object's transformation has changed.
   */
  get changed() {
    return !!this._engine.wasm._wl_object_is_changed(this.objectId);
  }
  /**
   * `true` if the object is destroyed, `false` otherwise.
   *
   * If {@link WonderlandEngine.erasePrototypeOnDestroy} is `true`,
   * reading a custom property will not work:
   *
   * ```js
   * engine.erasePrototypeOnDestroy = true;
   *
   * const obj = scene.addObject();
   * obj.customParam = 'Hello World!';
   *
   * console.log(obj.isDestroyed); // Prints `false`
   * obj.destroy();
   * console.log(obj.isDestroyed); // Prints `true`
   * console.log(obj.customParam); // Throws an error
   * ```
   *
   * @since 1.1.1
   */
  get isDestroyed() {
    return this._objectId < 0;
  }
  /**
   * Checks equality by comparing whether the wrapped native object ids are
   * equal.
   *
   * @param otherObject Object to check equality with.
   * @returns Whether this object equals the given object.
   */
  equals(otherObject) {
    if (!otherObject)
      return false;
    return this.objectId == otherObject.objectId;
  }
};
var Skin = class {
  /**
   * Index of the skin in the manager.
   * @hidden
   */
  _index;
  /** Wonderland Engine instance. @hidden */
  _engine;
  constructor(engine3, index) {
    this._engine = engine3;
    this._index = index;
  }
  /** Amount of joints in this skin. */
  get jointCount() {
    return this._engine.wasm._wl_skin_get_joint_count(this._index);
  }
  /** Joints object ids for this skin */
  get jointIds() {
    const wasm = this._engine.wasm;
    return new Uint16Array(wasm.HEAPU16.buffer, wasm._wl_skin_joint_ids(this._index), this.jointCount);
  }
  /**
   * Dual quaternions in a flat array of size 8 times {@link jointCount}.
   *
   * Inverse bind transforms of the skin.
   */
  get inverseBindTransforms() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_skin_inverse_bind_transforms(this._index), 8 * this.jointCount);
  }
  /**
   * Vectors in a flat array of size 3 times {@link jointCount}.
   *
   * Inverse bind scalings of the skin.
   */
  get inverseBindScalings() {
    const wasm = this._engine.wasm;
    return new Float32Array(wasm.HEAPF32.buffer, wasm._wl_skin_inverse_bind_scalings(this._index), 3 * this.jointCount);
  }
  /**
   * Checks equality by comparing whether the wrapped native skin ids are
   * equal.
   *
   * @param otherSkin Skin to check equality with.
   * @returns Whether this skin equals the given skin.
   *
   * @since 1.0.0
   */
  equals(otherSkin) {
    if (!otherSkin)
      return false;
    return this._index === otherSkin._index;
  }
};
var RayHit = class {
  /** Wonderland Engine instance. @hidden */
  _engine;
  /** Pointer to the memory heap. */
  _ptr;
  /**
   * @param ptr Pointer to the ray hits memory.
   */
  constructor(engine3, ptr) {
    if ((ptr & 3) !== 0) {
      throw new Error("Misaligned pointer: please report a bug");
    }
    this._engine = engine3;
    this._ptr = ptr;
  }
  /** Array of ray hit locations. */
  get locations() {
    let p2 = this._ptr;
    let l = [];
    for (let i = 0; i < this.hitCount; ++i) {
      l.push(new Float32Array(this._engine.wasm.HEAPF32.buffer, p2 + 12 * i, 3));
    }
    return l;
  }
  /** Array of ray hit normals (only when using {@link Physics#rayCast}. */
  get normals() {
    let p2 = this._ptr + 48;
    let l = [];
    for (let i = 0; i < this.hitCount; ++i) {
      l.push(new Float32Array(this._engine.wasm.HEAPF32.buffer, p2 + 12 * i, 3));
    }
    return l;
  }
  /**
   * Prefer these to recalculating the distance from locations.
   *
   * Distances of array hits to ray origin.
   */
  get distances() {
    const p2 = this._ptr + 48 * 2;
    return new Float32Array(this._engine.wasm.HEAPF32.buffer, p2, this.hitCount);
  }
  /** Hit objects */
  get objects() {
    const HEAPU16 = this._engine.wasm.HEAPU16;
    const objects = [null, null, null, null];
    let p2 = this._ptr + (48 * 2 + 16) >> 1;
    for (let i = 0; i < this.hitCount; ++i) {
      objects[i] = this._engine.wrapObject(HEAPU16[p2 + i]);
    }
    return objects;
  }
  /** Number of hits (max 4) */
  get hitCount() {
    return Math.min(this._engine.wasm.HEAPU32[this._ptr / 4 + 30], 4);
  }
};
var math = class {
  /** (Experimental!) Cubic Hermite spline interpolation for vector3 and quaternions.
   *
   * With `f == 0`, `out` will be `b`, if `f == 1`, `out` will be c.
   *
   * Whether a quaternion or vector3 interpolation is intended is determined by
   * length of `a`.
   *
   * @param out Array to write result to.
   * @param a First tangent/handle.
   * @param b First point or quaternion.
   * @param c Second point or quaternion.
   * @param d Second handle.
   * @param f Interpolation factor in [0; 1].
   * @returns The `out` parameter.
   *
   * @since 0.8.6
   */
  static cubicHermite(out, a, b, c, d, f, engine3 = WL) {
    const wasm = engine3.wasm;
    wasm._tempMemFloat.subarray(0).set(a);
    wasm._tempMemFloat.subarray(4).set(b);
    wasm._tempMemFloat.subarray(8).set(c);
    wasm._tempMemFloat.subarray(12).set(d);
    const isQuat = a.length == 4;
    wasm._wl_math_cubicHermite(wasm._tempMem + 4 * 16, wasm._tempMem + 4 * 0, wasm._tempMem + 4 * 4, wasm._tempMem + 4 * 8, wasm._tempMem + 4 * 12, f, isQuat);
    out[0] = wasm._tempMemFloat[16];
    out[1] = wasm._tempMemFloat[17];
    out[2] = wasm._tempMemFloat[18];
    if (isQuat)
      out[3] = wasm._tempMemFloat[19];
    return out;
  }
};
var I18N = class {
  /**
   * {@link Emitter} for language change events.
   *
   * First parameter to a listener is the old language index,
   * second parameter is the new language index.
   *
   * Usage from a within a component:
   * ```js
   * this.engine.i18n.onLanguageChanged.add((oldLanguageIndex, newLanguageIndex) => {
   *     const oldLanguage = this.engine.i18n.languageName(oldLanguageIndex);
   *     const newLanguage = this.engine.i18n.languageName(newLanguageIndex);
   *     console.log("Switched from", oldLanguage, "to", newLanguage);
   * });
   * ```
   */
  onLanguageChanged = new Emitter();
  /** Wonderland Engine instance. @hidden */
  _engine;
  /** Previously set language index. @hidden */
  _prevLanguageIndex = -1;
  /**
   * Constructor
   */
  constructor(engine3) {
    this._engine = engine3;
  }
  /**
   * Set current language and apply translations to linked text parameters.
   *
   * @note This is equivalent to {@link I18N.setLanguage}.
   *
   * @param code Language code to switch to
   */
  set language(code) {
    this.setLanguage(code);
  }
  /** Get current language code. */
  get language() {
    const wasm = this._engine.wasm;
    const code = wasm._wl_i18n_currentLanguage();
    if (code === 0)
      return null;
    return wasm.UTF8ToString(code);
  }
  /**
   * Get the current language index.
   *
   * This method is more efficient than its equivalent:
   *
   * ```js
   * const index = i18n.languageIndex(i18n.language);
   * ```
   */
  get currentIndex() {
    return this._engine.wasm._wl_i18n_currentLanguageIndex();
  }
  /** Previous language index. */
  get previousIndex() {
    return this._prevLanguageIndex;
  }
  /**
   * Set current language and apply translations to linked text parameters.
   *
   * @param code The language code.
   * @returns A promise that resolves with the current index code when the
   *     language is loaded.
   */
  setLanguage(code) {
    if (code == null)
      return Promise.resolve(this.currentIndex);
    const wasm = this._engine.wasm;
    this._prevLanguageIndex = this.currentIndex;
    wasm._wl_i18n_setLanguage(wasm.tempUTF8(code));
    return this._engine.scene._flushAppend(this._engine.scene.baseURL).then(() => this.currentIndex);
  }
  /**
   * Get translated string for a term for the currently loaded language.
   *
   * @param term Term to translate
   */
  translate(term) {
    const wasm = this._engine.wasm;
    const translation = wasm._wl_i18n_translate(wasm.tempUTF8(term));
    if (translation === 0)
      return null;
    return wasm.UTF8ToString(translation);
  }
  /**
   * Get the number of languages in the project.
   *
   */
  languageCount() {
    const wasm = this._engine.wasm;
    return wasm._wl_i18n_languageCount();
  }
  /**
   * Get a language code.
   *
   * @param index Index of the language to get the code from
   */
  languageIndex(code) {
    const wasm = this._engine.wasm;
    return wasm._wl_i18n_languageIndex(wasm.tempUTF8(code));
  }
  /**
   * Get a language code.
   *
   * @param index Index of the language to get the code from
   */
  languageCode(index) {
    const wasm = this._engine.wasm;
    const code = wasm._wl_i18n_languageCode(index);
    if (code === 0)
      return null;
    return wasm.UTF8ToString(code);
  }
  /**
   * Get a language name.
   *
   * @param index Index of the language to get the name from
   */
  languageName(index) {
    const wasm = this._engine.wasm;
    const name = wasm._wl_i18n_languageName(index);
    if (name === 0)
      return null;
    return wasm.UTF8ToString(name);
  }
};
var XR = class {
  /** Wonderland WASM bridge. @hidden */
  #wasm;
  #mode;
  constructor(wasm, mode) {
    this.#wasm = wasm;
    this.#mode = mode;
  }
  /** Current WebXR session mode */
  get sessionMode() {
    return this.#mode;
  }
  /** Current WebXR session */
  get session() {
    return this.#wasm.webxr_session;
  }
  /** Current WebXR frame */
  get frame() {
    return this.#wasm.webxr_frame;
  }
  referenceSpaceForType(type) {
    return this.#wasm.webxr_refSpaces[type] ?? null;
  }
  /** Set current reference space type used for retrieving eye, head, hand and joint poses */
  set currentReferenceSpace(refSpace) {
    this.#wasm.webxr_refSpace = refSpace;
    this.#wasm.webxr_refSpaceType = null;
    for (const type of Object.keys(this.#wasm.webxr_refSpaces)) {
      if (this.#wasm.webxr_refSpaces[type] === refSpace) {
        this.#wasm.webxr_refSpaceType = type;
      }
    }
  }
  /** Current reference space type used for retrieving eye, head, hand and joint poses */
  get currentReferenceSpace() {
    return this.#wasm.webxr_refSpace;
  }
  /** Current WebXR reference space type or `null` if not a default reference space */
  get currentReferenceSpaceType() {
    return this.#wasm.webxr_refSpaceType;
  }
  /** Current WebXR base layer  */
  get baseLayer() {
    return this.#wasm.webxr_baseLayer;
  }
  /** Current WebXR framebuffer */
  get framebuffers() {
    if (!Array.isArray(this.#wasm.webxr_fbo)) {
      return [this.#wasm.GL.framebuffers[this.#wasm.webxr_fbo]];
    }
    return this.#wasm.webxr_fbo.map((id) => this.#wasm.GL.framebuffers[id]);
  }
};

// node_modules/@wonderlandengine/api/dist/utils/fetch.js
function fetchWithProgress(path, onProgress) {
  return new Promise((resolve, reject) => {
    const xhr = new XMLHttpRequest();
    xhr.open("GET", path);
    xhr.responseType = "arraybuffer";
    xhr.onprogress = (progress) => {
      if (progress.lengthComputable) {
        onProgress?.(progress.loaded, progress.total);
      }
    };
    xhr.onload = () => {
      if (xhr.status >= 200 && xhr.status < 300) {
        const buffer2 = xhr.response;
        onProgress?.(buffer2.byteLength, buffer2.byteLength);
        resolve(buffer2);
      } else {
        reject(xhr.statusText);
      }
    };
    xhr.onerror = () => reject(xhr.statusText);
    xhr.send();
  });
}
function getBaseUrl(url) {
  return url.substring(0, url.lastIndexOf("/"));
}

// node_modules/@wonderlandengine/api/dist/utils/misc.js
function timeout(time) {
  return new Promise((res) => setTimeout(res, time));
}
function clamp(val, min5, max5) {
  return Math.max(Math.min(max5, val), min5);
}

// node_modules/@wonderlandengine/api/dist/scene.js
var MAGIC_BIN = "WLEV";
var Scene = class {
  /** Called before rendering the scene */
  onPreRender = new Emitter();
  /** Called after the scene has been rendered */
  onPostRender = new Emitter();
  /** Wonderland Engine instance. @hidden */
  _engine;
  /** Ray hit pointer in WASM heap. @hidden */
  _rayHit;
  /** Ray hit. @hidden */
  _hit;
  /**
   * Relative directory of the scene that was loaded with {@link Scene.load}
   * Used for loading any files relative to the main scene.
   *
   * We need this for the tests that load bin files since we aren't loading
   * from the deploy folder directly. (test/resources/projects/*.bin)
   *
   * @hidden
   */
  _baseURL;
  constructor(engine3) {
    this._engine = engine3;
    this._rayHit = engine3.wasm._malloc(4 * (3 * 4 + 3 * 4 + 4 + 2) + 4);
    this._hit = new RayHit(this._engine, this._rayHit);
    this._baseURL = "";
  }
  /**
   * Currently active view components.
   */
  get activeViews() {
    const wasm = this._engine.wasm;
    const count2 = wasm._wl_scene_get_active_views(this._engine.wasm._tempMem, 16);
    const views = [];
    const viewTypeIndex = wasm._typeIndexFor("view");
    for (let i = 0; i < count2; ++i) {
      views.push(new ViewComponent(this._engine, viewTypeIndex, this._engine.wasm._tempMemInt[i]));
    }
    return views;
  }
  /**
   * Relative directory of the scene that was loaded with {@link Scene.load}
   * Used for loading any files relative to the main scene.
   *
   * @hidden
   */
  get baseURL() {
    return this._baseURL;
  }
  /**
   * Cast a ray through the scene and find intersecting objects.
   *
   * The resulting ray hit will contain up to **4** closest ray hits,
   * sorted by increasing distance.
   *
   * @param o Ray origin.
   * @param d Ray direction.
   * @param group Collision group to filter by: only objects that are
   *        part of given group are considered for raycast.
   * @param maxDistance Maximum **inclusive** hit distance. Defaults to `100`.
   *
   * @returns The scene cached {@link RayHit} instance.
   * @note The returned object is owned by the Scene instance
   *   will be reused with the next {@link Scene#rayCast} call.
   */
  rayCast(o, d, group, maxDistance = 100) {
    this._engine.wasm._wl_scene_ray_cast(o[0], o[1], o[2], d[0], d[1], d[2], group, this._rayHit, maxDistance);
    return this._hit;
  }
  /**
   * Add an object to the scene.
   *
   * @param parent Parent object or `null`.
   * @returns A newly created object.
   */
  addObject(parent = null) {
    const parentId = parent ? parent.objectId : 0;
    const objectId = this._engine.wasm._wl_scene_add_object(parentId);
    return this._engine.wrapObject(objectId);
  }
  /**
   * Batch-add objects to the scene.
   *
   * Will provide better performance for adding multiple objects (e.g. > 16)
   * than calling {@link Scene#addObject} repeatedly in a loop.
   *
   * By providing upfront information of how many objects will be required,
   * the engine is able to batch-allocate the required memory rather than
   * convervatively grow the memory in small steps.
   *
   * **Experimental:** This API might change in upcoming versions.
   *
   * @param count Number of objects to add.
   * @param parent Parent object or `null`, default `null`.
   * @param componentCountHint Hint for how many components in total will
   *      be added to the created objects afterwards, default `0`.
   * @returns Newly created objects
   */
  addObjects(count2, parent = null, componentCountHint = 0) {
    const parentId = parent ? parent.objectId : 0;
    this._engine.wasm.requireTempMem(count2 * 2);
    const actualCount = this._engine.wasm._wl_scene_add_objects(parentId, count2, componentCountHint || 0, this._engine.wasm._tempMem, this._engine.wasm._tempMemSize >> 1);
    const ids = this._engine.wasm._tempMemUint16.subarray(0, actualCount);
    const wrapper = this._engine.wrapObject.bind(this._engine);
    const objects = Array.from(ids, wrapper);
    return objects;
  }
  /**
   * Pre-allocate memory for a given amount of objects and components.
   *
   * Will provide better performance for adding objects later with {@link Scene#addObject}
   * and {@link Scene#addObjects}.
   *
   * By providing upfront information of how many objects will be required,
   * the engine is able to batch-allocate the required memory rather than
   * conservatively grow the memory in small steps.
   *
   * **Experimental:** This API might change in upcoming versions.
   *
   * @param objectCount Number of objects to add.
   * @param componentCountPerType Amount of components to
   *      allocate for {@link Object3D.addComponent}, e.g. `{mesh: 100, collision: 200, "my-comp": 100}`.
   * @since 0.8.10
   */
  reserveObjects(objectCount, componentCountPerType) {
    const wasm = this._engine.wasm;
    componentCountPerType = componentCountPerType || {};
    const jsManagerIndex = wasm._jsManagerIndex;
    let countsPerTypeIndex = wasm._tempMemInt.subarray();
    countsPerTypeIndex.fill(0);
    for (const e of Object.entries(componentCountPerType)) {
      const typeIndex = wasm._typeIndexFor(e[0]);
      countsPerTypeIndex[typeIndex < 0 ? jsManagerIndex : typeIndex] += e[1];
    }
    wasm._wl_scene_reserve_objects(objectCount, wasm._tempMem);
  }
  /**
   * Set the background clear color.
   *
   * @param color new clear color (RGBA).
   * @since 0.8.5
   */
  set clearColor(color) {
    this._engine.wasm._wl_scene_set_clearColor(color[0], color[1], color[2], color[3]);
  }
  /**
   * Set whether to clear the color framebuffer before drawing.
   *
   * This function is useful if an external framework (e.g. an AR tracking
   * framework) is responsible for drawing a camera frame before Wonderland
   * Engine draws the scene on top of it.
   *
   * @param b Whether to enable color clear.
   * @since 0.9.4
   */
  set colorClearEnabled(b) {
    this._engine.wasm._wl_scene_enableColorClear(b);
  }
  /** Hosting engine instance. */
  get engine() {
    return this._engine;
  }
  /**
   * Load a scene file (.bin).
   *
   * Will replace the currently active scene with the one loaded
   * from given file. It is assumed that JavaScript components required by
   * the new scene were registered in advance.
   *
   * Once the scene is loaded successfully and initialized,
   * {@link WonderlandEngine.onSceneLoaded} is notified.
   *
   * #### ArrayBuffer
   *
   * The `load()` method accepts an in-memory buffer:
   *
   * ```js
   * scene.load({
   *     buffer: new ArrayBuffer(...),
   *     baseURL: 'https://my-website/assets'
   * })
   * ```
   *
   * @note The `baseURL` is mandatory. It's used to fetch images and languages.
   *
   * Use {@link Scene.setLoadingProgress} to update the loading progress bar
   * when using an ArrayBuffer.
   *
   * @param opts Path to the file to load, or an option object.
   *     For more information about the options, see the {@link SceneLoadOptions} documentation.
   * @returns Promise that resolves when the scene was loaded.
   */
  async load(options) {
    let buffer2 = null;
    let baseURL = null;
    let filename = null;
    if (isString(options)) {
      filename = options;
      buffer2 = await fetchWithProgress(filename, (bytes, size2) => {
        console.log(`Scene downloading: ${bytes} / ${size2}`);
        this.setLoadingProgress(bytes / size2);
      });
      baseURL = getBaseUrl(filename);
      console.log(`Scene download of ${buffer2.byteLength} bytes successful.`);
    } else {
      ({ buffer: buffer2, baseURL } = options);
      filename = baseURL ? `${baseURL}/scene.bin` : "scene.bin";
    }
    if (!buffer2) {
      throw new Error("Failed to load scene, buffer not provided");
    }
    if (!isString(baseURL)) {
      throw new Error("Failed to load scene, baseURL not provided");
    }
    this._baseURL = baseURL;
    const wasm = this._engine.wasm;
    const size = buffer2.byteLength;
    const ptr = wasm._malloc(size);
    new Uint8Array(wasm.HEAPU8.buffer, ptr, size).set(new Uint8Array(buffer2));
    try {
      wasm._wl_load_scene_bin(ptr, size, wasm.tempUTF8(filename));
    } finally {
      wasm._free(ptr);
    }
    const i18n = this._engine.i18n;
    const langPromise = i18n.setLanguage(i18n.languageCode(0));
    await Promise.all([langPromise, this._flushAppend(this._baseURL)]);
    this._engine.onSceneLoaded.notify();
  }
  /**
   * Append a scene file.
   *
   * Loads and parses the file and its images and appends the result
   * to the currently active scene.
   *
   * Supported formats are streamable Wonderland scene files (.bin) and glTF
   * 3D scenes (.gltf, .glb).
   *
   * ```js
   * WL.scene.append(filename).then(root => {
   *     // root contains the loaded scene
   * });
   * ```
   *
   * In case the `loadGltfExtensions` option is set to true, the response
   * will be an object containing both the root of the loaded scene and
   * any glTF extensions found on nodes, meshes and the root of the file.
   *
   * ```js
   * WL.scene.append(filename, { loadGltfExtensions: true }).then(({root, extensions}) => {
   *     // root contains the loaded scene
   *     // extensions.root contains any extensions at the root of glTF document
   *     const rootExtensions = extensions.root;
   *     // extensions.mesh and extensions.node contain extensions indexed by Object id
   *     const childObject = root.children[0];
   *     const meshExtensions = root.meshExtensions[childObject.objectId];
   *     const nodeExtensions = root.nodeExtensions[childObject.objectId];
   *     // extensions.idMapping contains a mapping from glTF node index to Object id
   * });
   * ```
   *
   * If the file to be loaded is located in a subfolder, it might be useful
   * to define the `baseURL` option. This will ensure any bin files
   * referenced by the loaded bin file are loaded at the correct path.
   *
   * ```js
   * WL.scene.append(filename, { baseURL: 'scenes' }).then(({root, extensions}) => {
   *     // do stuff
   * });
   * ```
   *
   * @param file The .bin, .gltf or .glb file to append. Should be a URL or
   *   an `ArrayBuffer` with the file content.
   * @param options Additional options for loading.
   * @returns Promise that resolves when the scene was appended.
   */
  async append(file, options = {}) {
    const { loadGltfExtensions = false, baseURL = isString(file) ? getBaseUrl(file) : this._baseURL } = options;
    const wasm = this._engine.wasm;
    const buffer2 = isString(file) ? await fetchWithProgress(file) : file;
    let error = null;
    let result = void 0;
    let callback = wasm.addFunction((objectId, extensionData, extensionDataSize) => {
      if (objectId < 0) {
        error = new Error(`Scene.append(): Internal runtime error, found root id = ${objectId}`);
        return;
      }
      const root = objectId ? this._engine.wrapObject(objectId) : null;
      result = root;
      if (!extensionData || !extensionDataSize)
        return;
      const marshalled = new Uint32Array(wasm.HEAPU32.buffer, extensionData, extensionDataSize / 4);
      const extensions = this._unmarshallGltfExtensions(marshalled);
      result = { root, extensions };
    }, "viii");
    const size = buffer2.byteLength;
    const ptr = wasm._malloc(size);
    const data = new Uint8Array(wasm.HEAPU8.buffer, ptr, size);
    data.set(new Uint8Array(buffer2));
    const isBinFile = data.byteLength > MAGIC_BIN.length && data.subarray(0, MAGIC_BIN.length).every((value, i) => value === MAGIC_BIN.charCodeAt(i));
    try {
      if (isBinFile) {
        wasm._wl_append_scene_bin(ptr, size, callback);
      } else {
        wasm._wl_append_scene_gltf(ptr, size, loadGltfExtensions, callback);
      }
    } catch (e) {
      wasm.removeFunction(callback);
      throw e;
    } finally {
      wasm._free(ptr);
    }
    while (result === void 0 && !error)
      await timeout(4);
    wasm.removeFunction(callback);
    if (error)
      throw error;
    if (isBinFile)
      await this._flushAppend(baseURL);
    return result;
  }
  /**
   * Update the loading screen progress bar.
   *
   * @param value Current loading percentage, in the range [0; 1].
   */
  setLoadingProgress(percentage) {
    const wasm = this.engine.wasm;
    wasm._wl_set_loading_screen_progress(clamp(percentage, 0, 1));
  }
  /**
   * Set the current material to render the sky.
   *
   * @note The sky needs to be enabled in the editor when creating the scene.
   * For more information, please refer to the background [tutorial](https://wonderlandengine.com/tutorials/background-effect/).
   */
  set skyMaterial(material) {
    this._engine.wasm._wl_scene_set_sky_material(material?._index ?? 0);
  }
  /** Current sky material, or `null` if no sky is set. */
  get skyMaterial() {
    const id = this._engine.wasm._wl_scene_get_sky_material();
    return id > 0 ? new Material(this._engine, id) : null;
  }
  /**
   * Load all currently queued bin files.
   *
   * Used by {@link Scene.append} and {@link Scene.load}
   * to load all delay-load bins.
   *
   * Used by {@link I18N.language} to trigger loading the
   * associated language bin, after it was queued.
   *
   * @param baseURL Url that is added to each path.
   * @param options Additional options for loading.
   *
   * @hidden
   */
  _flushAppend(baseURL) {
    const wasm = this._engine.wasm;
    const count2 = wasm._wl_scene_queued_bin_count();
    if (!count2)
      return Promise.resolve();
    const urls = new Array(count2).fill(0).map((_, i) => {
      const ptr = wasm._wl_scene_queued_bin_path(i);
      return wasm.UTF8ToString(ptr);
    });
    wasm._wl_scene_clear_queued_bin_list();
    const promises = urls.map((path) => this.append(baseURL.length ? `${baseURL}/${path}` : path));
    return Promise.all(promises).then((data) => {
      const i18n = this._engine.i18n;
      this._engine.i18n.onLanguageChanged.notify(i18n.previousIndex, i18n.currentIndex);
      return data;
    });
  }
  /**
   * Unmarshalls the GltfExtensions from an Uint32Array.
   *
   * @param data Array containing the gltf extension data.
   * @returns The extensions stored in an object literal.
   *
   * @hidden
   */
  _unmarshallGltfExtensions(data) {
    const extensions = {
      root: {},
      mesh: {},
      node: {},
      idMapping: []
    };
    let index = 0;
    const readString = () => {
      const strPtr = data[index++];
      const strLen = data[index++];
      return this._engine.wasm.UTF8ViewToString(strPtr, strPtr + strLen);
    };
    const idMappingSize = data[index++];
    const idMapping = new Array(idMappingSize);
    for (let i = 0; i < idMappingSize; ++i) {
      idMapping[i] = data[index++];
    }
    extensions.idMapping = idMapping;
    const meshExtensionsSize = data[index++];
    for (let i = 0; i < meshExtensionsSize; ++i) {
      const objectId = data[index++];
      extensions.mesh[idMapping[objectId]] = JSON.parse(readString());
    }
    const nodeExtensionsSize = data[index++];
    for (let i = 0; i < nodeExtensionsSize; ++i) {
      const objectId = data[index++];
      extensions.node[idMapping[objectId]] = JSON.parse(readString());
    }
    const rootExtensionsStr = readString();
    if (rootExtensionsStr) {
      extensions.root = JSON.parse(rootExtensionsStr);
    }
    return extensions;
  }
  /**
   * Reset the scene.
   *
   * This method deletes all used and allocated objects, and components.
   */
  reset() {
    this._engine.wasm._wl_scene_reset();
    this._baseURL = "";
  }
};

// node_modules/@wonderlandengine/api/dist/texture-manager.js
var TextureManager = class {
  /** Wonderland Engine instance. @hidden */
  _engine;
  /** Texture cache. @hidden */
  #cache = [];
  /** @hidden */
  constructor(engine3) {
    this._engine = engine3;
  }
  /**
   * Retrieve the texture with the given id.
   *
   * @param id The texture identifier.
   * @return The {@link Texture} if found, `null` otherwise.
   */
  get(id) {
    return this.#cache[id] ?? null;
  }
  /**
   * Load an image from URL as {@link Texture}.
   *
   * @param filename URL to load from.
   * @param crossOrigin Cross origin flag for the image object.
   * @returns Loaded texture.
   */
  load(filename, crossOrigin) {
    let image2 = new Image();
    image2.crossOrigin = crossOrigin ?? image2.crossOrigin;
    image2.src = filename;
    return new Promise((resolve, reject) => {
      image2.onload = () => {
        let texture = new Texture(this._engine, image2);
        if (!texture.valid) {
          reject("Failed to add image " + image2.src + " to texture atlas. Probably incompatible format.");
        }
        resolve(texture);
      };
      image2.onerror = function() {
        reject("Failed to load image. Not found or no read access");
      };
    });
  }
  /**
   * Wrap a texture ID using {@link Texture}.
   *
   * @note This method performs caching and will return the same
   * instance on subsequent calls.
   *
   * @param id ID of the texture to create.
   *
   * @returns The texture.
   */
  wrap(id) {
    const texture = this.#cache[id] ?? (this.#cache[id] = new Texture(this._engine, id));
    texture["_id"] = id;
    return texture;
  }
  /** Number of textures allocated in the manager. */
  get allocatedCount() {
    return this.#cache.length;
  }
  /**
   * Number of textures in the manager.
   *
   * @note For performance reasons, avoid calling this method when possible.
   */
  get count() {
    let count2 = 0;
    for (const tex of this.#cache) {
      if (tex && tex.id >= 0)
        ++count2;
    }
    return count2;
  }
  /**
   * Set a new texture in the manager cache.
   *
   * @note This api is meant to be used internally.
   *
   * @param texture The texture to add.
   *
   * @hidden
   */
  _set(texture) {
    this.#cache[texture.id] = texture;
  }
  /**
   * Destroys the texture.
   *
   * @note This api is meant to be used internally.
   *
   * @param texture The texture to destroy.
   *
   * @hidden
   */
  _destroy(texture) {
    this._engine.wasm._wl_texture_destroy(texture.id);
    const img = texture["_imageIndex"];
    if (img !== null) {
      this._engine.wasm._images[img] = null;
    }
  }
  /**
   * Reset the manager.
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _reset() {
    this.#cache.length = 0;
  }
};

// node_modules/@wonderlandengine/api/dist/engine.js
var WonderlandEngine = class {
  /**
   * {@link Emitter} for WebXR session end events.
   *
   * Usage from a within a component:
   * ```js
   * this.engine.onXRSessionEnd.add(() => console.log("XR session ended."));
   * ```
   */
  onXRSessionEnd = new Emitter();
  /**
   * {@link Emitter} for WebXR session start events.
   *
   * Usage from a within a component:
   * ```js
   * this.engine.onXRSessionStart.add((session, mode) => console.log(session, mode));
   * ```
   *
   * By default, this emitter is retained and will automatically call any callback added
   * while a session is already started:
   *
   * ```js
   * // XR session is already active.
   * this.engine.onXRSessionStart.add((session, mode) => {
   *     console.log(session, mode); // Triggered immediately.
   * });
   * ```
   */
  onXRSessionStart = new RetainEmitter();
  /**
   * {@link Emitter} for canvas / main framebuffer resize events.
   *
   * Usage from a within a component:
   * ```js
   * this.engine.onResize.add(() => {
   *     const canvas = this.engine.canvas;
   *     console.log(`New Size: ${canvas.width}, ${canvas.height}`);
   * });
   * ```
   *
   * @note The size of the canvas is in physical pixels, and is set via {@link WonderlandEngine.resize}.
   */
  onResize = new Emitter();
  /** Whether AR is supported by the browser. */
  arSupported = false;
  /** Whether VR is supported by the browser. */
  vrSupported = false;
  /**
   * {@link Emitter} for scene loaded events.
   *
   * Listeners get notified when a call to {@link Scene#load()} finishes,
   * which also happens after the main scene has replaced the loading screen.
   *
   * Usage from a within a component:
   * ```js
   * this.engine.onSceneLoaded.add(() => console.log("Scene switched!"));
   * ```
   */
  onSceneLoaded = new Emitter();
  /**
   * Current main scene.
   */
  scene = null;
  /**
   * Access to internationalization.
   */
  i18n = new I18N(this);
  /**
   * WebXR related state, `null` if no XR session is active.
   */
  xr = null;
  /**
   * If `true`, {@link Texture}, {@link Object3D}, and {@link Component}
   * instances have their prototype erased upon destruction.
   *
   * #### Object
   *
   * ```js
   * engine.erasePrototypeOnDestroy = true;
   *
   * const obj = engine.scene.addObject();
   * obj.name = 'iamalive';
   * console.log(obj.name); // Prints 'iamalive'
   *
   * obj.destroy();
   * console.log(obj.name); // Throws an error
   * ```
   *
   * #### Component
   *
   * Components will also be affected:
   *
   * ```js
   * class MyComponent extends Component {
   *     static TypeName = 'my-component';
   *     static Properties = {
   *         alive: Property.bool(true)
   *     };
   *
   *     start() {
   *         this.destroy();
   *         console.log(this.alive) // Throws an error
   *     }
   * }
   * ```
   *
   * A component is also destroyed if its ancestor gets destroyed:
   *
   * ```js
   * class MyComponent extends Component {
   *     ...
   *     start() {
   *         this.object.parent.destroy();
   *         console.log(this.alive) // Throws an error
   *     }
   * }
   * ```
   *
   * @note Native components will not be erased if destroyed via object destruction:
   *
   * ```js
   * const mesh = obj.addComponent('mesh');
   * obj.destroy();
   * console.log(mesh.active) // Doesn't throw even if the mesh is destroyed
   * ```
   *
   * @since 1.1.1
   */
  erasePrototypeOnDestroy = false;
  /**
   * Component class instances per type to avoid GC.
   *
   * @note Maps the manager index to the list of components.
   *
   * @hidden
   */
  _componentCache = {};
  /** Object class instances to avoid GC. @hidden */
  _objectCache = [];
  /**
   * WebAssembly bridge.
   *
   * @hidden
   */
  #wasm;
  /**
   * Physics manager, only available when physx is enabled in the runtime.
   *
   * @hidden
   */
  #physics = null;
  /** Texture manager. @hidden */
  #textures = new TextureManager(this);
  /**
   * Resize observer to track for canvas size changes.
   *
   * @hidden
   */
  #resizeObserver = null;
  /**
   * Create a new engine instance.
   *
   * @param wasm Wasm bridge instance
   * @param loadingScreen Loading screen .bin file data
   *
   * @hidden
   */
  constructor(wasm, loadingScreen) {
    this.#wasm = wasm;
    this.#wasm["_setEngine"](this);
    this.#wasm._loadingScreen = loadingScreen;
    this._componentCache = {};
    this._objectCache.length = 0;
    this.canvas.addEventListener("webglcontextlost", function(e) {
      console.error("Context lost:");
      console.error(e);
    }, false);
  }
  /**
   * Start the engine if it's not already running.
   *
   * When using the {@link loadRuntime} function, this method is called
   * automatically.
   */
  start() {
    this.wasm._wl_application_start();
  }
  /**
   * Register a custom JavaScript component type.
   *
   * You can register a component directly using a class inheriting from {@link Component}:
   *
   * ```js
   * import { Component, Type } from '@wonderlandengine/api';
   *
   * export class MyComponent extends Component {
   *     static TypeName = 'my-component';
   *     static Properties = {
   *         myParam: {type: Type.Float, default: 42.0},
   *     };
   *     init() {}
   *     start() {}
   *     update(dt) {}
   *     onActivate() {}
   *     onDeactivate() {}
   *     onDestroy() {}
   * });
   *
   * // Here, we assume we have an engine already instantiated.
   * // In general, the registration occurs in the `index.js` file in your
   * // final application.
   * engine.registerComponent(MyComponent);
   * ```
   *
   * {@label CLASSES}
   * @param classes Custom component(s) extending {@link Component}.
   *
   * @since 1.0.0
   */
  registerComponent(...classes) {
    for (const arg of classes) {
      this.wasm._registerComponent(arg);
    }
  }
  /**
   * Checks whether the given component is registered or not.
   *
   * @param typeOrClass A string representing the component typename (e.g., `'cursor-component'`),
   *     or a component class (e.g., `CursorComponent`).
   * @returns `true` if the component is registered, `false` otherwise.
   */
  isRegistered(typeOrClass) {
    return this.#wasm.isRegistered(isString(typeOrClass) ? typeOrClass : typeOrClass.TypeName);
  }
  /**
   * Resize the canvas and the rendering context.
   *
   * @note The `width` and `height` parameters will be scaled by the
   * `devicePixelRatio` value. By default, the pixel ratio used is
   * [window.devicePixelRatio](https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio).
   *
   * @param width The width, in CSS pixels.
   * @param height The height, in CSS pixels.
   * @param devicePixelRatio The pixel ratio factor.
   */
  resize(width, height, devicePixelRatio = window.devicePixelRatio) {
    width = width * devicePixelRatio;
    height = height * devicePixelRatio;
    this.canvas.width = width;
    this.canvas.height = height;
    this.wasm._wl_application_resize(width, height);
    this.onResize.notify();
  }
  /**
   * Run the next frame.
   *
   * @param fixedDelta The elapsed time between this frame and the previous one.
   *
   * @note The engine automatically schedules next frames. You should only
   * use this method for testing.
   */
  nextFrame(fixedDelta = 0) {
    this.#wasm._wl_nextFrame(fixedDelta);
  }
  /**
   * Request a XR session.
   *
   * @note Please use this call instead of directly calling `navigator.xr.requestSession()`.
   * Wonderland Engine requires to be aware that a session is started, and this
   * is done through this call.
   *
   * @param mode The XR mode.
   * @param features An array of required features, e.g., `['local-floor', 'hit-test']`.
   * @param optionalFeatures An array of optional features, e.g., `['bounded-floor', 'depth-sensing']`.
   * @returns A promise resolving with the `XRSession`, a string error message otherwise.
   */
  requestXRSession(mode, features, optionalFeatures = []) {
    if (!navigator.xr) {
      const isLocalhost = location.hostname === "localhost" || location.hostname === "127.0.0.1";
      const missingHTTPS = location.protocol !== "https:" && !isLocalhost;
      return Promise.reject(missingHTTPS ? "WebXR is only supported with HTTPS or on localhost!" : "WebXR unsupported in this browser.");
    }
    return this.#wasm.webxr_requestSession(mode, features, optionalFeatures);
  }
  /**
   * Wrap an object ID using {@link Object}.
   *
   * @note This method performs caching and will return the same
   * instance on subsequent calls.
   *
   * @param objectId ID of the object to create.
   *
   * @returns The object
   */
  wrapObject(objectId) {
    const cache11 = this._objectCache;
    const o = cache11[objectId] || (cache11[objectId] = new Object3D(this, objectId));
    o["_objectId"] = objectId;
    return o;
  }
  /* Public Getters & Setter */
  /**
   * WebAssembly bridge.
   *
   * @note Use with care. This object is used to communicate
   * with the WebAssembly code throughout the api.
   *
   * @hidden
   */
  get wasm() {
    return this.#wasm;
  }
  /** Canvas element that Wonderland Engine renders to. */
  get canvas() {
    return this.#wasm.canvas;
  }
  /**
   * Current WebXR session or `null` if no session active.
   *
   * @deprecated Use {@link XR.session} on the {@link xr}
   * object instead.
   */
  get xrSession() {
    return this.xr?.session ?? null;
  }
  /**
   * Current WebXR frame or `null` if no session active.
   *
   * @deprecated Use {@link XR.frame} on the {@link xr}
   * object instead.
   */
  get xrFrame() {
    return this.xr?.frame ?? null;
  }
  /**
   * Current WebXR base layer or `null` if no session active.
   *
   * @deprecated Use {@link XR.baseLayer} on the {@link xr}
   * object instead.
   */
  get xrBaseLayer() {
    return this.xr?.baseLayer ?? null;
  }
  /**
   * Current WebXR framebuffer or `null` if no session active.
   *
   * @deprecated Use {@link XR.framebuffers} on the
   * {@link xr} object instead.
   */
  get xrFramebuffer() {
    return this.xr?.framebuffers[0] ?? null;
  }
  /** Framebuffer scale factor. */
  get xrFramebufferScaleFactor() {
    return this.#wasm.webxr_framebufferScaleFactor;
  }
  set xrFramebufferScaleFactor(value) {
    this.#wasm.webxr_framebufferScaleFactor = value;
  }
  /** Physics manager, only available when physx is enabled in the runtime. */
  get physics() {
    return this.#physics;
  }
  /**
   * Texture managger.
   *
   * Use this to load or programmatically create new textures at runtime.
   */
  get textures() {
    return this.#textures;
  }
  /*
   * Enable or disable the mechanism to automatically resize the canvas.
   *
   * Internally, the engine uses a [ResizeObserver](https://developer.mozilla.org/en-US/docs/Web/API/ResizeObserver).
   * Changing the canvas css will thus automatically be tracked by the engine.
   */
  set autoResizeCanvas(flag) {
    const state = !!this.#resizeObserver;
    if (state === flag)
      return;
    if (!flag) {
      this.#resizeObserver?.unobserve(this.canvas);
      this.#resizeObserver = null;
      return;
    }
    this.#resizeObserver = new ResizeObserver((entries) => {
      for (const entry of entries) {
        if (entry.target === this.canvas) {
          this.resize(entry.contentRect.width, entry.contentRect.height);
        }
      }
    });
    this.#resizeObserver.observe(this.canvas);
  }
  /** `true` if the canvas is automatically resized by the engine. */
  get autoResizeCanvas() {
    return this.#resizeObserver !== null;
  }
  /** Retrieves the runtime version. */
  get runtimeVersion() {
    const wasm = this.#wasm;
    const v = wasm._wl_application_version(wasm._tempMem);
    return {
      major: wasm._tempMemUint16[0],
      minor: wasm._tempMemUint16[1],
      patch: wasm._tempMemUint16[2],
      rc: wasm._tempMemUint16[3]
    };
  }
  /* Internal-Only Methods */
  /**
   * Initialize the engine.
   *
   * @note Should be called after the WebAssembly is fully loaded.
   *
   * @hidden
   */
  _init() {
    this.scene = new Scene(this);
    this.#wasm._wl_set_error_callback(this.#wasm.addFunction((messagePtr) => {
      throw new Error(this.#wasm.UTF8ToString(messagePtr));
    }, "vi"));
    this.#physics = null;
    if (this.#wasm.withPhysX) {
      const physics = new Physics(this);
      this.#wasm._wl_physx_set_collision_callback(this.#wasm.addFunction((a, index, type, b) => {
        const callback = physics._callbacks[a][index];
        const component = new PhysXComponent(this, this.wasm._typeIndexFor("physx"), b);
        callback(type, component);
      }, "viiii"));
      this.#physics = physics;
    }
    this.resize(this.canvas.clientWidth, this.canvas.clientHeight);
  }
  /**
   * Reset the runtime state, including:
   *     - Component cache
   *     - Images
   *     - Callbacks
   *
   * @note This api is meant to be used internally.
   *
   * @hidden
   */
  _reset() {
    this._componentCache = {};
    this._objectCache.length = 0;
    this.#textures._reset();
    this.scene.reset();
    this.wasm.reset();
  }
  /**
   * Retrieves a component instance if it exists, or create and cache
   * a new one.
   *
   * @note This api is meant to be used internally. Please have a look at
   * {@link Object3D.addComponent} instead.
   *
   * @param type component type name
   * @param componentType Component manager index
   * @param componentId Component id in the manager
   *
   * @returns JavaScript instance wrapping the native component
   *
   * @hidden
   */
  _wrapComponent(type, componentType, componentId) {
    if (componentId < 0)
      return null;
    const c = this._componentCache[componentType] || (this._componentCache[componentType] = []);
    if (c[componentId]) {
      return c[componentId];
    }
    let component;
    if (type == "collision") {
      component = new CollisionComponent(this, componentType, componentId);
    } else if (type == "text") {
      component = new TextComponent(this, componentType, componentId);
    } else if (type == "view") {
      component = new ViewComponent(this, componentType, componentId);
    } else if (type == "mesh") {
      component = new MeshComponent(this, componentType, componentId);
    } else if (type == "input") {
      component = new InputComponent(this, componentType, componentId);
    } else if (type == "light") {
      component = new LightComponent(this, componentType, componentId);
    } else if (type == "animation") {
      component = new AnimationComponent(this, componentType, componentId);
    } else if (type == "physx") {
      component = new PhysXComponent(this, componentType, componentId);
    } else {
      const typeIndex = this.wasm._componentTypeIndices[type];
      const constructor = this.wasm._componentTypes[typeIndex];
      component = new constructor(this);
    }
    component._engine = this;
    component._manager = componentType;
    component._id = componentId;
    c[componentId] = component;
    return component;
  }
  /**
   * Perform cleanup upon object destruction.
   *
   * @param instance The instance to destroy.
   *
   * @hidden
   */
  _destroyObject(instance) {
    const id = instance.objectId;
    instance._objectId = -1;
    if (this.erasePrototypeOnDestroy && instance) {
      Object.setPrototypeOf(instance, DestroyedObjectInstance);
    }
    this._objectCache[id] = null;
  }
  /**
   * Perform cleanup upon component destruction.
   *
   * @param instance The instance to destroy.
   *
   * @hidden
   */
  _destroyComponent(instance) {
    const id = instance._id;
    const manager = instance._manager;
    instance._id = -1;
    instance._manager = -1;
    if (this.erasePrototypeOnDestroy && instance) {
      Object.setPrototypeOf(instance, DestroyedComponentInstance);
    }
    const cache11 = this._componentCache[manager];
    if (cache11)
      cache11[id] = null;
  }
  /**
   * Perform cleanup upon texture destruction.
   *
   * @param texture The instance to destroy.
   *
   * @hidden
   */
  _destroyTexture(texture) {
    this.textures._destroy(texture);
    if (this.erasePrototypeOnDestroy) {
      Object.setPrototypeOf(texture, DestroyedTextureInstance);
    }
  }
};

// node_modules/@wonderlandengine/api/dist/wasm.js
var _componentDefaults = /* @__PURE__ */ new Map([
  [Type.Bool, false],
  [Type.Int, 0],
  [Type.Float, 0],
  [Type.String, ""],
  [Type.Enum, void 0],
  [Type.Object, null],
  [Type.Mesh, null],
  [Type.Texture, null],
  [Type.Material, null],
  [Type.Animation, null],
  [Type.Skin, null],
  [Type.Color, [0, 0, 0, 1]]
]);
function _setupDefaults(ctor) {
  for (const name in ctor.Properties) {
    const p2 = ctor.Properties[name];
    if (p2.type === Type.Enum) {
      if (p2.values?.length) {
        if (typeof p2.default !== "number") {
          p2.default = p2.values.indexOf(p2.default);
        }
        if (p2.default < 0 || p2.default >= p2.values.length) {
          p2.default = 0;
        }
      } else {
        p2.default = void 0;
      }
    } else {
      p2.default = p2.default ?? _componentDefaults.get(p2.type);
    }
    ctor.prototype[name] = p2.default;
  }
}
var WASM = class {
  /**
   * Emscripten worker field.
   *
   * @note This api is meant to be used internally.
   */
  worker = "";
  /**
   * Emscripten wasm field.
   *
   * @note This api is meant to be used internally.
   */
  wasm = null;
  /**
   * Emscripten canvas.
   *
   * @note This api is meant to be used internally.
   */
  canvas = null;
  /** Current WebXR  */
  /**
   * Emscripten WebXR session.
   *
   * @note This api is meant to be used internally.
   */
  webxr_session = null;
  /**
   * Emscripten WebXR request session callback.
   *
   * @note This api is meant to be used internally.
   */
  webxr_requestSession = null;
  /**
   * Emscripten WebXR frame.
   *
   * @note This api is meant to be used internally.
   */
  webxr_frame = null;
  /**
   * Emscripten current WebXR reference space.
   *
   * @note This api is meant to be used internally.
   */
  webxr_refSpace = null;
  /**
   * Emscripten WebXR reference spaces.
   *
   * @note This api is meant to be used internally.
   */
  webxr_refSpaces = null;
  /**
   * Emscripten WebXR current reference space type.
   *
   * @note This api is meant to be used internally.
   */
  webxr_refSpaceType = null;
  /**
   * Emscripten WebXR GL projection layer.
   *
   * @note This api is meant to be used internally.
   */
  webxr_baseLayer = null;
  /**
   * Emscripten WebXR framebuffer scale factor.
   *
   * @note This api is meant to be used internally.
   */
  webxr_framebufferScaleFactor = 1;
  /**
   * Emscripten WebXR framebuffer(s).
   *
   * @note This api is meant to be used internally.
   */
  /* webxr_fbo will not get overwritten if we are rendering to the
   * default framebuffer, e.g., when using WebXR emulator. */
  webxr_fbo = 0;
  /**
   * Convert a WASM memory view to a JavaScript string.
   *
   * @param ptr Pointer start
   * @param ptrEnd Pointer end
   * @returns JavaScript string
   */
  UTF8ViewToString;
  /** If `true`, logs will not spam the console on error. */
  _deactivate_component_on_error = false;
  /** Temporary memory pointer. */
  _tempMem = null;
  /** Temporary memory size. */
  _tempMemSize = 0;
  /** Temporary float memory view. */
  _tempMemFloat = null;
  /** Temporary int memory view. */
  _tempMemInt = null;
  /** Temporary uint8 memory view. */
  _tempMemUint8 = null;
  /** Temporary uint32 memory view. */
  _tempMemUint32 = null;
  /** Temporary uint16 memory view. */
  _tempMemUint16 = null;
  /** Loading screen .bin file data */
  _loadingScreen = null;
  /** List of callbacks triggered when the scene is loaded. */
  _sceneLoadedCallback = [];
  /**
   * Material definition cache. Each pipeline has its own
   * associated material definition.
   */
  _materialDefinitions = [];
  /** Image cache. */
  _images = [];
  /** Component instances. */
  _components = [];
  /** Component Type info. */
  _componentTypes = [];
  /** Index per component type name. */
  _componentTypeIndices = {};
  /** Wonderland engine instance. */
  _engine = null;
  /**
   * `true` if this runtime is using physx.
   *
   * @note This api is meant to be used internally.
   */
  _withPhysX = false;
  /** Decoder for UTF8 `ArrayBuffer` to JavaScript string. */
  _utf8Decoder = new TextDecoder("utf8");
  /** JavaScript manager index. */
  _jsManagerIndexCached = null;
  /**
   * Registration index of {@link BrokenComponent}.
   *
   * This is used to return dummy instances when a component
   * isn't registered.
   *
   * @hidden
   */
  _brokenComponentIndex = 0;
  /**
   * Create a new instance of the WebAssembly <> API bridge.
   *
   * @param threads `true` if the runtime used has threads support
   */
  constructor(threads2) {
    if (threads2) {
      this.UTF8ViewToString = (s, e) => {
        if (!s)
          return "";
        return this._utf8Decoder.decode(this.HEAPU8.slice(s, e));
      };
      return;
    }
    this.UTF8ViewToString = (s, e) => {
      if (!s)
        return "";
      return this._utf8Decoder.decode(this.HEAPU8.subarray(s, e));
    };
    this._brokenComponentIndex = this._registerComponent(BrokenComponent);
  }
  /**
   * Reset the cache of the library.
   *
   * @note Should only be called when tearing down the runtime.
   */
  reset() {
    this.allocateTempMemory(1024);
    this._materialDefinitions = [];
    this._images = [];
    this._components = [];
    this._componentTypes = [];
    this._componentTypeIndices = {};
    this._jsManagerIndexCached = null;
    this._brokenComponentIndex = this._registerComponent(BrokenComponent);
  }
  /**
   * Checks whether the given component is registered or not.
   *
   * @param ctor  A string representing the component typename (e.g., `'cursor-component'`).
   * @returns `true` if the component is registered, `false` otherwise.
   */
  isRegistered(type) {
    return type in this._componentTypeIndices;
  }
  /**
   * Register a legacy component in this Emscripten instance.
   *
   * @note This api is meant to be used internally.
   *
   * @param typeName The name of the component.
   * @param params An object containing the parameters (properties).
   * @param object The object's prototype.
   * @returns The registration index
   */
  _registerComponentLegacy(typeName, params, object) {
    const ctor = class CustomComponent extends Component {
    };
    ctor.TypeName = typeName;
    ctor.Properties = params;
    Object.assign(ctor.prototype, object);
    return this._registerComponent(ctor);
  }
  /**
   * Register a class component in this Emscripten instance.
   *
   * @note This api is meant to be used internally.
   *
   * @param ctor The class to register.
   * @returns The registration index.
   */
  _registerComponent(ctor) {
    if (!ctor.TypeName)
      throw new Error("no name provided for component.");
    if (!ctor.prototype._triggerInit) {
      throw new Error(`registerComponent(): Component ${ctor.TypeName} must extend Component`);
    }
    inheritProperties(ctor);
    _setupDefaults(ctor);
    const typeIndex = ctor.TypeName in this._componentTypeIndices ? this._componentTypeIndices[ctor.TypeName] : this._componentTypes.length;
    this._componentTypes[typeIndex] = ctor;
    this._componentTypeIndices[ctor.TypeName] = typeIndex;
    if (ctor === BrokenComponent)
      return typeIndex;
    console.log("Registered component", ctor.TypeName, `(class ${ctor.name})`, "with index", typeIndex);
    if (ctor.onRegister)
      ctor.onRegister(this._engine);
    return typeIndex;
  }
  /**
   * Allocate the requested amount of temporary memory
   * in this WASM instance.
   *
   * @param size The number of bytes to allocate
   */
  allocateTempMemory(size) {
    console.log("Allocating temp mem:", size);
    this._tempMemSize = size;
    if (this._tempMem)
      this._free(this._tempMem);
    this._tempMem = this._malloc(this._tempMemSize);
    this.updateTempMemory();
  }
  /**
   * @todo: Delete this and only keep `allocateTempMemory`
   *
   * @param size Number of bytes to allocate
   */
  requireTempMem(size) {
    if (this._tempMemSize >= size)
      return;
    this.allocateTempMemory(Math.ceil(size / 1024) * 1024);
  }
  /**
   * Update the temporary memory views. This must be called whenever the
   * temporary memory address changes.
   *
   * @note This api is meant to be used internally.
   */
  updateTempMemory() {
    this._tempMemFloat = new Float32Array(this.HEAP8.buffer, this._tempMem, this._tempMemSize >> 2);
    this._tempMemInt = new Int32Array(this.HEAP8.buffer, this._tempMem, this._tempMemSize >> 2);
    this._tempMemUint32 = new Uint32Array(this.HEAP8.buffer, this._tempMem, this._tempMemSize >> 2);
    this._tempMemUint16 = new Uint16Array(this.HEAP8.buffer, this._tempMem, this._tempMemSize >> 1);
    this._tempMemUint8 = new Uint8Array(this.HEAP8.buffer, this._tempMem, this._tempMemSize);
  }
  /**
   * Returns a uint8 buffer view on temporary WASM memory.
   *
   * **Note**: this method might allocate if the requested memory is bigger
   * than the current temporary memory allocated.
   *
   * @param count The number of **elements** required
   * @returns A {@link TypedArray} over the WASM memory
   */
  getTempBufferU8(count2) {
    this.requireTempMem(count2);
    return this._tempMemUint8;
  }
  /**
   * Returns a uint16 buffer view on temporary WASM memory.
   *
   * **Note**: this method might allocate if the requested memory is bigger
   * than the current temporary memory allocated.
   *
   * @param count The number of **elements** required
   * @returns A {@link TypedArray} over the WASM memory
   */
  getTempBufferU16(count2) {
    this.requireTempMem(count2 * 2);
    return this._tempMemUint16;
  }
  /**
   * Returns a uint32 buffer view on temporary WASM memory.
   *
   * **Note**: this method might allocate if the requested memory is bigger
   * than the current temporary memory allocated.
   *
   * @param count The number of **elements** required.
   * @returns A {@link TypedArray} over the WASM memory.
   */
  getTempBufferU32(count2) {
    this.requireTempMem(count2 * 4);
    return this._tempMemUint32;
  }
  /**
   * Returns a int32 buffer view on temporary WASM memory.
   *
   * **Note**: this method might allocate if the requested memory is bigger
   * than the current temporary memory allocated.
   *
   * @param count The number of **elements** required.
   * @returns A {@link TypedArray} over the WASM memory.
   */
  getTempBufferI32(count2) {
    this.requireTempMem(count2 * 4);
    return this._tempMemInt;
  }
  /**
   * Returns a float32 buffer view on temporary WASM memory.
   *
   * **Note**: this method might allocate if the requested memory is bigger
   * than the current temporary memory allocated.
   *
   * @param count The number of **elements** required.
   * @returns A {@link TypedArray} over the WASM memory.
   */
  getTempBufferF32(count2) {
    this.requireTempMem(count2 * 4);
    return this._tempMemFloat;
  }
  /**
   * Copy the string into temporary WASM memory and retrieve the pointer.
   *
   * @note This method will compute the strlen and append a `\0`.
   *
   * @note The result should be used **directly** otherwise it might get
   * overridden by any next call modifying the temporary memory.
   *
   * @param str The string to write to temporary memory
   * @param byteOffset The starting byte offset in the temporary memory at which
   *     the string should be written. This is useful when using multiple temporaries.
   * @return The temporary pointer onto the WASM memory
   */
  tempUTF8(str5, byteOffset = 0) {
    const strLen = this.lengthBytesUTF8(str5) + 1;
    this.requireTempMem(strLen + byteOffset);
    const ptr = this._tempMem + byteOffset;
    this.stringToUTF8(str5, ptr, strLen);
    return ptr;
  }
  /**
   * Return the index of the component type.
   *
   * @note This method uses malloc and copies the string
   * to avoid overwriting caller's temporary data.
   *
   * @param type The type
   * @return The component type index
   */
  _typeIndexFor(type) {
    const lengthBytes = this.lengthBytesUTF8(type) + 1;
    const mem = this._malloc(lengthBytes);
    this.stringToUTF8(type, mem, lengthBytes);
    const componentType = this._wl_get_component_manager_index(mem);
    this._free(mem);
    return componentType;
  }
  /**
   * Return the name of component type stored at the given index.
   *
   * @param typeIndex The type index
   * @return The name as a string
   */
  _typeNameFor(typeIndex) {
    return this.UTF8ToString(this._wl_component_manager_name(typeIndex));
  }
  /**
   * Returns `true` if the runtime supports physx or not.
   */
  get withPhysX() {
    return this._withPhysX;
  }
  /** JavaScript manager index. */
  get _jsManagerIndex() {
    if (this._jsManagerIndexCached === null) {
      this._jsManagerIndexCached = this._typeIndexFor("js");
    }
    return this._jsManagerIndexCached;
  }
  /**
   * Set the engine instance holding this bridge.
   *
   * @note This api is meant to be used internally.
   *
   * @param engine The engine instance.
   */
  _setEngine(engine3) {
    this._engine = engine3;
  }
  /* WebAssembly to JS call bridge. */
  _wljs_xr_session_start(mode) {
    if (this._engine.xr === null) {
      this._engine.xr = new XR(this, mode);
      this._engine.onXRSessionStart.notify(this.webxr_session, mode);
    }
  }
  _wljs_xr_session_end() {
    const startEmitter = this._engine.onXRSessionStart;
    if (startEmitter instanceof RetainEmitter)
      startEmitter.reset();
    this._engine.onXRSessionEnd.notify();
    this._engine.xr = null;
  }
  _wljs_xr_disable() {
    this._engine.arSupported = false;
    this._engine.vrSupported = false;
  }
  _wljs_allocate(numComponents) {
    this._components = new Array(numComponents);
  }
  _wljs_init(withPhysX) {
    this._withPhysX = withPhysX;
    this.allocateTempMemory(1024);
  }
  _wljs_reallocate(numComponents) {
    if (numComponents > this._components.length) {
      this._components.length = numComponents;
    }
  }
  _wljs_scene_add_material_definition(definitionId) {
    const definition = /* @__PURE__ */ new Map();
    const nbParams = this._wl_material_definition_get_count(definitionId);
    for (let i = 0; i < nbParams; ++i) {
      const name = this.UTF8ToString(this._wl_material_definition_get_param_name(definitionId, i));
      const t = this._wl_material_definition_get_param_type(definitionId, i);
      definition.set(name, {
        index: i,
        type: {
          type: t & 255,
          componentCount: t >> 8 & 255,
          metaType: t >> 16 & 255
        }
      });
    }
    this._materialDefinitions[definitionId] = definition;
  }
  _wljs_set_component_param_bool(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v !== 0;
  }
  _wljs_set_component_param_int(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v;
  }
  _wljs_set_component_param_float(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v;
  }
  _wljs_set_component_param_string(c, p2, pe, v, ve) {
    const param = this.UTF8ViewToString(p2, pe);
    const value = this.UTF8ViewToString(v, ve);
    this._components[c][param] = value;
  }
  _wljs_set_component_param_color(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = new Float32Array([0, 8, 16, 24].map((s) => (v >>> s & 255) / 255));
  }
  _wljs_set_component_param_object(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v > 0 ? this._engine.wrapObject(v) : null;
  }
  _wljs_set_component_param_mesh(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v > 0 ? new Mesh(this._engine, v) : null;
  }
  _wljs_set_component_param_texture(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v > 0 ? this._engine.textures.wrap(v) : null;
  }
  _wljs_set_component_param_material(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v > 0 ? new Material(this._engine, v) : null;
  }
  _wljs_set_component_param_animation(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v > 0 ? new Animation(this._engine, v) : null;
  }
  _wljs_set_component_param_skin(c, p2, pe, v) {
    const param = this.UTF8ViewToString(p2, pe);
    this._components[c][param] = v > 0 ? new Skin(this._engine, v) : null;
  }
  _wljs_get_component_type_index(namePtr, nameEndPtr) {
    const typename = this.UTF8ViewToString(namePtr, nameEndPtr);
    const index = this._componentTypeIndices[typename];
    if (index === void 0) {
      return this._brokenComponentIndex;
    }
    return index;
  }
  _wljs_component_create(jsManagerIndex, index, id, type, object) {
    const ctor = this._componentTypes[type];
    if (!ctor) {
      throw new Error(`Type index ${type} isn't registered`);
    }
    let component = null;
    try {
      component = new ctor();
    } catch (e) {
      console.error(`Exception during instantiation of component ${ctor.TypeName}`);
      component = new BrokenComponent(this._engine);
    }
    component._engine = this._engine;
    component._manager = jsManagerIndex;
    component._id = id;
    component._object = this._engine.wrapObject(object);
    try {
      component.resetProperties();
    } catch (e) {
      console.error(`Exception during ${component.type} resetProperties() on object ${component.object.name}`);
    }
    this._components[index] = component;
    return component;
  }
  _wljs_component_init(component) {
    const c = this._components[component];
    c._triggerInit();
  }
  _wljs_component_update(component, dt) {
    const c = this._components[component];
    c._triggerUpdate(dt);
  }
  _wljs_component_onActivate(component) {
    const c = this._components[component];
    if (c)
      c._triggerOnActivate();
  }
  _wljs_component_onDeactivate(component) {
    const c = this._components[component];
    c._triggerOnDeactivate();
  }
  _wljs_component_onDestroy(component) {
    const c = this._components[component];
    c._triggerOnDestroy();
  }
  _wljs_swap(a, b) {
    const componentA = this._components[a];
    this._components[a] = this._components[b];
    this._components[b] = componentA;
  }
  _wljs_copy(src, dst) {
    const destComp = this._components[dst];
    try {
      destComp.copy(this._components[src]);
    } catch (e) {
      console.error(`Exception during ${destComp.type} copy() on object ${destComp.object.name}`);
    }
  }
};
function throwInvalidRuntime(version2) {
  return function() {
    throw new Error(`Feature added in version ${version2}.
	\u2192 Please use a Wonderland Engine editor version >= ${version2}`);
  };
}
var requireRuntime1_1_1 = throwInvalidRuntime("1.1.1");
WASM.prototype._wl_physx_component_get_offsetTranslation = requireRuntime1_1_1;
WASM.prototype._wl_physx_component_set_offsetTranslation = requireRuntime1_1_1;
WASM.prototype._wl_physx_component_get_offsetTransform = requireRuntime1_1_1;
WASM.prototype._wl_physx_component_set_offsetRotation = requireRuntime1_1_1;
WASM.prototype._wl_object_clone = requireRuntime1_1_1;

// node_modules/@wonderlandengine/api/dist/version.js
var APIVersion = {
  major: 1,
  minor: 1,
  patch: 3,
  rc: 0
};

// node_modules/@wonderlandengine/api/dist/index.js
var LOADING_SCREEN_PATH = "WonderlandRuntime-LoadingScreen.bin";
function loadScript(scriptURL) {
  return new Promise((res, rej) => {
    const s = document.createElement("script");
    const node = document.body.appendChild(s);
    s.onload = () => {
      document.body.removeChild(node);
      res();
    };
    s.onerror = (e) => {
      document.body.removeChild(node);
      rej(e);
    };
    s.src = scriptURL;
  });
}
async function detectFeatures() {
  let [simdSupported, threadsSupported] = await Promise.all([simd(), threads()]);
  if (simdSupported) {
    console.log("WASM SIMD is supported");
  } else {
    console.warn("WASM SIMD is not supported");
  }
  if (threadsSupported) {
    if (self.crossOriginIsolated) {
      console.log("WASM Threads is supported");
    } else {
      console.warn("WASM Threads is supported, but the page is not crossOriginIsolated, therefore thread support is disabled.");
    }
  } else {
    console.warn("WASM Threads is not supported");
  }
  threadsSupported = threadsSupported && self.crossOriginIsolated;
  return {
    simdSupported,
    threadsSupported
  };
}
var xrSupported = {
  ar: null,
  vr: null
};
function checkXRSupport() {
  if (typeof navigator === "undefined" || !navigator.xr) {
    xrSupported.vr = false;
    xrSupported.ar = false;
    return Promise.resolve(xrSupported);
  }
  const vrPromise = xrSupported.vr !== null ? Promise.resolve() : navigator.xr.isSessionSupported("immersive-vr").then((supported) => xrSupported.vr = supported);
  const arPromise = xrSupported.ar !== null ? Promise.resolve() : navigator.xr.isSessionSupported("immersive-ar").then((supported) => xrSupported.ar = supported);
  return Promise.all([vrPromise, arPromise]).then(() => xrSupported);
}
function checkRuntimeCompatibility(version2) {
  const { major, minor } = version2;
  let majorDiff = major - APIVersion.major;
  let minorDiff = minor - APIVersion.minor;
  if (!majorDiff && !minorDiff)
    return;
  const error = "checkRuntimeCompatibility(): Version compatibility mismatch:\n	\u2192 API and runtime compatibility is enforced on a patch level (versions x.y.*)\n";
  const isRuntimeOlder = majorDiff < 0 || !majorDiff && minorDiff < 0;
  if (isRuntimeOlder) {
    throw new Error(`${error}	\u2192 Please use a Wonderland Engine editor version >= ${APIVersion.major}.${APIVersion.minor}.*`);
  }
  throw new Error(`${error}	\u2192 Please use a new API version >= ${version2.major}.${version2.minor}.*`);
}
async function loadRuntime(runtime, options = {}) {
  const xrPromise = checkXRSupport();
  const baseURL = getBaseUrl(runtime);
  const { simdSupported, threadsSupported } = await detectFeatures();
  const { simd: simd2 = simdSupported, threads: threads2 = threadsSupported, physx = false, loader = false, xrFramebufferScaleFactor = 1, loadingScreen = baseURL ? `${baseURL}/${LOADING_SCREEN_PATH}` : LOADING_SCREEN_PATH, canvas = "canvas" } = options;
  const variant = [];
  if (loader)
    variant.push("loader");
  if (physx)
    variant.push("physx");
  if (simd2)
    variant.push("simd");
  if (threads2)
    variant.push("threads");
  const variantStr = variant.join("-");
  let filename = runtime;
  if (variantStr)
    filename = `${filename}-${variantStr}`;
  const download = function(filename2, errorMessage) {
    return fetch(filename2).then((r) => {
      if (!r.ok)
        return Promise.reject(errorMessage);
      return r.arrayBuffer();
    }).catch((_) => Promise.reject(errorMessage));
  };
  const [wasmData, loadingScreenData] = await Promise.all([
    download(`${filename}.wasm`, "Failed to fetch runtime .wasm file"),
    download(loadingScreen, "Failed to fetch loading screen file")
  ]);
  const glCanvas = document.getElementById(canvas);
  if (!glCanvas) {
    throw new Error(`loadRuntime(): Failed to find canvas with id '${canvas}'`);
  }
  if (!(glCanvas instanceof HTMLCanvasElement)) {
    throw new Error(`loadRuntime(): HTML element '${canvas}' must be a canvas`);
  }
  const wasm = new WASM(threads2);
  wasm.worker = `${filename}.worker.js`;
  wasm.wasm = wasmData;
  wasm.canvas = glCanvas;
  const engine3 = new WonderlandEngine(wasm, loadingScreenData);
  if (!window._WL) {
    window._WL = { runtimes: {} };
  }
  const runtimes = window._WL.runtimes;
  const runtimeGlobalId = variantStr ? variantStr : "default";
  if (!runtimes[runtimeGlobalId]) {
    await loadScript(`${filename}.js`);
    runtimes[runtimeGlobalId] = window.instantiateWonderlandRuntime;
    window.instantiateWonderlandRuntime = void 0;
  }
  await runtimes[runtimeGlobalId](wasm);
  engine3._init();
  checkRuntimeCompatibility(engine3.runtimeVersion);
  const xr = await xrPromise;
  engine3.arSupported = xr.ar;
  engine3.vrSupported = xr.vr;
  engine3.xrFramebufferScaleFactor = xrFramebufferScaleFactor;
  engine3.autoResizeCanvas = true;
  engine3.start();
  return engine3;
}

// node_modules/gl-matrix/esm/common.js
var EPSILON = 1e-6;
var ARRAY_TYPE = typeof Float32Array !== "undefined" ? Float32Array : Array;
var RANDOM = Math.random;
var degree = Math.PI / 180;
if (!Math.hypot)
  Math.hypot = function() {
    var y = 0, i = arguments.length;
    while (i--) {
      y += arguments[i] * arguments[i];
    }
    return Math.sqrt(y);
  };

// node_modules/gl-matrix/esm/mat3.js
function create() {
  var out = new ARRAY_TYPE(9);
  if (ARRAY_TYPE != Float32Array) {
    out[1] = 0;
    out[2] = 0;
    out[3] = 0;
    out[5] = 0;
    out[6] = 0;
    out[7] = 0;
  }
  out[0] = 1;
  out[4] = 1;
  out[8] = 1;
  return out;
}

// node_modules/gl-matrix/esm/mat4.js
var mat4_exports = {};
__export(mat4_exports, {
  add: () => add,
  adjoint: () => adjoint,
  clone: () => clone,
  copy: () => copy,
  create: () => create2,
  determinant: () => determinant,
  equals: () => equals,
  exactEquals: () => exactEquals,
  frob: () => frob,
  fromQuat: () => fromQuat,
  fromQuat2: () => fromQuat2,
  fromRotation: () => fromRotation,
  fromRotationTranslation: () => fromRotationTranslation,
  fromRotationTranslationScale: () => fromRotationTranslationScale,
  fromRotationTranslationScaleOrigin: () => fromRotationTranslationScaleOrigin,
  fromScaling: () => fromScaling,
  fromTranslation: () => fromTranslation,
  fromValues: () => fromValues,
  fromXRotation: () => fromXRotation,
  fromYRotation: () => fromYRotation,
  fromZRotation: () => fromZRotation,
  frustum: () => frustum,
  getRotation: () => getRotation,
  getScaling: () => getScaling,
  getTranslation: () => getTranslation,
  identity: () => identity,
  invert: () => invert,
  lookAt: () => lookAt,
  mul: () => mul,
  multiply: () => multiply,
  multiplyScalar: () => multiplyScalar,
  multiplyScalarAndAdd: () => multiplyScalarAndAdd,
  ortho: () => ortho,
  orthoNO: () => orthoNO,
  orthoZO: () => orthoZO,
  perspective: () => perspective,
  perspectiveFromFieldOfView: () => perspectiveFromFieldOfView,
  perspectiveNO: () => perspectiveNO,
  perspectiveZO: () => perspectiveZO,
  rotate: () => rotate,
  rotateX: () => rotateX,
  rotateY: () => rotateY,
  rotateZ: () => rotateZ,
  scale: () => scale,
  set: () => set,
  str: () => str,
  sub: () => sub,
  subtract: () => subtract,
  targetTo: () => targetTo,
  translate: () => translate,
  transpose: () => transpose
});
function create2() {
  var out = new ARRAY_TYPE(16);
  if (ARRAY_TYPE != Float32Array) {
    out[1] = 0;
    out[2] = 0;
    out[3] = 0;
    out[4] = 0;
    out[6] = 0;
    out[7] = 0;
    out[8] = 0;
    out[9] = 0;
    out[11] = 0;
    out[12] = 0;
    out[13] = 0;
    out[14] = 0;
  }
  out[0] = 1;
  out[5] = 1;
  out[10] = 1;
  out[15] = 1;
  return out;
}
function clone(a) {
  var out = new ARRAY_TYPE(16);
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  out[3] = a[3];
  out[4] = a[4];
  out[5] = a[5];
  out[6] = a[6];
  out[7] = a[7];
  out[8] = a[8];
  out[9] = a[9];
  out[10] = a[10];
  out[11] = a[11];
  out[12] = a[12];
  out[13] = a[13];
  out[14] = a[14];
  out[15] = a[15];
  return out;
}
function copy(out, a) {
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  out[3] = a[3];
  out[4] = a[4];
  out[5] = a[5];
  out[6] = a[6];
  out[7] = a[7];
  out[8] = a[8];
  out[9] = a[9];
  out[10] = a[10];
  out[11] = a[11];
  out[12] = a[12];
  out[13] = a[13];
  out[14] = a[14];
  out[15] = a[15];
  return out;
}
function fromValues(m00, m01, m02, m03, m10, m11, m12, m13, m20, m21, m22, m23, m30, m31, m32, m33) {
  var out = new ARRAY_TYPE(16);
  out[0] = m00;
  out[1] = m01;
  out[2] = m02;
  out[3] = m03;
  out[4] = m10;
  out[5] = m11;
  out[6] = m12;
  out[7] = m13;
  out[8] = m20;
  out[9] = m21;
  out[10] = m22;
  out[11] = m23;
  out[12] = m30;
  out[13] = m31;
  out[14] = m32;
  out[15] = m33;
  return out;
}
function set(out, m00, m01, m02, m03, m10, m11, m12, m13, m20, m21, m22, m23, m30, m31, m32, m33) {
  out[0] = m00;
  out[1] = m01;
  out[2] = m02;
  out[3] = m03;
  out[4] = m10;
  out[5] = m11;
  out[6] = m12;
  out[7] = m13;
  out[8] = m20;
  out[9] = m21;
  out[10] = m22;
  out[11] = m23;
  out[12] = m30;
  out[13] = m31;
  out[14] = m32;
  out[15] = m33;
  return out;
}
function identity(out) {
  out[0] = 1;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = 1;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[10] = 1;
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function transpose(out, a) {
  if (out === a) {
    var a01 = a[1], a02 = a[2], a03 = a[3];
    var a12 = a[6], a13 = a[7];
    var a23 = a[11];
    out[1] = a[4];
    out[2] = a[8];
    out[3] = a[12];
    out[4] = a01;
    out[6] = a[9];
    out[7] = a[13];
    out[8] = a02;
    out[9] = a12;
    out[11] = a[14];
    out[12] = a03;
    out[13] = a13;
    out[14] = a23;
  } else {
    out[0] = a[0];
    out[1] = a[4];
    out[2] = a[8];
    out[3] = a[12];
    out[4] = a[1];
    out[5] = a[5];
    out[6] = a[9];
    out[7] = a[13];
    out[8] = a[2];
    out[9] = a[6];
    out[10] = a[10];
    out[11] = a[14];
    out[12] = a[3];
    out[13] = a[7];
    out[14] = a[11];
    out[15] = a[15];
  }
  return out;
}
function invert(out, a) {
  var a00 = a[0], a01 = a[1], a02 = a[2], a03 = a[3];
  var a10 = a[4], a11 = a[5], a12 = a[6], a13 = a[7];
  var a20 = a[8], a21 = a[9], a22 = a[10], a23 = a[11];
  var a30 = a[12], a31 = a[13], a32 = a[14], a33 = a[15];
  var b00 = a00 * a11 - a01 * a10;
  var b01 = a00 * a12 - a02 * a10;
  var b02 = a00 * a13 - a03 * a10;
  var b03 = a01 * a12 - a02 * a11;
  var b04 = a01 * a13 - a03 * a11;
  var b05 = a02 * a13 - a03 * a12;
  var b06 = a20 * a31 - a21 * a30;
  var b07 = a20 * a32 - a22 * a30;
  var b08 = a20 * a33 - a23 * a30;
  var b09 = a21 * a32 - a22 * a31;
  var b10 = a21 * a33 - a23 * a31;
  var b11 = a22 * a33 - a23 * a32;
  var det = b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;
  if (!det) {
    return null;
  }
  det = 1 / det;
  out[0] = (a11 * b11 - a12 * b10 + a13 * b09) * det;
  out[1] = (a02 * b10 - a01 * b11 - a03 * b09) * det;
  out[2] = (a31 * b05 - a32 * b04 + a33 * b03) * det;
  out[3] = (a22 * b04 - a21 * b05 - a23 * b03) * det;
  out[4] = (a12 * b08 - a10 * b11 - a13 * b07) * det;
  out[5] = (a00 * b11 - a02 * b08 + a03 * b07) * det;
  out[6] = (a32 * b02 - a30 * b05 - a33 * b01) * det;
  out[7] = (a20 * b05 - a22 * b02 + a23 * b01) * det;
  out[8] = (a10 * b10 - a11 * b08 + a13 * b06) * det;
  out[9] = (a01 * b08 - a00 * b10 - a03 * b06) * det;
  out[10] = (a30 * b04 - a31 * b02 + a33 * b00) * det;
  out[11] = (a21 * b02 - a20 * b04 - a23 * b00) * det;
  out[12] = (a11 * b07 - a10 * b09 - a12 * b06) * det;
  out[13] = (a00 * b09 - a01 * b07 + a02 * b06) * det;
  out[14] = (a31 * b01 - a30 * b03 - a32 * b00) * det;
  out[15] = (a20 * b03 - a21 * b01 + a22 * b00) * det;
  return out;
}
function adjoint(out, a) {
  var a00 = a[0], a01 = a[1], a02 = a[2], a03 = a[3];
  var a10 = a[4], a11 = a[5], a12 = a[6], a13 = a[7];
  var a20 = a[8], a21 = a[9], a22 = a[10], a23 = a[11];
  var a30 = a[12], a31 = a[13], a32 = a[14], a33 = a[15];
  out[0] = a11 * (a22 * a33 - a23 * a32) - a21 * (a12 * a33 - a13 * a32) + a31 * (a12 * a23 - a13 * a22);
  out[1] = -(a01 * (a22 * a33 - a23 * a32) - a21 * (a02 * a33 - a03 * a32) + a31 * (a02 * a23 - a03 * a22));
  out[2] = a01 * (a12 * a33 - a13 * a32) - a11 * (a02 * a33 - a03 * a32) + a31 * (a02 * a13 - a03 * a12);
  out[3] = -(a01 * (a12 * a23 - a13 * a22) - a11 * (a02 * a23 - a03 * a22) + a21 * (a02 * a13 - a03 * a12));
  out[4] = -(a10 * (a22 * a33 - a23 * a32) - a20 * (a12 * a33 - a13 * a32) + a30 * (a12 * a23 - a13 * a22));
  out[5] = a00 * (a22 * a33 - a23 * a32) - a20 * (a02 * a33 - a03 * a32) + a30 * (a02 * a23 - a03 * a22);
  out[6] = -(a00 * (a12 * a33 - a13 * a32) - a10 * (a02 * a33 - a03 * a32) + a30 * (a02 * a13 - a03 * a12));
  out[7] = a00 * (a12 * a23 - a13 * a22) - a10 * (a02 * a23 - a03 * a22) + a20 * (a02 * a13 - a03 * a12);
  out[8] = a10 * (a21 * a33 - a23 * a31) - a20 * (a11 * a33 - a13 * a31) + a30 * (a11 * a23 - a13 * a21);
  out[9] = -(a00 * (a21 * a33 - a23 * a31) - a20 * (a01 * a33 - a03 * a31) + a30 * (a01 * a23 - a03 * a21));
  out[10] = a00 * (a11 * a33 - a13 * a31) - a10 * (a01 * a33 - a03 * a31) + a30 * (a01 * a13 - a03 * a11);
  out[11] = -(a00 * (a11 * a23 - a13 * a21) - a10 * (a01 * a23 - a03 * a21) + a20 * (a01 * a13 - a03 * a11));
  out[12] = -(a10 * (a21 * a32 - a22 * a31) - a20 * (a11 * a32 - a12 * a31) + a30 * (a11 * a22 - a12 * a21));
  out[13] = a00 * (a21 * a32 - a22 * a31) - a20 * (a01 * a32 - a02 * a31) + a30 * (a01 * a22 - a02 * a21);
  out[14] = -(a00 * (a11 * a32 - a12 * a31) - a10 * (a01 * a32 - a02 * a31) + a30 * (a01 * a12 - a02 * a11));
  out[15] = a00 * (a11 * a22 - a12 * a21) - a10 * (a01 * a22 - a02 * a21) + a20 * (a01 * a12 - a02 * a11);
  return out;
}
function determinant(a) {
  var a00 = a[0], a01 = a[1], a02 = a[2], a03 = a[3];
  var a10 = a[4], a11 = a[5], a12 = a[6], a13 = a[7];
  var a20 = a[8], a21 = a[9], a22 = a[10], a23 = a[11];
  var a30 = a[12], a31 = a[13], a32 = a[14], a33 = a[15];
  var b00 = a00 * a11 - a01 * a10;
  var b01 = a00 * a12 - a02 * a10;
  var b02 = a00 * a13 - a03 * a10;
  var b03 = a01 * a12 - a02 * a11;
  var b04 = a01 * a13 - a03 * a11;
  var b05 = a02 * a13 - a03 * a12;
  var b06 = a20 * a31 - a21 * a30;
  var b07 = a20 * a32 - a22 * a30;
  var b08 = a20 * a33 - a23 * a30;
  var b09 = a21 * a32 - a22 * a31;
  var b10 = a21 * a33 - a23 * a31;
  var b11 = a22 * a33 - a23 * a32;
  return b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;
}
function multiply(out, a, b) {
  var a00 = a[0], a01 = a[1], a02 = a[2], a03 = a[3];
  var a10 = a[4], a11 = a[5], a12 = a[6], a13 = a[7];
  var a20 = a[8], a21 = a[9], a22 = a[10], a23 = a[11];
  var a30 = a[12], a31 = a[13], a32 = a[14], a33 = a[15];
  var b0 = b[0], b1 = b[1], b2 = b[2], b3 = b[3];
  out[0] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
  out[1] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
  out[2] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
  out[3] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;
  b0 = b[4];
  b1 = b[5];
  b2 = b[6];
  b3 = b[7];
  out[4] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
  out[5] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
  out[6] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
  out[7] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;
  b0 = b[8];
  b1 = b[9];
  b2 = b[10];
  b3 = b[11];
  out[8] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
  out[9] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
  out[10] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
  out[11] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;
  b0 = b[12];
  b1 = b[13];
  b2 = b[14];
  b3 = b[15];
  out[12] = b0 * a00 + b1 * a10 + b2 * a20 + b3 * a30;
  out[13] = b0 * a01 + b1 * a11 + b2 * a21 + b3 * a31;
  out[14] = b0 * a02 + b1 * a12 + b2 * a22 + b3 * a32;
  out[15] = b0 * a03 + b1 * a13 + b2 * a23 + b3 * a33;
  return out;
}
function translate(out, a, v) {
  var x = v[0], y = v[1], z = v[2];
  var a00, a01, a02, a03;
  var a10, a11, a12, a13;
  var a20, a21, a22, a23;
  if (a === out) {
    out[12] = a[0] * x + a[4] * y + a[8] * z + a[12];
    out[13] = a[1] * x + a[5] * y + a[9] * z + a[13];
    out[14] = a[2] * x + a[6] * y + a[10] * z + a[14];
    out[15] = a[3] * x + a[7] * y + a[11] * z + a[15];
  } else {
    a00 = a[0];
    a01 = a[1];
    a02 = a[2];
    a03 = a[3];
    a10 = a[4];
    a11 = a[5];
    a12 = a[6];
    a13 = a[7];
    a20 = a[8];
    a21 = a[9];
    a22 = a[10];
    a23 = a[11];
    out[0] = a00;
    out[1] = a01;
    out[2] = a02;
    out[3] = a03;
    out[4] = a10;
    out[5] = a11;
    out[6] = a12;
    out[7] = a13;
    out[8] = a20;
    out[9] = a21;
    out[10] = a22;
    out[11] = a23;
    out[12] = a00 * x + a10 * y + a20 * z + a[12];
    out[13] = a01 * x + a11 * y + a21 * z + a[13];
    out[14] = a02 * x + a12 * y + a22 * z + a[14];
    out[15] = a03 * x + a13 * y + a23 * z + a[15];
  }
  return out;
}
function scale(out, a, v) {
  var x = v[0], y = v[1], z = v[2];
  out[0] = a[0] * x;
  out[1] = a[1] * x;
  out[2] = a[2] * x;
  out[3] = a[3] * x;
  out[4] = a[4] * y;
  out[5] = a[5] * y;
  out[6] = a[6] * y;
  out[7] = a[7] * y;
  out[8] = a[8] * z;
  out[9] = a[9] * z;
  out[10] = a[10] * z;
  out[11] = a[11] * z;
  out[12] = a[12];
  out[13] = a[13];
  out[14] = a[14];
  out[15] = a[15];
  return out;
}
function rotate(out, a, rad, axis) {
  var x = axis[0], y = axis[1], z = axis[2];
  var len4 = Math.hypot(x, y, z);
  var s, c, t;
  var a00, a01, a02, a03;
  var a10, a11, a12, a13;
  var a20, a21, a22, a23;
  var b00, b01, b02;
  var b10, b11, b12;
  var b20, b21, b22;
  if (len4 < EPSILON) {
    return null;
  }
  len4 = 1 / len4;
  x *= len4;
  y *= len4;
  z *= len4;
  s = Math.sin(rad);
  c = Math.cos(rad);
  t = 1 - c;
  a00 = a[0];
  a01 = a[1];
  a02 = a[2];
  a03 = a[3];
  a10 = a[4];
  a11 = a[5];
  a12 = a[6];
  a13 = a[7];
  a20 = a[8];
  a21 = a[9];
  a22 = a[10];
  a23 = a[11];
  b00 = x * x * t + c;
  b01 = y * x * t + z * s;
  b02 = z * x * t - y * s;
  b10 = x * y * t - z * s;
  b11 = y * y * t + c;
  b12 = z * y * t + x * s;
  b20 = x * z * t + y * s;
  b21 = y * z * t - x * s;
  b22 = z * z * t + c;
  out[0] = a00 * b00 + a10 * b01 + a20 * b02;
  out[1] = a01 * b00 + a11 * b01 + a21 * b02;
  out[2] = a02 * b00 + a12 * b01 + a22 * b02;
  out[3] = a03 * b00 + a13 * b01 + a23 * b02;
  out[4] = a00 * b10 + a10 * b11 + a20 * b12;
  out[5] = a01 * b10 + a11 * b11 + a21 * b12;
  out[6] = a02 * b10 + a12 * b11 + a22 * b12;
  out[7] = a03 * b10 + a13 * b11 + a23 * b12;
  out[8] = a00 * b20 + a10 * b21 + a20 * b22;
  out[9] = a01 * b20 + a11 * b21 + a21 * b22;
  out[10] = a02 * b20 + a12 * b21 + a22 * b22;
  out[11] = a03 * b20 + a13 * b21 + a23 * b22;
  if (a !== out) {
    out[12] = a[12];
    out[13] = a[13];
    out[14] = a[14];
    out[15] = a[15];
  }
  return out;
}
function rotateX(out, a, rad) {
  var s = Math.sin(rad);
  var c = Math.cos(rad);
  var a10 = a[4];
  var a11 = a[5];
  var a12 = a[6];
  var a13 = a[7];
  var a20 = a[8];
  var a21 = a[9];
  var a22 = a[10];
  var a23 = a[11];
  if (a !== out) {
    out[0] = a[0];
    out[1] = a[1];
    out[2] = a[2];
    out[3] = a[3];
    out[12] = a[12];
    out[13] = a[13];
    out[14] = a[14];
    out[15] = a[15];
  }
  out[4] = a10 * c + a20 * s;
  out[5] = a11 * c + a21 * s;
  out[6] = a12 * c + a22 * s;
  out[7] = a13 * c + a23 * s;
  out[8] = a20 * c - a10 * s;
  out[9] = a21 * c - a11 * s;
  out[10] = a22 * c - a12 * s;
  out[11] = a23 * c - a13 * s;
  return out;
}
function rotateY(out, a, rad) {
  var s = Math.sin(rad);
  var c = Math.cos(rad);
  var a00 = a[0];
  var a01 = a[1];
  var a02 = a[2];
  var a03 = a[3];
  var a20 = a[8];
  var a21 = a[9];
  var a22 = a[10];
  var a23 = a[11];
  if (a !== out) {
    out[4] = a[4];
    out[5] = a[5];
    out[6] = a[6];
    out[7] = a[7];
    out[12] = a[12];
    out[13] = a[13];
    out[14] = a[14];
    out[15] = a[15];
  }
  out[0] = a00 * c - a20 * s;
  out[1] = a01 * c - a21 * s;
  out[2] = a02 * c - a22 * s;
  out[3] = a03 * c - a23 * s;
  out[8] = a00 * s + a20 * c;
  out[9] = a01 * s + a21 * c;
  out[10] = a02 * s + a22 * c;
  out[11] = a03 * s + a23 * c;
  return out;
}
function rotateZ(out, a, rad) {
  var s = Math.sin(rad);
  var c = Math.cos(rad);
  var a00 = a[0];
  var a01 = a[1];
  var a02 = a[2];
  var a03 = a[3];
  var a10 = a[4];
  var a11 = a[5];
  var a12 = a[6];
  var a13 = a[7];
  if (a !== out) {
    out[8] = a[8];
    out[9] = a[9];
    out[10] = a[10];
    out[11] = a[11];
    out[12] = a[12];
    out[13] = a[13];
    out[14] = a[14];
    out[15] = a[15];
  }
  out[0] = a00 * c + a10 * s;
  out[1] = a01 * c + a11 * s;
  out[2] = a02 * c + a12 * s;
  out[3] = a03 * c + a13 * s;
  out[4] = a10 * c - a00 * s;
  out[5] = a11 * c - a01 * s;
  out[6] = a12 * c - a02 * s;
  out[7] = a13 * c - a03 * s;
  return out;
}
function fromTranslation(out, v) {
  out[0] = 1;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = 1;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[10] = 1;
  out[11] = 0;
  out[12] = v[0];
  out[13] = v[1];
  out[14] = v[2];
  out[15] = 1;
  return out;
}
function fromScaling(out, v) {
  out[0] = v[0];
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = v[1];
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[10] = v[2];
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function fromRotation(out, rad, axis) {
  var x = axis[0], y = axis[1], z = axis[2];
  var len4 = Math.hypot(x, y, z);
  var s, c, t;
  if (len4 < EPSILON) {
    return null;
  }
  len4 = 1 / len4;
  x *= len4;
  y *= len4;
  z *= len4;
  s = Math.sin(rad);
  c = Math.cos(rad);
  t = 1 - c;
  out[0] = x * x * t + c;
  out[1] = y * x * t + z * s;
  out[2] = z * x * t - y * s;
  out[3] = 0;
  out[4] = x * y * t - z * s;
  out[5] = y * y * t + c;
  out[6] = z * y * t + x * s;
  out[7] = 0;
  out[8] = x * z * t + y * s;
  out[9] = y * z * t - x * s;
  out[10] = z * z * t + c;
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function fromXRotation(out, rad) {
  var s = Math.sin(rad);
  var c = Math.cos(rad);
  out[0] = 1;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = c;
  out[6] = s;
  out[7] = 0;
  out[8] = 0;
  out[9] = -s;
  out[10] = c;
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function fromYRotation(out, rad) {
  var s = Math.sin(rad);
  var c = Math.cos(rad);
  out[0] = c;
  out[1] = 0;
  out[2] = -s;
  out[3] = 0;
  out[4] = 0;
  out[5] = 1;
  out[6] = 0;
  out[7] = 0;
  out[8] = s;
  out[9] = 0;
  out[10] = c;
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function fromZRotation(out, rad) {
  var s = Math.sin(rad);
  var c = Math.cos(rad);
  out[0] = c;
  out[1] = s;
  out[2] = 0;
  out[3] = 0;
  out[4] = -s;
  out[5] = c;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[10] = 1;
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function fromRotationTranslation(out, q, v) {
  var x = q[0], y = q[1], z = q[2], w = q[3];
  var x2 = x + x;
  var y2 = y + y;
  var z2 = z + z;
  var xx = x * x2;
  var xy = x * y2;
  var xz = x * z2;
  var yy = y * y2;
  var yz = y * z2;
  var zz = z * z2;
  var wx = w * x2;
  var wy = w * y2;
  var wz = w * z2;
  out[0] = 1 - (yy + zz);
  out[1] = xy + wz;
  out[2] = xz - wy;
  out[3] = 0;
  out[4] = xy - wz;
  out[5] = 1 - (xx + zz);
  out[6] = yz + wx;
  out[7] = 0;
  out[8] = xz + wy;
  out[9] = yz - wx;
  out[10] = 1 - (xx + yy);
  out[11] = 0;
  out[12] = v[0];
  out[13] = v[1];
  out[14] = v[2];
  out[15] = 1;
  return out;
}
function fromQuat2(out, a) {
  var translation = new ARRAY_TYPE(3);
  var bx = -a[0], by = -a[1], bz = -a[2], bw = a[3], ax = a[4], ay = a[5], az = a[6], aw = a[7];
  var magnitude = bx * bx + by * by + bz * bz + bw * bw;
  if (magnitude > 0) {
    translation[0] = (ax * bw + aw * bx + ay * bz - az * by) * 2 / magnitude;
    translation[1] = (ay * bw + aw * by + az * bx - ax * bz) * 2 / magnitude;
    translation[2] = (az * bw + aw * bz + ax * by - ay * bx) * 2 / magnitude;
  } else {
    translation[0] = (ax * bw + aw * bx + ay * bz - az * by) * 2;
    translation[1] = (ay * bw + aw * by + az * bx - ax * bz) * 2;
    translation[2] = (az * bw + aw * bz + ax * by - ay * bx) * 2;
  }
  fromRotationTranslation(out, a, translation);
  return out;
}
function getTranslation(out, mat) {
  out[0] = mat[12];
  out[1] = mat[13];
  out[2] = mat[14];
  return out;
}
function getScaling(out, mat) {
  var m11 = mat[0];
  var m12 = mat[1];
  var m13 = mat[2];
  var m21 = mat[4];
  var m22 = mat[5];
  var m23 = mat[6];
  var m31 = mat[8];
  var m32 = mat[9];
  var m33 = mat[10];
  out[0] = Math.hypot(m11, m12, m13);
  out[1] = Math.hypot(m21, m22, m23);
  out[2] = Math.hypot(m31, m32, m33);
  return out;
}
function getRotation(out, mat) {
  var scaling = new ARRAY_TYPE(3);
  getScaling(scaling, mat);
  var is1 = 1 / scaling[0];
  var is2 = 1 / scaling[1];
  var is3 = 1 / scaling[2];
  var sm11 = mat[0] * is1;
  var sm12 = mat[1] * is2;
  var sm13 = mat[2] * is3;
  var sm21 = mat[4] * is1;
  var sm22 = mat[5] * is2;
  var sm23 = mat[6] * is3;
  var sm31 = mat[8] * is1;
  var sm32 = mat[9] * is2;
  var sm33 = mat[10] * is3;
  var trace = sm11 + sm22 + sm33;
  var S = 0;
  if (trace > 0) {
    S = Math.sqrt(trace + 1) * 2;
    out[3] = 0.25 * S;
    out[0] = (sm23 - sm32) / S;
    out[1] = (sm31 - sm13) / S;
    out[2] = (sm12 - sm21) / S;
  } else if (sm11 > sm22 && sm11 > sm33) {
    S = Math.sqrt(1 + sm11 - sm22 - sm33) * 2;
    out[3] = (sm23 - sm32) / S;
    out[0] = 0.25 * S;
    out[1] = (sm12 + sm21) / S;
    out[2] = (sm31 + sm13) / S;
  } else if (sm22 > sm33) {
    S = Math.sqrt(1 + sm22 - sm11 - sm33) * 2;
    out[3] = (sm31 - sm13) / S;
    out[0] = (sm12 + sm21) / S;
    out[1] = 0.25 * S;
    out[2] = (sm23 + sm32) / S;
  } else {
    S = Math.sqrt(1 + sm33 - sm11 - sm22) * 2;
    out[3] = (sm12 - sm21) / S;
    out[0] = (sm31 + sm13) / S;
    out[1] = (sm23 + sm32) / S;
    out[2] = 0.25 * S;
  }
  return out;
}
function fromRotationTranslationScale(out, q, v, s) {
  var x = q[0], y = q[1], z = q[2], w = q[3];
  var x2 = x + x;
  var y2 = y + y;
  var z2 = z + z;
  var xx = x * x2;
  var xy = x * y2;
  var xz = x * z2;
  var yy = y * y2;
  var yz = y * z2;
  var zz = z * z2;
  var wx = w * x2;
  var wy = w * y2;
  var wz = w * z2;
  var sx = s[0];
  var sy = s[1];
  var sz = s[2];
  out[0] = (1 - (yy + zz)) * sx;
  out[1] = (xy + wz) * sx;
  out[2] = (xz - wy) * sx;
  out[3] = 0;
  out[4] = (xy - wz) * sy;
  out[5] = (1 - (xx + zz)) * sy;
  out[6] = (yz + wx) * sy;
  out[7] = 0;
  out[8] = (xz + wy) * sz;
  out[9] = (yz - wx) * sz;
  out[10] = (1 - (xx + yy)) * sz;
  out[11] = 0;
  out[12] = v[0];
  out[13] = v[1];
  out[14] = v[2];
  out[15] = 1;
  return out;
}
function fromRotationTranslationScaleOrigin(out, q, v, s, o) {
  var x = q[0], y = q[1], z = q[2], w = q[3];
  var x2 = x + x;
  var y2 = y + y;
  var z2 = z + z;
  var xx = x * x2;
  var xy = x * y2;
  var xz = x * z2;
  var yy = y * y2;
  var yz = y * z2;
  var zz = z * z2;
  var wx = w * x2;
  var wy = w * y2;
  var wz = w * z2;
  var sx = s[0];
  var sy = s[1];
  var sz = s[2];
  var ox = o[0];
  var oy = o[1];
  var oz = o[2];
  var out0 = (1 - (yy + zz)) * sx;
  var out1 = (xy + wz) * sx;
  var out2 = (xz - wy) * sx;
  var out4 = (xy - wz) * sy;
  var out5 = (1 - (xx + zz)) * sy;
  var out6 = (yz + wx) * sy;
  var out8 = (xz + wy) * sz;
  var out9 = (yz - wx) * sz;
  var out10 = (1 - (xx + yy)) * sz;
  out[0] = out0;
  out[1] = out1;
  out[2] = out2;
  out[3] = 0;
  out[4] = out4;
  out[5] = out5;
  out[6] = out6;
  out[7] = 0;
  out[8] = out8;
  out[9] = out9;
  out[10] = out10;
  out[11] = 0;
  out[12] = v[0] + ox - (out0 * ox + out4 * oy + out8 * oz);
  out[13] = v[1] + oy - (out1 * ox + out5 * oy + out9 * oz);
  out[14] = v[2] + oz - (out2 * ox + out6 * oy + out10 * oz);
  out[15] = 1;
  return out;
}
function fromQuat(out, q) {
  var x = q[0], y = q[1], z = q[2], w = q[3];
  var x2 = x + x;
  var y2 = y + y;
  var z2 = z + z;
  var xx = x * x2;
  var yx = y * x2;
  var yy = y * y2;
  var zx = z * x2;
  var zy = z * y2;
  var zz = z * z2;
  var wx = w * x2;
  var wy = w * y2;
  var wz = w * z2;
  out[0] = 1 - yy - zz;
  out[1] = yx + wz;
  out[2] = zx - wy;
  out[3] = 0;
  out[4] = yx - wz;
  out[5] = 1 - xx - zz;
  out[6] = zy + wx;
  out[7] = 0;
  out[8] = zx + wy;
  out[9] = zy - wx;
  out[10] = 1 - xx - yy;
  out[11] = 0;
  out[12] = 0;
  out[13] = 0;
  out[14] = 0;
  out[15] = 1;
  return out;
}
function frustum(out, left, right, bottom, top, near, far) {
  var rl = 1 / (right - left);
  var tb = 1 / (top - bottom);
  var nf = 1 / (near - far);
  out[0] = near * 2 * rl;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = near * 2 * tb;
  out[6] = 0;
  out[7] = 0;
  out[8] = (right + left) * rl;
  out[9] = (top + bottom) * tb;
  out[10] = (far + near) * nf;
  out[11] = -1;
  out[12] = 0;
  out[13] = 0;
  out[14] = far * near * 2 * nf;
  out[15] = 0;
  return out;
}
function perspectiveNO(out, fovy, aspect, near, far) {
  var f = 1 / Math.tan(fovy / 2), nf;
  out[0] = f / aspect;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = f;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[11] = -1;
  out[12] = 0;
  out[13] = 0;
  out[15] = 0;
  if (far != null && far !== Infinity) {
    nf = 1 / (near - far);
    out[10] = (far + near) * nf;
    out[14] = 2 * far * near * nf;
  } else {
    out[10] = -1;
    out[14] = -2 * near;
  }
  return out;
}
var perspective = perspectiveNO;
function perspectiveZO(out, fovy, aspect, near, far) {
  var f = 1 / Math.tan(fovy / 2), nf;
  out[0] = f / aspect;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = f;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[11] = -1;
  out[12] = 0;
  out[13] = 0;
  out[15] = 0;
  if (far != null && far !== Infinity) {
    nf = 1 / (near - far);
    out[10] = far * nf;
    out[14] = far * near * nf;
  } else {
    out[10] = -1;
    out[14] = -near;
  }
  return out;
}
function perspectiveFromFieldOfView(out, fov, near, far) {
  var upTan = Math.tan(fov.upDegrees * Math.PI / 180);
  var downTan = Math.tan(fov.downDegrees * Math.PI / 180);
  var leftTan = Math.tan(fov.leftDegrees * Math.PI / 180);
  var rightTan = Math.tan(fov.rightDegrees * Math.PI / 180);
  var xScale = 2 / (leftTan + rightTan);
  var yScale = 2 / (upTan + downTan);
  out[0] = xScale;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = yScale;
  out[6] = 0;
  out[7] = 0;
  out[8] = -((leftTan - rightTan) * xScale * 0.5);
  out[9] = (upTan - downTan) * yScale * 0.5;
  out[10] = far / (near - far);
  out[11] = -1;
  out[12] = 0;
  out[13] = 0;
  out[14] = far * near / (near - far);
  out[15] = 0;
  return out;
}
function orthoNO(out, left, right, bottom, top, near, far) {
  var lr = 1 / (left - right);
  var bt = 1 / (bottom - top);
  var nf = 1 / (near - far);
  out[0] = -2 * lr;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = -2 * bt;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[10] = 2 * nf;
  out[11] = 0;
  out[12] = (left + right) * lr;
  out[13] = (top + bottom) * bt;
  out[14] = (far + near) * nf;
  out[15] = 1;
  return out;
}
var ortho = orthoNO;
function orthoZO(out, left, right, bottom, top, near, far) {
  var lr = 1 / (left - right);
  var bt = 1 / (bottom - top);
  var nf = 1 / (near - far);
  out[0] = -2 * lr;
  out[1] = 0;
  out[2] = 0;
  out[3] = 0;
  out[4] = 0;
  out[5] = -2 * bt;
  out[6] = 0;
  out[7] = 0;
  out[8] = 0;
  out[9] = 0;
  out[10] = nf;
  out[11] = 0;
  out[12] = (left + right) * lr;
  out[13] = (top + bottom) * bt;
  out[14] = near * nf;
  out[15] = 1;
  return out;
}
function lookAt(out, eye2, center, up) {
  var x0, x1, x2, y0, y1, y2, z0, z1, z2, len4;
  var eyex = eye2[0];
  var eyey = eye2[1];
  var eyez = eye2[2];
  var upx = up[0];
  var upy = up[1];
  var upz = up[2];
  var centerx = center[0];
  var centery = center[1];
  var centerz = center[2];
  if (Math.abs(eyex - centerx) < EPSILON && Math.abs(eyey - centery) < EPSILON && Math.abs(eyez - centerz) < EPSILON) {
    return identity(out);
  }
  z0 = eyex - centerx;
  z1 = eyey - centery;
  z2 = eyez - centerz;
  len4 = 1 / Math.hypot(z0, z1, z2);
  z0 *= len4;
  z1 *= len4;
  z2 *= len4;
  x0 = upy * z2 - upz * z1;
  x1 = upz * z0 - upx * z2;
  x2 = upx * z1 - upy * z0;
  len4 = Math.hypot(x0, x1, x2);
  if (!len4) {
    x0 = 0;
    x1 = 0;
    x2 = 0;
  } else {
    len4 = 1 / len4;
    x0 *= len4;
    x1 *= len4;
    x2 *= len4;
  }
  y0 = z1 * x2 - z2 * x1;
  y1 = z2 * x0 - z0 * x2;
  y2 = z0 * x1 - z1 * x0;
  len4 = Math.hypot(y0, y1, y2);
  if (!len4) {
    y0 = 0;
    y1 = 0;
    y2 = 0;
  } else {
    len4 = 1 / len4;
    y0 *= len4;
    y1 *= len4;
    y2 *= len4;
  }
  out[0] = x0;
  out[1] = y0;
  out[2] = z0;
  out[3] = 0;
  out[4] = x1;
  out[5] = y1;
  out[6] = z1;
  out[7] = 0;
  out[8] = x2;
  out[9] = y2;
  out[10] = z2;
  out[11] = 0;
  out[12] = -(x0 * eyex + x1 * eyey + x2 * eyez);
  out[13] = -(y0 * eyex + y1 * eyey + y2 * eyez);
  out[14] = -(z0 * eyex + z1 * eyey + z2 * eyez);
  out[15] = 1;
  return out;
}
function targetTo(out, eye2, target, up) {
  var eyex = eye2[0], eyey = eye2[1], eyez = eye2[2], upx = up[0], upy = up[1], upz = up[2];
  var z0 = eyex - target[0], z1 = eyey - target[1], z2 = eyez - target[2];
  var len4 = z0 * z0 + z1 * z1 + z2 * z2;
  if (len4 > 0) {
    len4 = 1 / Math.sqrt(len4);
    z0 *= len4;
    z1 *= len4;
    z2 *= len4;
  }
  var x0 = upy * z2 - upz * z1, x1 = upz * z0 - upx * z2, x2 = upx * z1 - upy * z0;
  len4 = x0 * x0 + x1 * x1 + x2 * x2;
  if (len4 > 0) {
    len4 = 1 / Math.sqrt(len4);
    x0 *= len4;
    x1 *= len4;
    x2 *= len4;
  }
  out[0] = x0;
  out[1] = x1;
  out[2] = x2;
  out[3] = 0;
  out[4] = z1 * x2 - z2 * x1;
  out[5] = z2 * x0 - z0 * x2;
  out[6] = z0 * x1 - z1 * x0;
  out[7] = 0;
  out[8] = z0;
  out[9] = z1;
  out[10] = z2;
  out[11] = 0;
  out[12] = eyex;
  out[13] = eyey;
  out[14] = eyez;
  out[15] = 1;
  return out;
}
function str(a) {
  return "mat4(" + a[0] + ", " + a[1] + ", " + a[2] + ", " + a[3] + ", " + a[4] + ", " + a[5] + ", " + a[6] + ", " + a[7] + ", " + a[8] + ", " + a[9] + ", " + a[10] + ", " + a[11] + ", " + a[12] + ", " + a[13] + ", " + a[14] + ", " + a[15] + ")";
}
function frob(a) {
  return Math.hypot(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7], a[8], a[9], a[10], a[11], a[12], a[13], a[14], a[15]);
}
function add(out, a, b) {
  out[0] = a[0] + b[0];
  out[1] = a[1] + b[1];
  out[2] = a[2] + b[2];
  out[3] = a[3] + b[3];
  out[4] = a[4] + b[4];
  out[5] = a[5] + b[5];
  out[6] = a[6] + b[6];
  out[7] = a[7] + b[7];
  out[8] = a[8] + b[8];
  out[9] = a[9] + b[9];
  out[10] = a[10] + b[10];
  out[11] = a[11] + b[11];
  out[12] = a[12] + b[12];
  out[13] = a[13] + b[13];
  out[14] = a[14] + b[14];
  out[15] = a[15] + b[15];
  return out;
}
function subtract(out, a, b) {
  out[0] = a[0] - b[0];
  out[1] = a[1] - b[1];
  out[2] = a[2] - b[2];
  out[3] = a[3] - b[3];
  out[4] = a[4] - b[4];
  out[5] = a[5] - b[5];
  out[6] = a[6] - b[6];
  out[7] = a[7] - b[7];
  out[8] = a[8] - b[8];
  out[9] = a[9] - b[9];
  out[10] = a[10] - b[10];
  out[11] = a[11] - b[11];
  out[12] = a[12] - b[12];
  out[13] = a[13] - b[13];
  out[14] = a[14] - b[14];
  out[15] = a[15] - b[15];
  return out;
}
function multiplyScalar(out, a, b) {
  out[0] = a[0] * b;
  out[1] = a[1] * b;
  out[2] = a[2] * b;
  out[3] = a[3] * b;
  out[4] = a[4] * b;
  out[5] = a[5] * b;
  out[6] = a[6] * b;
  out[7] = a[7] * b;
  out[8] = a[8] * b;
  out[9] = a[9] * b;
  out[10] = a[10] * b;
  out[11] = a[11] * b;
  out[12] = a[12] * b;
  out[13] = a[13] * b;
  out[14] = a[14] * b;
  out[15] = a[15] * b;
  return out;
}
function multiplyScalarAndAdd(out, a, b, scale7) {
  out[0] = a[0] + b[0] * scale7;
  out[1] = a[1] + b[1] * scale7;
  out[2] = a[2] + b[2] * scale7;
  out[3] = a[3] + b[3] * scale7;
  out[4] = a[4] + b[4] * scale7;
  out[5] = a[5] + b[5] * scale7;
  out[6] = a[6] + b[6] * scale7;
  out[7] = a[7] + b[7] * scale7;
  out[8] = a[8] + b[8] * scale7;
  out[9] = a[9] + b[9] * scale7;
  out[10] = a[10] + b[10] * scale7;
  out[11] = a[11] + b[11] * scale7;
  out[12] = a[12] + b[12] * scale7;
  out[13] = a[13] + b[13] * scale7;
  out[14] = a[14] + b[14] * scale7;
  out[15] = a[15] + b[15] * scale7;
  return out;
}
function exactEquals(a, b) {
  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2] && a[3] === b[3] && a[4] === b[4] && a[5] === b[5] && a[6] === b[6] && a[7] === b[7] && a[8] === b[8] && a[9] === b[9] && a[10] === b[10] && a[11] === b[11] && a[12] === b[12] && a[13] === b[13] && a[14] === b[14] && a[15] === b[15];
}
function equals(a, b) {
  var a0 = a[0], a12 = a[1], a22 = a[2], a32 = a[3];
  var a42 = a[4], a52 = a[5], a6 = a[6], a7 = a[7];
  var a8 = a[8], a9 = a[9], a10 = a[10], a11 = a[11];
  var a122 = a[12], a13 = a[13], a14 = a[14], a15 = a[15];
  var b0 = b[0], b1 = b[1], b2 = b[2], b3 = b[3];
  var b4 = b[4], b5 = b[5], b6 = b[6], b7 = b[7];
  var b8 = b[8], b9 = b[9], b10 = b[10], b11 = b[11];
  var b12 = b[12], b13 = b[13], b14 = b[14], b15 = b[15];
  return Math.abs(a0 - b0) <= EPSILON * Math.max(1, Math.abs(a0), Math.abs(b0)) && Math.abs(a12 - b1) <= EPSILON * Math.max(1, Math.abs(a12), Math.abs(b1)) && Math.abs(a22 - b2) <= EPSILON * Math.max(1, Math.abs(a22), Math.abs(b2)) && Math.abs(a32 - b3) <= EPSILON * Math.max(1, Math.abs(a32), Math.abs(b3)) && Math.abs(a42 - b4) <= EPSILON * Math.max(1, Math.abs(a42), Math.abs(b4)) && Math.abs(a52 - b5) <= EPSILON * Math.max(1, Math.abs(a52), Math.abs(b5)) && Math.abs(a6 - b6) <= EPSILON * Math.max(1, Math.abs(a6), Math.abs(b6)) && Math.abs(a7 - b7) <= EPSILON * Math.max(1, Math.abs(a7), Math.abs(b7)) && Math.abs(a8 - b8) <= EPSILON * Math.max(1, Math.abs(a8), Math.abs(b8)) && Math.abs(a9 - b9) <= EPSILON * Math.max(1, Math.abs(a9), Math.abs(b9)) && Math.abs(a10 - b10) <= EPSILON * Math.max(1, Math.abs(a10), Math.abs(b10)) && Math.abs(a11 - b11) <= EPSILON * Math.max(1, Math.abs(a11), Math.abs(b11)) && Math.abs(a122 - b12) <= EPSILON * Math.max(1, Math.abs(a122), Math.abs(b12)) && Math.abs(a13 - b13) <= EPSILON * Math.max(1, Math.abs(a13), Math.abs(b13)) && Math.abs(a14 - b14) <= EPSILON * Math.max(1, Math.abs(a14), Math.abs(b14)) && Math.abs(a15 - b15) <= EPSILON * Math.max(1, Math.abs(a15), Math.abs(b15));
}
var mul = multiply;
var sub = subtract;

// node_modules/gl-matrix/esm/quat.js
var quat_exports = {};
__export(quat_exports, {
  add: () => add4,
  calculateW: () => calculateW,
  clone: () => clone4,
  conjugate: () => conjugate,
  copy: () => copy4,
  create: () => create5,
  dot: () => dot3,
  equals: () => equals4,
  exactEquals: () => exactEquals4,
  exp: () => exp,
  fromEuler: () => fromEuler,
  fromMat3: () => fromMat3,
  fromValues: () => fromValues4,
  getAngle: () => getAngle,
  getAxisAngle: () => getAxisAngle,
  identity: () => identity2,
  invert: () => invert2,
  len: () => len2,
  length: () => length3,
  lerp: () => lerp3,
  ln: () => ln,
  mul: () => mul3,
  multiply: () => multiply3,
  normalize: () => normalize3,
  pow: () => pow,
  random: () => random2,
  rotateX: () => rotateX3,
  rotateY: () => rotateY3,
  rotateZ: () => rotateZ3,
  rotationTo: () => rotationTo,
  scale: () => scale4,
  set: () => set4,
  setAxes: () => setAxes,
  setAxisAngle: () => setAxisAngle,
  slerp: () => slerp,
  sqlerp: () => sqlerp,
  sqrLen: () => sqrLen2,
  squaredLength: () => squaredLength3,
  str: () => str3
});

// node_modules/gl-matrix/esm/vec3.js
var vec3_exports = {};
__export(vec3_exports, {
  add: () => add2,
  angle: () => angle,
  bezier: () => bezier,
  ceil: () => ceil,
  clone: () => clone2,
  copy: () => copy2,
  create: () => create3,
  cross: () => cross,
  dist: () => dist,
  distance: () => distance,
  div: () => div,
  divide: () => divide,
  dot: () => dot,
  equals: () => equals2,
  exactEquals: () => exactEquals2,
  floor: () => floor,
  forEach: () => forEach,
  fromValues: () => fromValues2,
  hermite: () => hermite,
  inverse: () => inverse,
  len: () => len,
  length: () => length,
  lerp: () => lerp,
  max: () => max,
  min: () => min,
  mul: () => mul2,
  multiply: () => multiply2,
  negate: () => negate,
  normalize: () => normalize,
  random: () => random,
  rotateX: () => rotateX2,
  rotateY: () => rotateY2,
  rotateZ: () => rotateZ2,
  round: () => round,
  scale: () => scale2,
  scaleAndAdd: () => scaleAndAdd,
  set: () => set2,
  sqrDist: () => sqrDist,
  sqrLen: () => sqrLen,
  squaredDistance: () => squaredDistance,
  squaredLength: () => squaredLength,
  str: () => str2,
  sub: () => sub2,
  subtract: () => subtract2,
  transformMat3: () => transformMat3,
  transformMat4: () => transformMat4,
  transformQuat: () => transformQuat,
  zero: () => zero
});
function create3() {
  var out = new ARRAY_TYPE(3);
  if (ARRAY_TYPE != Float32Array) {
    out[0] = 0;
    out[1] = 0;
    out[2] = 0;
  }
  return out;
}
function clone2(a) {
  var out = new ARRAY_TYPE(3);
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  return out;
}
function length(a) {
  var x = a[0];
  var y = a[1];
  var z = a[2];
  return Math.hypot(x, y, z);
}
function fromValues2(x, y, z) {
  var out = new ARRAY_TYPE(3);
  out[0] = x;
  out[1] = y;
  out[2] = z;
  return out;
}
function copy2(out, a) {
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  return out;
}
function set2(out, x, y, z) {
  out[0] = x;
  out[1] = y;
  out[2] = z;
  return out;
}
function add2(out, a, b) {
  out[0] = a[0] + b[0];
  out[1] = a[1] + b[1];
  out[2] = a[2] + b[2];
  return out;
}
function subtract2(out, a, b) {
  out[0] = a[0] - b[0];
  out[1] = a[1] - b[1];
  out[2] = a[2] - b[2];
  return out;
}
function multiply2(out, a, b) {
  out[0] = a[0] * b[0];
  out[1] = a[1] * b[1];
  out[2] = a[2] * b[2];
  return out;
}
function divide(out, a, b) {
  out[0] = a[0] / b[0];
  out[1] = a[1] / b[1];
  out[2] = a[2] / b[2];
  return out;
}
function ceil(out, a) {
  out[0] = Math.ceil(a[0]);
  out[1] = Math.ceil(a[1]);
  out[2] = Math.ceil(a[2]);
  return out;
}
function floor(out, a) {
  out[0] = Math.floor(a[0]);
  out[1] = Math.floor(a[1]);
  out[2] = Math.floor(a[2]);
  return out;
}
function min(out, a, b) {
  out[0] = Math.min(a[0], b[0]);
  out[1] = Math.min(a[1], b[1]);
  out[2] = Math.min(a[2], b[2]);
  return out;
}
function max(out, a, b) {
  out[0] = Math.max(a[0], b[0]);
  out[1] = Math.max(a[1], b[1]);
  out[2] = Math.max(a[2], b[2]);
  return out;
}
function round(out, a) {
  out[0] = Math.round(a[0]);
  out[1] = Math.round(a[1]);
  out[2] = Math.round(a[2]);
  return out;
}
function scale2(out, a, b) {
  out[0] = a[0] * b;
  out[1] = a[1] * b;
  out[2] = a[2] * b;
  return out;
}
function scaleAndAdd(out, a, b, scale7) {
  out[0] = a[0] + b[0] * scale7;
  out[1] = a[1] + b[1] * scale7;
  out[2] = a[2] + b[2] * scale7;
  return out;
}
function distance(a, b) {
  var x = b[0] - a[0];
  var y = b[1] - a[1];
  var z = b[2] - a[2];
  return Math.hypot(x, y, z);
}
function squaredDistance(a, b) {
  var x = b[0] - a[0];
  var y = b[1] - a[1];
  var z = b[2] - a[2];
  return x * x + y * y + z * z;
}
function squaredLength(a) {
  var x = a[0];
  var y = a[1];
  var z = a[2];
  return x * x + y * y + z * z;
}
function negate(out, a) {
  out[0] = -a[0];
  out[1] = -a[1];
  out[2] = -a[2];
  return out;
}
function inverse(out, a) {
  out[0] = 1 / a[0];
  out[1] = 1 / a[1];
  out[2] = 1 / a[2];
  return out;
}
function normalize(out, a) {
  var x = a[0];
  var y = a[1];
  var z = a[2];
  var len4 = x * x + y * y + z * z;
  if (len4 > 0) {
    len4 = 1 / Math.sqrt(len4);
  }
  out[0] = a[0] * len4;
  out[1] = a[1] * len4;
  out[2] = a[2] * len4;
  return out;
}
function dot(a, b) {
  return a[0] * b[0] + a[1] * b[1] + a[2] * b[2];
}
function cross(out, a, b) {
  var ax = a[0], ay = a[1], az = a[2];
  var bx = b[0], by = b[1], bz = b[2];
  out[0] = ay * bz - az * by;
  out[1] = az * bx - ax * bz;
  out[2] = ax * by - ay * bx;
  return out;
}
function lerp(out, a, b, t) {
  var ax = a[0];
  var ay = a[1];
  var az = a[2];
  out[0] = ax + t * (b[0] - ax);
  out[1] = ay + t * (b[1] - ay);
  out[2] = az + t * (b[2] - az);
  return out;
}
function hermite(out, a, b, c, d, t) {
  var factorTimes2 = t * t;
  var factor1 = factorTimes2 * (2 * t - 3) + 1;
  var factor2 = factorTimes2 * (t - 2) + t;
  var factor3 = factorTimes2 * (t - 1);
  var factor4 = factorTimes2 * (3 - 2 * t);
  out[0] = a[0] * factor1 + b[0] * factor2 + c[0] * factor3 + d[0] * factor4;
  out[1] = a[1] * factor1 + b[1] * factor2 + c[1] * factor3 + d[1] * factor4;
  out[2] = a[2] * factor1 + b[2] * factor2 + c[2] * factor3 + d[2] * factor4;
  return out;
}
function bezier(out, a, b, c, d, t) {
  var inverseFactor = 1 - t;
  var inverseFactorTimesTwo = inverseFactor * inverseFactor;
  var factorTimes2 = t * t;
  var factor1 = inverseFactorTimesTwo * inverseFactor;
  var factor2 = 3 * t * inverseFactorTimesTwo;
  var factor3 = 3 * factorTimes2 * inverseFactor;
  var factor4 = factorTimes2 * t;
  out[0] = a[0] * factor1 + b[0] * factor2 + c[0] * factor3 + d[0] * factor4;
  out[1] = a[1] * factor1 + b[1] * factor2 + c[1] * factor3 + d[1] * factor4;
  out[2] = a[2] * factor1 + b[2] * factor2 + c[2] * factor3 + d[2] * factor4;
  return out;
}
function random(out, scale7) {
  scale7 = scale7 || 1;
  var r = RANDOM() * 2 * Math.PI;
  var z = RANDOM() * 2 - 1;
  var zScale = Math.sqrt(1 - z * z) * scale7;
  out[0] = Math.cos(r) * zScale;
  out[1] = Math.sin(r) * zScale;
  out[2] = z * scale7;
  return out;
}
function transformMat4(out, a, m) {
  var x = a[0], y = a[1], z = a[2];
  var w = m[3] * x + m[7] * y + m[11] * z + m[15];
  w = w || 1;
  out[0] = (m[0] * x + m[4] * y + m[8] * z + m[12]) / w;
  out[1] = (m[1] * x + m[5] * y + m[9] * z + m[13]) / w;
  out[2] = (m[2] * x + m[6] * y + m[10] * z + m[14]) / w;
  return out;
}
function transformMat3(out, a, m) {
  var x = a[0], y = a[1], z = a[2];
  out[0] = x * m[0] + y * m[3] + z * m[6];
  out[1] = x * m[1] + y * m[4] + z * m[7];
  out[2] = x * m[2] + y * m[5] + z * m[8];
  return out;
}
function transformQuat(out, a, q) {
  var qx = q[0], qy = q[1], qz = q[2], qw = q[3];
  var x = a[0], y = a[1], z = a[2];
  var uvx = qy * z - qz * y, uvy = qz * x - qx * z, uvz = qx * y - qy * x;
  var uuvx = qy * uvz - qz * uvy, uuvy = qz * uvx - qx * uvz, uuvz = qx * uvy - qy * uvx;
  var w2 = qw * 2;
  uvx *= w2;
  uvy *= w2;
  uvz *= w2;
  uuvx *= 2;
  uuvy *= 2;
  uuvz *= 2;
  out[0] = x + uvx + uuvx;
  out[1] = y + uvy + uuvy;
  out[2] = z + uvz + uuvz;
  return out;
}
function rotateX2(out, a, b, rad) {
  var p2 = [], r = [];
  p2[0] = a[0] - b[0];
  p2[1] = a[1] - b[1];
  p2[2] = a[2] - b[2];
  r[0] = p2[0];
  r[1] = p2[1] * Math.cos(rad) - p2[2] * Math.sin(rad);
  r[2] = p2[1] * Math.sin(rad) + p2[2] * Math.cos(rad);
  out[0] = r[0] + b[0];
  out[1] = r[1] + b[1];
  out[2] = r[2] + b[2];
  return out;
}
function rotateY2(out, a, b, rad) {
  var p2 = [], r = [];
  p2[0] = a[0] - b[0];
  p2[1] = a[1] - b[1];
  p2[2] = a[2] - b[2];
  r[0] = p2[2] * Math.sin(rad) + p2[0] * Math.cos(rad);
  r[1] = p2[1];
  r[2] = p2[2] * Math.cos(rad) - p2[0] * Math.sin(rad);
  out[0] = r[0] + b[0];
  out[1] = r[1] + b[1];
  out[2] = r[2] + b[2];
  return out;
}
function rotateZ2(out, a, b, rad) {
  var p2 = [], r = [];
  p2[0] = a[0] - b[0];
  p2[1] = a[1] - b[1];
  p2[2] = a[2] - b[2];
  r[0] = p2[0] * Math.cos(rad) - p2[1] * Math.sin(rad);
  r[1] = p2[0] * Math.sin(rad) + p2[1] * Math.cos(rad);
  r[2] = p2[2];
  out[0] = r[0] + b[0];
  out[1] = r[1] + b[1];
  out[2] = r[2] + b[2];
  return out;
}
function angle(a, b) {
  var ax = a[0], ay = a[1], az = a[2], bx = b[0], by = b[1], bz = b[2], mag1 = Math.sqrt(ax * ax + ay * ay + az * az), mag2 = Math.sqrt(bx * bx + by * by + bz * bz), mag = mag1 * mag2, cosine2 = mag && dot(a, b) / mag;
  return Math.acos(Math.min(Math.max(cosine2, -1), 1));
}
function zero(out) {
  out[0] = 0;
  out[1] = 0;
  out[2] = 0;
  return out;
}
function str2(a) {
  return "vec3(" + a[0] + ", " + a[1] + ", " + a[2] + ")";
}
function exactEquals2(a, b) {
  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2];
}
function equals2(a, b) {
  var a0 = a[0], a12 = a[1], a22 = a[2];
  var b0 = b[0], b1 = b[1], b2 = b[2];
  return Math.abs(a0 - b0) <= EPSILON * Math.max(1, Math.abs(a0), Math.abs(b0)) && Math.abs(a12 - b1) <= EPSILON * Math.max(1, Math.abs(a12), Math.abs(b1)) && Math.abs(a22 - b2) <= EPSILON * Math.max(1, Math.abs(a22), Math.abs(b2));
}
var sub2 = subtract2;
var mul2 = multiply2;
var div = divide;
var dist = distance;
var sqrDist = squaredDistance;
var len = length;
var sqrLen = squaredLength;
var forEach = function() {
  var vec = create3();
  return function(a, stride, offset, count2, fn, arg) {
    var i, l;
    if (!stride) {
      stride = 3;
    }
    if (!offset) {
      offset = 0;
    }
    if (count2) {
      l = Math.min(count2 * stride + offset, a.length);
    } else {
      l = a.length;
    }
    for (i = offset; i < l; i += stride) {
      vec[0] = a[i];
      vec[1] = a[i + 1];
      vec[2] = a[i + 2];
      fn(vec, vec, arg);
      a[i] = vec[0];
      a[i + 1] = vec[1];
      a[i + 2] = vec[2];
    }
    return a;
  };
}();

// node_modules/gl-matrix/esm/vec4.js
function create4() {
  var out = new ARRAY_TYPE(4);
  if (ARRAY_TYPE != Float32Array) {
    out[0] = 0;
    out[1] = 0;
    out[2] = 0;
    out[3] = 0;
  }
  return out;
}
function clone3(a) {
  var out = new ARRAY_TYPE(4);
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  out[3] = a[3];
  return out;
}
function fromValues3(x, y, z, w) {
  var out = new ARRAY_TYPE(4);
  out[0] = x;
  out[1] = y;
  out[2] = z;
  out[3] = w;
  return out;
}
function copy3(out, a) {
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  out[3] = a[3];
  return out;
}
function set3(out, x, y, z, w) {
  out[0] = x;
  out[1] = y;
  out[2] = z;
  out[3] = w;
  return out;
}
function add3(out, a, b) {
  out[0] = a[0] + b[0];
  out[1] = a[1] + b[1];
  out[2] = a[2] + b[2];
  out[3] = a[3] + b[3];
  return out;
}
function scale3(out, a, b) {
  out[0] = a[0] * b;
  out[1] = a[1] * b;
  out[2] = a[2] * b;
  out[3] = a[3] * b;
  return out;
}
function length2(a) {
  var x = a[0];
  var y = a[1];
  var z = a[2];
  var w = a[3];
  return Math.hypot(x, y, z, w);
}
function squaredLength2(a) {
  var x = a[0];
  var y = a[1];
  var z = a[2];
  var w = a[3];
  return x * x + y * y + z * z + w * w;
}
function normalize2(out, a) {
  var x = a[0];
  var y = a[1];
  var z = a[2];
  var w = a[3];
  var len4 = x * x + y * y + z * z + w * w;
  if (len4 > 0) {
    len4 = 1 / Math.sqrt(len4);
  }
  out[0] = x * len4;
  out[1] = y * len4;
  out[2] = z * len4;
  out[3] = w * len4;
  return out;
}
function dot2(a, b) {
  return a[0] * b[0] + a[1] * b[1] + a[2] * b[2] + a[3] * b[3];
}
function lerp2(out, a, b, t) {
  var ax = a[0];
  var ay = a[1];
  var az = a[2];
  var aw = a[3];
  out[0] = ax + t * (b[0] - ax);
  out[1] = ay + t * (b[1] - ay);
  out[2] = az + t * (b[2] - az);
  out[3] = aw + t * (b[3] - aw);
  return out;
}
function exactEquals3(a, b) {
  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2] && a[3] === b[3];
}
function equals3(a, b) {
  var a0 = a[0], a12 = a[1], a22 = a[2], a32 = a[3];
  var b0 = b[0], b1 = b[1], b2 = b[2], b3 = b[3];
  return Math.abs(a0 - b0) <= EPSILON * Math.max(1, Math.abs(a0), Math.abs(b0)) && Math.abs(a12 - b1) <= EPSILON * Math.max(1, Math.abs(a12), Math.abs(b1)) && Math.abs(a22 - b2) <= EPSILON * Math.max(1, Math.abs(a22), Math.abs(b2)) && Math.abs(a32 - b3) <= EPSILON * Math.max(1, Math.abs(a32), Math.abs(b3));
}
var forEach2 = function() {
  var vec = create4();
  return function(a, stride, offset, count2, fn, arg) {
    var i, l;
    if (!stride) {
      stride = 4;
    }
    if (!offset) {
      offset = 0;
    }
    if (count2) {
      l = Math.min(count2 * stride + offset, a.length);
    } else {
      l = a.length;
    }
    for (i = offset; i < l; i += stride) {
      vec[0] = a[i];
      vec[1] = a[i + 1];
      vec[2] = a[i + 2];
      vec[3] = a[i + 3];
      fn(vec, vec, arg);
      a[i] = vec[0];
      a[i + 1] = vec[1];
      a[i + 2] = vec[2];
      a[i + 3] = vec[3];
    }
    return a;
  };
}();

// node_modules/gl-matrix/esm/quat.js
function create5() {
  var out = new ARRAY_TYPE(4);
  if (ARRAY_TYPE != Float32Array) {
    out[0] = 0;
    out[1] = 0;
    out[2] = 0;
  }
  out[3] = 1;
  return out;
}
function identity2(out) {
  out[0] = 0;
  out[1] = 0;
  out[2] = 0;
  out[3] = 1;
  return out;
}
function setAxisAngle(out, axis, rad) {
  rad = rad * 0.5;
  var s = Math.sin(rad);
  out[0] = s * axis[0];
  out[1] = s * axis[1];
  out[2] = s * axis[2];
  out[3] = Math.cos(rad);
  return out;
}
function getAxisAngle(out_axis, q) {
  var rad = Math.acos(q[3]) * 2;
  var s = Math.sin(rad / 2);
  if (s > EPSILON) {
    out_axis[0] = q[0] / s;
    out_axis[1] = q[1] / s;
    out_axis[2] = q[2] / s;
  } else {
    out_axis[0] = 1;
    out_axis[1] = 0;
    out_axis[2] = 0;
  }
  return rad;
}
function getAngle(a, b) {
  var dotproduct = dot3(a, b);
  return Math.acos(2 * dotproduct * dotproduct - 1);
}
function multiply3(out, a, b) {
  var ax = a[0], ay = a[1], az = a[2], aw = a[3];
  var bx = b[0], by = b[1], bz = b[2], bw = b[3];
  out[0] = ax * bw + aw * bx + ay * bz - az * by;
  out[1] = ay * bw + aw * by + az * bx - ax * bz;
  out[2] = az * bw + aw * bz + ax * by - ay * bx;
  out[3] = aw * bw - ax * bx - ay * by - az * bz;
  return out;
}
function rotateX3(out, a, rad) {
  rad *= 0.5;
  var ax = a[0], ay = a[1], az = a[2], aw = a[3];
  var bx = Math.sin(rad), bw = Math.cos(rad);
  out[0] = ax * bw + aw * bx;
  out[1] = ay * bw + az * bx;
  out[2] = az * bw - ay * bx;
  out[3] = aw * bw - ax * bx;
  return out;
}
function rotateY3(out, a, rad) {
  rad *= 0.5;
  var ax = a[0], ay = a[1], az = a[2], aw = a[3];
  var by = Math.sin(rad), bw = Math.cos(rad);
  out[0] = ax * bw - az * by;
  out[1] = ay * bw + aw * by;
  out[2] = az * bw + ax * by;
  out[3] = aw * bw - ay * by;
  return out;
}
function rotateZ3(out, a, rad) {
  rad *= 0.5;
  var ax = a[0], ay = a[1], az = a[2], aw = a[3];
  var bz = Math.sin(rad), bw = Math.cos(rad);
  out[0] = ax * bw + ay * bz;
  out[1] = ay * bw - ax * bz;
  out[2] = az * bw + aw * bz;
  out[3] = aw * bw - az * bz;
  return out;
}
function calculateW(out, a) {
  var x = a[0], y = a[1], z = a[2];
  out[0] = x;
  out[1] = y;
  out[2] = z;
  out[3] = Math.sqrt(Math.abs(1 - x * x - y * y - z * z));
  return out;
}
function exp(out, a) {
  var x = a[0], y = a[1], z = a[2], w = a[3];
  var r = Math.sqrt(x * x + y * y + z * z);
  var et = Math.exp(w);
  var s = r > 0 ? et * Math.sin(r) / r : 0;
  out[0] = x * s;
  out[1] = y * s;
  out[2] = z * s;
  out[3] = et * Math.cos(r);
  return out;
}
function ln(out, a) {
  var x = a[0], y = a[1], z = a[2], w = a[3];
  var r = Math.sqrt(x * x + y * y + z * z);
  var t = r > 0 ? Math.atan2(r, w) / r : 0;
  out[0] = x * t;
  out[1] = y * t;
  out[2] = z * t;
  out[3] = 0.5 * Math.log(x * x + y * y + z * z + w * w);
  return out;
}
function pow(out, a, b) {
  ln(out, a);
  scale4(out, out, b);
  exp(out, out);
  return out;
}
function slerp(out, a, b, t) {
  var ax = a[0], ay = a[1], az = a[2], aw = a[3];
  var bx = b[0], by = b[1], bz = b[2], bw = b[3];
  var omega, cosom, sinom, scale0, scale1;
  cosom = ax * bx + ay * by + az * bz + aw * bw;
  if (cosom < 0) {
    cosom = -cosom;
    bx = -bx;
    by = -by;
    bz = -bz;
    bw = -bw;
  }
  if (1 - cosom > EPSILON) {
    omega = Math.acos(cosom);
    sinom = Math.sin(omega);
    scale0 = Math.sin((1 - t) * omega) / sinom;
    scale1 = Math.sin(t * omega) / sinom;
  } else {
    scale0 = 1 - t;
    scale1 = t;
  }
  out[0] = scale0 * ax + scale1 * bx;
  out[1] = scale0 * ay + scale1 * by;
  out[2] = scale0 * az + scale1 * bz;
  out[3] = scale0 * aw + scale1 * bw;
  return out;
}
function random2(out) {
  var u1 = RANDOM();
  var u2 = RANDOM();
  var u3 = RANDOM();
  var sqrt1MinusU1 = Math.sqrt(1 - u1);
  var sqrtU1 = Math.sqrt(u1);
  out[0] = sqrt1MinusU1 * Math.sin(2 * Math.PI * u2);
  out[1] = sqrt1MinusU1 * Math.cos(2 * Math.PI * u2);
  out[2] = sqrtU1 * Math.sin(2 * Math.PI * u3);
  out[3] = sqrtU1 * Math.cos(2 * Math.PI * u3);
  return out;
}
function invert2(out, a) {
  var a0 = a[0], a12 = a[1], a22 = a[2], a32 = a[3];
  var dot6 = a0 * a0 + a12 * a12 + a22 * a22 + a32 * a32;
  var invDot = dot6 ? 1 / dot6 : 0;
  out[0] = -a0 * invDot;
  out[1] = -a12 * invDot;
  out[2] = -a22 * invDot;
  out[3] = a32 * invDot;
  return out;
}
function conjugate(out, a) {
  out[0] = -a[0];
  out[1] = -a[1];
  out[2] = -a[2];
  out[3] = a[3];
  return out;
}
function fromMat3(out, m) {
  var fTrace = m[0] + m[4] + m[8];
  var fRoot;
  if (fTrace > 0) {
    fRoot = Math.sqrt(fTrace + 1);
    out[3] = 0.5 * fRoot;
    fRoot = 0.5 / fRoot;
    out[0] = (m[5] - m[7]) * fRoot;
    out[1] = (m[6] - m[2]) * fRoot;
    out[2] = (m[1] - m[3]) * fRoot;
  } else {
    var i = 0;
    if (m[4] > m[0])
      i = 1;
    if (m[8] > m[i * 3 + i])
      i = 2;
    var j = (i + 1) % 3;
    var k = (i + 2) % 3;
    fRoot = Math.sqrt(m[i * 3 + i] - m[j * 3 + j] - m[k * 3 + k] + 1);
    out[i] = 0.5 * fRoot;
    fRoot = 0.5 / fRoot;
    out[3] = (m[j * 3 + k] - m[k * 3 + j]) * fRoot;
    out[j] = (m[j * 3 + i] + m[i * 3 + j]) * fRoot;
    out[k] = (m[k * 3 + i] + m[i * 3 + k]) * fRoot;
  }
  return out;
}
function fromEuler(out, x, y, z) {
  var halfToRad = 0.5 * Math.PI / 180;
  x *= halfToRad;
  y *= halfToRad;
  z *= halfToRad;
  var sx = Math.sin(x);
  var cx = Math.cos(x);
  var sy = Math.sin(y);
  var cy = Math.cos(y);
  var sz = Math.sin(z);
  var cz = Math.cos(z);
  out[0] = sx * cy * cz - cx * sy * sz;
  out[1] = cx * sy * cz + sx * cy * sz;
  out[2] = cx * cy * sz - sx * sy * cz;
  out[3] = cx * cy * cz + sx * sy * sz;
  return out;
}
function str3(a) {
  return "quat(" + a[0] + ", " + a[1] + ", " + a[2] + ", " + a[3] + ")";
}
var clone4 = clone3;
var fromValues4 = fromValues3;
var copy4 = copy3;
var set4 = set3;
var add4 = add3;
var mul3 = multiply3;
var scale4 = scale3;
var dot3 = dot2;
var lerp3 = lerp2;
var length3 = length2;
var len2 = length3;
var squaredLength3 = squaredLength2;
var sqrLen2 = squaredLength3;
var normalize3 = normalize2;
var exactEquals4 = exactEquals3;
var equals4 = equals3;
var rotationTo = function() {
  var tmpvec3 = create3();
  var xUnitVec3 = fromValues2(1, 0, 0);
  var yUnitVec3 = fromValues2(0, 1, 0);
  return function(out, a, b) {
    var dot6 = dot(a, b);
    if (dot6 < -0.999999) {
      cross(tmpvec3, xUnitVec3, a);
      if (len(tmpvec3) < 1e-6)
        cross(tmpvec3, yUnitVec3, a);
      normalize(tmpvec3, tmpvec3);
      setAxisAngle(out, tmpvec3, Math.PI);
      return out;
    } else if (dot6 > 0.999999) {
      out[0] = 0;
      out[1] = 0;
      out[2] = 0;
      out[3] = 1;
      return out;
    } else {
      cross(tmpvec3, a, b);
      out[0] = tmpvec3[0];
      out[1] = tmpvec3[1];
      out[2] = tmpvec3[2];
      out[3] = 1 + dot6;
      return normalize3(out, out);
    }
  };
}();
var sqlerp = function() {
  var temp1 = create5();
  var temp2 = create5();
  return function(out, a, b, c, d, t) {
    slerp(temp1, a, d, t);
    slerp(temp2, b, c, t);
    slerp(out, temp1, temp2, 2 * t * (1 - t));
    return out;
  };
}();
var setAxes = function() {
  var matr = create();
  return function(out, view, right, up) {
    matr[0] = right[0];
    matr[3] = right[1];
    matr[6] = right[2];
    matr[1] = up[0];
    matr[4] = up[1];
    matr[7] = up[2];
    matr[2] = -view[0];
    matr[5] = -view[1];
    matr[8] = -view[2];
    return normalize3(out, fromMat3(out, matr));
  };
}();

// node_modules/gl-matrix/esm/quat2.js
var quat2_exports = {};
__export(quat2_exports, {
  add: () => add5,
  clone: () => clone5,
  conjugate: () => conjugate2,
  copy: () => copy5,
  create: () => create6,
  dot: () => dot4,
  equals: () => equals5,
  exactEquals: () => exactEquals5,
  fromMat4: () => fromMat4,
  fromRotation: () => fromRotation2,
  fromRotationTranslation: () => fromRotationTranslation2,
  fromRotationTranslationValues: () => fromRotationTranslationValues,
  fromTranslation: () => fromTranslation2,
  fromValues: () => fromValues5,
  getDual: () => getDual,
  getReal: () => getReal,
  getTranslation: () => getTranslation2,
  identity: () => identity3,
  invert: () => invert3,
  len: () => len3,
  length: () => length4,
  lerp: () => lerp4,
  mul: () => mul4,
  multiply: () => multiply4,
  normalize: () => normalize4,
  rotateAroundAxis: () => rotateAroundAxis,
  rotateByQuatAppend: () => rotateByQuatAppend,
  rotateByQuatPrepend: () => rotateByQuatPrepend,
  rotateX: () => rotateX4,
  rotateY: () => rotateY4,
  rotateZ: () => rotateZ4,
  scale: () => scale5,
  set: () => set5,
  setDual: () => setDual,
  setReal: () => setReal,
  sqrLen: () => sqrLen3,
  squaredLength: () => squaredLength4,
  str: () => str4,
  translate: () => translate2
});
function create6() {
  var dq = new ARRAY_TYPE(8);
  if (ARRAY_TYPE != Float32Array) {
    dq[0] = 0;
    dq[1] = 0;
    dq[2] = 0;
    dq[4] = 0;
    dq[5] = 0;
    dq[6] = 0;
    dq[7] = 0;
  }
  dq[3] = 1;
  return dq;
}
function clone5(a) {
  var dq = new ARRAY_TYPE(8);
  dq[0] = a[0];
  dq[1] = a[1];
  dq[2] = a[2];
  dq[3] = a[3];
  dq[4] = a[4];
  dq[5] = a[5];
  dq[6] = a[6];
  dq[7] = a[7];
  return dq;
}
function fromValues5(x1, y1, z1, w1, x2, y2, z2, w2) {
  var dq = new ARRAY_TYPE(8);
  dq[0] = x1;
  dq[1] = y1;
  dq[2] = z1;
  dq[3] = w1;
  dq[4] = x2;
  dq[5] = y2;
  dq[6] = z2;
  dq[7] = w2;
  return dq;
}
function fromRotationTranslationValues(x1, y1, z1, w1, x2, y2, z2) {
  var dq = new ARRAY_TYPE(8);
  dq[0] = x1;
  dq[1] = y1;
  dq[2] = z1;
  dq[3] = w1;
  var ax = x2 * 0.5, ay = y2 * 0.5, az = z2 * 0.5;
  dq[4] = ax * w1 + ay * z1 - az * y1;
  dq[5] = ay * w1 + az * x1 - ax * z1;
  dq[6] = az * w1 + ax * y1 - ay * x1;
  dq[7] = -ax * x1 - ay * y1 - az * z1;
  return dq;
}
function fromRotationTranslation2(out, q, t) {
  var ax = t[0] * 0.5, ay = t[1] * 0.5, az = t[2] * 0.5, bx = q[0], by = q[1], bz = q[2], bw = q[3];
  out[0] = bx;
  out[1] = by;
  out[2] = bz;
  out[3] = bw;
  out[4] = ax * bw + ay * bz - az * by;
  out[5] = ay * bw + az * bx - ax * bz;
  out[6] = az * bw + ax * by - ay * bx;
  out[7] = -ax * bx - ay * by - az * bz;
  return out;
}
function fromTranslation2(out, t) {
  out[0] = 0;
  out[1] = 0;
  out[2] = 0;
  out[3] = 1;
  out[4] = t[0] * 0.5;
  out[5] = t[1] * 0.5;
  out[6] = t[2] * 0.5;
  out[7] = 0;
  return out;
}
function fromRotation2(out, q) {
  out[0] = q[0];
  out[1] = q[1];
  out[2] = q[2];
  out[3] = q[3];
  out[4] = 0;
  out[5] = 0;
  out[6] = 0;
  out[7] = 0;
  return out;
}
function fromMat4(out, a) {
  var outer = create5();
  getRotation(outer, a);
  var t = new ARRAY_TYPE(3);
  getTranslation(t, a);
  fromRotationTranslation2(out, outer, t);
  return out;
}
function copy5(out, a) {
  out[0] = a[0];
  out[1] = a[1];
  out[2] = a[2];
  out[3] = a[3];
  out[4] = a[4];
  out[5] = a[5];
  out[6] = a[6];
  out[7] = a[7];
  return out;
}
function identity3(out) {
  out[0] = 0;
  out[1] = 0;
  out[2] = 0;
  out[3] = 1;
  out[4] = 0;
  out[5] = 0;
  out[6] = 0;
  out[7] = 0;
  return out;
}
function set5(out, x1, y1, z1, w1, x2, y2, z2, w2) {
  out[0] = x1;
  out[1] = y1;
  out[2] = z1;
  out[3] = w1;
  out[4] = x2;
  out[5] = y2;
  out[6] = z2;
  out[7] = w2;
  return out;
}
var getReal = copy4;
function getDual(out, a) {
  out[0] = a[4];
  out[1] = a[5];
  out[2] = a[6];
  out[3] = a[7];
  return out;
}
var setReal = copy4;
function setDual(out, q) {
  out[4] = q[0];
  out[5] = q[1];
  out[6] = q[2];
  out[7] = q[3];
  return out;
}
function getTranslation2(out, a) {
  var ax = a[4], ay = a[5], az = a[6], aw = a[7], bx = -a[0], by = -a[1], bz = -a[2], bw = a[3];
  out[0] = (ax * bw + aw * bx + ay * bz - az * by) * 2;
  out[1] = (ay * bw + aw * by + az * bx - ax * bz) * 2;
  out[2] = (az * bw + aw * bz + ax * by - ay * bx) * 2;
  return out;
}
function translate2(out, a, v) {
  var ax1 = a[0], ay1 = a[1], az1 = a[2], aw1 = a[3], bx1 = v[0] * 0.5, by1 = v[1] * 0.5, bz1 = v[2] * 0.5, ax2 = a[4], ay2 = a[5], az2 = a[6], aw2 = a[7];
  out[0] = ax1;
  out[1] = ay1;
  out[2] = az1;
  out[3] = aw1;
  out[4] = aw1 * bx1 + ay1 * bz1 - az1 * by1 + ax2;
  out[5] = aw1 * by1 + az1 * bx1 - ax1 * bz1 + ay2;
  out[6] = aw1 * bz1 + ax1 * by1 - ay1 * bx1 + az2;
  out[7] = -ax1 * bx1 - ay1 * by1 - az1 * bz1 + aw2;
  return out;
}
function rotateX4(out, a, rad) {
  var bx = -a[0], by = -a[1], bz = -a[2], bw = a[3], ax = a[4], ay = a[5], az = a[6], aw = a[7], ax1 = ax * bw + aw * bx + ay * bz - az * by, ay1 = ay * bw + aw * by + az * bx - ax * bz, az1 = az * bw + aw * bz + ax * by - ay * bx, aw1 = aw * bw - ax * bx - ay * by - az * bz;
  rotateX3(out, a, rad);
  bx = out[0];
  by = out[1];
  bz = out[2];
  bw = out[3];
  out[4] = ax1 * bw + aw1 * bx + ay1 * bz - az1 * by;
  out[5] = ay1 * bw + aw1 * by + az1 * bx - ax1 * bz;
  out[6] = az1 * bw + aw1 * bz + ax1 * by - ay1 * bx;
  out[7] = aw1 * bw - ax1 * bx - ay1 * by - az1 * bz;
  return out;
}
function rotateY4(out, a, rad) {
  var bx = -a[0], by = -a[1], bz = -a[2], bw = a[3], ax = a[4], ay = a[5], az = a[6], aw = a[7], ax1 = ax * bw + aw * bx + ay * bz - az * by, ay1 = ay * bw + aw * by + az * bx - ax * bz, az1 = az * bw + aw * bz + ax * by - ay * bx, aw1 = aw * bw - ax * bx - ay * by - az * bz;
  rotateY3(out, a, rad);
  bx = out[0];
  by = out[1];
  bz = out[2];
  bw = out[3];
  out[4] = ax1 * bw + aw1 * bx + ay1 * bz - az1 * by;
  out[5] = ay1 * bw + aw1 * by + az1 * bx - ax1 * bz;
  out[6] = az1 * bw + aw1 * bz + ax1 * by - ay1 * bx;
  out[7] = aw1 * bw - ax1 * bx - ay1 * by - az1 * bz;
  return out;
}
function rotateZ4(out, a, rad) {
  var bx = -a[0], by = -a[1], bz = -a[2], bw = a[3], ax = a[4], ay = a[5], az = a[6], aw = a[7], ax1 = ax * bw + aw * bx + ay * bz - az * by, ay1 = ay * bw + aw * by + az * bx - ax * bz, az1 = az * bw + aw * bz + ax * by - ay * bx, aw1 = aw * bw - ax * bx - ay * by - az * bz;
  rotateZ3(out, a, rad);
  bx = out[0];
  by = out[1];
  bz = out[2];
  bw = out[3];
  out[4] = ax1 * bw + aw1 * bx + ay1 * bz - az1 * by;
  out[5] = ay1 * bw + aw1 * by + az1 * bx - ax1 * bz;
  out[6] = az1 * bw + aw1 * bz + ax1 * by - ay1 * bx;
  out[7] = aw1 * bw - ax1 * bx - ay1 * by - az1 * bz;
  return out;
}
function rotateByQuatAppend(out, a, q) {
  var qx = q[0], qy = q[1], qz = q[2], qw = q[3], ax = a[0], ay = a[1], az = a[2], aw = a[3];
  out[0] = ax * qw + aw * qx + ay * qz - az * qy;
  out[1] = ay * qw + aw * qy + az * qx - ax * qz;
  out[2] = az * qw + aw * qz + ax * qy - ay * qx;
  out[3] = aw * qw - ax * qx - ay * qy - az * qz;
  ax = a[4];
  ay = a[5];
  az = a[6];
  aw = a[7];
  out[4] = ax * qw + aw * qx + ay * qz - az * qy;
  out[5] = ay * qw + aw * qy + az * qx - ax * qz;
  out[6] = az * qw + aw * qz + ax * qy - ay * qx;
  out[7] = aw * qw - ax * qx - ay * qy - az * qz;
  return out;
}
function rotateByQuatPrepend(out, q, a) {
  var qx = q[0], qy = q[1], qz = q[2], qw = q[3], bx = a[0], by = a[1], bz = a[2], bw = a[3];
  out[0] = qx * bw + qw * bx + qy * bz - qz * by;
  out[1] = qy * bw + qw * by + qz * bx - qx * bz;
  out[2] = qz * bw + qw * bz + qx * by - qy * bx;
  out[3] = qw * bw - qx * bx - qy * by - qz * bz;
  bx = a[4];
  by = a[5];
  bz = a[6];
  bw = a[7];
  out[4] = qx * bw + qw * bx + qy * bz - qz * by;
  out[5] = qy * bw + qw * by + qz * bx - qx * bz;
  out[6] = qz * bw + qw * bz + qx * by - qy * bx;
  out[7] = qw * bw - qx * bx - qy * by - qz * bz;
  return out;
}
function rotateAroundAxis(out, a, axis, rad) {
  if (Math.abs(rad) < EPSILON) {
    return copy5(out, a);
  }
  var axisLength = Math.hypot(axis[0], axis[1], axis[2]);
  rad = rad * 0.5;
  var s = Math.sin(rad);
  var bx = s * axis[0] / axisLength;
  var by = s * axis[1] / axisLength;
  var bz = s * axis[2] / axisLength;
  var bw = Math.cos(rad);
  var ax1 = a[0], ay1 = a[1], az1 = a[2], aw1 = a[3];
  out[0] = ax1 * bw + aw1 * bx + ay1 * bz - az1 * by;
  out[1] = ay1 * bw + aw1 * by + az1 * bx - ax1 * bz;
  out[2] = az1 * bw + aw1 * bz + ax1 * by - ay1 * bx;
  out[3] = aw1 * bw - ax1 * bx - ay1 * by - az1 * bz;
  var ax = a[4], ay = a[5], az = a[6], aw = a[7];
  out[4] = ax * bw + aw * bx + ay * bz - az * by;
  out[5] = ay * bw + aw * by + az * bx - ax * bz;
  out[6] = az * bw + aw * bz + ax * by - ay * bx;
  out[7] = aw * bw - ax * bx - ay * by - az * bz;
  return out;
}
function add5(out, a, b) {
  out[0] = a[0] + b[0];
  out[1] = a[1] + b[1];
  out[2] = a[2] + b[2];
  out[3] = a[3] + b[3];
  out[4] = a[4] + b[4];
  out[5] = a[5] + b[5];
  out[6] = a[6] + b[6];
  out[7] = a[7] + b[7];
  return out;
}
function multiply4(out, a, b) {
  var ax0 = a[0], ay0 = a[1], az0 = a[2], aw0 = a[3], bx1 = b[4], by1 = b[5], bz1 = b[6], bw1 = b[7], ax1 = a[4], ay1 = a[5], az1 = a[6], aw1 = a[7], bx0 = b[0], by0 = b[1], bz0 = b[2], bw0 = b[3];
  out[0] = ax0 * bw0 + aw0 * bx0 + ay0 * bz0 - az0 * by0;
  out[1] = ay0 * bw0 + aw0 * by0 + az0 * bx0 - ax0 * bz0;
  out[2] = az0 * bw0 + aw0 * bz0 + ax0 * by0 - ay0 * bx0;
  out[3] = aw0 * bw0 - ax0 * bx0 - ay0 * by0 - az0 * bz0;
  out[4] = ax0 * bw1 + aw0 * bx1 + ay0 * bz1 - az0 * by1 + ax1 * bw0 + aw1 * bx0 + ay1 * bz0 - az1 * by0;
  out[5] = ay0 * bw1 + aw0 * by1 + az0 * bx1 - ax0 * bz1 + ay1 * bw0 + aw1 * by0 + az1 * bx0 - ax1 * bz0;
  out[6] = az0 * bw1 + aw0 * bz1 + ax0 * by1 - ay0 * bx1 + az1 * bw0 + aw1 * bz0 + ax1 * by0 - ay1 * bx0;
  out[7] = aw0 * bw1 - ax0 * bx1 - ay0 * by1 - az0 * bz1 + aw1 * bw0 - ax1 * bx0 - ay1 * by0 - az1 * bz0;
  return out;
}
var mul4 = multiply4;
function scale5(out, a, b) {
  out[0] = a[0] * b;
  out[1] = a[1] * b;
  out[2] = a[2] * b;
  out[3] = a[3] * b;
  out[4] = a[4] * b;
  out[5] = a[5] * b;
  out[6] = a[6] * b;
  out[7] = a[7] * b;
  return out;
}
var dot4 = dot3;
function lerp4(out, a, b, t) {
  var mt = 1 - t;
  if (dot4(a, b) < 0)
    t = -t;
  out[0] = a[0] * mt + b[0] * t;
  out[1] = a[1] * mt + b[1] * t;
  out[2] = a[2] * mt + b[2] * t;
  out[3] = a[3] * mt + b[3] * t;
  out[4] = a[4] * mt + b[4] * t;
  out[5] = a[5] * mt + b[5] * t;
  out[6] = a[6] * mt + b[6] * t;
  out[7] = a[7] * mt + b[7] * t;
  return out;
}
function invert3(out, a) {
  var sqlen = squaredLength4(a);
  out[0] = -a[0] / sqlen;
  out[1] = -a[1] / sqlen;
  out[2] = -a[2] / sqlen;
  out[3] = a[3] / sqlen;
  out[4] = -a[4] / sqlen;
  out[5] = -a[5] / sqlen;
  out[6] = -a[6] / sqlen;
  out[7] = a[7] / sqlen;
  return out;
}
function conjugate2(out, a) {
  out[0] = -a[0];
  out[1] = -a[1];
  out[2] = -a[2];
  out[3] = a[3];
  out[4] = -a[4];
  out[5] = -a[5];
  out[6] = -a[6];
  out[7] = a[7];
  return out;
}
var length4 = length3;
var len3 = length4;
var squaredLength4 = squaredLength3;
var sqrLen3 = squaredLength4;
function normalize4(out, a) {
  var magnitude = squaredLength4(a);
  if (magnitude > 0) {
    magnitude = Math.sqrt(magnitude);
    var a0 = a[0] / magnitude;
    var a12 = a[1] / magnitude;
    var a22 = a[2] / magnitude;
    var a32 = a[3] / magnitude;
    var b0 = a[4];
    var b1 = a[5];
    var b2 = a[6];
    var b3 = a[7];
    var a_dot_b = a0 * b0 + a12 * b1 + a22 * b2 + a32 * b3;
    out[0] = a0;
    out[1] = a12;
    out[2] = a22;
    out[3] = a32;
    out[4] = (b0 - a0 * a_dot_b) / magnitude;
    out[5] = (b1 - a12 * a_dot_b) / magnitude;
    out[6] = (b2 - a22 * a_dot_b) / magnitude;
    out[7] = (b3 - a32 * a_dot_b) / magnitude;
  }
  return out;
}
function str4(a) {
  return "quat2(" + a[0] + ", " + a[1] + ", " + a[2] + ", " + a[3] + ", " + a[4] + ", " + a[5] + ", " + a[6] + ", " + a[7] + ")";
}
function exactEquals5(a, b) {
  return a[0] === b[0] && a[1] === b[1] && a[2] === b[2] && a[3] === b[3] && a[4] === b[4] && a[5] === b[5] && a[6] === b[6] && a[7] === b[7];
}
function equals5(a, b) {
  var a0 = a[0], a12 = a[1], a22 = a[2], a32 = a[3], a42 = a[4], a52 = a[5], a6 = a[6], a7 = a[7];
  var b0 = b[0], b1 = b[1], b2 = b[2], b3 = b[3], b4 = b[4], b5 = b[5], b6 = b[6], b7 = b[7];
  return Math.abs(a0 - b0) <= EPSILON * Math.max(1, Math.abs(a0), Math.abs(b0)) && Math.abs(a12 - b1) <= EPSILON * Math.max(1, Math.abs(a12), Math.abs(b1)) && Math.abs(a22 - b2) <= EPSILON * Math.max(1, Math.abs(a22), Math.abs(b2)) && Math.abs(a32 - b3) <= EPSILON * Math.max(1, Math.abs(a32), Math.abs(b3)) && Math.abs(a42 - b4) <= EPSILON * Math.max(1, Math.abs(a42), Math.abs(b4)) && Math.abs(a52 - b5) <= EPSILON * Math.max(1, Math.abs(a52), Math.abs(b5)) && Math.abs(a6 - b6) <= EPSILON * Math.max(1, Math.abs(a6), Math.abs(b6)) && Math.abs(a7 - b7) <= EPSILON * Math.max(1, Math.abs(a7), Math.abs(b7));
}

// node_modules/@wonderlandengine/mind-ar-tracking/dist/index.js
var __create = Object.create;
var __defProp2 = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __defNormalProp2 = (obj, key, value) => key in obj ? __defProp2(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __commonJS = (cb, mod4) => function __require() {
  return mod4 || (0, cb[__getOwnPropNames(cb)[0]])((mod4 = { exports: {} }).exports, mod4), mod4.exports;
};
var __export2 = (target, all4) => {
  for (var name in all4)
    __defProp2(target, name, { get: all4[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp2(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod4, isNodeMode, target) => (target = mod4 != null ? __create(__getProtoOf(mod4)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod4 || !mod4.__esModule ? __defProp2(target, "default", { value: mod4, enumerable: true }) : target,
  mod4
));
var __toCommonJS = (mod4) => __copyProps(__defProp2({}, "__esModule", { value: true }), mod4);
var __publicField2 = (obj, key, value) => {
  __defNormalProp2(obj, typeof key !== "symbol" ? key + "" : key, value);
  return value;
};
function notYetImplemented(kernelName) {
  throw new Error(`'${kernelName}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}
var EPSILON_FLOAT32;
var EPSILON_FLOAT16;
var DataStorage;
var KernelBackend;
var init_backend = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/backend.js"() {
    EPSILON_FLOAT32 = 1e-7;
    EPSILON_FLOAT16 = 1e-4;
    DataStorage = class {
      constructor(backend2, dataMover) {
        this.backend = backend2;
        this.dataMover = dataMover;
        this.data = /* @__PURE__ */ new WeakMap();
        this.dataIdsCount = 0;
      }
      get(dataId) {
        if (!this.data.has(dataId)) {
          this.dataMover.moveData(this.backend, dataId);
        }
        return this.data.get(dataId);
      }
      set(dataId, value) {
        this.dataIdsCount++;
        this.data.set(dataId, value);
      }
      has(dataId) {
        return this.data.has(dataId);
      }
      delete(dataId) {
        this.dataIdsCount--;
        return this.data.delete(dataId);
      }
      numDataIds() {
        return this.dataIdsCount;
      }
    };
    KernelBackend = class {
      refCount(dataId) {
        return notYetImplemented("refCount");
      }
      incRef(dataId) {
        return notYetImplemented("incRef");
      }
      timerAvailable() {
        return true;
      }
      time(f) {
        return notYetImplemented("time");
      }
      read(dataId) {
        return notYetImplemented("read");
      }
      readSync(dataId) {
        return notYetImplemented("readSync");
      }
      readToGPU(dataId, options) {
        return notYetImplemented("readToGPU");
      }
      numDataIds() {
        return notYetImplemented("numDataIds");
      }
      disposeData(dataId, force) {
        return notYetImplemented("disposeData");
      }
      write(values, shape, dtype) {
        return notYetImplemented("write");
      }
      move(dataId, values, shape, dtype, refCount) {
        return notYetImplemented("move");
      }
      createTensorFromGPUData(values, shape, dtype) {
        return notYetImplemented("createTensorFromGPUData");
      }
      memory() {
        return notYetImplemented("memory");
      }
      /** Returns the highest precision for floats in bits (e.g. 16 or 32) */
      floatPrecision() {
        return notYetImplemented("floatPrecision");
      }
      /** Returns the smallest representable number.  */
      epsilon() {
        return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
      }
      dispose() {
        return notYetImplemented("dispose");
      }
    };
  }
});
function shuffle(array2) {
  let counter = array2.length;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    swap(array2, counter, index);
  }
}
function shuffleCombo(array2, array22) {
  if (array2.length !== array22.length) {
    throw new Error(`Array sizes must match to be shuffled together First array length was ${array2.length}Second array length was ${array22.length}`);
  }
  let counter = array2.length;
  let index = 0;
  while (counter > 0) {
    index = Math.random() * counter | 0;
    counter--;
    swap(array2, counter, index);
    swap(array22, counter, index);
  }
}
function clamp2(min5, x, max5) {
  return Math.max(min5, Math.min(x, max5));
}
function nearestLargerEven(val) {
  return val % 2 === 0 ? val : val + 1;
}
function swap(object, left, right) {
  const temp = object[left];
  object[left] = object[right];
  object[right] = temp;
}
function sum(arr) {
  let sum5 = 0;
  for (let i = 0; i < arr.length; i++) {
    sum5 += arr[i];
  }
  return sum5;
}
function randUniform(a, b) {
  const r = Math.random();
  return b * r + (1 - r) * a;
}
function distSquared(a, b) {
  let result = 0;
  for (let i = 0; i < a.length; i++) {
    const diff = Number(a[i]) - Number(b[i]);
    result += diff * diff;
  }
  return result;
}
function assert(expr, msg) {
  if (!expr) {
    throw new Error(typeof msg === "string" ? msg : msg());
  }
}
function assertShapesMatch(shapeA, shapeB, errorMessagePrefix = "") {
  assert(arraysEqual(shapeA, shapeB), () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);
}
function assertNonNull(a) {
  assert(a != null, () => `The input to the tensor constructor must be a non-null value.`);
}
function sizeFromShape(shape) {
  if (shape.length === 0) {
    return 1;
  }
  let size = shape[0];
  for (let i = 1; i < shape.length; i++) {
    size *= shape[i];
  }
  return size;
}
function isScalarShape(shape) {
  return shape.length === 0;
}
function arraysEqual(n1, n2) {
  if (n1 === n2) {
    return true;
  }
  if (n1 == null || n2 == null) {
    return false;
  }
  if (n1.length !== n2.length) {
    return false;
  }
  for (let i = 0; i < n1.length; i++) {
    if (n1[i] !== n2[i]) {
      return false;
    }
  }
  return true;
}
function isInt(a) {
  return a % 1 === 0;
}
function tanh(x) {
  if (Math.tanh != null) {
    return Math.tanh(x);
  }
  if (x === Infinity) {
    return 1;
  } else if (x === -Infinity) {
    return -1;
  } else {
    const e2x = Math.exp(2 * x);
    return (e2x - 1) / (e2x + 1);
  }
}
function sizeToSquarishShape(size) {
  const width = Math.ceil(Math.sqrt(size));
  return [width, Math.ceil(size / width)];
}
function createShuffledIndices(n) {
  const shuffledIndices = new Uint32Array(n);
  for (let i = 0; i < n; ++i) {
    shuffledIndices[i] = i;
  }
  shuffle(shuffledIndices);
  return shuffledIndices;
}
function rightPad(a, size) {
  if (size <= a.length) {
    return a;
  }
  return a + " ".repeat(size - a.length);
}
function repeatedTry(checkFn, delayFn = (counter) => 0, maxCounter, scheduleFn) {
  return new Promise((resolve, reject) => {
    let tryCount = 0;
    const tryFn = () => {
      if (checkFn()) {
        resolve();
        return;
      }
      tryCount++;
      const nextBackoff = delayFn(tryCount);
      if (maxCounter != null && tryCount >= maxCounter) {
        reject();
        return;
      }
      if (scheduleFn != null) {
        scheduleFn(tryFn, nextBackoff);
      } else {
        setTimeout(tryFn, nextBackoff);
      }
    };
    tryFn();
  });
}
function inferFromImplicitShape(shape, size) {
  let shapeProd = 1;
  let implicitIdx = -1;
  for (let i = 0; i < shape.length; ++i) {
    if (shape[i] >= 0) {
      shapeProd *= shape[i];
    } else if (shape[i] === -1) {
      if (implicitIdx !== -1) {
        throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${implicitIdx} and dim ${i}`);
      }
      implicitIdx = i;
    } else if (shape[i] < 0) {
      throw Error(`Shapes can not be < 0. Found ${shape[i]} at dim ${i}`);
    }
  }
  if (implicitIdx === -1) {
    if (size > 0 && size !== shapeProd) {
      throw Error(`Size(${size}) must match the product of shape ${shape}`);
    }
    return shape;
  }
  if (shapeProd === 0) {
    throw Error(`Cannot infer the missing size in [${shape}] when there are 0 elements`);
  }
  if (size % shapeProd !== 0) {
    throw Error(`The implicit shape can't be a fractional number. Got ${size} / ${shapeProd}`);
  }
  const newShape = shape.slice();
  newShape[implicitIdx] = size / shapeProd;
  return newShape;
}
function parseAxisParam(axis, shape) {
  const rank = shape.length;
  axis = axis == null ? shape.map((s, i) => i) : [].concat(axis);
  assert(axis.every((ax) => ax >= -rank && ax < rank), () => `All values in axis param must be in range [-${rank}, ${rank}) but got axis ${axis}`);
  assert(axis.every((ax) => isInt(ax)), () => `All values in axis param must be integers but got axis ${axis}`);
  return axis.map((a) => a < 0 ? rank + a : a);
}
function squeezeShape(shape, axis) {
  const newShape = [];
  const keptDims = [];
  const isEmptyArray = axis != null && Array.isArray(axis) && axis.length === 0;
  const axes = axis == null || isEmptyArray ? null : parseAxisParam(axis, shape).sort();
  let j = 0;
  for (let i = 0; i < shape.length; ++i) {
    if (axes != null) {
      if (axes[j] === i && shape[i] !== 1) {
        throw new Error(`Can't squeeze axis ${i} since its dim '${shape[i]}' is not 1`);
      }
      if ((axes[j] == null || axes[j] > i) && shape[i] === 1) {
        newShape.push(shape[i]);
        keptDims.push(i);
      }
      if (axes[j] <= i) {
        j++;
      }
    }
    if (shape[i] !== 1) {
      newShape.push(shape[i]);
      keptDims.push(i);
    }
  }
  return { newShape, keptDims };
}
function getTypedArrayFromDType(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function getArrayFromDType(dtype, size) {
  let values = null;
  if (dtype == null || dtype === "float32") {
    values = new Float32Array(size);
  } else if (dtype === "int32") {
    values = new Int32Array(size);
  } else if (dtype === "bool") {
    values = new Uint8Array(size);
  } else if (dtype === "string") {
    values = new Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
  return values;
}
function checkConversionForErrors(vals, dtype) {
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      throw Error(`A tensor of type ${dtype} being uploaded contains ${num}.`);
    }
  }
}
function isValidDtype(dtype) {
  return dtype === "bool" || dtype === "complex64" || dtype === "float32" || dtype === "int32" || dtype === "string";
}
function hasEncodingLoss(oldType, newType) {
  if (newType === "complex64") {
    return false;
  }
  if (newType === "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "int32" && oldType !== "float32" && oldType !== "complex64") {
    return false;
  }
  if (newType === "bool" && oldType === "bool") {
    return false;
  }
  return true;
}
function bytesPerElement(dtype) {
  if (dtype === "float32" || dtype === "int32") {
    return 4;
  } else if (dtype === "complex64") {
    return 8;
  } else if (dtype === "bool") {
    return 1;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function bytesFromStringArray(arr) {
  if (arr == null) {
    return 0;
  }
  let bytes = 0;
  arr.forEach((x) => bytes += x.length);
  return bytes;
}
function isString2(value) {
  return typeof value === "string" || value instanceof String;
}
function isBoolean(value) {
  return typeof value === "boolean";
}
function isNumber2(value) {
  return typeof value === "number";
}
function inferDtype(values) {
  if (Array.isArray(values)) {
    return inferDtype(values[0]);
  }
  if (values instanceof Float32Array) {
    return "float32";
  } else if (values instanceof Int32Array || values instanceof Uint8Array || values instanceof Uint8ClampedArray) {
    return "int32";
  } else if (isNumber2(values)) {
    return "float32";
  } else if (isString2(values)) {
    return "string";
  } else if (isBoolean(values)) {
    return "bool";
  }
  return "float32";
}
function isFunction(f) {
  return !!(f && f.constructor && f.call && f.apply);
}
function nearestDivisor(size, start) {
  for (let i = start; i < size; ++i) {
    if (size % i === 0) {
      return i;
    }
  }
  return size;
}
function computeStrides(shape) {
  const rank = shape.length;
  if (rank < 2) {
    return [];
  }
  const strides = new Array(rank - 1);
  strides[rank - 2] = shape[rank - 1];
  for (let i = rank - 3; i >= 0; --i) {
    strides[i] = strides[i + 1] * shape[i + 1];
  }
  return strides;
}
function createNestedArray(offset, shape, a, isComplex = false) {
  const ret = new Array();
  if (shape.length === 1) {
    const d = shape[0] * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = a[offset + i];
    }
  } else {
    const d = shape[0];
    const rest = shape.slice(1);
    const len4 = rest.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
    for (let i = 0; i < d; i++) {
      ret[i] = createNestedArray(offset + i * len4, rest, a, isComplex);
    }
  }
  return ret;
}
function toNestedArray(shape, a, isComplex = false) {
  if (shape.length === 0) {
    return a[0];
  }
  const size = shape.reduce((acc, c) => acc * c) * (isComplex ? 2 : 1);
  if (size === 0) {
    return [];
  }
  if (size !== a.length) {
    throw new Error(`[${shape}] does not match the input size ${a.length}${isComplex ? " for a complex tensor" : ""}.`);
  }
  return createNestedArray(0, shape, a, isComplex);
}
function convertBackendValuesAndArrayBuffer(data, dtype) {
  if (Array.isArray(data)) {
    return data;
  }
  if (dtype === "float32") {
    return data instanceof Float32Array ? data : new Float32Array(data);
  } else if (dtype === "int32") {
    return data instanceof Int32Array ? data : new Int32Array(data);
  } else if (dtype === "bool" || dtype === "string") {
    return Uint8Array.from(new Int32Array(data));
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
function makeOnesTypedArray(size, dtype) {
  const array2 = makeZerosTypedArray(size, dtype);
  for (let i = 0; i < array2.length; i++) {
    array2[i] = 1;
  }
  return array2;
}
function makeZerosTypedArray(size, dtype) {
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(size);
  } else if (dtype === "int32") {
    return new Int32Array(size);
  } else if (dtype === "bool") {
    return new Uint8Array(size);
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function makeZerosNestedTypedArray(shape, dtype) {
  const size = shape.reduce((prev, curr) => prev * curr, 1);
  if (dtype == null || dtype === "float32") {
    return toNestedArray(shape, new Float32Array(size));
  } else if (dtype === "int32") {
    return toNestedArray(shape, new Int32Array(size));
  } else if (dtype === "bool") {
    return toNestedArray(shape, new Uint8Array(size));
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function assertNonNegativeIntegerDimensions(shape) {
  shape.forEach((dimSize) => {
    assert(Number.isInteger(dimSize) && dimSize >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${shape}].`);
  });
}
function locToIndex(locs, rank, strides) {
  if (rank === 0) {
    return 0;
  } else if (rank === 1) {
    return locs[0];
  }
  let index = locs[locs.length - 1];
  for (let i = 0; i < locs.length - 1; ++i) {
    index += strides[i] * locs[i];
  }
  return index;
}
function indexToLoc(index, rank, strides) {
  if (rank === 0) {
    return [];
  } else if (rank === 1) {
    return [index];
  }
  const locs = new Array(rank);
  for (let i = 0; i < locs.length - 1; ++i) {
    locs[i] = Math.floor(index / strides[i]);
    index -= locs[i] * strides[i];
  }
  locs[locs.length - 1] = index;
  return locs;
}
function isPromise(object) {
  return object && object.then && typeof object.then === "function";
}
var init_util_base = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/util_base.js"() {
  }
});
function getQueryParams(queryString) {
  const params = {};
  queryString.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s, ...t) => {
    decodeParam(params, t[0], t[1]);
    return t.join("=");
  });
  return params;
}
function decodeParam(params, name, value) {
  params[decodeURIComponent(name)] = decodeURIComponent(value || "");
}
function parseValue(flagName, value) {
  value = value.toLowerCase();
  if (value === "true" || value === "false") {
    return value === "true";
  } else if (`${+value}` === value) {
    return +value;
  }
  throw new Error(`Could not parse value flag value ${value} for flag ${flagName}.`);
}
function env() {
  return ENV;
}
function setEnvironmentGlobal(environment) {
  ENV = environment;
}
var TENSORFLOWJS_FLAGS_PREFIX;
var Environment;
var ENV;
var init_environment = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/environment.js"() {
    init_util_base();
    TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";
    Environment = class {
      // tslint:disable-next-line: no-any
      constructor(global2) {
        this.global = global2;
        this.flags = {};
        this.flagRegistry = {};
        this.urlFlags = {};
        this.getQueryParams = getQueryParams;
        this.populateURLFlags();
      }
      setPlatform(platformName, platform) {
        if (this.platform != null) {
          if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
            console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${platformName}.`);
          }
        }
        this.platformName = platformName;
        this.platform = platform;
      }
      registerFlag(flagName, evaluationFn, setHook) {
        this.flagRegistry[flagName] = { evaluationFn, setHook };
        if (this.urlFlags[flagName] != null) {
          const flagValue = this.urlFlags[flagName];
          if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
            console.warn(`Setting feature override from URL ${flagName}: ${flagValue}.`);
          }
          this.set(flagName, flagValue);
        }
      }
      async getAsync(flagName) {
        if (flagName in this.flags) {
          return this.flags[flagName];
        }
        this.flags[flagName] = await this.evaluateFlag(flagName);
        return this.flags[flagName];
      }
      get(flagName) {
        if (flagName in this.flags) {
          return this.flags[flagName];
        }
        const flagValue = this.evaluateFlag(flagName);
        if (isPromise(flagValue)) {
          throw new Error(`Flag ${flagName} cannot be synchronously evaluated. Please use getAsync() instead.`);
        }
        this.flags[flagName] = flagValue;
        return this.flags[flagName];
      }
      getNumber(flagName) {
        return this.get(flagName);
      }
      getBool(flagName) {
        return this.get(flagName);
      }
      getFlags() {
        return this.flags;
      }
      // For backwards compatibility.
      get features() {
        return this.flags;
      }
      set(flagName, value) {
        if (this.flagRegistry[flagName] == null) {
          throw new Error(`Cannot set flag ${flagName} as it has not been registered.`);
        }
        this.flags[flagName] = value;
        if (this.flagRegistry[flagName].setHook != null) {
          this.flagRegistry[flagName].setHook(value);
        }
      }
      evaluateFlag(flagName) {
        if (this.flagRegistry[flagName] == null) {
          throw new Error(`Cannot evaluate flag '${flagName}': no evaluation function found.`);
        }
        return this.flagRegistry[flagName].evaluationFn();
      }
      setFlags(flags) {
        this.flags = Object.assign({}, flags);
      }
      reset() {
        this.flags = {};
        this.urlFlags = {};
        this.populateURLFlags();
      }
      populateURLFlags() {
        if (typeof this.global === "undefined" || typeof this.global.location === "undefined" || typeof this.global.location.search === "undefined") {
          return;
        }
        const urlParams = this.getQueryParams(this.global.location.search);
        if (TENSORFLOWJS_FLAGS_PREFIX in urlParams) {
          const keyValues = urlParams[TENSORFLOWJS_FLAGS_PREFIX].split(",");
          keyValues.forEach((keyValue) => {
            const [key, value] = keyValue.split(":");
            this.urlFlags[key] = parseValue(key, value);
          });
        }
      }
    };
    ENV = null;
  }
});
function getGlobalNamespace() {
  if (globalNameSpace == null) {
    let ns;
    if (typeof window !== "undefined") {
      ns = window;
    } else if (typeof global !== "undefined") {
      ns = global;
    } else if (typeof process !== "undefined") {
      ns = process;
    } else if (typeof self !== "undefined") {
      ns = self;
    } else {
      throw new Error("Could not find a global object");
    }
    globalNameSpace = ns;
  }
  return globalNameSpace;
}
function getGlobalMap() {
  const ns = getGlobalNamespace();
  if (ns._tfGlobals == null) {
    ns._tfGlobals = /* @__PURE__ */ new Map();
  }
  return ns._tfGlobals;
}
function getGlobal(key, init) {
  const globalMap = getGlobalMap();
  if (globalMap.has(key)) {
    return globalMap.get(key);
  } else {
    const singleton = init();
    globalMap.set(key, singleton);
    return globalMap.get(key);
  }
}
var globalNameSpace;
var init_global_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/global_util.js"() {
  }
});
var Abs;
var Acos;
var Acosh;
var Add;
var AddN;
var All;
var Any;
var ArgMax;
var ArgMin;
var Asin;
var Asinh;
var Atan;
var Atanh;
var Atan2;
var AvgPool;
var AvgPoolGrad;
var AvgPool3D;
var AvgPool3DGrad;
var BatchMatMul;
var BatchToSpaceND;
var Bincount;
var BroadcastTo;
var BroadcastArgs;
var Cast;
var Ceil;
var ClipByValue;
var Complex;
var ComplexAbs;
var Concat;
var Conv2D;
var Conv2DBackpropFilter;
var Conv2DBackpropInput;
var Conv3D;
var Conv3DBackpropFilterV2;
var Conv3DBackpropInputV2;
var Cos;
var Cosh;
var Cumprod;
var Cumsum;
var CropAndResize;
var DenseBincount;
var DepthToSpace;
var DepthwiseConv2dNative;
var DepthwiseConv2dNativeBackpropFilter;
var DepthwiseConv2dNativeBackpropInput;
var Diag;
var Dilation2D;
var Dilation2DBackpropInput;
var Dilation2DBackpropFilter;
var RealDiv;
var Einsum;
var Elu;
var EluGrad;
var Erf;
var Equal;
var Exp;
var ExpandDims;
var Expm1;
var FFT;
var Fill;
var FlipLeftRight;
var Floor;
var FloorDiv;
var FusedBatchNorm;
var GatherV2;
var GatherNd;
var Greater;
var GreaterEqual;
var Identity;
var IFFT;
var Imag;
var IsFinite;
var IsInf;
var IsNan;
var LeakyRelu;
var Less;
var LessEqual;
var LinSpace;
var Log;
var Log1p;
var LogicalAnd;
var LogicalNot;
var LogicalOr;
var LogSoftmax;
var LRN;
var LRNGrad;
var Max;
var Maximum;
var MaxPool;
var MaxPoolGrad;
var MaxPool3D;
var MaxPool3DGrad;
var MaxPoolWithArgmax;
var Mean;
var Min;
var Minimum;
var MirrorPad;
var Mod;
var Multinomial;
var Multiply;
var Neg;
var NotEqual;
var NonMaxSuppressionV3;
var NonMaxSuppressionV4;
var NonMaxSuppressionV5;
var OnesLike;
var OneHot;
var Pack;
var PadV2;
var Pow;
var Prelu;
var Prod;
var RaggedGather;
var RaggedRange;
var RaggedTensorToTensor;
var Range;
var Real;
var Reciprocal;
var Relu;
var Reshape;
var ResizeNearestNeighbor;
var ResizeNearestNeighborGrad;
var ResizeBilinear;
var ResizeBilinearGrad;
var Relu6;
var Reverse;
var Round;
var Rsqrt;
var ScatterNd;
var SearchSorted;
var Select;
var Selu;
var Slice;
var Sin;
var Sinh;
var Sign;
var Sigmoid;
var Softplus;
var Sqrt;
var Sum;
var SpaceToBatchND;
var SplitV;
var Softmax;
var SparseFillEmptyRows;
var SparseReshape;
var SparseSegmentMean;
var SparseSegmentSum;
var SparseToDense;
var SquaredDifference;
var Square;
var StridedSlice;
var StringNGrams;
var StringSplit;
var StringToHashBucketFast;
var Sub;
var Tan;
var Tanh;
var Tile;
var TopK;
var Transform;
var Transpose;
var Unique;
var Unpack;
var UnsortedSegmentSum;
var ZerosLike;
var Step;
var FromPixels;
var RotateWithOffset;
var _FusedMatMul;
var FusedConv2D;
var FusedDepthwiseConv2D;
var init_kernel_names = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/kernel_names.js"() {
    Abs = "Abs";
    Acos = "Acos";
    Acosh = "Acosh";
    Add = "Add";
    AddN = "AddN";
    All = "All";
    Any = "Any";
    ArgMax = "ArgMax";
    ArgMin = "ArgMin";
    Asin = "Asin";
    Asinh = "Asinh";
    Atan = "Atan";
    Atanh = "Atanh";
    Atan2 = "Atan2";
    AvgPool = "AvgPool";
    AvgPoolGrad = "AvgPoolGrad";
    AvgPool3D = "AvgPool3D";
    AvgPool3DGrad = "AvgPool3DGrad";
    BatchMatMul = "BatchMatMul";
    BatchToSpaceND = "BatchToSpaceND";
    Bincount = "Bincount";
    BroadcastTo = "BroadcastTo";
    BroadcastArgs = "BroadcastArgs";
    Cast = "Cast";
    Ceil = "Ceil";
    ClipByValue = "ClipByValue";
    Complex = "Complex";
    ComplexAbs = "ComplexAbs";
    Concat = "Concat";
    Conv2D = "Conv2D";
    Conv2DBackpropFilter = "Conv2DBackpropFilter";
    Conv2DBackpropInput = "Conv2DBackpropInput";
    Conv3D = "Conv3D";
    Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2";
    Conv3DBackpropInputV2 = "Conv3DBackpropInputV2";
    Cos = "Cos";
    Cosh = "Cosh";
    Cumprod = "Cumprod";
    Cumsum = "Cumsum";
    CropAndResize = "CropAndResize";
    DenseBincount = "DenseBincount";
    DepthToSpace = "DepthToSpace";
    DepthwiseConv2dNative = "DepthwiseConv2dNative";
    DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter";
    DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput";
    Diag = "Diag";
    Dilation2D = "Dilation2D";
    Dilation2DBackpropInput = "Dilation2DBackpropInput";
    Dilation2DBackpropFilter = "Dilation2DBackpropFilter";
    RealDiv = "RealDiv";
    Einsum = "Einsum";
    Elu = "Elu";
    EluGrad = "EluGrad";
    Erf = "Erf";
    Equal = "Equal";
    Exp = "Exp";
    ExpandDims = "ExpandDims";
    Expm1 = "Expm1";
    FFT = "FFT";
    Fill = "Fill";
    FlipLeftRight = "FlipLeftRight";
    Floor = "Floor";
    FloorDiv = "FloorDiv";
    FusedBatchNorm = "FusedBatchNorm";
    GatherV2 = "GatherV2";
    GatherNd = "GatherNd";
    Greater = "Greater";
    GreaterEqual = "GreaterEqual";
    Identity = "Identity";
    IFFT = "IFFT";
    Imag = "Imag";
    IsFinite = "IsFinite";
    IsInf = "IsInf";
    IsNan = "IsNan";
    LeakyRelu = "LeakyRelu";
    Less = "Less";
    LessEqual = "LessEqual";
    LinSpace = "LinSpace";
    Log = "Log";
    Log1p = "Log1p";
    LogicalAnd = "LogicalAnd";
    LogicalNot = "LogicalNot";
    LogicalOr = "LogicalOr";
    LogSoftmax = "LogSoftmax";
    LRN = "LRN";
    LRNGrad = "LRNGrad";
    Max = "Max";
    Maximum = "Maximum";
    MaxPool = "MaxPool";
    MaxPoolGrad = "MaxPoolGrad";
    MaxPool3D = "MaxPool3D";
    MaxPool3DGrad = "MaxPool3DGrad";
    MaxPoolWithArgmax = "MaxPoolWithArgmax";
    Mean = "Mean";
    Min = "Min";
    Minimum = "Minimum";
    MirrorPad = "MirrorPad";
    Mod = "Mod";
    Multinomial = "Multinomial";
    Multiply = "Multiply";
    Neg = "Neg";
    NotEqual = "NotEqual";
    NonMaxSuppressionV3 = "NonMaxSuppressionV3";
    NonMaxSuppressionV4 = "NonMaxSuppressionV4";
    NonMaxSuppressionV5 = "NonMaxSuppressionV5";
    OnesLike = "OnesLike";
    OneHot = "OneHot";
    Pack = "Pack";
    PadV2 = "PadV2";
    Pow = "Pow";
    Prelu = "Prelu";
    Prod = "Prod";
    RaggedGather = "RaggedGather";
    RaggedRange = "RaggedRange";
    RaggedTensorToTensor = "RaggedTensorToTensor";
    Range = "Range";
    Real = "Real";
    Reciprocal = "Reciprocal";
    Relu = "Relu";
    Reshape = "Reshape";
    ResizeNearestNeighbor = "ResizeNearestNeighbor";
    ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad";
    ResizeBilinear = "ResizeBilinear";
    ResizeBilinearGrad = "ResizeBilinearGrad";
    Relu6 = "Relu6";
    Reverse = "Reverse";
    Round = "Round";
    Rsqrt = "Rsqrt";
    ScatterNd = "ScatterNd";
    SearchSorted = "SearchSorted";
    Select = "Select";
    Selu = "Selu";
    Slice = "Slice";
    Sin = "Sin";
    Sinh = "Sinh";
    Sign = "Sign";
    Sigmoid = "Sigmoid";
    Softplus = "Softplus";
    Sqrt = "Sqrt";
    Sum = "Sum";
    SpaceToBatchND = "SpaceToBatchND";
    SplitV = "SplitV";
    Softmax = "Softmax";
    SparseFillEmptyRows = "SparseFillEmptyRows";
    SparseReshape = "SparseReshape";
    SparseSegmentMean = "SparseSegmentMean";
    SparseSegmentSum = "SparseSegmentSum";
    SparseToDense = "SparseToDense";
    SquaredDifference = "SquaredDifference";
    Square = "Square";
    StridedSlice = "StridedSlice";
    StringNGrams = "StringNGrams";
    StringSplit = "StringSplit";
    StringToHashBucketFast = "StringToHashBucketFast";
    Sub = "Sub";
    Tan = "Tan";
    Tanh = "Tanh";
    Tile = "Tile";
    TopK = "TopK";
    Transform = "Transform";
    Transpose = "Transpose";
    Unique = "Unique";
    Unpack = "Unpack";
    UnsortedSegmentSum = "UnsortedSegmentSum";
    ZerosLike = "ZerosLike";
    Step = "Step";
    FromPixels = "FromPixels";
    RotateWithOffset = "RotateWithOffset";
    _FusedMatMul = "_FusedMatMul";
    FusedConv2D = "FusedConv2D";
    FusedDepthwiseConv2D = "FusedDepthwiseConv2D";
  }
});
function warn(...msg) {
  if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
    console.warn(...msg);
  }
}
function log(...msg) {
  if (!(env().getBool("IS_TEST") || env().getBool("PROD"))) {
    console.log(...msg);
  }
}
var init_log = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/log.js"() {
    init_environment();
  }
});
function getKernel(kernelName, backendName) {
  const key = makeKey(kernelName, backendName);
  return kernelRegistry.get(key);
}
function getGradient(kernelName) {
  return gradRegistry.get(kernelName);
}
function getKernelsForBackend(backendName) {
  const it = kernelRegistry.entries();
  const result = [];
  while (true) {
    const { done, value } = it.next();
    if (done) {
      break;
    }
    const [key, config] = value;
    const [backend2] = key.split("_");
    if (backend2 === backendName) {
      result.push(config);
    }
  }
  return result;
}
function registerKernel(config) {
  const { kernelName, backendName } = config;
  const key = makeKey(kernelName, backendName);
  if (kernelRegistry.has(key)) {
    warn(`The kernel '${kernelName}' for backend '${backendName}' is already registered`);
  }
  kernelRegistry.set(key, config);
}
function registerGradient(config) {
  const { kernelName } = config;
  if (gradRegistry.has(kernelName)) {
    if (env().getBool("DEBUG")) {
      warn(`Overriding the gradient for '${kernelName}'`);
    }
  }
  gradRegistry.set(kernelName, config);
}
function makeKey(kernelName, backendName) {
  return `${backendName}_${kernelName}`;
}
var kernelRegistry;
var gradRegistry;
var init_kernel_registry = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/kernel_registry.js"() {
    init_environment();
    init_global_util();
    init_log();
    kernelRegistry = getGlobal("kernelRegistry", () => /* @__PURE__ */ new Map());
    gradRegistry = getGlobal("gradRegistry", () => /* @__PURE__ */ new Map());
  }
});
var require_long = __commonJS({
  "node_modules/long/src/long.js"(exports, module) {
    module.exports = Long2;
    var wasm = null;
    try {
      wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([
        0,
        97,
        115,
        109,
        1,
        0,
        0,
        0,
        1,
        13,
        2,
        96,
        0,
        1,
        127,
        96,
        4,
        127,
        127,
        127,
        127,
        1,
        127,
        3,
        7,
        6,
        0,
        1,
        1,
        1,
        1,
        1,
        6,
        6,
        1,
        127,
        1,
        65,
        0,
        11,
        7,
        50,
        6,
        3,
        109,
        117,
        108,
        0,
        1,
        5,
        100,
        105,
        118,
        95,
        115,
        0,
        2,
        5,
        100,
        105,
        118,
        95,
        117,
        0,
        3,
        5,
        114,
        101,
        109,
        95,
        115,
        0,
        4,
        5,
        114,
        101,
        109,
        95,
        117,
        0,
        5,
        8,
        103,
        101,
        116,
        95,
        104,
        105,
        103,
        104,
        0,
        0,
        10,
        191,
        1,
        6,
        4,
        0,
        35,
        0,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        126,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        127,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        128,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        129,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11,
        36,
        1,
        1,
        126,
        32,
        0,
        173,
        32,
        1,
        173,
        66,
        32,
        134,
        132,
        32,
        2,
        173,
        32,
        3,
        173,
        66,
        32,
        134,
        132,
        130,
        34,
        4,
        66,
        32,
        135,
        167,
        36,
        0,
        32,
        4,
        167,
        11
      ])), {}).exports;
    } catch (e) {
    }
    function Long2(low, high, unsigned) {
      this.low = low | 0;
      this.high = high | 0;
      this.unsigned = !!unsigned;
    }
    Long2.prototype.__isLong__;
    Object.defineProperty(Long2.prototype, "__isLong__", { value: true });
    function isLong(obj) {
      return (obj && obj["__isLong__"]) === true;
    }
    Long2.isLong = isLong;
    var INT_CACHE = {};
    var UINT_CACHE = {};
    function fromInt(value, unsigned) {
      var obj, cachedObj, cache11;
      if (unsigned) {
        value >>>= 0;
        if (cache11 = 0 <= value && value < 256) {
          cachedObj = UINT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, (value | 0) < 0 ? -1 : 0, true);
        if (cache11)
          UINT_CACHE[value] = obj;
        return obj;
      } else {
        value |= 0;
        if (cache11 = -128 <= value && value < 128) {
          cachedObj = INT_CACHE[value];
          if (cachedObj)
            return cachedObj;
        }
        obj = fromBits(value, value < 0 ? -1 : 0, false);
        if (cache11)
          INT_CACHE[value] = obj;
        return obj;
      }
    }
    Long2.fromInt = fromInt;
    function fromNumber(value, unsigned) {
      if (isNaN(value))
        return unsigned ? UZERO : ZERO2;
      if (unsigned) {
        if (value < 0)
          return UZERO;
        if (value >= TWO_PWR_64_DBL)
          return MAX_UNSIGNED_VALUE;
      } else {
        if (value <= -TWO_PWR_63_DBL)
          return MIN_VALUE;
        if (value + 1 >= TWO_PWR_63_DBL)
          return MAX_VALUE;
      }
      if (value < 0)
        return fromNumber(-value, unsigned).neg();
      return fromBits(value % TWO_PWR_32_DBL | 0, value / TWO_PWR_32_DBL | 0, unsigned);
    }
    Long2.fromNumber = fromNumber;
    function fromBits(lowBits, highBits, unsigned) {
      return new Long2(lowBits, highBits, unsigned);
    }
    Long2.fromBits = fromBits;
    var pow_dbl = Math.pow;
    function fromString(str5, unsigned, radix) {
      if (str5.length === 0)
        throw Error("empty string");
      if (str5 === "NaN" || str5 === "Infinity" || str5 === "+Infinity" || str5 === "-Infinity")
        return ZERO2;
      if (typeof unsigned === "number") {
        radix = unsigned, unsigned = false;
      } else {
        unsigned = !!unsigned;
      }
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      var p2;
      if ((p2 = str5.indexOf("-")) > 0)
        throw Error("interior hyphen");
      else if (p2 === 0) {
        return fromString(str5.substring(1), unsigned, radix).neg();
      }
      var radixToPower = fromNumber(pow_dbl(radix, 8));
      var result = ZERO2;
      for (var i = 0; i < str5.length; i += 8) {
        var size = Math.min(8, str5.length - i), value = parseInt(str5.substring(i, i + size), radix);
        if (size < 8) {
          var power = fromNumber(pow_dbl(radix, size));
          result = result.mul(power).add(fromNumber(value));
        } else {
          result = result.mul(radixToPower);
          result = result.add(fromNumber(value));
        }
      }
      result.unsigned = unsigned;
      return result;
    }
    Long2.fromString = fromString;
    function fromValue(val, unsigned) {
      if (typeof val === "number")
        return fromNumber(val, unsigned);
      if (typeof val === "string")
        return fromString(val, unsigned);
      return fromBits(val.low, val.high, typeof unsigned === "boolean" ? unsigned : val.unsigned);
    }
    Long2.fromValue = fromValue;
    var TWO_PWR_16_DBL = 1 << 16;
    var TWO_PWR_24_DBL = 1 << 24;
    var TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL;
    var TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL;
    var TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2;
    var TWO_PWR_24 = fromInt(TWO_PWR_24_DBL);
    var ZERO2 = fromInt(0);
    Long2.ZERO = ZERO2;
    var UZERO = fromInt(0, true);
    Long2.UZERO = UZERO;
    var ONE = fromInt(1);
    Long2.ONE = ONE;
    var UONE = fromInt(1, true);
    Long2.UONE = UONE;
    var NEG_ONE = fromInt(-1);
    Long2.NEG_ONE = NEG_ONE;
    var MAX_VALUE = fromBits(4294967295 | 0, 2147483647 | 0, false);
    Long2.MAX_VALUE = MAX_VALUE;
    var MAX_UNSIGNED_VALUE = fromBits(4294967295 | 0, 4294967295 | 0, true);
    Long2.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
    var MIN_VALUE = fromBits(0, 2147483648 | 0, false);
    Long2.MIN_VALUE = MIN_VALUE;
    var LongPrototype = Long2.prototype;
    LongPrototype.toInt = function toInt() {
      return this.unsigned ? this.low >>> 0 : this.low;
    };
    LongPrototype.toNumber = function toNumber() {
      if (this.unsigned)
        return (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0);
      return this.high * TWO_PWR_32_DBL + (this.low >>> 0);
    };
    LongPrototype.toString = function toString(radix) {
      radix = radix || 10;
      if (radix < 2 || 36 < radix)
        throw RangeError("radix");
      if (this.isZero())
        return "0";
      if (this.isNegative()) {
        if (this.eq(MIN_VALUE)) {
          var radixLong = fromNumber(radix), div3 = this.div(radixLong), rem1 = div3.mul(radixLong).sub(this);
          return div3.toString(radix) + rem1.toInt().toString(radix);
        } else
          return "-" + this.neg().toString(radix);
      }
      var radixToPower = fromNumber(pow_dbl(radix, 6), this.unsigned), rem = this;
      var result = "";
      while (true) {
        var remDiv = rem.div(radixToPower), intval = rem.sub(remDiv.mul(radixToPower)).toInt() >>> 0, digits = intval.toString(radix);
        rem = remDiv;
        if (rem.isZero())
          return digits + result;
        else {
          while (digits.length < 6)
            digits = "0" + digits;
          result = "" + digits + result;
        }
      }
    };
    LongPrototype.getHighBits = function getHighBits() {
      return this.high;
    };
    LongPrototype.getHighBitsUnsigned = function getHighBitsUnsigned() {
      return this.high >>> 0;
    };
    LongPrototype.getLowBits = function getLowBits() {
      return this.low;
    };
    LongPrototype.getLowBitsUnsigned = function getLowBitsUnsigned() {
      return this.low >>> 0;
    };
    LongPrototype.getNumBitsAbs = function getNumBitsAbs() {
      if (this.isNegative())
        return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();
      var val = this.high != 0 ? this.high : this.low;
      for (var bit = 31; bit > 0; bit--)
        if ((val & 1 << bit) != 0)
          break;
      return this.high != 0 ? bit + 33 : bit + 1;
    };
    LongPrototype.isZero = function isZero() {
      return this.high === 0 && this.low === 0;
    };
    LongPrototype.eqz = LongPrototype.isZero;
    LongPrototype.isNegative = function isNegative() {
      return !this.unsigned && this.high < 0;
    };
    LongPrototype.isPositive = function isPositive() {
      return this.unsigned || this.high >= 0;
    };
    LongPrototype.isOdd = function isOdd() {
      return (this.low & 1) === 1;
    };
    LongPrototype.isEven = function isEven2() {
      return (this.low & 1) === 0;
    };
    LongPrototype.equals = function equals6(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.unsigned !== other.unsigned && this.high >>> 31 === 1 && other.high >>> 31 === 1)
        return false;
      return this.high === other.high && this.low === other.low;
    };
    LongPrototype.eq = LongPrototype.equals;
    LongPrototype.notEquals = function notEquals(other) {
      return !this.eq(
        /* validates */
        other
      );
    };
    LongPrototype.neq = LongPrototype.notEquals;
    LongPrototype.ne = LongPrototype.notEquals;
    LongPrototype.lessThan = function lessThan(other) {
      return this.comp(
        /* validates */
        other
      ) < 0;
    };
    LongPrototype.lt = LongPrototype.lessThan;
    LongPrototype.lessThanOrEqual = function lessThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) <= 0;
    };
    LongPrototype.lte = LongPrototype.lessThanOrEqual;
    LongPrototype.le = LongPrototype.lessThanOrEqual;
    LongPrototype.greaterThan = function greaterThan(other) {
      return this.comp(
        /* validates */
        other
      ) > 0;
    };
    LongPrototype.gt = LongPrototype.greaterThan;
    LongPrototype.greaterThanOrEqual = function greaterThanOrEqual(other) {
      return this.comp(
        /* validates */
        other
      ) >= 0;
    };
    LongPrototype.gte = LongPrototype.greaterThanOrEqual;
    LongPrototype.ge = LongPrototype.greaterThanOrEqual;
    LongPrototype.compare = function compare(other) {
      if (!isLong(other))
        other = fromValue(other);
      if (this.eq(other))
        return 0;
      var thisNeg = this.isNegative(), otherNeg = other.isNegative();
      if (thisNeg && !otherNeg)
        return -1;
      if (!thisNeg && otherNeg)
        return 1;
      if (!this.unsigned)
        return this.sub(other).isNegative() ? -1 : 1;
      return other.high >>> 0 > this.high >>> 0 || other.high === this.high && other.low >>> 0 > this.low >>> 0 ? -1 : 1;
    };
    LongPrototype.comp = LongPrototype.compare;
    LongPrototype.negate = function negate2() {
      if (!this.unsigned && this.eq(MIN_VALUE))
        return MIN_VALUE;
      return this.not().add(ONE);
    };
    LongPrototype.neg = LongPrototype.negate;
    LongPrototype.add = function add42(addend) {
      if (!isLong(addend))
        addend = fromValue(addend);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = addend.high >>> 16;
      var b32 = addend.high & 65535;
      var b16 = addend.low >>> 16;
      var b00 = addend.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 + b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 + b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 + b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 + b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.subtract = function subtract3(subtrahend) {
      if (!isLong(subtrahend))
        subtrahend = fromValue(subtrahend);
      return this.add(subtrahend.neg());
    };
    LongPrototype.sub = LongPrototype.subtract;
    LongPrototype.multiply = function multiply32(multiplier) {
      if (this.isZero())
        return ZERO2;
      if (!isLong(multiplier))
        multiplier = fromValue(multiplier);
      if (wasm) {
        var low = wasm.mul(
          this.low,
          this.high,
          multiplier.low,
          multiplier.high
        );
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (multiplier.isZero())
        return ZERO2;
      if (this.eq(MIN_VALUE))
        return multiplier.isOdd() ? MIN_VALUE : ZERO2;
      if (multiplier.eq(MIN_VALUE))
        return this.isOdd() ? MIN_VALUE : ZERO2;
      if (this.isNegative()) {
        if (multiplier.isNegative())
          return this.neg().mul(multiplier.neg());
        else
          return this.neg().mul(multiplier).neg();
      } else if (multiplier.isNegative())
        return this.mul(multiplier.neg()).neg();
      if (this.lt(TWO_PWR_24) && multiplier.lt(TWO_PWR_24))
        return fromNumber(this.toNumber() * multiplier.toNumber(), this.unsigned);
      var a48 = this.high >>> 16;
      var a32 = this.high & 65535;
      var a16 = this.low >>> 16;
      var a00 = this.low & 65535;
      var b48 = multiplier.high >>> 16;
      var b32 = multiplier.high & 65535;
      var b16 = multiplier.low >>> 16;
      var b00 = multiplier.low & 65535;
      var c48 = 0, c32 = 0, c16 = 0, c00 = 0;
      c00 += a00 * b00;
      c16 += c00 >>> 16;
      c00 &= 65535;
      c16 += a16 * b00;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c16 += a00 * b16;
      c32 += c16 >>> 16;
      c16 &= 65535;
      c32 += a32 * b00;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a16 * b16;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c32 += a00 * b32;
      c48 += c32 >>> 16;
      c32 &= 65535;
      c48 += a48 * b00 + a32 * b16 + a16 * b32 + a00 * b48;
      c48 &= 65535;
      return fromBits(c16 << 16 | c00, c48 << 16 | c32, this.unsigned);
    };
    LongPrototype.mul = LongPrototype.multiply;
    LongPrototype.divide = function divide2(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (divisor.isZero())
        throw Error("division by zero");
      if (wasm) {
        if (!this.unsigned && this.high === -2147483648 && divisor.low === -1 && divisor.high === -1) {
          return this;
        }
        var low = (this.unsigned ? wasm.div_u : wasm.div_s)(
          this.low,
          this.high,
          divisor.low,
          divisor.high
        );
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      if (this.isZero())
        return this.unsigned ? UZERO : ZERO2;
      var approx, rem, res;
      if (!this.unsigned) {
        if (this.eq(MIN_VALUE)) {
          if (divisor.eq(ONE) || divisor.eq(NEG_ONE))
            return MIN_VALUE;
          else if (divisor.eq(MIN_VALUE))
            return ONE;
          else {
            var halfThis = this.shr(1);
            approx = halfThis.div(divisor).shl(1);
            if (approx.eq(ZERO2)) {
              return divisor.isNegative() ? ONE : NEG_ONE;
            } else {
              rem = this.sub(divisor.mul(approx));
              res = approx.add(rem.div(divisor));
              return res;
            }
          }
        } else if (divisor.eq(MIN_VALUE))
          return this.unsigned ? UZERO : ZERO2;
        if (this.isNegative()) {
          if (divisor.isNegative())
            return this.neg().div(divisor.neg());
          return this.neg().div(divisor).neg();
        } else if (divisor.isNegative())
          return this.div(divisor.neg()).neg();
        res = ZERO2;
      } else {
        if (!divisor.unsigned)
          divisor = divisor.toUnsigned();
        if (divisor.gt(this))
          return UZERO;
        if (divisor.gt(this.shru(1)))
          return UONE;
        res = UZERO;
      }
      rem = this;
      while (rem.gte(divisor)) {
        approx = Math.max(1, Math.floor(rem.toNumber() / divisor.toNumber()));
        var log22 = Math.ceil(Math.log(approx) / Math.LN2), delta = log22 <= 48 ? 1 : pow_dbl(2, log22 - 48), approxRes = fromNumber(approx), approxRem = approxRes.mul(divisor);
        while (approxRem.isNegative() || approxRem.gt(rem)) {
          approx -= delta;
          approxRes = fromNumber(approx, this.unsigned);
          approxRem = approxRes.mul(divisor);
        }
        if (approxRes.isZero())
          approxRes = ONE;
        res = res.add(approxRes);
        rem = rem.sub(approxRem);
      }
      return res;
    };
    LongPrototype.div = LongPrototype.divide;
    LongPrototype.modulo = function modulo(divisor) {
      if (!isLong(divisor))
        divisor = fromValue(divisor);
      if (wasm) {
        var low = (this.unsigned ? wasm.rem_u : wasm.rem_s)(
          this.low,
          this.high,
          divisor.low,
          divisor.high
        );
        return fromBits(low, wasm.get_high(), this.unsigned);
      }
      return this.sub(this.div(divisor).mul(divisor));
    };
    LongPrototype.mod = LongPrototype.modulo;
    LongPrototype.rem = LongPrototype.modulo;
    LongPrototype.not = function not() {
      return fromBits(~this.low, ~this.high, this.unsigned);
    };
    LongPrototype.and = function and(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low & other.low, this.high & other.high, this.unsigned);
    };
    LongPrototype.or = function or(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low | other.low, this.high | other.high, this.unsigned);
    };
    LongPrototype.xor = function xor(other) {
      if (!isLong(other))
        other = fromValue(other);
      return fromBits(this.low ^ other.low, this.high ^ other.high, this.unsigned);
    };
    LongPrototype.shiftLeft = function shiftLeft(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low << numBits, this.high << numBits | this.low >>> 32 - numBits, this.unsigned);
      else
        return fromBits(0, this.low << numBits - 32, this.unsigned);
    };
    LongPrototype.shl = LongPrototype.shiftLeft;
    LongPrototype.shiftRight = function shiftRight(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      if ((numBits &= 63) === 0)
        return this;
      else if (numBits < 32)
        return fromBits(this.low >>> numBits | this.high << 32 - numBits, this.high >> numBits, this.unsigned);
      else
        return fromBits(this.high >> numBits - 32, this.high >= 0 ? 0 : -1, this.unsigned);
    };
    LongPrototype.shr = LongPrototype.shiftRight;
    LongPrototype.shiftRightUnsigned = function shiftRightUnsigned(numBits) {
      if (isLong(numBits))
        numBits = numBits.toInt();
      numBits &= 63;
      if (numBits === 0)
        return this;
      else {
        var high = this.high;
        if (numBits < 32) {
          var low = this.low;
          return fromBits(low >>> numBits | high << 32 - numBits, high >>> numBits, this.unsigned);
        } else if (numBits === 32)
          return fromBits(high, 0, this.unsigned);
        else
          return fromBits(high >>> numBits - 32, 0, this.unsigned);
      }
    };
    LongPrototype.shru = LongPrototype.shiftRightUnsigned;
    LongPrototype.shr_u = LongPrototype.shiftRightUnsigned;
    LongPrototype.toSigned = function toSigned() {
      if (!this.unsigned)
        return this;
      return fromBits(this.low, this.high, false);
    };
    LongPrototype.toUnsigned = function toUnsigned() {
      if (this.unsigned)
        return this;
      return fromBits(this.low, this.high, true);
    };
    LongPrototype.toBytes = function toBytes(le) {
      return le ? this.toBytesLE() : this.toBytesBE();
    };
    LongPrototype.toBytesLE = function toBytesLE() {
      var hi = this.high, lo = this.low;
      return [
        lo & 255,
        lo >>> 8 & 255,
        lo >>> 16 & 255,
        lo >>> 24,
        hi & 255,
        hi >>> 8 & 255,
        hi >>> 16 & 255,
        hi >>> 24
      ];
    };
    LongPrototype.toBytesBE = function toBytesBE() {
      var hi = this.high, lo = this.low;
      return [
        hi >>> 24,
        hi >>> 16 & 255,
        hi >>> 8 & 255,
        hi & 255,
        lo >>> 24,
        lo >>> 16 & 255,
        lo >>> 8 & 255,
        lo & 255
      ];
    };
    Long2.fromBytes = function fromBytes(bytes, unsigned, le) {
      return le ? Long2.fromBytesLE(bytes, unsigned) : Long2.fromBytesBE(bytes, unsigned);
    };
    Long2.fromBytesLE = function fromBytesLE(bytes, unsigned) {
      return new Long2(
        bytes[0] | bytes[1] << 8 | bytes[2] << 16 | bytes[3] << 24,
        bytes[4] | bytes[5] << 8 | bytes[6] << 16 | bytes[7] << 24,
        unsigned
      );
    };
    Long2.fromBytesBE = function fromBytesBE(bytes, unsigned) {
      return new Long2(
        bytes[4] << 24 | bytes[5] << 16 | bytes[6] << 8 | bytes[7],
        bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3],
        unsigned
      );
    };
  }
});
function hexToLong(hex) {
  return Long.fromString(hex, true, 16);
}
function shiftMix(val) {
  return val.xor(val.shru(47));
}
function fetch2(s, offset, numBytes) {
  const bytes = s.slice(offset, offset + numBytes);
  return Long.fromBytes(Array.from(bytes), true, true);
}
function fetch64(s, offset) {
  return fetch2(s, offset, 8);
}
function fetch32(s, offset) {
  return fetch2(s, offset, 4);
}
function rotate64(val, shift) {
  return shift === 0 ? val : val.shru(shift).or(val.shl(64 - shift));
}
function hashLen16(u, v, mul22 = hexToLong("9ddfea08eb382d69")) {
  let a = u.xor(v).mul(mul22);
  a = a.xor(a.shru(47));
  let b = v.xor(a).mul(mul22);
  b = b.xor(b.shru(47));
  b = b.mul(mul22);
  return b;
}
function weakHashLen32WithSeeds(w, x, y, z, a, b) {
  a = a.add(w);
  b = rotate64(b.add(a).add(z), 21);
  const c = a;
  a = a.add(x);
  a = a.add(y);
  b = b.add(rotate64(a, 44));
  return [a.add(z), b.add(c)];
}
function weakHashLen32WithSeedsStr(s, offset, a, b) {
  return weakHashLen32WithSeeds(fetch64(s, offset), fetch64(s, offset + 8), fetch64(s, offset + 16), fetch64(s, offset + 24), a, b);
}
function hashLen0to16(s, len4 = s.length) {
  if (len4 >= 8) {
    const mul22 = k2.add(len4 * 2);
    const a = fetch64(s, 0).add(k2);
    const b = fetch64(s, len4 - 8);
    const c = rotate64(b, 37).mul(mul22).add(a);
    const d = rotate64(a, 25).add(b).mul(mul22);
    return hashLen16(c, d, mul22);
  }
  if (len4 >= 4) {
    const mul22 = k2.add(len4 * 2);
    const a = fetch32(s, 0);
    return hashLen16(a.shl(3).add(len4), fetch32(s, len4 - 4), mul22);
  }
  if (len4 > 0) {
    const a = s[0];
    const b = s[len4 >> 1];
    const c = s[len4 - 1];
    const y = a + (b << 8);
    const z = len4 + (c << 2);
    return shiftMix(k2.mul(y).xor(k0.mul(z))).mul(k2);
  }
  return k2;
}
function hashLen17to32(s, len4 = s.length) {
  const mul22 = k2.add(len4 * 2);
  const a = fetch64(s, 0).mul(k1);
  const b = fetch64(s, 8);
  const c = fetch64(s, len4 - 8).mul(mul22);
  const d = fetch64(s, len4 - 16).mul(k2);
  return hashLen16(rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d), a.add(rotate64(b.add(k2), 18)).add(c), mul22);
}
function hashLen33to64(s, len4 = s.length) {
  const mul22 = k2.add(len4 * 2);
  const a = fetch64(s, 0).mul(k2);
  const b = fetch64(s, 8);
  const c = fetch64(s, len4 - 8).mul(mul22);
  const d = fetch64(s, len4 - 16).mul(k2);
  const y = rotate64(a.add(b), 43).add(rotate64(c, 30)).add(d);
  const z = hashLen16(y, a.add(rotate64(b.add(k2), 18)).add(c), mul22);
  const e = fetch64(s, 16).mul(mul22);
  const f = fetch64(s, 24);
  const g = y.add(fetch64(s, len4 - 32)).mul(mul22);
  const h = z.add(fetch64(s, len4 - 24)).mul(mul22);
  return hashLen16(rotate64(e.add(f), 43).add(rotate64(g, 30)).add(h), e.add(rotate64(f.add(a), 18)).add(g), mul22);
}
function fingerPrint64(s, len4 = s.length) {
  const seed = Long.fromNumber(81, true);
  if (len4 <= 32) {
    if (len4 <= 16) {
      return hashLen0to16(s, len4);
    } else {
      return hashLen17to32(s, len4);
    }
  } else if (len4 <= 64) {
    return hashLen33to64(s, len4);
  }
  let x = seed;
  let y = seed.mul(k1).add(113);
  let z = shiftMix(y.mul(k2).add(113)).mul(k2);
  let v = [Long.UZERO, Long.UZERO];
  let w = [Long.UZERO, Long.UZERO];
  x = x.mul(k2).add(fetch64(s, 0));
  let offset = 0;
  const end = (len4 - 1 >> 6) * 64;
  const last64 = end + (len4 - 1 & 63) - 63;
  do {
    x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(k1);
    y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(k1);
    x = x.xor(w[1]);
    y = y.add(v[0]).add(fetch64(s, offset + 40));
    z = rotate64(z.add(w[0]), 33).mul(k1);
    v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(k1), x.add(w[0]));
    w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
    [z, x] = [x, z];
    offset += 64;
  } while (offset !== end);
  const mul22 = k1.add(z.and(255).shl(1));
  offset = last64;
  w[0] = w[0].add(len4 - 1 & 63);
  v[0] = v[0].add(w[0]);
  w[0] = w[0].add(v[0]);
  x = rotate64(x.add(y).add(v[0]).add(fetch64(s, offset + 8)), 37).mul(mul22);
  y = rotate64(y.add(v[1]).add(fetch64(s, offset + 48)), 42).mul(mul22);
  x = x.xor(w[1].mul(9));
  y = y.add(v[0].mul(9).add(fetch64(s, offset + 40)));
  z = rotate64(z.add(w[0]), 33).mul(mul22);
  v = weakHashLen32WithSeedsStr(s, offset, v[1].mul(mul22), x.add(w[0]));
  w = weakHashLen32WithSeedsStr(s, offset + 32, z.add(w[1]), y.add(fetch64(s, offset + 16)));
  [z, x] = [x, z];
  return hashLen16(hashLen16(v[0], w[0], mul22).add(shiftMix(y).mul(k0)).add(z), hashLen16(v[1], w[1], mul22).add(x), mul22);
}
var LongExports;
var Long;
var k0;
var k1;
var k2;
var init_hash_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/hash_util.js"() {
    LongExports = __toESM(require_long());
    Long = // tslint:disable-next-line
    LongExports.default || LongExports;
    k0 = hexToLong("c3a5c85c97cb3127");
    k1 = hexToLong("b492b66fbe98f273");
    k2 = hexToLong("9ae16a3b2f90404f");
  }
});
var util_exports = {};
__export2(util_exports, {
  arraysEqual: () => arraysEqual,
  assert: () => assert,
  assertNonNegativeIntegerDimensions: () => assertNonNegativeIntegerDimensions,
  assertNonNull: () => assertNonNull,
  assertShapesMatch: () => assertShapesMatch,
  bytesFromStringArray: () => bytesFromStringArray,
  bytesPerElement: () => bytesPerElement,
  checkConversionForErrors: () => checkConversionForErrors,
  clamp: () => clamp2,
  computeStrides: () => computeStrides,
  convertBackendValuesAndArrayBuffer: () => convertBackendValuesAndArrayBuffer,
  createScalarValue: () => createScalarValue,
  createShuffledIndices: () => createShuffledIndices,
  decodeString: () => decodeString,
  distSquared: () => distSquared,
  encodeString: () => encodeString,
  fetch: () => fetch3,
  fingerPrint64: () => fingerPrint64,
  flatten: () => flatten,
  getArrayFromDType: () => getArrayFromDType,
  getTypedArrayFromDType: () => getTypedArrayFromDType,
  hasEncodingLoss: () => hasEncodingLoss,
  hexToLong: () => hexToLong,
  indexToLoc: () => indexToLoc,
  inferDtype: () => inferDtype,
  inferFromImplicitShape: () => inferFromImplicitShape,
  isBoolean: () => isBoolean,
  isFunction: () => isFunction,
  isInt: () => isInt,
  isNumber: () => isNumber2,
  isPromise: () => isPromise,
  isScalarShape: () => isScalarShape,
  isString: () => isString2,
  isTypedArray: () => isTypedArray,
  isValidDtype: () => isValidDtype,
  locToIndex: () => locToIndex,
  makeOnesTypedArray: () => makeOnesTypedArray,
  makeZerosNestedTypedArray: () => makeZerosNestedTypedArray,
  makeZerosTypedArray: () => makeZerosTypedArray,
  nearestDivisor: () => nearestDivisor,
  nearestLargerEven: () => nearestLargerEven,
  now: () => now,
  parseAxisParam: () => parseAxisParam,
  randUniform: () => randUniform,
  repeatedTry: () => repeatedTry,
  rightPad: () => rightPad,
  shuffle: () => shuffle,
  shuffleCombo: () => shuffleCombo,
  sizeFromShape: () => sizeFromShape,
  sizeToSquarishShape: () => sizeToSquarishShape,
  squeezeShape: () => squeezeShape,
  sum: () => sum,
  swap: () => swap,
  tanh: () => tanh,
  toNestedArray: () => toNestedArray,
  toTypedArray: () => toTypedArray
});
function createScalarValue(value, dtype) {
  if (dtype === "string") {
    return encodeString(value);
  }
  return toTypedArray([value], dtype);
}
function noConversionNeeded(a, dtype) {
  return a instanceof Float32Array && dtype === "float32" || a instanceof Int32Array && dtype === "int32" || a instanceof Uint8Array && dtype === "bool";
}
function toTypedArray(a, dtype) {
  if (dtype === "string") {
    throw new Error("Cannot convert a string[] to a TypedArray");
  }
  if (Array.isArray(a)) {
    a = flatten(a);
  }
  if (env().getBool("DEBUG")) {
    checkConversionForErrors(a, dtype);
  }
  if (noConversionNeeded(a, dtype)) {
    return a;
  }
  if (dtype == null || dtype === "float32" || dtype === "complex64") {
    return new Float32Array(a);
  } else if (dtype === "int32") {
    return new Int32Array(a);
  } else if (dtype === "bool") {
    const bool = new Uint8Array(a.length);
    for (let i = 0; i < bool.length; ++i) {
      if (Math.round(a[i]) !== 0) {
        bool[i] = 1;
      }
    }
    return bool;
  } else {
    throw new Error(`Unknown data type ${dtype}`);
  }
}
function now() {
  return env().platform.now();
}
function fetch3(path, requestInits) {
  return env().platform.fetch(path, requestInits);
}
function encodeString(s, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env().platform.encode(s, encoding);
}
function decodeString(bytes, encoding = "utf-8") {
  encoding = encoding || "utf-8";
  return env().platform.decode(bytes, encoding);
}
function isTypedArray(a) {
  return env().platform.isTypedArray(a);
}
function flatten(arr, result = [], skipTypedArray = false) {
  if (result == null) {
    result = [];
  }
  if (typeof arr === "boolean" || typeof arr === "number" || typeof arr === "string" || isPromise(arr) || arr == null || isTypedArray(arr) && skipTypedArray) {
    result.push(arr);
  } else if (Array.isArray(arr) || isTypedArray(arr)) {
    for (let i = 0; i < arr.length; ++i) {
      flatten(arr[i], result, skipTypedArray);
    }
  } else {
    let maxIndex = -1;
    for (const key of Object.keys(arr)) {
      if (/^([1-9]+[0-9]*|0)$/.test(key)) {
        maxIndex = Math.max(maxIndex, Number(key));
      }
    }
    for (let i = 0; i <= maxIndex; i++) {
      flatten(arr[i], result, skipTypedArray);
    }
  }
  return result;
}
var init_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/util.js"() {
    init_environment();
    init_util_base();
    init_util_base();
    init_hash_util();
  }
});
function checkComputationForErrors(vals, dtype, kernelName) {
  if (dtype !== "float32") {
    return false;
  }
  for (let i = 0; i < vals.length; i++) {
    const num = vals[i];
    if (isNaN(num) || !isFinite(num)) {
      console.warn(`Found ${num} in the result of '${kernelName}'`);
      return true;
    }
  }
  return false;
}
var Profiler;
var Logger;
var init_profiler = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/profiler.js"() {
    init_environment();
    init_util();
    Profiler = class {
      constructor(backendTimer, logger) {
        this.backendTimer = backendTimer;
        this.logger = logger;
        if (logger == null) {
          this.logger = new Logger();
        }
      }
      profileKernel(kernelName, inputs, f) {
        let outputs;
        const holdResultWrapperFn = () => {
          outputs = f();
        };
        let timer;
        const start = now();
        if (this.backendTimer.timerAvailable()) {
          timer = this.backendTimer.time(holdResultWrapperFn);
        } else {
          holdResultWrapperFn();
          for (const output of outputs) {
            output.dataSync();
          }
          timer = Promise.resolve({ kernelMs: now() - start });
        }
        if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
          for (let i = 0; i < outputs.length; i++) {
            const output = outputs[i];
            output.data().then((tensorVals) => {
              checkComputationForErrors(tensorVals, output.dtype, kernelName);
            });
          }
        }
        const kernelProfile = {
          kernelName,
          outputs,
          inputs,
          timeMs: timer.then((timing) => timing.kernelMs),
          extraInfo: timer.then((timing) => timing.getExtraProfileInfo != null ? timing.getExtraProfileInfo() : "")
        };
        return kernelProfile;
      }
      logKernelProfile(kernelProfile) {
        const { kernelName, outputs, timeMs, inputs, extraInfo } = kernelProfile;
        outputs.forEach((result) => {
          Promise.all([result.data(), timeMs, extraInfo]).then((valueContainer) => {
            this.logger.logKernelProfile(kernelName, result, valueContainer[0], valueContainer[1], inputs, valueContainer[2]);
          });
        });
      }
    };
    Logger = class {
      logKernelProfile(name, result, vals, timeMs, inputs, extraInfo) {
        const time = typeof timeMs === "number" ? rightPad(`${timeMs}ms`, 9) : timeMs["error"];
        const paddedName = rightPad(name, 25);
        const rank = result.rank;
        const size = result.size;
        const shape = rightPad(result.shape.toString(), 14);
        let inputShapesDescription = "";
        for (const name2 in inputs) {
          const input2 = inputs[name2];
          if (input2 != null) {
            const inputShape = input2.shape || result.shape;
            const inputRank = inputShape.length;
            inputShapesDescription += `${name2}: ${inputRank}D ${inputRank > 0 ? inputShape : ""} `;
          }
        }
        console.log(`%c${paddedName}	%c${time}	%c${rank}D ${shape}	%c${size}	%c${inputShapesDescription}	%c${extraInfo}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
      }
    };
  }
});
function getFilteredNodesXToY(tape, xs, y) {
  const tensorsFromX = {};
  const nodesFromX = {};
  for (let i = 0; i < xs.length; i++) {
    tensorsFromX[xs[i].id] = true;
  }
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (const inputName in nodeInputs) {
      const input2 = nodeInputs[inputName];
      let anyInputFromX = false;
      for (let j = 0; j < xs.length; j++) {
        if (tensorsFromX[input2.id]) {
          node.outputs.forEach((output) => tensorsFromX[output.id] = true);
          anyInputFromX = true;
          nodesFromX[node.id] = true;
          break;
        }
      }
      if (anyInputFromX) {
        break;
      }
    }
  }
  const tensorsLeadToY = {};
  tensorsLeadToY[y.id] = true;
  const nodesToY = {};
  for (let i = tape.length - 1; i >= 0; i--) {
    const node = tape[i];
    const nodeInputs = node.inputs;
    for (let j = 0; j < node.outputs.length; j++) {
      if (tensorsLeadToY[node.outputs[j].id]) {
        for (const inputName in nodeInputs) {
          tensorsLeadToY[nodeInputs[inputName].id] = true;
          nodesToY[node.id] = true;
        }
        break;
      }
    }
  }
  const filteredTape = [];
  for (let i = 0; i < tape.length; i++) {
    const node = tape[i];
    if (nodesFromX[node.id] && nodesToY[node.id]) {
      const prunedInputs = {};
      for (const inputName in node.inputs) {
        const nodeInput = node.inputs[inputName];
        if (tensorsFromX[nodeInput.id]) {
          prunedInputs[inputName] = nodeInput;
        }
      }
      const prunedNode = Object.assign({}, node);
      prunedNode.inputs = prunedInputs;
      prunedNode.outputs = node.outputs;
      filteredTape.push(prunedNode);
    }
  }
  return filteredTape;
}
function backpropagateGradients(tensorAccumulatedGradientMap, filteredTape, tidy2, add42) {
  for (let i = filteredTape.length - 1; i >= 0; i--) {
    const node = filteredTape[i];
    const dys = [];
    node.outputs.forEach((o) => {
      const gradTensor = tensorAccumulatedGradientMap[o.id];
      if (gradTensor != null) {
        dys.push(gradTensor);
      } else {
        dys.push(null);
      }
    });
    if (node.gradient == null) {
      throw new Error(`Cannot compute gradient: gradient function not found for ${node.kernelName}.`);
    }
    const inputGradients = node.gradient(dys);
    for (const inputName in node.inputs) {
      if (!(inputName in inputGradients)) {
        throw new Error(`Cannot backprop through input ${inputName}. Available gradients found: ${Object.keys(inputGradients)}.`);
      }
      const dx = tidy2(() => inputGradients[inputName]());
      if (dx.dtype !== "float32") {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input ${inputName} must have 'float32' dtype, but has '${dx.dtype}'`);
      }
      const x = node.inputs[inputName];
      if (!arraysEqual(dx.shape, x.shape)) {
        throw new Error(`Error in gradient for op ${node.kernelName}. The gradient of input '${inputName}' has shape '${dx.shape}', which does not match the shape of the input '${x.shape}'`);
      }
      if (tensorAccumulatedGradientMap[x.id] == null) {
        tensorAccumulatedGradientMap[x.id] = dx;
      } else {
        const curGradient = tensorAccumulatedGradientMap[x.id];
        tensorAccumulatedGradientMap[x.id] = add42(curGradient, dx);
        curGradient.dispose();
      }
    }
  }
}
var init_tape = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tape.js"() {
    init_util();
  }
});
function tensorToString(vals, shape, dtype, verbose) {
  const strides = computeStrides(shape);
  const padPerCol = computeMaxSizePerColumn(vals, shape, dtype, strides);
  const rank = shape.length;
  const valsLines = subTensorToString(vals, shape, dtype, strides, padPerCol);
  const lines = ["Tensor"];
  if (verbose) {
    lines.push(`  dtype: ${dtype}`);
    lines.push(`  rank: ${rank}`);
    lines.push(`  shape: [${shape}]`);
    lines.push(`  values:`);
  }
  lines.push(valsLines.map((l) => "    " + l).join("\n"));
  return lines.join("\n");
}
function computeMaxSizePerColumn(vals, shape, dtype, strides) {
  const n = sizeFromShape(shape);
  const numCols = strides[strides.length - 1];
  const padPerCol = new Array(numCols).fill(0);
  const rank = shape.length;
  const valuesOrTuples = dtype === "complex64" ? createComplexTuples(vals) : vals;
  if (rank > 1) {
    for (let row = 0; row < n / numCols; row++) {
      const offset = row * numCols;
      for (let j = 0; j < numCols; j++) {
        padPerCol[j] = Math.max(padPerCol[j], valToString(valuesOrTuples[offset + j], 0, dtype).length);
      }
    }
  }
  return padPerCol;
}
function valToString(val, pad2, dtype) {
  let valStr;
  if (Array.isArray(val)) {
    valStr = `${parseFloat(val[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ${parseFloat(val[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`;
  } else if (isString2(val)) {
    valStr = `'${val}'`;
  } else if (dtype === "bool") {
    valStr = boolNumToString(val);
  } else {
    valStr = parseFloat(val.toFixed(FORMAT_NUM_SIG_DIGITS)).toString();
  }
  return rightPad(valStr, pad2);
}
function boolNumToString(v) {
  return v === 0 ? "false" : "true";
}
function subTensorToString(vals, shape, dtype, strides, padPerCol, isLast = true) {
  const storagePerElement = dtype === "complex64" ? 2 : 1;
  const size = shape[0];
  const rank = shape.length;
  if (rank === 0) {
    if (dtype === "complex64") {
      const complexTuple = createComplexTuples(vals);
      return [valToString(complexTuple[0], 0, dtype)];
    }
    if (dtype === "bool") {
      return [boolNumToString(vals[0])];
    }
    return [vals[0].toString()];
  }
  if (rank === 1) {
    if (size > FORMAT_LIMIT_NUM_VALS) {
      const firstValsSize = FORMAT_NUM_FIRST_LAST_VALS * storagePerElement;
      let firstVals = Array.from(vals.slice(0, firstValsSize));
      let lastVals = Array.from(vals.slice((size - FORMAT_NUM_FIRST_LAST_VALS) * storagePerElement, size * storagePerElement));
      if (dtype === "complex64") {
        firstVals = createComplexTuples(firstVals);
        lastVals = createComplexTuples(lastVals);
      }
      return [
        "[" + firstVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + ", ..., " + lastVals.map((x, i) => valToString(x, padPerCol[size - FORMAT_NUM_FIRST_LAST_VALS + i], dtype)).join(", ") + "]"
      ];
    }
    const displayVals = dtype === "complex64" ? createComplexTuples(vals) : Array.from(vals);
    return [
      "[" + displayVals.map((x, i) => valToString(x, padPerCol[i], dtype)).join(", ") + "]"
    ];
  }
  const subshape = shape.slice(1);
  const substrides = strides.slice(1);
  const stride = strides[0] * storagePerElement;
  const lines = [];
  if (size > FORMAT_LIMIT_NUM_VALS) {
    for (let i = 0; i < FORMAT_NUM_FIRST_LAST_VALS; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(
        vals.slice(start, end),
        subshape,
        dtype,
        substrides,
        padPerCol,
        false
        /* isLast */
      ));
    }
    lines.push("...");
    for (let i = size - FORMAT_NUM_FIRST_LAST_VALS; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(
        vals.slice(start, end),
        subshape,
        dtype,
        substrides,
        padPerCol,
        i === size - 1
        /* isLast */
      ));
    }
  } else {
    for (let i = 0; i < size; i++) {
      const start = i * stride;
      const end = start + stride;
      lines.push(...subTensorToString(
        vals.slice(start, end),
        subshape,
        dtype,
        substrides,
        padPerCol,
        i === size - 1
        /* isLast */
      ));
    }
  }
  const sep = rank === 2 ? "," : "";
  lines[0] = "[" + (size > 0 ? lines[0] + sep : "");
  for (let i = 1; i < lines.length - 1; i++) {
    lines[i] = " " + lines[i] + sep;
  }
  let newLineSep = ",\n";
  for (let i = 2; i < rank; i++) {
    newLineSep += "\n";
  }
  lines[lines.length - 1] = " " + lines[lines.length - 1] + "]" + (isLast ? "" : newLineSep);
  return lines;
}
function createComplexTuples(vals) {
  const complexTuples = [];
  for (let i = 0; i < vals.length; i += 2) {
    complexTuples.push([vals[i], vals[i + 1]]);
  }
  return complexTuples;
}
var FORMAT_LIMIT_NUM_VALS;
var FORMAT_NUM_FIRST_LAST_VALS;
var FORMAT_NUM_SIG_DIGITS;
var init_tensor_format = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor_format.js"() {
    init_util();
    FORMAT_LIMIT_NUM_VALS = 20;
    FORMAT_NUM_FIRST_LAST_VALS = 3;
    FORMAT_NUM_SIG_DIGITS = 7;
  }
});
function setTensorTracker(fn) {
  trackerFn = fn;
}
function setOpHandler(handler) {
  opHandler = handler;
}
function setDeprecationWarningFn(fn) {
  deprecationWarningFn = fn;
}
function getGlobalTensorClass() {
  return getGlobal("Tensor", () => {
    return Tensor;
  });
}
var TensorBuffer;
var trackerFn;
var opHandler;
var deprecationWarningFn;
var Tensor;
var Variable;
var init_tensor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor.js"() {
    init_global_util();
    init_tensor_format();
    init_util();
    init_util();
    TensorBuffer = class {
      constructor(shape, dtype, values) {
        this.dtype = dtype;
        this.shape = shape.slice();
        this.size = sizeFromShape(shape);
        if (values != null) {
          const n = values.length;
          assert(n === this.size, () => `Length of values '${n}' does not match the size inferred by the shape '${this.size}'.`);
        }
        if (dtype === "complex64") {
          throw new Error(`complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).`);
        }
        this.values = values || getArrayFromDType(dtype, this.size);
        this.strides = computeStrides(shape);
      }
      /**
       * Sets a value in the buffer at a given location.
       *
       * @param value The value to set.
       * @param locs  The location indices.
       *
       * @doc {heading: 'Tensors', subheading: 'Creation'}
       */
      set(value, ...locs) {
        if (locs.length === 0) {
          locs = [0];
        }
        assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must match the rank (${this.rank})`);
        const index = this.locToIndex(locs);
        this.values[index] = value;
      }
      /**
       * Returns the value in the buffer at the provided location.
       *
       * @param locs The location indices.
       *
       * @doc {heading: 'Tensors', subheading: 'Creation'}
       */
      get(...locs) {
        if (locs.length === 0) {
          locs = [0];
        }
        let i = 0;
        for (const loc of locs) {
          if (loc < 0 || loc >= this.shape[i]) {
            const msg = `Requested out of range element at ${locs}.   Buffer shape=${this.shape}`;
            throw new Error(msg);
          }
          i++;
        }
        let index = locs[locs.length - 1];
        for (let i2 = 0; i2 < locs.length - 1; ++i2) {
          index += this.strides[i2] * locs[i2];
        }
        return this.values[index];
      }
      locToIndex(locs) {
        if (this.rank === 0) {
          return 0;
        } else if (this.rank === 1) {
          return locs[0];
        }
        let index = locs[locs.length - 1];
        for (let i = 0; i < locs.length - 1; ++i) {
          index += this.strides[i] * locs[i];
        }
        return index;
      }
      indexToLoc(index) {
        if (this.rank === 0) {
          return [];
        } else if (this.rank === 1) {
          return [index];
        }
        const locs = new Array(this.shape.length);
        for (let i = 0; i < locs.length - 1; ++i) {
          locs[i] = Math.floor(index / this.strides[i]);
          index -= locs[i] * this.strides[i];
        }
        locs[locs.length - 1] = index;
        return locs;
      }
      get rank() {
        return this.shape.length;
      }
      /**
       * Creates an immutable `tf.Tensor` object from the buffer.
       *
       * @doc {heading: 'Tensors', subheading: 'Creation'}
       */
      toTensor() {
        return trackerFn().makeTensor(this.values, this.shape, this.dtype);
      }
    };
    trackerFn = null;
    opHandler = null;
    deprecationWarningFn = null;
    Tensor = class {
      constructor(shape, dtype, dataId, id) {
        this.kept = false;
        this.isDisposedInternal = false;
        this.shape = shape.slice();
        this.dtype = dtype || "float32";
        this.size = sizeFromShape(shape);
        this.strides = computeStrides(shape);
        this.dataId = dataId;
        this.id = id;
        this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
      }
      get rank() {
        return this.shape.length;
      }
      /**
       * Returns a promise of `tf.TensorBuffer` that holds the underlying data.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      async buffer() {
        const vals = await this.data();
        return opHandler.buffer(this.shape, this.dtype, vals);
      }
      /**
       * Returns a `tf.TensorBuffer` that holds the underlying data.
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      bufferSync() {
        return opHandler.buffer(this.shape, this.dtype, this.dataSync());
      }
      /**
       * Returns the tensor data as a nested array. The transfer of data is done
       * asynchronously.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      async array() {
        const vals = await this.data();
        return toNestedArray(this.shape, vals, this.dtype === "complex64");
      }
      /**
       * Returns the tensor data as a nested array. The transfer of data is done
       * synchronously.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      arraySync() {
        return toNestedArray(this.shape, this.dataSync(), this.dtype === "complex64");
      }
      /**
       * Asynchronously downloads the values from the `tf.Tensor`. Returns a
       * promise of `TypedArray` that resolves when the computation has finished.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      async data() {
        this.throwIfDisposed();
        const data = trackerFn().read(this.dataId);
        if (this.dtype === "string") {
          const bytes = await data;
          try {
            return bytes.map((b) => decodeString(b));
          } catch (_a2) {
            throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
          }
        }
        return data;
      }
      /**
       * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`
       * and `data()`, this method prevents data from being downloaded to CPU.
       *
       * For WebGL backend, the data will be stored on a densely packed texture.
       * This means that the texture will use the RGBA channels to store value.
       *
       * For WebGPU backend, the data will be stored on a buffer. There is no
       * parameter, so can not use a user-defined size to create the buffer.
       *
       * @param options:
       *     For WebGL,
       *         - customTexShape: Optional. If set, will use the user defined
       *     texture shape to create the texture.
       *
       * @returns For WebGL backend, a GPUData contains the new texture and
       *     its information.
       *     {
       *        tensorRef: The tensor that is associated with this texture,
       *        texture: WebGLTexture,
       *        texShape: [number, number] // [height, width]
       *     }
       *
       *     For WebGPU backend, a GPUData contains the new buffer and
       *     its information.
       *     {
       *        tensorRef: The tensor that is associated with this buffer,
       *        buffer: GPUBuffer,
       *        bufSize: number
       *     }
       *
       *     Remember to dispose the GPUData after it is used by
       *     `res.tensorRef.dispose()`.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      dataToGPU(options) {
        this.throwIfDisposed();
        return trackerFn().readToGPU(this.dataId, options);
      }
      /**
       * Synchronously downloads the values from the `tf.Tensor`. This blocks the
       * UI thread until the values are ready, which can cause performance issues.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      dataSync() {
        this.throwIfDisposed();
        const data = trackerFn().readSync(this.dataId);
        if (this.dtype === "string") {
          try {
            return data.map((b) => decodeString(b));
          } catch (_a2) {
            throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
          }
        }
        return data;
      }
      /** Returns the underlying bytes of the tensor's data. */
      async bytes() {
        this.throwIfDisposed();
        const data = await trackerFn().read(this.dataId);
        if (this.dtype === "string") {
          return data;
        } else {
          return new Uint8Array(data.buffer);
        }
      }
      /**
       * Disposes `tf.Tensor` from memory.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      dispose() {
        if (this.isDisposed) {
          return;
        }
        trackerFn().disposeTensor(this);
        this.isDisposedInternal = true;
      }
      get isDisposed() {
        return this.isDisposedInternal;
      }
      throwIfDisposed() {
        if (this.isDisposed) {
          throw new Error(`Tensor is disposed.`);
        }
      }
      /**
       * Prints the `tf.Tensor`. See `tf.print` for details.
       *
       * @param verbose Whether to print verbose information about the tensor,
       *    including dtype and size.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      print(verbose = false) {
        return opHandler.print(this, verbose);
      }
      /**
       * Returns a copy of the tensor. See `tf.clone` for details.
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      clone() {
        this.throwIfDisposed();
        return opHandler.clone(this);
      }
      /**
       * Returns a human-readable description of the tensor. Useful for logging.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      toString(verbose = false) {
        const vals = this.dataSync();
        return tensorToString(vals, this.shape, this.dtype, verbose);
      }
      cast(dtype) {
        this.throwIfDisposed();
        return opHandler.cast(this, dtype);
      }
      variable(trainable = true, name, dtype) {
        this.throwIfDisposed();
        return trackerFn().makeVariable(this, trainable, name, dtype);
      }
    };
    Object.defineProperty(Tensor, Symbol.hasInstance, {
      value: (instance) => {
        return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;
      }
    });
    getGlobalTensorClass();
    Variable = class extends Tensor {
      constructor(initialValue, trainable, name, tensorId) {
        super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);
        this.trainable = trainable;
        this.name = name;
      }
      /**
       * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have
       * the same shape and dtype as the old `tf.Tensor`.
       *
       * @param newValue New tensor to be assigned to this variable.
       *
       * @doc {heading: 'Tensors', subheading: 'Classes'}
       */
      assign(newValue) {
        if (newValue.dtype !== this.dtype) {
          throw new Error(`dtype of the new value (${newValue.dtype}) and previous value (${this.dtype}) must match`);
        }
        if (!arraysEqual(newValue.shape, this.shape)) {
          throw new Error(`shape of the new value (${newValue.shape}) and previous value (${this.shape}) must match`);
        }
        trackerFn().disposeTensor(this);
        this.dataId = newValue.dataId;
        trackerFn().incRef(
          this,
          null
          /* backend */
        );
      }
      dispose() {
        trackerFn().disposeVariable(this);
        this.isDisposedInternal = true;
      }
    };
    Object.defineProperty(Variable, Symbol.hasInstance, {
      value: (instance) => {
        return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;
      }
    });
  }
});
function upcastType(typeA, typeB) {
  if (typeA === "string" || typeB === "string") {
    if (typeA === "string" && typeB === "string") {
      return "string";
    }
    throw new Error(`Can not upcast ${typeA} with ${typeB}`);
  }
  return upcastTypeMap[typeA][typeB];
}
function sumOutType(type) {
  return upcastType(type, "int32");
}
var Rank;
var UpcastInt32AndMap;
var UpcastBoolAndMap;
var UpcastFloat32AndMap;
var UpcastComplex64AndMap;
var upcastTypeMap;
var init_types = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/types.js"() {
    (function(Rank2) {
      Rank2["R0"] = "R0";
      Rank2["R1"] = "R1";
      Rank2["R2"] = "R2";
      Rank2["R3"] = "R3";
      Rank2["R4"] = "R4";
      Rank2["R5"] = "R5";
      Rank2["R6"] = "R6";
    })(Rank || (Rank = {}));
    (function(UpcastInt32AndMap2) {
      UpcastInt32AndMap2["float32"] = "float32";
      UpcastInt32AndMap2["int32"] = "int32";
      UpcastInt32AndMap2["bool"] = "int32";
      UpcastInt32AndMap2["complex64"] = "complex64";
    })(UpcastInt32AndMap || (UpcastInt32AndMap = {}));
    (function(UpcastBoolAndMap2) {
      UpcastBoolAndMap2["float32"] = "float32";
      UpcastBoolAndMap2["int32"] = "int32";
      UpcastBoolAndMap2["bool"] = "bool";
      UpcastBoolAndMap2["complex64"] = "complex64";
    })(UpcastBoolAndMap || (UpcastBoolAndMap = {}));
    (function(UpcastFloat32AndMap2) {
      UpcastFloat32AndMap2["float32"] = "float32";
      UpcastFloat32AndMap2["int32"] = "float32";
      UpcastFloat32AndMap2["bool"] = "float32";
      UpcastFloat32AndMap2["complex64"] = "complex64";
    })(UpcastFloat32AndMap || (UpcastFloat32AndMap = {}));
    (function(UpcastComplex64AndMap2) {
      UpcastComplex64AndMap2["float32"] = "complex64";
      UpcastComplex64AndMap2["int32"] = "complex64";
      UpcastComplex64AndMap2["bool"] = "complex64";
      UpcastComplex64AndMap2["complex64"] = "complex64";
    })(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
    upcastTypeMap = {
      "float32": UpcastFloat32AndMap,
      "int32": UpcastInt32AndMap,
      "bool": UpcastBoolAndMap,
      "complex64": UpcastComplex64AndMap
    };
  }
});
var tensor_util_exports = {};
__export2(tensor_util_exports, {
  assertTypesMatch: () => assertTypesMatch,
  getTensorsInContainer: () => getTensorsInContainer,
  isTensorInList: () => isTensorInList,
  makeTypesMatch: () => makeTypesMatch
});
function makeTypesMatch(a, b) {
  if (a.dtype === b.dtype) {
    return [a, b];
  }
  const dtype = upcastType(a.dtype, b.dtype);
  return [a.cast(dtype), b.cast(dtype)];
}
function assertTypesMatch(a, b) {
  assert(a.dtype === b.dtype, () => `The dtypes of the first(${a.dtype}) and second(${b.dtype}) input must match`);
}
function isTensorInList(tensor2, tensorList) {
  return tensorList.some((x) => x.id === tensor2.id);
}
function getTensorsInContainer(result) {
  const list = [];
  const seen = /* @__PURE__ */ new Set();
  walkTensorContainer(result, list, seen);
  return list;
}
function walkTensorContainer(container, list, seen) {
  if (container == null) {
    return;
  }
  if (container instanceof Tensor) {
    list.push(container);
    return;
  }
  if (!isIterable(container)) {
    return;
  }
  const iterable = container;
  for (const k in iterable) {
    const val = iterable[k];
    if (!seen.has(val)) {
      seen.add(val);
      walkTensorContainer(val, list, seen);
    }
  }
}
function isIterable(obj) {
  return Array.isArray(obj) || typeof obj === "object";
}
var init_tensor_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor_util.js"() {
    init_tensor();
    init_types();
    init_util();
  }
});
function isRegisteredKernelInvocation(kernelInvocation) {
  return kernelInvocation.kernelName != null;
}
function ones(shape) {
  const values = makeOnesTypedArray(sizeFromShape(shape), "float32");
  return ENGINE.makeTensor(values, shape, "float32");
}
function getOrMakeEngine() {
  const ns = getGlobalNamespace();
  if (ns._tfengine == null) {
    const environment = new Environment(ns);
    ns._tfengine = new Engine(environment);
  }
  setEnvironmentGlobal(ns._tfengine.ENV);
  setTensorTracker(() => ns._tfengine);
  return ns._tfengine;
}
function add6(a, b) {
  const inputs = { a, b };
  return ENGINE.runKernel(Add, inputs);
}
var EngineState;
var Engine;
var ENGINE;
var init_engine = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/engine.js"() {
    init_backend();
    init_environment();
    init_global_util();
    init_kernel_names();
    init_kernel_registry();
    init_log();
    init_profiler();
    init_tape();
    init_tensor();
    init_tensor_util();
    init_util();
    init_util();
    EngineState = class {
      constructor() {
        this.registeredVariables = {};
        this.nextTapeNodeId = 0;
        this.numBytes = 0;
        this.numTensors = 0;
        this.numStringTensors = 0;
        this.numDataBuffers = 0;
        this.gradientDepth = 0;
        this.kernelDepth = 0;
        this.scopeStack = [];
        this.numDataMovesStack = [];
        this.nextScopeId = 0;
        this.tensorInfo = /* @__PURE__ */ new WeakMap();
        this.profiling = false;
        this.activeProfile = {
          newBytes: 0,
          newTensors: 0,
          peakBytes: 0,
          kernels: [],
          result: null,
          get kernelNames() {
            return Array.from(new Set(this.kernels.map((k) => k.name)));
          }
        };
      }
      dispose() {
        for (const variableName in this.registeredVariables) {
          this.registeredVariables[variableName].dispose();
        }
      }
    };
    Engine = class {
      constructor(ENV6) {
        this.ENV = ENV6;
        this.registry = {};
        this.registryFactory = {};
        this.pendingBackendInitId = 0;
        this.state = new EngineState();
      }
      async ready() {
        if (this.pendingBackendInit != null) {
          return this.pendingBackendInit.then(() => {
          });
        }
        if (this.backendInstance != null) {
          return;
        }
        const sortedBackends = this.getSortedBackends();
        for (let i = 0; i < sortedBackends.length; i++) {
          const backendName = sortedBackends[i];
          const success = await this.initializeBackend(backendName).success;
          if (success) {
            await this.setBackend(backendName);
            return;
          }
        }
        throw new Error(`Could not initialize any backends, all backend initializations failed.`);
      }
      get backend() {
        if (this.pendingBackendInit != null) {
          throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
        }
        if (this.backendInstance == null) {
          const { name, asyncInit } = this.initializeBackendsAndReturnBest();
          if (asyncInit) {
            throw new Error(`The highest priority backend '${name}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
          }
          this.setBackend(name);
        }
        return this.backendInstance;
      }
      backendNames() {
        return Object.keys(this.registryFactory);
      }
      findBackend(backendName) {
        if (!(backendName in this.registry)) {
          if (backendName in this.registryFactory) {
            const { asyncInit } = this.initializeBackend(backendName);
            if (asyncInit) {
              return null;
            }
          } else {
            return null;
          }
        }
        return this.registry[backendName];
      }
      findBackendFactory(backendName) {
        if (!(backendName in this.registryFactory)) {
          return null;
        }
        return this.registryFactory[backendName].factory;
      }
      registerBackend(backendName, factory, priority = 1) {
        if (backendName in this.registryFactory) {
          warn(`${backendName} backend was already registered. Reusing existing backend factory.`);
          return false;
        }
        this.registryFactory[backendName] = { factory, priority };
        return true;
      }
      async setBackend(backendName) {
        if (this.registryFactory[backendName] == null) {
          throw new Error(`Backend name '${backendName}' not found in registry`);
        }
        this.backendName = backendName;
        if (this.registry[backendName] == null) {
          this.backendInstance = null;
          const { success, asyncInit } = this.initializeBackend(backendName);
          const result = asyncInit ? await success : success;
          if (!result) {
            return false;
          }
        }
        this.backendInstance = this.registry[backendName];
        this.setupRegisteredKernels();
        this.profiler = new Profiler(this.backendInstance);
        return true;
      }
      setupRegisteredKernels() {
        const kernels = getKernelsForBackend(this.backendName);
        kernels.forEach((kernel) => {
          if (kernel.setupFunc != null) {
            kernel.setupFunc(this.backendInstance);
          }
        });
      }
      disposeRegisteredKernels(backendName) {
        const kernels = getKernelsForBackend(backendName);
        kernels.forEach((kernel) => {
          if (kernel.disposeFunc != null) {
            kernel.disposeFunc(this.registry[backendName]);
          }
        });
      }
      /**
       * Initializes a backend by looking up the backend name in the factory
       * registry and calling the factory method. Returns a boolean representing
       * whether the initialization of the backend suceeded. Throws an error if
       * there is no backend in the factory registry.
       */
      initializeBackend(backendName) {
        const registryFactoryEntry = this.registryFactory[backendName];
        if (registryFactoryEntry == null) {
          throw new Error(`Cannot initialize backend ${backendName}, no registration found.`);
        }
        try {
          const backend2 = registryFactoryEntry.factory();
          if (backend2 && !(backend2 instanceof KernelBackend) && typeof backend2.then === "function") {
            const promiseId = ++this.pendingBackendInitId;
            const success = backend2.then((backendInstance) => {
              if (promiseId < this.pendingBackendInitId) {
                return false;
              }
              this.registry[backendName] = backendInstance;
              this.pendingBackendInit = null;
              return true;
            }).catch((err) => {
              if (promiseId < this.pendingBackendInitId) {
                return false;
              }
              this.pendingBackendInit = null;
              warn(`Initialization of backend ${backendName} failed`);
              warn(err.stack || err.message);
              return false;
            });
            this.pendingBackendInit = success;
            return { success, asyncInit: true };
          } else {
            this.registry[backendName] = backend2;
            return { success: true, asyncInit: false };
          }
        } catch (err) {
          warn(`Initialization of backend ${backendName} failed`);
          warn(err.stack || err.message);
          return { success: false, asyncInit: false };
        }
      }
      removeBackend(backendName) {
        if (!(backendName in this.registryFactory)) {
          throw new Error(`${backendName} backend not found in registry`);
        }
        if (this.backendName === backendName && this.pendingBackendInit != null) {
          this.pendingBackendInitId++;
        }
        if (backendName in this.registry) {
          this.disposeRegisteredKernels(backendName);
          this.registry[backendName].dispose();
          delete this.registry[backendName];
        }
        delete this.registryFactory[backendName];
        if (this.backendName === backendName) {
          this.pendingBackendInit = null;
          this.backendName = null;
          this.backendInstance = null;
        }
      }
      getSortedBackends() {
        if (Object.keys(this.registryFactory).length === 0) {
          throw new Error("No backend found in registry.");
        }
        return Object.keys(this.registryFactory).sort((a, b) => {
          return this.registryFactory[b].priority - this.registryFactory[a].priority;
        });
      }
      initializeBackendsAndReturnBest() {
        const sortedBackends = this.getSortedBackends();
        for (let i = 0; i < sortedBackends.length; i++) {
          const backendName = sortedBackends[i];
          const { success, asyncInit } = this.initializeBackend(backendName);
          if (asyncInit || success) {
            return { name: backendName, asyncInit };
          }
        }
        throw new Error(`Could not initialize any backends, all backend initializations failed.`);
      }
      moveData(backend2, dataId) {
        const info = this.state.tensorInfo.get(dataId);
        const srcBackend = info.backend;
        const values = this.readSync(dataId);
        const refCount = srcBackend.refCount(dataId);
        srcBackend.disposeData(dataId, true);
        info.backend = backend2;
        backend2.move(dataId, values, info.shape, info.dtype, refCount);
        if (this.shouldCheckForMemLeaks()) {
          this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
        }
      }
      tidy(nameOrFn, fn) {
        let name = null;
        if (fn == null) {
          if (typeof nameOrFn !== "function") {
            throw new Error("Please provide a function to tidy()");
          }
          fn = nameOrFn;
        } else {
          if (typeof nameOrFn !== "string" && !(nameOrFn instanceof String)) {
            throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
          }
          if (typeof fn !== "function") {
            throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
          }
          name = nameOrFn;
        }
        let result;
        return this.scopedRun(() => this.startScope(name), () => this.endScope(result), () => {
          result = fn();
          if (result instanceof Promise) {
            console.error("Cannot return a Promise inside of tidy.");
          }
          return result;
        });
      }
      scopedRun(start, end, f) {
        start();
        try {
          const res = f();
          end();
          return res;
        } catch (ex) {
          end();
          throw ex;
        }
      }
      nextTensorId() {
        return Engine.nextTensorId++;
      }
      nextVariableId() {
        return Engine.nextVariableId++;
      }
      /**
       * This method is called instead of the public-facing tensor.clone() when
       * saving a tensor for backwards pass. It makes sure to add the clone
       * operation to the tape regardless of being called inside a kernel
       * execution.
       */
      clone(x) {
        const y = ENGINE.runKernel(Identity, { x });
        const inputs = { x };
        const grad = (dy) => ({
          x: () => {
            const dtype = "float32";
            const gradInputs = { x: dy };
            const attrs = { dtype };
            return ENGINE.runKernel(
              Cast,
              gradInputs,
              // tslint:disable-next-line: no-unnecessary-type-assertion
              attrs
            );
          }
        });
        const saved = [];
        this.addTapeNode(this.state.activeScope.name, inputs, [y], grad, saved, {});
        return y;
      }
      /**
       * Execute a kernel with the given name and return the output tensor.
       *
       * @param kernelName The name of the kernel to execute.
       * @param inputs A map of input names to tensors.
       * @param attrs A map of attribute names to their values. An attribute is a
       *     primitive (non-tensor) input to the kernel.
       * @param inputsToSave A list of tensors, inputs to save for the backprop
       *     computation.
       * @param outputsToSave A list of booleans, specifying which output to save
       *     for the backprop computation. These are booleans since the output
       * tensors are not visible to the user.
       */
      runKernel(kernelName, inputs, attrs) {
        if (this.backendName == null) {
          this.backend;
        }
        const hasKernel = getKernel(kernelName, this.backendName) != null;
        if (!hasKernel) {
          throw new Error(`Kernel '${kernelName}' not registered for backend '${this.backendName}'`);
        }
        return this.runKernelFunc({ kernelName, inputs, attrs });
      }
      shouldCheckForMemLeaks() {
        return this.ENV.getBool("IS_TEST");
      }
      checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos) {
        const numDataIdsAfter = this.backend.numDataIds();
        let numOutputDataIds = 0;
        outInfos.forEach((info) => {
          numOutputDataIds += info.dtype === "complex64" ? 3 : 1;
        });
        const numMoves = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
        const dataIdsLeaked = numDataIdsAfter - numDataIdsBefore - numOutputDataIds - numMoves;
        if (dataIdsLeaked > 0) {
          throw new Error(`Backend '${this.backendName}' has an internal memory leak (${dataIdsLeaked} data ids) after running '${kernelName}'`);
        }
      }
      /**
       * Internal helper method to execute a kernel Func
       *
       * Use `runKernel` to execute kernels from outside of engine.
       */
      runKernelFunc(kernelParams) {
        let outputs;
        let saved = [];
        const isTapeOn = this.isTapeOn();
        const startingBytecount = this.state.numBytes;
        const startingNumTensors = this.state.numTensors;
        if (this.shouldCheckForMemLeaks()) {
          this.state.numDataMovesStack.push(0);
        }
        let kernelFunc;
        if (this.backendName == null) {
          this.backend;
        }
        let out;
        const kernelOrScopeName = isRegisteredKernelInvocation(kernelParams) ? kernelParams.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
        if (isRegisteredKernelInvocation(kernelParams)) {
          const { kernelName, inputs: inputs2, attrs: attrs2 } = kernelParams;
          if (this.backendName == null) {
            this.backend;
          }
          const kernel = getKernel(kernelName, this.backendName);
          assert(kernel != null, () => `Cannot find registered kernel '${kernelName}' for backend '${this.backendName}'`);
          kernelFunc = () => {
            const numDataIdsBefore = this.backend.numDataIds();
            out = kernel.kernelFunc({ inputs: inputs2, attrs: attrs2, backend: this.backend });
            const outInfos = Array.isArray(out) ? out : [out];
            if (this.shouldCheckForMemLeaks()) {
              this.checkKernelForMemLeak(kernelName, numDataIdsBefore, outInfos);
            }
            const outTensors = outInfos.map((outInfo) => {
              if (outInfo.rank != null) {
                return outInfo;
              }
              return this.makeTensorFromTensorInfo(outInfo);
            });
            if (isTapeOn) {
              const tensorsToSave = this.getTensorsForGradient(kernelName, inputs2, outTensors);
              saved = this.saveTensorsForBackwardMode(tensorsToSave);
            }
            return outTensors;
          };
        } else {
          const { forwardFunc } = kernelParams;
          const saveFunc = (tensors) => {
            if (!isTapeOn) {
              return;
            }
            saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
          };
          kernelFunc = () => {
            const numDataIdsBefore = this.backend.numDataIds();
            out = this.tidy(() => forwardFunc(this.backend, saveFunc));
            const outs = Array.isArray(out) ? out : [out];
            if (this.shouldCheckForMemLeaks()) {
              this.checkKernelForMemLeak(kernelOrScopeName, numDataIdsBefore, outs);
            }
            return outs;
          };
        }
        const { inputs, attrs } = kernelParams;
        const backwardsFunc = isRegisteredKernelInvocation(kernelParams) ? null : kernelParams.backwardsFunc;
        let kernelProfile;
        this.scopedRun(
          // Stop recording to a tape when running a kernel.
          () => this.state.kernelDepth++,
          () => this.state.kernelDepth--,
          () => {
            if (!this.ENV.getBool("DEBUG") && !this.state.profiling) {
              outputs = kernelFunc();
            } else {
              kernelProfile = this.profiler.profileKernel(kernelOrScopeName, inputs, () => kernelFunc());
              if (this.ENV.getBool("DEBUG")) {
                this.profiler.logKernelProfile(kernelProfile);
              }
              outputs = kernelProfile.outputs;
            }
          }
        );
        if (isTapeOn) {
          this.addTapeNode(kernelOrScopeName, inputs, outputs, backwardsFunc, saved, attrs);
        }
        if (this.state.profiling) {
          this.state.activeProfile.kernels.push({
            name: kernelOrScopeName,
            bytesAdded: this.state.numBytes - startingBytecount,
            totalBytesSnapshot: this.state.numBytes,
            tensorsAdded: this.state.numTensors - startingNumTensors,
            totalTensorsSnapshot: this.state.numTensors,
            inputShapes: Object.keys(inputs).map((key) => inputs[key] != null ? inputs[key].shape : null),
            outputShapes: outputs.map((item) => item.shape),
            kernelTimeMs: kernelProfile.timeMs,
            extraInfo: kernelProfile.extraInfo
          });
        }
        return Array.isArray(out) ? outputs : outputs[0];
      }
      /**
       * Saves tensors used in forward mode for use in backward mode.
       *
       * @param tensors the list of tensors to save.
       */
      saveTensorsForBackwardMode(tensors) {
        const saved = tensors.map((tensor2) => this.keep(this.clone(tensor2)));
        return saved;
      }
      /**
       * Returns a list of tensors to save for a given gradient calculation.
       *
       * @param kernelName name of kernel to look up gradient for.
       * @param inputs a map of input tensors.
       * @param outputs an array of output tensors from forward mode of kernel.
       */
      getTensorsForGradient(kernelName, inputs, outputs) {
        const gradConfig = getGradient(kernelName);
        if (gradConfig != null) {
          const inputsToSave = gradConfig.inputsToSave || [];
          const outputsToSave = gradConfig.outputsToSave || [];
          let inputTensorsToSave;
          if (gradConfig.saveAllInputs) {
            assert(Array.isArray(inputs), () => "saveAllInputs is true, expected inputs to be an array.");
            inputTensorsToSave = Object.keys(inputs).map((key) => inputs[key]);
          } else {
            inputTensorsToSave = inputsToSave.map((inputName) => inputs[inputName]);
          }
          const outputTensorsToSave = outputs.filter((_, i) => outputsToSave[i]);
          return inputTensorsToSave.concat(outputTensorsToSave);
        }
        return [];
      }
      /**
       * Internal method used by public APIs for tensor creation. Makes a new
       * tensor with the provided shape, dtype and values. It always
       * creates a new data id and writes the values to the underlying backend.
       */
      makeTensor(values, shape, dtype, backend2) {
        if (values == null) {
          throw new Error("Values passed to engine.makeTensor() are null");
        }
        dtype = dtype || "float32";
        backend2 = backend2 || this.backend;
        let backendVals = values;
        if (dtype === "string" && isString2(values[0])) {
          backendVals = values.map((d) => encodeString(d));
        }
        const dataId = backend2.write(backendVals, shape, dtype);
        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
        this.trackTensor(t, backend2);
        if (dtype === "string") {
          const info = this.state.tensorInfo.get(dataId);
          const newBytes = bytesFromStringArray(backendVals);
          this.state.numBytes += newBytes - info.bytes;
          info.bytes = newBytes;
        }
        return t;
      }
      /**
       * Internal method used by backends. Makes a new tensor
       * that is a wrapper around an existing data id. It doesn't create
       * a new data id, only increments the ref count used in memory tracking.
       * @deprecated
       */
      makeTensorFromDataId(dataId, shape, dtype, backend2) {
        dtype = dtype || "float32";
        const tensorInfo = { dataId, shape, dtype };
        return this.makeTensorFromTensorInfo(tensorInfo, backend2);
      }
      /**
       * Internal method used by backends. Makes a new tensor that is a wrapper
       * around an existing data id in TensorInfo. It doesn't create a new data id,
       * only increments the ref count used in memory tracking.
       */
      makeTensorFromTensorInfo(tensorInfo, backend2) {
        const { dataId, shape, dtype } = tensorInfo;
        const t = new Tensor(shape, dtype, dataId, this.nextTensorId());
        this.trackTensor(t, backend2);
        return t;
      }
      makeVariable(initialValue, trainable = true, name, dtype) {
        name = name || this.nextVariableId().toString();
        if (dtype != null && dtype !== initialValue.dtype) {
          initialValue = initialValue.cast(dtype);
        }
        const v = new Variable(initialValue, trainable, name, this.nextTensorId());
        if (this.state.registeredVariables[v.name] != null) {
          throw new Error(`Variable with name ${v.name} was already registered`);
        }
        this.state.registeredVariables[v.name] = v;
        this.incRef(v, this.backend);
        return v;
      }
      trackTensor(a, backend2) {
        this.state.numTensors++;
        if (a.dtype === "string") {
          this.state.numStringTensors++;
        }
        let bytes = 0;
        if (a.dtype !== "complex64" && a.dtype !== "string") {
          bytes = a.size * bytesPerElement(a.dtype);
        }
        this.state.numBytes += bytes;
        if (!this.state.tensorInfo.has(a.dataId)) {
          this.state.numDataBuffers++;
          this.state.tensorInfo.set(a.dataId, {
            backend: backend2 || this.backend,
            dtype: a.dtype,
            shape: a.shape,
            bytes
          });
        }
        if (!(a instanceof Variable)) {
          this.track(a);
        }
      }
      // Track the tensor by dataId and increase the refCount for the dataId in the
      // backend.
      // TODO(pyu10055): This is currently used by makeVariable method, to increase
      // refCount on the backend for the dataId. It can potentially be replaced with
      // Identity op indead of calling backend directly.
      incRef(a, backend2) {
        this.trackTensor(a, backend2);
        this.backend.incRef(a.dataId);
      }
      removeDataId(dataId, backend2) {
        if (this.state.tensorInfo.has(dataId) && this.state.tensorInfo.get(dataId).backend === backend2) {
          this.state.tensorInfo.delete(dataId);
          this.state.numDataBuffers--;
        }
      }
      disposeTensor(a) {
        if (!this.state.tensorInfo.has(a.dataId)) {
          return;
        }
        const info = this.state.tensorInfo.get(a.dataId);
        this.state.numTensors--;
        if (a.dtype === "string") {
          this.state.numStringTensors--;
          this.state.numBytes -= info.bytes;
        }
        if (a.dtype !== "complex64" && a.dtype !== "string") {
          const bytes = a.size * bytesPerElement(a.dtype);
          this.state.numBytes -= bytes;
        }
        if (info.backend.disposeData(a.dataId)) {
          this.removeDataId(a.dataId, info.backend);
        }
      }
      disposeVariables() {
        for (const varName in this.state.registeredVariables) {
          const v = this.state.registeredVariables[varName];
          this.disposeVariable(v);
        }
      }
      disposeVariable(v) {
        this.disposeTensor(v);
        if (this.state.registeredVariables[v.name] != null) {
          delete this.state.registeredVariables[v.name];
        }
      }
      memory() {
        const info = this.backend.memory();
        info.numTensors = this.state.numTensors;
        info.numDataBuffers = this.state.numDataBuffers;
        info.numBytes = this.state.numBytes;
        if (this.state.numStringTensors > 0) {
          info.unreliable = true;
          if (info.reasons == null) {
            info.reasons = [];
          }
          info.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)");
        }
        return info;
      }
      async profile(query) {
        this.state.profiling = true;
        const startBytes = this.state.numBytes;
        const startNumTensors = this.state.numTensors;
        this.state.activeProfile.kernels = [];
        this.state.activeProfile.result = await query();
        this.state.profiling = false;
        this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((d) => d.totalBytesSnapshot));
        this.state.activeProfile.newBytes = this.state.numBytes - startBytes;
        this.state.activeProfile.newTensors = this.state.numTensors - startNumTensors;
        for (const kernel of this.state.activeProfile.kernels) {
          kernel.kernelTimeMs = await kernel.kernelTimeMs;
          kernel.extraInfo = await kernel.extraInfo;
        }
        return this.state.activeProfile;
      }
      isTapeOn() {
        return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
      }
      addTapeNode(kernelName, inputs, outputs, gradientsFunc, saved, attrs) {
        const tapeNode = { id: this.state.nextTapeNodeId++, kernelName, inputs, outputs, saved };
        const gradConfig = getGradient(kernelName);
        if (gradConfig != null) {
          gradientsFunc = gradConfig.gradFunc;
        }
        if (gradientsFunc != null) {
          tapeNode.gradient = (dys) => {
            dys = dys.map((dy, i) => {
              if (dy == null) {
                const output = outputs[i];
                const vals = makeZerosTypedArray(output.size, output.dtype);
                return this.makeTensor(vals, output.shape, output.dtype);
              }
              return dy;
            });
            return gradientsFunc(dys.length > 1 ? dys : dys[0], saved, attrs);
          };
        }
        this.state.activeTape.push(tapeNode);
      }
      keep(result) {
        result.kept = true;
        return result;
      }
      startTape() {
        if (this.state.gradientDepth === 0) {
          this.state.activeTape = [];
        }
        this.state.gradientDepth++;
      }
      endTape() {
        this.state.gradientDepth--;
      }
      /**
       * Start a scope. Use this with endScope() to achieve the same functionality
       * as scope() without the need for a function closure.
       */
      startScope(name) {
        const scopeInfo = {
          track: [],
          name: "unnamed scope",
          id: this.state.nextScopeId++
        };
        if (name) {
          scopeInfo.name = name;
        }
        this.state.scopeStack.push(scopeInfo);
        this.state.activeScope = scopeInfo;
      }
      /**
       * End a scope. Use this with startScope() to achieve the same functionality
       * as scope() without the need for a function closure.
       */
      endScope(result) {
        const tensorsToTrackInParent = getTensorsInContainer(result);
        const tensorsToTrackInParentSet = new Set(tensorsToTrackInParent.map((t) => t.id));
        for (let i = 0; i < this.state.activeScope.track.length; i++) {
          const tensor2 = this.state.activeScope.track[i];
          if (!tensor2.kept && !tensorsToTrackInParentSet.has(tensor2.id)) {
            tensor2.dispose();
          }
        }
        const oldScope = this.state.scopeStack.pop();
        this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1];
        tensorsToTrackInParent.forEach((tensor2) => {
          if (!tensor2.kept && tensor2.scopeId === oldScope.id) {
            this.track(tensor2);
          }
        });
      }
      /**
       * Returns gradients of `f` with respect to each of the `xs`. The gradients
       * returned are of the same length as `xs`, but some might be null if `f`
       * was not a function of that `x`. It also takes optional dy to multiply the
       * gradient, which defaults to `1`.
       */
      gradients(f, xs, dy, allowNoGradients = false) {
        assert(xs.length > 0, () => "gradients() received an empty list of xs.");
        if (dy != null && dy.dtype !== "float32") {
          throw new Error(`dy must have 'float32' dtype, but has '${dy.dtype}'`);
        }
        const y = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", f));
        assert(y instanceof Tensor, () => "The result y returned by f() must be a tensor.");
        const filteredTape = getFilteredNodesXToY(this.state.activeTape, xs, y);
        if (!allowNoGradients && filteredTape.length === 0 && xs.length > 0) {
          throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
        }
        return this.tidy("backward", () => {
          const accumulatedGradientMap = {};
          accumulatedGradientMap[y.id] = dy == null ? ones(y.shape) : dy;
          backpropagateGradients(
            accumulatedGradientMap,
            filteredTape,
            // Pass the tidy function to avoid circular dep with `tape.ts`.
            (f2) => this.tidy(f2),
            // Pass an add function to avoide a circular dep with `tape.ts`.
            add6
          );
          const grads = xs.map((x) => accumulatedGradientMap[x.id]);
          if (this.state.gradientDepth === 0) {
            this.state.activeTape.forEach((node) => {
              for (const tensor2 of node.saved) {
                tensor2.dispose();
              }
            });
            this.state.activeTape = null;
          }
          return { value: y, grads };
        });
      }
      customGrad(f) {
        assert(isFunction(f), () => "The f passed in customGrad(f) must be a function.");
        return (...inputs) => {
          assert(inputs.every((t) => t instanceof Tensor), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
          let res;
          const inputMap = {};
          inputs.forEach((input2, i) => {
            inputMap[i] = input2;
          });
          const forwardFunc = (_, save) => {
            res = f(...[...inputs, save]);
            assert(res.value instanceof Tensor, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor");
            assert(isFunction(res.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.");
            return res.value;
          };
          const backwardsFunc = (dy, saved) => {
            const gradRes = res.gradFunc(dy, saved);
            const grads = Array.isArray(gradRes) ? gradRes : [gradRes];
            assert(grads.length === inputs.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).");
            assert(grads.every((t) => t instanceof Tensor), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
            const gradMap = {};
            grads.forEach((grad, i) => {
              gradMap[i] = () => grad;
            });
            return gradMap;
          };
          return this.runKernelFunc({
            forwardFunc,
            backwardsFunc,
            inputs: inputMap
          });
        };
      }
      readSync(dataId) {
        const info = this.state.tensorInfo.get(dataId);
        return info.backend.readSync(dataId);
      }
      read(dataId) {
        const info = this.state.tensorInfo.get(dataId);
        return info.backend.read(dataId);
      }
      readToGPU(dataId, options) {
        const info = this.state.tensorInfo.get(dataId);
        return info.backend.readToGPU(dataId, options);
      }
      async time(query) {
        const start = now();
        const timingInfo = await this.backend.time(query);
        timingInfo.wallMs = now() - start;
        return timingInfo;
      }
      /**
       * Tracks a Tensor in the current scope to be automatically cleaned up
       * when the current scope ends, and returns the value.
       *
       * @param result The Tensor to track in the current scope.
       */
      track(result) {
        if (this.state.activeScope != null) {
          result.scopeId = this.state.activeScope.id;
          this.state.activeScope.track.push(result);
        }
        return result;
      }
      get registeredVariables() {
        return this.state.registeredVariables;
      }
      /**
       * Resets the engine state. Removes all backends but does not remove
       * registered backend factories.
       */
      reset() {
        this.pendingBackendInitId++;
        this.state.dispose();
        this.ENV.reset();
        this.state = new EngineState();
        for (const backendName in this.registry) {
          this.disposeRegisteredKernels(backendName);
          this.registry[backendName].dispose();
          delete this.registry[backendName];
        }
        this.backendName = null;
        this.backendInstance = null;
        this.pendingBackendInit = null;
      }
    };
    Engine.nextTensorId = 0;
    Engine.nextVariableId = 0;
    ENGINE = getOrMakeEngine();
  }
});
var device_util_exports = {};
__export2(device_util_exports, {
  isBrowser: () => isBrowser,
  isMobile: () => isMobile,
  mockIsMobile: () => mockIsMobile
});
function _isNavigatorDefined() {
  return typeof navigator !== "undefined" && navigator != null;
}
function mockIsMobile(value) {
  isMobileMockValue = value;
}
function isMobile(nav) {
  if (isMobileMockValue !== void 0) {
    return isMobileMockValue;
  }
  if (nav || _isNavigatorDefined()) {
    if (!nav) {
      nav = navigator;
    }
    if (nav.product === "ReactNative") {
      return true;
    }
    const a = nav.userAgent || nav.vendor || // tslint:disable-next-line:no-any
    (typeof window !== "undefined" ? window.opera : "");
    if (!a) {
      const navAny = nav;
      return navAny.userAgentData && navAny.userAgentData.mobile;
    }
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a) || // tslint:disable-next-line:max-line-length
    /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0, 4));
  }
  return false;
}
function isBrowser() {
  return typeof window !== "undefined" && window.document != null || //@ts-ignore
  typeof WorkerGlobalScope !== "undefined";
}
var isMobileMockValue;
var init_device_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/device_util.js"() {
  }
});
var ENV2;
var init_flags = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/flags.js"() {
    init_engine();
    init_device_util();
    init_environment();
    ENV2 = env();
    ENV2.registerFlag("DEBUG", () => false, (debugValue) => {
      if (debugValue) {
        console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
      }
    });
    ENV2.registerFlag("IS_BROWSER", () => isBrowser());
    ENV2.registerFlag("IS_NODE", () => typeof process !== "undefined" && typeof process.versions !== "undefined" && typeof process.versions.node !== "undefined");
    ENV2.registerFlag("IS_CHROME", () => typeof navigator !== "undefined" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
    ENV2.registerFlag("PROD", () => false);
    ENV2.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV2.getBool("DEBUG"));
    ENV2.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
    ENV2.registerFlag("IS_TEST", () => false);
    ENV2.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => true);
    ENV2.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);
    ENV2.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", () => false);
    ENV2.registerFlag("USE_SETTIMEOUTCUSTOM", () => false);
  }
});
function inferShape(val, dtype) {
  let firstElem = val;
  if (isTypedArray(val)) {
    return dtype === "string" ? [] : [val.length];
  }
  const isObject = typeof val === "object";
  if (isObject) {
    if ("texture" in val) {
      const usedChannels = val.channels || "RGBA";
      return [val.height, val.width * usedChannels.length];
    } else if ("buffer" in val && !(val.buffer instanceof ArrayBuffer)) {
      return [val.buffer.size / (dtype == null ? 4 : bytesPerElement(dtype))];
    }
  }
  if (!Array.isArray(val)) {
    return [];
  }
  const shape = [];
  while (Array.isArray(firstElem) || isTypedArray(firstElem) && dtype !== "string") {
    shape.push(firstElem.length);
    firstElem = firstElem[0];
  }
  if (Array.isArray(val) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")) {
    deepAssertShapeConsistency(val, shape, []);
  }
  return shape;
}
function deepAssertShapeConsistency(val, shape, indices) {
  indices = indices || [];
  if (!Array.isArray(val) && !isTypedArray(val)) {
    assert(shape.length === 0, () => `Element arr[${indices.join("][")}] is a primitive, but should be an array/TypedArray of ${shape[0]} elements`);
    return;
  }
  assert(shape.length > 0, () => `Element arr[${indices.join("][")}] should be a primitive, but is an array of ${val.length} elements`);
  assert(val.length === shape[0], () => `Element arr[${indices.join("][")}] should have ${shape[0]} elements, but has ${val.length} elements`);
  const subShape = shape.slice(1);
  for (let i = 0; i < val.length; ++i) {
    deepAssertShapeConsistency(val[i], subShape, indices.concat(i));
  }
}
function assertDtype(expectedDtype, actualDType, argName, functionName) {
  if (expectedDtype === "string_or_numeric") {
    return;
  }
  if (expectedDtype == null) {
    throw new Error(`Expected dtype cannot be null.`);
  }
  if (expectedDtype !== "numeric" && expectedDtype !== actualDType || expectedDtype === "numeric" && actualDType === "string") {
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be ${expectedDtype} tensor, but got ${actualDType} tensor`);
  }
}
function convertToTensor(x, argName, functionName, parseAsDtype = "numeric") {
  if (x instanceof Tensor) {
    assertDtype(parseAsDtype, x.dtype, argName, functionName);
    return x;
  }
  let inferredDtype = inferDtype(x);
  if (inferredDtype !== "string" && ["bool", "int32", "float32"].indexOf(parseAsDtype) >= 0) {
    inferredDtype = parseAsDtype;
  }
  assertDtype(parseAsDtype, inferredDtype, argName, functionName);
  if (x == null || !isTypedArray(x) && !Array.isArray(x) && typeof x !== "number" && typeof x !== "boolean" && typeof x !== "string") {
    const type = x == null ? "null" : x.constructor.name;
    throw new Error(`Argument '${argName}' passed to '${functionName}' must be a Tensor or TensorLike, but got '${type}'`);
  }
  const inferredShape = inferShape(x, inferredDtype);
  if (!isTypedArray(x) && !Array.isArray(x)) {
    x = [x];
  }
  const skipTypedArray = true;
  const values = inferredDtype !== "string" ? toTypedArray(x, inferredDtype) : flatten(x, [], skipTypedArray);
  return ENGINE.makeTensor(values, inferredShape, inferredDtype);
}
function convertToTensorArray(arg, argName, functionName, parseAsDtype = "numeric") {
  if (!Array.isArray(arg)) {
    throw new Error(`Argument ${argName} passed to ${functionName} must be a \`Tensor[]\` or \`TensorLike[]\``);
  }
  const tensors = arg;
  return tensors.map((t, i) => convertToTensor(t, `${argName}[${i}]`, functionName, parseAsDtype));
}
var init_tensor_util_env = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/tensor_util_env.js"() {
    init_engine();
    init_environment();
    init_tensor();
    init_util();
    init_util_base();
  }
});
function op(f) {
  const keys = Object.keys(f);
  if (keys.length !== 1) {
    throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${keys.length} keys.`);
  }
  let opName = keys[0];
  const fn = f[opName];
  if (opName.endsWith("_")) {
    opName = opName.substring(0, opName.length - 1);
  }
  opName = opName + OP_SCOPE_SUFFIX;
  const f2 = (...args) => {
    ENGINE.startScope(opName);
    try {
      const result = fn(...args);
      if (isPromise(result)) {
        console.error("Cannot return a Promise inside of tidy.");
      }
      ENGINE.endScope(result);
      return result;
    } catch (ex) {
      ENGINE.endScope(null);
      throw ex;
    }
  };
  Object.defineProperty(f2, "name", { value: opName, configurable: true });
  return f2;
}
var OP_SCOPE_SUFFIX;
var init_operation = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/operation.js"() {
    init_engine();
    init_util();
    OP_SCOPE_SUFFIX = "__op";
  }
});
function complex_(real4, imag4) {
  const $real = convertToTensor(real4, "real", "complex");
  const $imag = convertToTensor(imag4, "imag", "complex");
  assertShapesMatch($real.shape, $imag.shape, `real and imag shapes, ${$real.shape} and ${$imag.shape}, must match in call to tf.complex().`);
  const inputs = { real: $real, imag: $imag };
  return ENGINE.runKernel(Complex, inputs);
}
var complex;
var init_complex = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/complex.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    complex = /* @__PURE__ */ op({ complex_ });
  }
});
function makeTensor(values, shape, inferredShape, dtype) {
  if (dtype == null) {
    dtype = inferDtype(values);
  } else if (dtype === "complex64") {
    throw new Error(`Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).`);
  }
  if (typeof values === "object" && ("texture" in values || "buffer" in values && !(values.buffer instanceof ArrayBuffer))) {
    if (dtype !== "float32" && dtype !== "int32") {
      throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${dtype}.`);
    }
    return ENGINE.backend.createTensorFromGPUData(values, shape || inferredShape, dtype);
  }
  if (!isTypedArray(values) && !Array.isArray(values) && typeof values !== "number" && typeof values !== "boolean" && typeof values !== "string") {
    throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  }
  if (shape != null) {
    assertNonNegativeIntegerDimensions(shape);
    const providedSize = sizeFromShape(shape);
    const inferredSize = sizeFromShape(inferredShape);
    assert(providedSize === inferredSize, () => `Based on the provided shape, [${shape}], the tensor should have ${providedSize} values but has ${inferredSize}`);
    for (let i = 0; i < inferredShape.length; ++i) {
      const inferred = inferredShape[i];
      const flatDimsDontMatch = i === inferredShape.length - 1 ? inferred !== sizeFromShape(shape.slice(i)) : true;
      assert(inferredShape[i] === shape[i] || !flatDimsDontMatch, () => `Error creating a new Tensor. Inferred shape (${inferredShape}) does not match the provided shape (${shape}). `);
    }
  }
  if (!isTypedArray(values) && !Array.isArray(values)) {
    values = [values];
  }
  shape = shape || inferredShape;
  values = dtype !== "string" ? toTypedArray(values, dtype) : flatten(values, [], true);
  return ENGINE.makeTensor(values, shape, dtype);
}
var init_tensor_ops_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js"() {
    init_engine();
    init_util();
  }
});
function tensor(values, shape, dtype) {
  const inferredShape = inferShape(values, dtype);
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor.js"() {
    init_tensor_util_env();
    init_tensor_ops_util();
  }
});
var DTYPE_VALUE_SIZE_MAP;
var init_types2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/types.js"() {
    DTYPE_VALUE_SIZE_MAP = {
      "float32": 4,
      "float16": 2,
      "int32": 4,
      "uint16": 2,
      "uint8": 1,
      "bool": 1,
      "complex64": 8
    };
  }
});
async function encodeWeights(tensors, group) {
  const specs = [];
  const dataPromises = [];
  const names = Array.isArray(tensors) ? tensors.map((tensor2) => tensor2.name) : Object.keys(tensors);
  for (let i = 0; i < names.length; ++i) {
    const name = names[i];
    const t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];
    if (t.dtype !== "float32" && t.dtype !== "int32" && t.dtype !== "bool" && t.dtype !== "string" && t.dtype !== "complex64") {
      throw new Error(`Unsupported dtype in weight '${name}': ${t.dtype}`);
    }
    const spec = { name, shape: t.shape, dtype: t.dtype };
    if (t.dtype === "string") {
      const utf8bytes = new Promise(async (resolve) => {
        const vals = await t.bytes();
        const totalNumBytes = vals.reduce((p2, c) => p2 + c.length, 0) + NUM_BYTES_STRING_LENGTH * vals.length;
        const bytes = new Uint8Array(totalNumBytes);
        let offset = 0;
        for (let i2 = 0; i2 < vals.length; i2++) {
          const val = vals[i2];
          const bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);
          bytes.set(bytesOfLength, offset);
          offset += NUM_BYTES_STRING_LENGTH;
          bytes.set(val, offset);
          offset += val.length;
        }
        resolve(bytes);
      });
      dataPromises.push(utf8bytes);
    } else {
      dataPromises.push(t.data());
    }
    if (group != null) {
      spec.group = group;
    }
    specs.push(spec);
  }
  const tensorValues = await Promise.all(dataPromises);
  return { data: concatenateTypedArrays(tensorValues), specs };
}
function decodeWeights(buffer2, specs) {
  const out = {};
  let float16Decode;
  let offset = 0;
  for (const spec of specs) {
    const name = spec.name;
    const dtype = spec.dtype;
    const shape = spec.shape;
    const size = sizeFromShape(shape);
    let values;
    if ("quantization" in spec) {
      const quantization = spec.quantization;
      if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
        if (!("min" in quantization && "scale" in quantization)) {
          throw new Error(`Weight ${spec.name} with quantization ${quantization.dtype} doesn't have corresponding metadata min and scale.`);
        }
      } else if (quantization.dtype === "float16") {
        if (dtype !== "float32") {
          throw new Error(`Weight ${spec.name} is quantized with ${quantization.dtype} which only supports weights of type float32 not ${dtype}.`);
        }
      } else {
        throw new Error(`Weight ${spec.name} has unknown quantization dtype ${quantization.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
      }
      const quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];
      const byteBuffer = buffer2.slice(offset, offset + size * quantizationSizeFactor);
      const quantizedArray = quantization.dtype === "uint8" ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);
      if (dtype === "float32") {
        if (quantization.dtype === "uint8" || quantization.dtype === "uint16") {
          values = new Float32Array(quantizedArray.length);
          for (let i = 0; i < quantizedArray.length; i++) {
            const v = quantizedArray[i];
            values[i] = v * quantization.scale + quantization.min;
          }
        } else if (quantization.dtype === "float16") {
          if (float16Decode === void 0) {
            float16Decode = getFloat16Decoder();
          }
          values = float16Decode(quantizedArray);
        } else {
          throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type float32.`);
        }
      } else if (dtype === "int32") {
        if (quantization.dtype !== "uint8" && quantization.dtype !== "uint16") {
          throw new Error(`Unsupported quantization type ${quantization.dtype} for weight type int32.`);
        }
        values = new Int32Array(quantizedArray.length);
        for (let i = 0; i < quantizedArray.length; i++) {
          const v = quantizedArray[i];
          values[i] = Math.round(v * quantization.scale + quantization.min);
        }
      } else {
        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
      }
      offset += size * quantizationSizeFactor;
    } else if (dtype === "string") {
      const size2 = sizeFromShape(spec.shape);
      values = [];
      for (let i = 0; i < size2; i++) {
        const byteLength = new Uint32Array(buffer2.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];
        offset += NUM_BYTES_STRING_LENGTH;
        const bytes = new Uint8Array(buffer2.slice(offset, offset + byteLength));
        values.push(bytes);
        offset += byteLength;
      }
    } else {
      const dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];
      const byteBuffer = buffer2.slice(offset, offset + size * dtypeFactor);
      if (dtype === "float32") {
        values = new Float32Array(byteBuffer);
      } else if (dtype === "int32") {
        values = new Int32Array(byteBuffer);
      } else if (dtype === "bool") {
        values = new Uint8Array(byteBuffer);
      } else if (dtype === "complex64") {
        values = new Float32Array(byteBuffer);
        const real4 = new Float32Array(values.length / 2);
        const image2 = new Float32Array(values.length / 2);
        for (let i = 0; i < real4.length; i++) {
          real4[i] = values[i * 2];
          image2[i] = values[i * 2 + 1];
        }
        const realTensor = tensor(real4, shape, "float32");
        const imageTensor = tensor(image2, shape, "float32");
        out[name] = complex(realTensor, imageTensor);
        realTensor.dispose();
        imageTensor.dispose();
      } else {
        throw new Error(`Unsupported dtype in weight '${name}': ${dtype}`);
      }
      offset += size * dtypeFactor;
    }
    if (dtype !== "complex64") {
      out[name] = tensor(values, shape, dtype);
    }
  }
  return out;
}
function concatenateTypedArrays(xs) {
  if (xs === null) {
    throw new Error(`Invalid input value: ${JSON.stringify(xs)}`);
  }
  let totalByteLength = 0;
  const normalizedXs = [];
  xs.forEach((x) => {
    totalByteLength += x.byteLength;
    normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));
    if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {
      throw new Error(`Unsupported TypedArray subtype: ${x.constructor.name}`);
    }
  });
  const y = new Uint8Array(totalByteLength);
  let offset = 0;
  normalizedXs.forEach((x) => {
    y.set(new Uint8Array(x.buffer), offset);
    offset += x.byteLength;
  });
  return y.buffer;
}
function stringByteLength(str5) {
  if (useNodeBuffer) {
    return Buffer.byteLength(str5);
  }
  return new Blob([str5]).size;
}
function arrayBufferToBase64String(buffer2) {
  if (useNodeBuffer) {
    return Buffer.from(buffer2).toString("base64");
  }
  const buf = new Uint8Array(buffer2);
  let s = "";
  for (let i = 0, l = buf.length; i < l; i++) {
    s += String.fromCharCode(buf[i]);
  }
  return btoa(s);
}
function base64StringToArrayBuffer(str5) {
  if (useNodeBuffer) {
    const buf = Buffer.from(str5, "base64");
    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);
  }
  const s = atob(str5);
  const buffer2 = new Uint8Array(s.length);
  for (let i = 0; i < s.length; ++i) {
    buffer2.set([s.charCodeAt(i)], i);
  }
  return buffer2.buffer;
}
function concatenateArrayBuffers(buffers) {
  if (buffers.length === 1) {
    return buffers[0];
  }
  let totalByteLength = 0;
  buffers.forEach((buffer2) => {
    totalByteLength += buffer2.byteLength;
  });
  const temp = new Uint8Array(totalByteLength);
  let offset = 0;
  buffers.forEach((buffer2) => {
    temp.set(new Uint8Array(buffer2), offset);
    offset += buffer2.byteLength;
  });
  return temp.buffer;
}
function basename(path) {
  const SEPARATOR = "/";
  path = path.trim();
  while (path.endsWith(SEPARATOR)) {
    path = path.slice(0, path.length - 1);
  }
  const items = path.split(SEPARATOR);
  return items[items.length - 1];
}
function getModelJSONForModelArtifacts(artifacts, manifest) {
  const result = {
    modelTopology: artifacts.modelTopology,
    format: artifacts.format,
    generatedBy: artifacts.generatedBy,
    convertedBy: artifacts.convertedBy,
    weightsManifest: manifest
  };
  if (artifacts.signature != null) {
    result.signature = artifacts.signature;
  }
  if (artifacts.userDefinedMetadata != null) {
    result.userDefinedMetadata = artifacts.userDefinedMetadata;
  }
  if (artifacts.modelInitializer != null) {
    result.modelInitializer = artifacts.modelInitializer;
  }
  if (artifacts.initializerSignature != null) {
    result.initializerSignature = artifacts.initializerSignature;
  }
  if (artifacts.trainingConfig != null) {
    result.trainingConfig = artifacts.trainingConfig;
  }
  return result;
}
function getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData) {
  const modelArtifacts = {
    modelTopology: modelJSON.modelTopology,
    format: modelJSON.format,
    generatedBy: modelJSON.generatedBy,
    convertedBy: modelJSON.convertedBy
  };
  if (modelJSON.trainingConfig != null) {
    modelArtifacts.trainingConfig = modelJSON.trainingConfig;
  }
  if (modelJSON.weightsManifest != null) {
    if (!weightSpecs) {
      throw new Error("modelJSON has weightsManifest but weightSpecs is null");
    }
    if (!weightData) {
      throw new Error("modelJSON has weightsManifest but weightData is null");
    }
    modelArtifacts.weightSpecs = weightSpecs;
    modelArtifacts.weightData = weightData;
  }
  if (modelJSON.signature != null) {
    modelArtifacts.signature = modelJSON.signature;
  }
  if (modelJSON.userDefinedMetadata != null) {
    modelArtifacts.userDefinedMetadata = modelJSON.userDefinedMetadata;
  }
  if (modelJSON.modelInitializer != null) {
    modelArtifacts.modelInitializer = modelJSON.modelInitializer;
  }
  if (modelJSON.initializerSignature != null) {
    modelArtifacts.initializerSignature = modelJSON.initializerSignature;
  }
  return modelArtifacts;
}
async function getModelArtifactsForJSON(modelJSON, loadWeights2) {
  let weightSpecs;
  let weightData;
  if (modelJSON.weightsManifest != null) {
    [weightSpecs, weightData] = await loadWeights2(modelJSON.weightsManifest);
  }
  return getModelArtifactsForJSONSync(modelJSON, weightSpecs, weightData);
}
function getModelArtifactsInfoForJSON(modelArtifacts) {
  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
    throw new Error("Expected JSON model topology, received ArrayBuffer.");
  }
  return {
    dateSaved: /* @__PURE__ */ new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),
    weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),
    weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength
  };
}
function getWeightSpecs(weightsManifest) {
  const weightSpecs = [];
  for (const entry of weightsManifest) {
    weightSpecs.push(...entry.weights);
  }
  return weightSpecs;
}
function computeFloat16MantisaTable() {
  const convertMantissa = (i) => {
    let m = i << 13;
    let e = 0;
    while ((m & 8388608) === 0) {
      e -= 8388608;
      m <<= 1;
    }
    m &= ~8388608;
    e += 947912704;
    return m | e;
  };
  const mantisaTable = new Uint32Array(2048);
  mantisaTable[0] = 0;
  for (let i = 1; i < 1024; i++) {
    mantisaTable[i] = convertMantissa(i);
  }
  for (let i = 1024; i < 2048; i++) {
    mantisaTable[i] = 939524096 + (i - 1024 << 13);
  }
  return mantisaTable;
}
function computeFloat16ExponentTable() {
  const exponentTable = new Uint32Array(64);
  exponentTable[0] = 0;
  exponentTable[31] = 1199570944;
  exponentTable[32] = 2147483648;
  exponentTable[63] = 3347054592;
  for (let i = 1; i < 31; i++) {
    exponentTable[i] = i << 23;
  }
  for (let i = 33; i < 63; i++) {
    exponentTable[i] = 2147483648 + (i - 32 << 23);
  }
  return exponentTable;
}
function computeFloat16OffsetTable() {
  const offsetTable = new Uint32Array(64);
  for (let i = 0; i < 64; i++) {
    offsetTable[i] = 1024;
  }
  offsetTable[0] = offsetTable[32] = 0;
  return offsetTable;
}
function getFloat16Decoder() {
  const mantisaTable = computeFloat16MantisaTable();
  const exponentTable = computeFloat16ExponentTable();
  const offsetTable = computeFloat16OffsetTable();
  return (quantizedArray) => {
    const buffer2 = new ArrayBuffer(4 * quantizedArray.length);
    const bufferUint32View = new Uint32Array(buffer2);
    for (let index = 0; index < quantizedArray.length; index++) {
      const float16Bits = quantizedArray[index];
      const float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 1023)] + exponentTable[float16Bits >> 10];
      bufferUint32View[index] = float32Bits;
    }
    return new Float32Array(buffer2);
  };
}
var NUM_BYTES_STRING_LENGTH;
var useNodeBuffer;
var init_io_utils = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/io_utils.js"() {
    init_complex();
    init_tensor2();
    init_util();
    init_types2();
    NUM_BYTES_STRING_LENGTH = 4;
    useNodeBuffer = typeof Buffer !== "undefined" && (typeof Blob === "undefined" || typeof atob === "undefined" || typeof btoa === "undefined");
  }
});
var IORouterRegistry;
var registerSaveRouter;
var registerLoadRouter;
var getSaveHandlers;
var getLoadHandlers;
var init_router_registry = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/router_registry.js"() {
    IORouterRegistry = class {
      constructor() {
        this.saveRouters = [];
        this.loadRouters = [];
      }
      static getInstance() {
        if (IORouterRegistry.instance == null) {
          IORouterRegistry.instance = new IORouterRegistry();
        }
        return IORouterRegistry.instance;
      }
      /**
       * Register a save-handler router.
       *
       * @param saveRouter A function that maps a URL-like string onto an instance
       * of `IOHandler` with the `save` method defined or `null`.
       */
      static registerSaveRouter(saveRouter) {
        IORouterRegistry.getInstance().saveRouters.push(saveRouter);
      }
      /**
       * Register a load-handler router.
       *
       * @param loadRouter A function that maps a URL-like string onto an instance
       * of `IOHandler` with the `load` method defined or `null`.
       */
      static registerLoadRouter(loadRouter) {
        IORouterRegistry.getInstance().loadRouters.push(loadRouter);
      }
      /**
       * Look up IOHandler for saving, given a URL-like string.
       *
       * @param url
       * @returns If only one match is found, an instance of IOHandler with the
       * `save` method defined. If no match is found, `null`.
       * @throws Error, if more than one match is found.
       */
      static getSaveHandlers(url) {
        return IORouterRegistry.getHandlers(url, "save");
      }
      /**
       * Look up IOHandler for loading, given a URL-like string.
       *
       * @param url
       * @param loadOptions Optional, custom load options.
       * @returns All valid handlers for `url`, given the currently registered
       *   handler routers.
       */
      static getLoadHandlers(url, loadOptions) {
        return IORouterRegistry.getHandlers(url, "load", loadOptions);
      }
      static getHandlers(url, handlerType, loadOptions) {
        const validHandlers = [];
        const routers = handlerType === "load" ? IORouterRegistry.getInstance().loadRouters : IORouterRegistry.getInstance().saveRouters;
        routers.forEach((router) => {
          const handler = router(url, loadOptions);
          if (handler !== null) {
            validHandlers.push(handler);
          }
        });
        return validHandlers;
      }
    };
    registerSaveRouter = (loudRouter) => IORouterRegistry.registerSaveRouter(loudRouter);
    registerLoadRouter = (loudRouter) => IORouterRegistry.registerLoadRouter(loudRouter);
    getSaveHandlers = (url) => IORouterRegistry.getSaveHandlers(url);
    getLoadHandlers = (url, loadOptions) => IORouterRegistry.getLoadHandlers(url, loadOptions);
  }
});
function getIndexedDBFactory() {
  if (!env().getBool("IS_BROWSER")) {
    throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  }
  const theWindow = typeof window === "undefined" ? self : window;
  const factory = theWindow.indexedDB || theWindow.mozIndexedDB || theWindow.webkitIndexedDB || theWindow.msIndexedDB || theWindow.shimIndexedDB;
  if (factory == null) {
    throw new Error("The current browser does not appear to support IndexedDB.");
  }
  return factory;
}
function setUpDatabase(openRequest) {
  const db = openRequest.result;
  db.createObjectStore(MODEL_STORE_NAME, { keyPath: "modelPath" });
  db.createObjectStore(INFO_STORE_NAME, { keyPath: "modelPath" });
}
function browserIndexedDB(modelPath) {
  return new BrowserIndexedDB(modelPath);
}
function maybeStripScheme(key) {
  return key.startsWith(BrowserIndexedDB.URL_SCHEME) ? key.slice(BrowserIndexedDB.URL_SCHEME.length) : key;
}
var DATABASE_NAME;
var DATABASE_VERSION;
var MODEL_STORE_NAME;
var INFO_STORE_NAME;
var BrowserIndexedDB;
var indexedDBRouter;
var BrowserIndexedDBManager;
var init_indexed_db = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/indexed_db.js"() {
    init_flags();
    init_environment();
    init_io_utils();
    init_router_registry();
    DATABASE_NAME = "tensorflowjs";
    DATABASE_VERSION = 1;
    MODEL_STORE_NAME = "models_store";
    INFO_STORE_NAME = "model_info_store";
    BrowserIndexedDB = class {
      constructor(modelPath) {
        this.indexedDB = getIndexedDBFactory();
        if (modelPath == null || !modelPath) {
          throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
        }
        this.modelPath = modelPath;
      }
      async save(modelArtifacts) {
        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
          throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
        }
        return this.databaseAction(this.modelPath, modelArtifacts);
      }
      async load() {
        return this.databaseAction(this.modelPath);
      }
      /**
       * Perform database action to put model artifacts into or read model artifacts
       * from IndexedDB object store.
       *
       * Whether the action is put or get depends on whether `modelArtifacts` is
       * specified. If it is specified, the action will be put; otherwise the action
       * will be get.
       *
       * @param modelPath A unique string path for the model.
       * @param modelArtifacts If specified, it will be the model artifacts to be
       *   stored in IndexedDB.
       * @returns A `Promise` of `SaveResult`, if the action is put, or a `Promise`
       *   of `ModelArtifacts`, if the action is get.
       */
      databaseAction(modelPath, modelArtifacts) {
        return new Promise((resolve, reject) => {
          const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
          openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
          openRequest.onsuccess = () => {
            const db = openRequest.result;
            if (modelArtifacts == null) {
              const modelTx = db.transaction(MODEL_STORE_NAME, "readonly");
              const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
              const getRequest = modelStore.get(this.modelPath);
              getRequest.onsuccess = () => {
                if (getRequest.result == null) {
                  db.close();
                  return reject(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
                } else {
                  resolve(getRequest.result.modelArtifacts);
                }
              };
              getRequest.onerror = (error) => {
                db.close();
                return reject(getRequest.error);
              };
              modelTx.oncomplete = () => db.close();
            } else {
              const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
              const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
              let infoStore = infoTx.objectStore(INFO_STORE_NAME);
              const putInfoRequest = infoStore.put({ modelPath: this.modelPath, modelArtifactsInfo });
              let modelTx;
              putInfoRequest.onsuccess = () => {
                modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                const putModelRequest = modelStore.put({
                  modelPath: this.modelPath,
                  modelArtifacts,
                  modelArtifactsInfo
                });
                putModelRequest.onsuccess = () => resolve({ modelArtifactsInfo });
                putModelRequest.onerror = (error) => {
                  infoStore = infoTx.objectStore(INFO_STORE_NAME);
                  const deleteInfoRequest = infoStore.delete(this.modelPath);
                  deleteInfoRequest.onsuccess = () => {
                    db.close();
                    return reject(putModelRequest.error);
                  };
                  deleteInfoRequest.onerror = (error2) => {
                    db.close();
                    return reject(putModelRequest.error);
                  };
                };
              };
              putInfoRequest.onerror = (error) => {
                db.close();
                return reject(putInfoRequest.error);
              };
              infoTx.oncomplete = () => {
                if (modelTx == null) {
                  db.close();
                } else {
                  modelTx.oncomplete = () => db.close();
                }
              };
            }
          };
          openRequest.onerror = (error) => reject(openRequest.error);
        });
      }
    };
    BrowserIndexedDB.URL_SCHEME = "indexeddb://";
    indexedDBRouter = (url) => {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserIndexedDB.URL_SCHEME)) {
          return browserIndexedDB(url.slice(BrowserIndexedDB.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(indexedDBRouter);
    IORouterRegistry.registerLoadRouter(indexedDBRouter);
    BrowserIndexedDBManager = class {
      constructor() {
        this.indexedDB = getIndexedDBFactory();
      }
      async listModels() {
        return new Promise((resolve, reject) => {
          const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
          openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
          openRequest.onsuccess = () => {
            const db = openRequest.result;
            const tx = db.transaction(INFO_STORE_NAME, "readonly");
            const store = tx.objectStore(INFO_STORE_NAME);
            const getAllInfoRequest = store.getAll();
            getAllInfoRequest.onsuccess = () => {
              const out = {};
              for (const item of getAllInfoRequest.result) {
                out[item.modelPath] = item.modelArtifactsInfo;
              }
              resolve(out);
            };
            getAllInfoRequest.onerror = (error) => {
              db.close();
              return reject(getAllInfoRequest.error);
            };
            tx.oncomplete = () => db.close();
          };
          openRequest.onerror = (error) => reject(openRequest.error);
        });
      }
      async removeModel(path) {
        path = maybeStripScheme(path);
        return new Promise((resolve, reject) => {
          const openRequest = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
          openRequest.onupgradeneeded = () => setUpDatabase(openRequest);
          openRequest.onsuccess = () => {
            const db = openRequest.result;
            const infoTx = db.transaction(INFO_STORE_NAME, "readwrite");
            const infoStore = infoTx.objectStore(INFO_STORE_NAME);
            const getInfoRequest = infoStore.get(path);
            let modelTx;
            getInfoRequest.onsuccess = () => {
              if (getInfoRequest.result == null) {
                db.close();
                return reject(new Error(`Cannot find model with path '${path}' in IndexedDB.`));
              } else {
                const deleteInfoRequest = infoStore.delete(path);
                const deleteModelData = () => {
                  modelTx = db.transaction(MODEL_STORE_NAME, "readwrite");
                  const modelStore = modelTx.objectStore(MODEL_STORE_NAME);
                  const deleteModelRequest = modelStore.delete(path);
                  deleteModelRequest.onsuccess = () => resolve(getInfoRequest.result.modelArtifactsInfo);
                  deleteModelRequest.onerror = (error) => reject(getInfoRequest.error);
                };
                deleteInfoRequest.onsuccess = deleteModelData;
                deleteInfoRequest.onerror = (error) => {
                  deleteModelData();
                  db.close();
                  return reject(getInfoRequest.error);
                };
              }
            };
            getInfoRequest.onerror = (error) => {
              db.close();
              return reject(getInfoRequest.error);
            };
            infoTx.oncomplete = () => {
              if (modelTx == null) {
                db.close();
              } else {
                modelTx.oncomplete = () => db.close();
              }
            };
          };
          openRequest.onerror = (error) => reject(openRequest.error);
        });
      }
    };
  }
});
function getModelKeys(path) {
  return {
    info: [PATH_PREFIX, path, INFO_SUFFIX].join(PATH_SEPARATOR),
    topology: [PATH_PREFIX, path, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
    weightSpecs: [PATH_PREFIX, path, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
    weightData: [PATH_PREFIX, path, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
    modelMetadata: [PATH_PREFIX, path, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
  };
}
function removeItems(keys) {
  for (const key of Object.values(keys)) {
    window.localStorage.removeItem(key);
  }
}
function getModelPathFromKey(key) {
  const items = key.split(PATH_SEPARATOR);
  if (items.length < 3) {
    throw new Error(`Invalid key format: ${key}`);
  }
  return items.slice(1, items.length - 1).join(PATH_SEPARATOR);
}
function maybeStripScheme2(key) {
  return key.startsWith(BrowserLocalStorage.URL_SCHEME) ? key.slice(BrowserLocalStorage.URL_SCHEME.length) : key;
}
function browserLocalStorage(modelPath) {
  return new BrowserLocalStorage(modelPath);
}
var PATH_SEPARATOR;
var PATH_PREFIX;
var INFO_SUFFIX;
var MODEL_TOPOLOGY_SUFFIX;
var WEIGHT_SPECS_SUFFIX;
var WEIGHT_DATA_SUFFIX;
var MODEL_METADATA_SUFFIX;
var BrowserLocalStorage;
var localStorageRouter;
var BrowserLocalStorageManager;
var init_local_storage = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/local_storage.js"() {
    init_flags();
    init_environment();
    init_util();
    init_io_utils();
    init_router_registry();
    PATH_SEPARATOR = "/";
    PATH_PREFIX = "tensorflowjs_models";
    INFO_SUFFIX = "info";
    MODEL_TOPOLOGY_SUFFIX = "model_topology";
    WEIGHT_SPECS_SUFFIX = "weight_specs";
    WEIGHT_DATA_SUFFIX = "weight_data";
    MODEL_METADATA_SUFFIX = "model_metadata";
    BrowserLocalStorage = class {
      constructor(modelPath) {
        if (!env().getBool("IS_BROWSER") || typeof window === "undefined" || typeof window.localStorage === "undefined") {
          throw new Error("The current environment does not support local storage.");
        }
        this.LS = window.localStorage;
        if (modelPath == null || !modelPath) {
          throw new Error("For local storage, modelPath must not be null, undefined or empty.");
        }
        this.modelPath = modelPath;
        this.keys = getModelKeys(this.modelPath);
      }
      /**
       * Save model artifacts to browser local storage.
       *
       * See the documentation to `browserLocalStorage` for details on the saved
       * artifacts.
       *
       * @param modelArtifacts The model artifacts to be stored.
       * @returns An instance of SaveResult.
       */
      async save(modelArtifacts) {
        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
          throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
        } else {
          const topology = JSON.stringify(modelArtifacts.modelTopology);
          const weightSpecs = JSON.stringify(modelArtifacts.weightSpecs);
          const modelArtifactsInfo = getModelArtifactsInfoForJSON(modelArtifacts);
          try {
            this.LS.setItem(this.keys.info, JSON.stringify(modelArtifactsInfo));
            this.LS.setItem(this.keys.topology, topology);
            this.LS.setItem(this.keys.weightSpecs, weightSpecs);
            this.LS.setItem(this.keys.weightData, arrayBufferToBase64String(modelArtifacts.weightData));
            const metadata = {
              format: modelArtifacts.format,
              generatedBy: modelArtifacts.generatedBy,
              convertedBy: modelArtifacts.convertedBy,
              signature: modelArtifacts.signature != null ? modelArtifacts.signature : void 0,
              userDefinedMetadata: modelArtifacts.userDefinedMetadata != null ? modelArtifacts.userDefinedMetadata : void 0,
              modelInitializer: modelArtifacts.modelInitializer != null ? modelArtifacts.modelInitializer : void 0,
              initializerSignature: modelArtifacts.initializerSignature != null ? modelArtifacts.initializerSignature : void 0,
              trainingConfig: modelArtifacts.trainingConfig != null ? modelArtifacts.trainingConfig : void 0
            };
            this.LS.setItem(this.keys.modelMetadata, JSON.stringify(metadata));
            return { modelArtifactsInfo };
          } catch (err) {
            removeItems(this.keys);
            throw new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${modelArtifactsInfo.modelTopologyBytes}, weightSpecsBytes=${modelArtifactsInfo.weightSpecsBytes}, weightDataBytes=${modelArtifactsInfo.weightDataBytes}.`);
          }
        }
      }
      /**
       * Load a model from local storage.
       *
       * See the documentation to `browserLocalStorage` for details on the saved
       * artifacts.
       *
       * @returns The loaded model (if loading succeeds).
       */
      async load() {
        const info = JSON.parse(this.LS.getItem(this.keys.info));
        if (info == null) {
          throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
        }
        if (info.modelTopologyType !== "JSON") {
          throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
        }
        const out = {};
        const topology = JSON.parse(this.LS.getItem(this.keys.topology));
        if (topology == null) {
          throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
        }
        out.modelTopology = topology;
        const weightSpecs = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
        if (weightSpecs == null) {
          throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
        }
        out.weightSpecs = weightSpecs;
        const metadataString = this.LS.getItem(this.keys.modelMetadata);
        if (metadataString != null) {
          const metadata = JSON.parse(metadataString);
          out.format = metadata.format;
          out.generatedBy = metadata.generatedBy;
          out.convertedBy = metadata.convertedBy;
          if (metadata.signature != null) {
            out.signature = metadata.signature;
          }
          if (metadata.userDefinedMetadata != null) {
            out.userDefinedMetadata = metadata.userDefinedMetadata;
          }
          if (metadata.modelInitializer != null) {
            out.modelInitializer = metadata.modelInitializer;
          }
          if (metadata.initializerSignature != null) {
            out.initializerSignature = metadata.initializerSignature;
          }
          if (metadata.trainingConfig != null) {
            out.trainingConfig = metadata.trainingConfig;
          }
        }
        const weightDataBase64 = this.LS.getItem(this.keys.weightData);
        if (weightDataBase64 == null) {
          throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
        }
        out.weightData = base64StringToArrayBuffer(weightDataBase64);
        return out;
      }
    };
    BrowserLocalStorage.URL_SCHEME = "localstorage://";
    localStorageRouter = (url) => {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserLocalStorage.URL_SCHEME)) {
          return browserLocalStorage(url.slice(BrowserLocalStorage.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(localStorageRouter);
    IORouterRegistry.registerLoadRouter(localStorageRouter);
    BrowserLocalStorageManager = class {
      constructor() {
        assert(env().getBool("IS_BROWSER"), () => "Current environment is not a web browser");
        assert(typeof window === "undefined" || typeof window.localStorage !== "undefined", () => "Current browser does not appear to support localStorage");
        this.LS = window.localStorage;
      }
      async listModels() {
        const out = {};
        const prefix = PATH_PREFIX + PATH_SEPARATOR;
        const suffix = PATH_SEPARATOR + INFO_SUFFIX;
        for (let i = 0; i < this.LS.length; ++i) {
          const key = this.LS.key(i);
          if (key.startsWith(prefix) && key.endsWith(suffix)) {
            const modelPath = getModelPathFromKey(key);
            out[modelPath] = JSON.parse(this.LS.getItem(key));
          }
        }
        return out;
      }
      async removeModel(path) {
        path = maybeStripScheme2(path);
        const keys = getModelKeys(path);
        if (this.LS.getItem(keys.info) == null) {
          throw new Error(`Cannot find model at path '${path}'`);
        }
        const info = JSON.parse(this.LS.getItem(keys.info));
        removeItems(keys);
        return info;
      }
    };
  }
});
function parseURL(url) {
  if (url.indexOf(URL_SCHEME_SUFFIX) === -1) {
    throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry.getSchemes().join(",")}`);
  }
  return {
    scheme: url.split(URL_SCHEME_SUFFIX)[0],
    path: url.split(URL_SCHEME_SUFFIX)[1]
  };
}
async function cloneModelInternal(sourceURL, destURL, deleteSource = false) {
  assert(sourceURL !== destURL, () => `Old path and new path are the same: '${sourceURL}'`);
  const loadHandlers = IORouterRegistry.getLoadHandlers(sourceURL);
  assert(loadHandlers.length > 0, () => `Copying failed because no load handler is found for source URL ${sourceURL}.`);
  assert(loadHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) load handlers for source URL ${sourceURL}.`);
  const loadHandler = loadHandlers[0];
  const saveHandlers = IORouterRegistry.getSaveHandlers(destURL);
  assert(saveHandlers.length > 0, () => `Copying failed because no save handler is found for destination URL ${destURL}.`);
  assert(saveHandlers.length < 2, () => `Copying failed because more than one (${loadHandlers.length}) save handlers for destination URL ${destURL}.`);
  const saveHandler = saveHandlers[0];
  const sourceScheme = parseURL(sourceURL).scheme;
  const sourcePath = parseURL(sourceURL).path;
  const sameMedium = sourceScheme === parseURL(sourceURL).scheme;
  const modelArtifacts = await loadHandler.load();
  if (deleteSource && sameMedium) {
    await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
  }
  const saveResult = await saveHandler.save(modelArtifacts);
  if (deleteSource && !sameMedium) {
    await ModelStoreManagerRegistry.getManager(sourceScheme).removeModel(sourcePath);
  }
  return saveResult.modelArtifactsInfo;
}
async function listModels() {
  const schemes = ModelStoreManagerRegistry.getSchemes();
  const out = {};
  for (const scheme of schemes) {
    const schemeOut = await ModelStoreManagerRegistry.getManager(scheme).listModels();
    for (const path in schemeOut) {
      const url = scheme + URL_SCHEME_SUFFIX + path;
      out[url] = schemeOut[path];
    }
  }
  return out;
}
async function removeModel(url) {
  const schemeAndPath = parseURL(url);
  const manager = ModelStoreManagerRegistry.getManager(schemeAndPath.scheme);
  return manager.removeModel(schemeAndPath.path);
}
async function copyModel(sourceURL, destURL) {
  const deleteSource = false;
  return cloneModelInternal(sourceURL, destURL, deleteSource);
}
async function moveModel(sourceURL, destURL) {
  const deleteSource = true;
  return cloneModelInternal(sourceURL, destURL, deleteSource);
}
var URL_SCHEME_SUFFIX;
var ModelStoreManagerRegistry;
var init_model_management = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/model_management.js"() {
    init_util();
    init_router_registry();
    URL_SCHEME_SUFFIX = "://";
    ModelStoreManagerRegistry = class {
      constructor() {
        this.managers = {};
      }
      static getInstance() {
        if (ModelStoreManagerRegistry.instance == null) {
          ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry();
        }
        return ModelStoreManagerRegistry.instance;
      }
      /**
       * Register a save-handler router.
       *
       * @param saveRouter A function that maps a URL-like string onto an instance
       * of `IOHandler` with the `save` method defined or `null`.
       */
      static registerManager(scheme, manager) {
        assert(scheme != null, () => "scheme must not be undefined or null.");
        if (scheme.endsWith(URL_SCHEME_SUFFIX)) {
          scheme = scheme.slice(0, scheme.indexOf(URL_SCHEME_SUFFIX));
        }
        assert(scheme.length > 0, () => "scheme must not be an empty string.");
        const registry = ModelStoreManagerRegistry.getInstance();
        assert(registry.managers[scheme] == null, () => `A model store manager is already registered for scheme '${scheme}'.`);
        registry.managers[scheme] = manager;
      }
      static getManager(scheme) {
        const manager = ModelStoreManagerRegistry.getInstance().managers[scheme];
        if (manager == null) {
          throw new Error(`Cannot find model manager for scheme '${scheme}'`);
        }
        return manager;
      }
      static getSchemes() {
        return Object.keys(ModelStoreManagerRegistry.getInstance().managers);
      }
    };
  }
});
var PlatformBrowser;
var init_platform_browser = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/platforms/platform_browser.js"() {
    init_flags();
    init_environment();
    init_indexed_db();
    init_local_storage();
    init_model_management();
    PlatformBrowser = class {
      constructor() {
        this.messageName = "setTimeoutCustom";
        this.functionRefs = [];
        this.handledMessageCount = 0;
        this.hasEventListener = false;
      }
      fetch(path, init) {
        return fetch(path, init);
      }
      now() {
        return performance.now();
      }
      encode(text, encoding) {
        if (encoding !== "utf-8" && encoding !== "utf8") {
          throw new Error(`Browser's encoder only supports utf-8, but got ${encoding}`);
        }
        if (this.textEncoder == null) {
          this.textEncoder = new TextEncoder();
        }
        return this.textEncoder.encode(text);
      }
      decode(bytes, encoding) {
        return new TextDecoder(encoding).decode(bytes);
      }
      // If the setTimeout nesting level is greater than 5 and timeout is less
      // than 4ms, timeout will be clamped to 4ms, which hurts the perf.
      // Interleaving window.postMessage and setTimeout will trick the browser and
      // avoid the clamp.
      setTimeoutCustom(functionRef, delay) {
        if (typeof window === "undefined" || !env().getBool("USE_SETTIMEOUTCUSTOM")) {
          setTimeout(functionRef, delay);
          return;
        }
        this.functionRefs.push(functionRef);
        setTimeout(() => {
          window.postMessage({ name: this.messageName, index: this.functionRefs.length - 1 }, "*");
        }, delay);
        if (!this.hasEventListener) {
          this.hasEventListener = true;
          window.addEventListener("message", (event) => {
            if (event.source === window && event.data.name === this.messageName) {
              event.stopPropagation();
              const functionRef2 = this.functionRefs[event.data.index];
              functionRef2();
              this.handledMessageCount++;
              if (this.handledMessageCount === this.functionRefs.length) {
                this.functionRefs = [];
                this.handledMessageCount = 0;
              }
            }
          }, true);
        }
      }
      isTypedArray(a) {
        return a instanceof Float32Array || a instanceof Int32Array || a instanceof Uint8Array || a instanceof Uint8ClampedArray;
      }
    };
    if (env().get("IS_BROWSER")) {
      env().setPlatform("browser", new PlatformBrowser());
      try {
        ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
      } catch (err) {
      }
      try {
        ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
      } catch (err) {
      }
    }
  }
});
var require_browser = __commonJS({
  "(disabled):node_modules/node-fetch/browser.js"() {
  }
});
var require_util = __commonJS({
  "(disabled):util"() {
  }
});
var getNodeFetch;
var systemFetch;
var PlatformNode;
var init_platform_node = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js"() {
    init_environment();
    getNodeFetch = {
      // tslint:disable-next-line:no-require-imports
      importFetch: () => require_browser()
    };
    PlatformNode = class {
      constructor() {
        this.util = require_util();
        this.textEncoder = new this.util.TextEncoder();
      }
      fetch(path, requestInits) {
        if (env().global.fetch != null) {
          return env().global.fetch(path, requestInits);
        }
        if (systemFetch == null) {
          systemFetch = getNodeFetch.importFetch();
        }
        return systemFetch(path, requestInits);
      }
      now() {
        const time = process.hrtime();
        return time[0] * 1e3 + time[1] / 1e6;
      }
      encode(text, encoding) {
        if (encoding !== "utf-8" && encoding !== "utf8") {
          throw new Error(`Node built-in encoder only supports utf-8, but got ${encoding}`);
        }
        return this.textEncoder.encode(text);
      }
      decode(bytes, encoding) {
        if (bytes.length === 0) {
          return "";
        }
        return new this.util.TextDecoder(encoding).decode(bytes);
      }
      isTypedArray(a) {
        return this.util.types.isFloat32Array(a) || this.util.types.isInt32Array(a) || this.util.types.isUint8Array(a) || this.util.types.isUint8ClampedArray(a);
      }
    };
    if (env().get("IS_NODE") && !env().get("IS_BROWSER")) {
      env().setPlatform("node", new PlatformNode());
    }
  }
});
function buffer(shape, dtype = "float32", values) {
  dtype = dtype || "float32";
  assertNonNegativeIntegerDimensions(shape);
  return new TensorBuffer(shape, dtype, values);
}
var init_buffer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/buffer.js"() {
    init_tensor();
    init_util();
  }
});
function cast_(x, dtype) {
  const $x = convertToTensor(x, "x", "cast");
  if (!isValidDtype(dtype)) {
    throw new Error(`Failed to cast to unknown dtype ${dtype}`);
  }
  if (dtype === "string" && $x.dtype !== "string" || dtype !== "string" && $x.dtype === "string") {
    throw new Error("Only strings can be casted to strings");
  }
  const inputs = { x: $x };
  const attrs = { dtype };
  return ENGINE.runKernel(Cast, inputs, attrs);
}
var cast;
var init_cast = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cast.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    cast = /* @__PURE__ */ op({ cast_ });
  }
});
function clone_(x) {
  const $x = convertToTensor(x, "x", "clone", "string_or_numeric");
  const inputs = { x: $x };
  return ENGINE.runKernel(Identity, inputs);
}
var clone6;
var init_clone = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/clone.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    clone6 = /* @__PURE__ */ op({ clone_ });
  }
});
function print(x, verbose = false) {
  console.log(x.toString(verbose));
}
var init_print = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/print.js"() {
  }
});
var opHandler2;
var init_base_side_effects = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/base_side_effects.js"() {
    init_engine();
    init_flags();
    init_platform_browser();
    init_platform_node();
    init_buffer();
    init_cast();
    init_clone();
    init_print();
    init_tensor();
    getOrMakeEngine();
    opHandler2 = {
      buffer,
      cast,
      clone: clone6,
      print
    };
    setOpHandler(opHandler2);
  }
});
function deprecationWarn(msg) {
  if (env().getBool("DEPRECATION_WARNINGS_ENABLED")) {
    console.warn(msg + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
  }
}
function engine() {
  return ENGINE;
}
function memory() {
  return ENGINE.memory();
}
function tidy(nameOrFn, fn) {
  return ENGINE.tidy(nameOrFn, fn);
}
function dispose(container) {
  const tensors = getTensorsInContainer(container);
  tensors.forEach((tensor2) => tensor2.dispose());
}
function keep(result) {
  return ENGINE.keep(result);
}
function registerBackend(name, factory, priority = 1) {
  return ENGINE.registerBackend(name, factory, priority);
}
function backend() {
  return ENGINE.backend;
}
var init_globals = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/globals.js"() {
    init_engine();
    init_environment();
    init_tensor();
    init_tensor_util();
    setDeprecationWarningFn(deprecationWarn);
  }
});
function add_(a, b) {
  let $a = convertToTensor(a, "a", "add");
  let $b = convertToTensor(b, "b", "add");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Add, inputs);
}
var add22;
var init_add = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/add.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    add22 = /* @__PURE__ */ op({ add_ });
  }
});
function floorDiv_(a, b) {
  let $a = convertToTensor(a, "a", "floorDiv");
  let $b = convertToTensor(b, "b", "floorDiv");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(FloorDiv, inputs);
}
var floorDiv;
var init_floorDiv = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/floorDiv.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    floorDiv = /* @__PURE__ */ op({ floorDiv_ });
  }
});
function div_(a, b) {
  let $a = convertToTensor(a, "a", "div");
  let $b = convertToTensor(b, "b", "div");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "int32" && $b.dtype === "int32") {
    return floorDiv($a, $b);
  }
  const inputs = { a: $a, b: $b };
  const attrs = {};
  return ENGINE.runKernel(RealDiv, inputs, attrs);
}
var div2;
var init_div = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/div.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_floorDiv();
    init_operation();
    div2 = /* @__PURE__ */ op({ div_ });
  }
});
function mul_(a, b) {
  let $a = convertToTensor(a, "a", "mul");
  let $b = convertToTensor(b, "b", "mul");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Multiply, inputs);
}
var mul5;
var init_mul = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mul.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    mul5 = /* @__PURE__ */ op({ mul_ });
  }
});
function abs_(x) {
  const $x = convertToTensor(x, "x", "abs");
  if ($x.dtype === "complex64") {
    const inputs = { x: $x };
    return ENGINE.runKernel(ComplexAbs, inputs);
  } else {
    const inputs = { x: $x };
    return ENGINE.runKernel(Abs, inputs);
  }
}
var abs;
var init_abs = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/abs.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    abs = /* @__PURE__ */ op({ abs_ });
  }
});
function acos_(x) {
  const $x = convertToTensor(x, "x", "acos");
  const inputs = { x: $x };
  return ENGINE.runKernel(Acos, inputs);
}
var acos;
var init_acos = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/acos.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    acos = /* @__PURE__ */ op({ acos_ });
  }
});
function acosh_(x) {
  const $x = convertToTensor(x, "x", "acosh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Acosh, inputs);
}
var acosh;
var init_acosh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/acosh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    acosh = /* @__PURE__ */ op({ acosh_ });
  }
});
function all_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "all", "bool");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(All, inputs, attrs);
}
var all;
var init_all = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/all.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    all = /* @__PURE__ */ op({ all_ });
  }
});
function any_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "any", "bool");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Any, inputs, attrs);
}
var any;
var init_any = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/any.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    any = /* @__PURE__ */ op({ any_ });
  }
});
function argMax_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "argMax");
  const inputs = { x: $x };
  const attrs = { axis };
  return ENGINE.runKernel(ArgMax, inputs, attrs);
}
var argMax;
var init_arg_max = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/arg_max.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    argMax = /* @__PURE__ */ op({ argMax_ });
  }
});
function argMin_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "argMin");
  const inputs = { x: $x };
  const attrs = { axis };
  return ENGINE.runKernel(ArgMin, inputs, attrs);
}
var argMin;
var init_arg_min = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/arg_min.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    argMin = /* @__PURE__ */ op({ argMin_ });
  }
});
function asin_(x) {
  const $x = convertToTensor(x, "x", "asin");
  const inputs = { x: $x };
  return ENGINE.runKernel(Asin, inputs);
}
var asin;
var init_asin = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/asin.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    asin = /* @__PURE__ */ op({ asin_ });
  }
});
function asinh_(x) {
  const $x = convertToTensor(x, "x", "asinh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Asinh, inputs);
}
var asinh;
var init_asinh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/asinh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    asinh = /* @__PURE__ */ op({ asinh_ });
  }
});
function atan_(x) {
  const $x = convertToTensor(x, "x", "atan");
  const inputs = { x: $x };
  return ENGINE.runKernel(Atan, inputs);
}
var atan;
var init_atan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/atan.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    atan = /* @__PURE__ */ op({ atan_ });
  }
});
function atan2_(a, b) {
  let $a = convertToTensor(a, "a", "atan2");
  let $b = convertToTensor(b, "b", "atan2");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Atan2, inputs);
}
var atan2;
var init_atan2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/atan2.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    atan2 = /* @__PURE__ */ op({ atan2_ });
  }
});
function atanh_(x) {
  const $x = convertToTensor(x, "x", "atanh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Atanh, inputs);
}
var atanh;
var init_atanh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/atanh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    atanh = /* @__PURE__ */ op({ atanh_ });
  }
});
function computeDilation2DInfo(inputShape, filterShape, strides, pad2, dataFormat = "NHWC", dilations) {
  const inputChannels = inputShape[3];
  const $filterShape = [...filterShape, inputChannels];
  const $dataFormat = convertConv2DDataFormat(dataFormat);
  return computeConv2DInfo(inputShape, $filterShape, strides, dilations, pad2, null, null, $dataFormat);
}
function computePool2DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "channelsLast") {
  const [filterHeight, filterWidth] = parseTupleParam(filterSize);
  let filterShape;
  if (dataFormat === "channelsLast") {
    filterShape = [filterHeight, filterWidth, inShape[3], inShape[3]];
  } else if (dataFormat === "channelsFirst") {
    filterShape = [filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, false, dataFormat);
}
function computePool3DInfo(inShape, filterSize, strides, dilations, pad2, roundingMode, dataFormat = "NDHWC") {
  const [filterDepth, filterHeight, filterWidth] = parse3TupleParam(filterSize);
  let filterShape;
  let $dataFormat;
  if (dataFormat === "NDHWC") {
    $dataFormat = "channelsLast";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[4], inShape[4]];
  } else if (dataFormat === "NCDHW") {
    $dataFormat = "channelsFirst";
    filterShape = [filterDepth, filterHeight, filterWidth, inShape[1], inShape[1]];
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  return computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, false, $dataFormat, roundingMode);
}
function computeConv2DInfo(inShape, filterShape, strides, dilations, pad2, roundingMode, depthwise = false, dataFormat = "channelsLast") {
  let [batchSize, inHeight, inWidth, inChannels] = [-1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideHeight, strideWidth] = parseTupleParam(strides);
  const [dilationHeight, dilationWidth] = parseTupleParam(dilations);
  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
  const { padInfo, outHeight, outWidth } = getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, effectiveFilterHeight, effectiveFilterWidth, roundingMode, dataFormat);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inHeight,
    inWidth,
    inChannels,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideHeight,
    strideWidth,
    filterHeight,
    filterWidth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeConv3DInfo(inShape, filterShape, strides, dilations, pad2, depthwise = false, dataFormat = "channelsLast", roundingMode) {
  let [batchSize, inDepth, inHeight, inWidth, inChannels] = [-1, -1, -1, -1, -1];
  if (dataFormat === "channelsLast") {
    [batchSize, inDepth, inHeight, inWidth, inChannels] = inShape;
  } else if (dataFormat === "channelsFirst") {
    [batchSize, inChannels, inDepth, inHeight, inWidth] = inShape;
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
  const [filterDepth, filterHeight, filterWidth, , filterChannels] = filterShape;
  const [strideDepth, strideHeight, strideWidth] = parse3TupleParam(strides);
  const [dilationDepth, dilationHeight, dilationWidth] = parse3TupleParam(dilations);
  const effectiveFilterDepth = getEffectiveFilterSize(filterDepth, dilationDepth);
  const effectiveFilterHeight = getEffectiveFilterSize(filterHeight, dilationHeight);
  const effectiveFilterWidth = getEffectiveFilterSize(filterWidth, dilationWidth);
  const { padInfo, outDepth, outHeight, outWidth } = get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, effectiveFilterDepth, effectiveFilterHeight, effectiveFilterWidth, roundingMode);
  const outChannels = depthwise ? filterChannels * inChannels : filterChannels;
  let outShape;
  if (dataFormat === "channelsFirst") {
    outShape = [batchSize, outChannels, outDepth, outHeight, outWidth];
  } else if (dataFormat === "channelsLast") {
    outShape = [batchSize, outDepth, outHeight, outWidth, outChannels];
  }
  return {
    batchSize,
    dataFormat,
    inDepth,
    inHeight,
    inWidth,
    inChannels,
    outDepth,
    outHeight,
    outWidth,
    outChannels,
    padInfo,
    strideDepth,
    strideHeight,
    strideWidth,
    filterDepth,
    filterHeight,
    filterWidth,
    effectiveFilterDepth,
    effectiveFilterHeight,
    effectiveFilterWidth,
    dilationDepth,
    dilationHeight,
    dilationWidth,
    inShape,
    outShape,
    filterShape
  };
}
function computeOutputShape2D(inShape, fieldSize, stride, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad(inShape, fieldSize, stride);
  }
  const inputRows = inShape[0];
  const inputCols = inShape[1];
  const outputRows = round2((inputRows - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  const outputCols = round2((inputCols - fieldSize + 2 * zeroPad) / stride + 1, roundingMode);
  return [outputRows, outputCols];
}
function computeOutputShape4D(inShape, filterShape, outChannels, strides, zeroPad, roundingMode) {
  if (zeroPad == null) {
    zeroPad = computeDefaultPad(inShape, filterShape[0], strides[0]);
  }
  const outShape = [0, 0, 0, outChannels];
  for (let index = 0; index < 3; index++) {
    if (inShape[index] + 2 * zeroPad >= filterShape[index]) {
      outShape[index] = round2((inShape[index] - filterShape[index] + 2 * zeroPad) / strides[index] + 1, roundingMode);
    }
  }
  return outShape;
}
function computeDefaultPad(inputShape, fieldSize, stride, dilation = 1) {
  const effectiveFieldSize = getEffectiveFilterSize(fieldSize, dilation);
  return Math.floor((inputShape[0] * (stride - 1) - stride + effectiveFieldSize) / 2);
}
function parseTupleParam(param) {
  if (typeof param === "number") {
    return [param, param, param];
  }
  if (param.length === 2) {
    return [param[0], param[1], 1];
  }
  return param;
}
function parse3TupleParam(param) {
  return typeof param === "number" ? [param, param, param] : param;
}
function getEffectiveFilterSize(filterSize, dilation) {
  if (dilation <= 1) {
    return filterSize;
  }
  return filterSize + (filterSize - 1) * (dilation - 1);
}
function getPadAndOutInfo(pad2, inHeight, inWidth, strideHeight, strideWidth, filterHeight, filterWidth, roundingMode, dataFormat) {
  let padInfo;
  let outHeight;
  let outWidth;
  if (typeof pad2 === "number") {
    const padType = pad2 === 0 ? "VALID" : "NUMBER";
    padInfo = { top: pad2, bottom: pad2, left: pad2, right: pad2, type: padType };
    const outShape = computeOutputShape2D([inHeight, inWidth], filterHeight, strideHeight, pad2, roundingMode);
    outHeight = outShape[0];
    outWidth = outShape[1];
  } else if (pad2 === "same") {
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongHeight = Math.max(0, (outHeight - 1) * strideHeight + filterHeight - inHeight);
    const padAlongWidth = Math.max(0, (outWidth - 1) * strideWidth + filterWidth - inWidth);
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = { top, bottom, left, right, type: "SAME" };
  } else if (pad2 === "valid") {
    padInfo = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" };
    outHeight = Math.ceil((inHeight - filterHeight + 1) / strideHeight);
    outWidth = Math.ceil((inWidth - filterWidth + 1) / strideWidth);
  } else if (typeof pad2 === "object") {
    const top = dataFormat === "channelsLast" ? pad2[1][0] : pad2[2][0];
    const bottom = dataFormat === "channelsLast" ? pad2[1][1] : pad2[2][1];
    const left = dataFormat === "channelsLast" ? pad2[2][0] : pad2[3][0];
    const right = dataFormat === "channelsLast" ? pad2[2][1] : pad2[3][1];
    const padType = top === 0 && bottom === 0 && left === 0 && right === 0 ? "VALID" : "EXPLICIT";
    padInfo = { top, bottom, left, right, type: padType };
    outHeight = round2((inHeight - filterHeight + top + bottom) / strideHeight + 1, roundingMode);
    outWidth = round2((inWidth - filterWidth + left + right) / strideWidth + 1, roundingMode);
  } else {
    throw Error(`Unknown padding parameter: ${pad2}`);
  }
  return { padInfo, outHeight, outWidth };
}
function get3DPadAndOutInfo(pad2, inDepth, inHeight, inWidth, strideDepth, strideHeight, strideWidth, filterDepth, filterHeight, filterWidth, roundingMode) {
  let padInfo;
  let outDepth;
  let outHeight;
  let outWidth;
  if (pad2 === "valid") {
    pad2 = 0;
  }
  if (typeof pad2 === "number") {
    const padType = pad2 === 0 ? "VALID" : "NUMBER";
    padInfo = {
      top: pad2,
      bottom: pad2,
      left: pad2,
      right: pad2,
      front: pad2,
      back: pad2,
      type: padType
    };
    const outShape = computeOutputShape4D([inDepth, inHeight, inWidth, 1], [filterDepth, filterHeight, filterWidth], 1, [strideDepth, strideHeight, strideWidth], pad2, roundingMode);
    outDepth = outShape[0];
    outHeight = outShape[1];
    outWidth = outShape[2];
  } else if (pad2 === "same") {
    outDepth = Math.ceil(inDepth / strideDepth);
    outHeight = Math.ceil(inHeight / strideHeight);
    outWidth = Math.ceil(inWidth / strideWidth);
    const padAlongDepth = (outDepth - 1) * strideDepth + filterDepth - inDepth;
    const padAlongHeight = (outHeight - 1) * strideHeight + filterHeight - inHeight;
    const padAlongWidth = (outWidth - 1) * strideWidth + filterWidth - inWidth;
    const front = Math.floor(padAlongDepth / 2);
    const back = padAlongDepth - front;
    const top = Math.floor(padAlongHeight / 2);
    const bottom = padAlongHeight - top;
    const left = Math.floor(padAlongWidth / 2);
    const right = padAlongWidth - left;
    padInfo = { top, bottom, left, right, front, back, type: "SAME" };
  } else {
    throw Error(`Unknown padding parameter: ${pad2}`);
  }
  return { padInfo, outDepth, outHeight, outWidth };
}
function round2(value, roundingMode) {
  if (!roundingMode) {
    return Math.trunc(value);
  }
  switch (roundingMode) {
    case "round":
      return Math.round(value);
    case "ceil":
      return Math.ceil(value);
    case "floor":
      return Math.floor(value);
    default:
      throw new Error(`Unknown roundingMode ${roundingMode}`);
  }
}
function tupleValuesAreOne(param) {
  const [dimA, dimB, dimC] = parseTupleParam(param);
  return dimA === 1 && dimB === 1 && dimC === 1;
}
function eitherStridesOrDilationsAreOne(strides, dilations) {
  return tupleValuesAreOne(strides) || tupleValuesAreOne(dilations);
}
function stridesOrDilationsArePositive(values) {
  return parseTupleParam(values).every((value) => value > 0);
}
function convertConv2DDataFormat(dataFormat) {
  if (dataFormat === "NHWC") {
    return "channelsLast";
  } else if (dataFormat === "NCHW") {
    return "channelsFirst";
  } else {
    throw new Error(`Unknown dataFormat ${dataFormat}`);
  }
}
function checkPadOnDimRoundingMode(opDesc, pad2, dimRoundingMode) {
  if (dimRoundingMode != null) {
    if (typeof pad2 === "string") {
      throw Error(`Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    } else if (typeof pad2 === "number") {
      assert(isInt(pad2), () => `Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${pad2}.`);
    } else if (typeof pad2 === "object") {
      pad2.forEach((p2) => {
        p2.forEach((v) => {
          assert(isInt(v), () => `Error in ${opDesc}: pad must be an integer when using dimRoundingMode ${dimRoundingMode} but got pad ${v}.`);
        });
      });
    } else {
      throw Error(`Error in ${opDesc}: Unknown padding parameter: ${pad2}`);
    }
  }
}
var init_conv_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv_util.js"() {
    init_util();
  }
});
function reshape_(x, shape) {
  const $x = convertToTensor(x, "x", "reshape", "string_or_numeric");
  const inputs = { x: $x };
  const attrs = { shape };
  return ENGINE.runKernel(Reshape, inputs, attrs);
}
var reshape;
var init_reshape = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reshape.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    reshape = /* @__PURE__ */ op({ reshape_ });
  }
});
function avgPool_(x, filterSize, strides, pad2, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "avgPool", "float32");
  const dilations = 1;
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${x4D.rank}.`);
  checkPadOnDimRoundingMode("avgPool", pad2, dimRoundingMode);
  const inputs = { x: x4D };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
  let res = ENGINE.runKernel(AvgPool, inputs, attrs);
  res = cast(res, $x.dtype);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var avgPool;
var init_avg_pool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_cast();
    init_conv_util();
    init_operation();
    init_reshape();
    avgPool = /* @__PURE__ */ op({ avgPool_ });
  }
});
function avgPool3d_(x, filterSize, strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor(x, "x", "avgPool3d", "float32");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert(dataFormat === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  assert(typeof strides === "number" && strides > 0 || Array.isArray(strides) && strides[0] > 0 && strides[1] > 0 && strides[2] > 0, () => `Error in avgPool3d: Stride must be > 0, but got '${strides}'`);
  checkPadOnDimRoundingMode("avgPool3d", pad2, dimRoundingMode);
  const inputs = { x: x5D };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
  let res = ENGINE.runKernel(AvgPool3D, inputs, attrs);
  res = cast(res, x5D.dtype);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var avgPool3d;
var init_avg_pool_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_cast();
    init_conv_util();
    init_operation();
    init_reshape();
    avgPool3d = /* @__PURE__ */ op({ avgPool3d_ });
  }
});
function concat_(tensors, axis = 0) {
  assert(tensors.length >= 1, () => "Pass at least one tensor to concat");
  const $tensors = convertToTensorArray(tensors, "tensors", "concat", "string_or_numeric");
  if ($tensors[0].dtype === "complex64") {
    $tensors.forEach((tensor2) => {
      if (tensor2.dtype !== "complex64") {
        throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${tensor2.dtype}. `);
      }
    });
  }
  if ($tensors.length === 1) {
    return clone6($tensors[0]);
  }
  const inputs = $tensors;
  const attr = { axis };
  return ENGINE.runKernel(Concat, inputs, attr);
}
var concat;
var init_concat = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_clone();
    init_operation();
    concat = /* @__PURE__ */ op({ concat_ });
  }
});
function matMul_(a, b, transposeA = false, transposeB = false) {
  let $a = convertToTensor(a, "a", "matMul");
  let $b = convertToTensor(b, "b", "matMul");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  const attrs = { transposeA, transposeB };
  return ENGINE.runKernel(BatchMatMul, inputs, attrs);
}
var matMul;
var init_mat_mul = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mat_mul.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    matMul = /* @__PURE__ */ op({ matMul_ });
  }
});
function sigmoid_(x) {
  const $x = convertToTensor(x, "x", "sigmoid", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sigmoid, inputs);
}
var sigmoid;
var init_sigmoid = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sigmoid.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sigmoid = /* @__PURE__ */ op({ sigmoid_ });
  }
});
function slice_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice", "string_or_numeric");
  if ($x.rank === 0) {
    throw new Error("Slicing scalar is not possible");
  }
  const inputs = { x: $x };
  const attrs = { begin, size };
  return ENGINE.runKernel(Slice, inputs, attrs);
}
var slice;
var init_slice = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    slice = /* @__PURE__ */ op({ slice_ });
  }
});
function tanh_(x) {
  const $x = convertToTensor(x, "x", "tanh", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Tanh, inputs);
}
var tanh2;
var init_tanh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tanh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    tanh2 = /* @__PURE__ */ op({ tanh_ });
  }
});
function batchToSpaceND_(x, blockShape, crops) {
  const $x = convertToTensor(x, "x", "batchToSpaceND");
  const prod4 = blockShape.reduce((a, b) => a * b);
  assert($x.rank >= 1 + blockShape.length, () => `input rank is ${$x.rank} but should be > than blockShape.length ${blockShape.length}`);
  assert(crops.length === blockShape.length, () => `crops.length is ${crops.length} but should be equal to blockShape.length  ${blockShape.length}`);
  assert($x.shape[0] % prod4 === 0, () => `input tensor batch is ${$x.shape[0]} but is not divisible by the product of the elements of blockShape ${blockShape.join(" * ")} === ${prod4}`);
  const inputs = { x: $x };
  const attrs = { blockShape, crops };
  return ENGINE.runKernel(BatchToSpaceND, inputs, attrs);
}
var batchToSpaceND;
var init_batch_to_space_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    batchToSpaceND = /* @__PURE__ */ op({ batchToSpaceND_ });
  }
});
function xAs4D(x) {
  let x4D;
  if (x.rank === 0 || x.rank === 1) {
    x4D = reshape(x, [1, 1, 1, x.size]);
  } else if (x.rank === 2) {
    x4D = reshape(x, [1, 1, x.shape[0], x.shape[1]]);
  } else if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  } else {
    x4D = x;
  }
  return x4D;
}
var init_batchnorm_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm_util.js"() {
    init_reshape();
  }
});
function batchNorm_(x, mean3, variance, offset, scale22, varianceEpsilon) {
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean3, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale22 != null) {
    $scale = convertToTensor(scale22, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($mean.rank === $variance.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  assert($offset == null || $mean.rank === $offset.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  assert($scale == null || $mean.rank === $scale.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  const x4D = xAs4D($x);
  const inputs = {
    x: x4D,
    scale: $scale,
    offset: $offset,
    mean: $mean,
    variance: $variance
  };
  const attrs = { varianceEpsilon };
  const res = ENGINE.runKernel(FusedBatchNorm, inputs, attrs);
  return reshape(res, $x.shape);
}
var batchNorm;
var init_batchnorm = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_batchnorm_util();
    init_operation();
    init_reshape();
    batchNorm = /* @__PURE__ */ op({ batchNorm_ });
  }
});
function batchNorm2d_(x, mean3, variance, offset, scale22, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean3, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale22 != null) {
    $scale = convertToTensor(scale22, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${$x.rank}.`);
  assert($mean.rank === 2 || $mean.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 2 || $variance.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 2 || $scale.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 2 || $offset.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm2d;
var init_batchnorm2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm2d.js"() {
    init_tensor_util_env();
    init_util();
    init_batchnorm();
    init_operation();
    batchNorm2d = /* @__PURE__ */ op({ batchNorm2d_ });
  }
});
function batchNorm3d_(x, mean3, variance, offset, scale22, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean3, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale22 != null) {
    $scale = convertToTensor(scale22, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${$x.rank}.`);
  assert($mean.rank === 3 || $mean.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 3 || $variance.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 3 || $scale.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 3 || $offset.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm3d;
var init_batchnorm3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm3d.js"() {
    init_tensor_util_env();
    init_util();
    init_batchnorm();
    init_operation();
    batchNorm3d = /* @__PURE__ */ op({ batchNorm3d_ });
  }
});
function batchNorm4d_(x, mean3, variance, offset, scale22, varianceEpsilon) {
  const $x = convertToTensor(x, "x", "batchNorm");
  const $mean = convertToTensor(mean3, "mean", "batchNorm");
  const $variance = convertToTensor(variance, "variance", "batchNorm");
  let $scale;
  if (scale22 != null) {
    $scale = convertToTensor(scale22, "scale", "batchNorm");
  }
  let $offset;
  if (offset != null) {
    $offset = convertToTensor(offset, "offset", "batchNorm");
  }
  assert($x.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${$x.rank}.`);
  assert($mean.rank === 4 || $mean.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${$mean.rank}.`);
  assert($variance.rank === 4 || $variance.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${$variance.rank}.`);
  if ($scale != null) {
    assert($scale.rank === 4 || $scale.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${$scale.rank}.`);
  }
  if ($offset != null) {
    assert($offset.rank === 4 || $offset.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${$offset.rank}.`);
  }
  return batchNorm($x, $mean, $variance, $offset, $scale, varianceEpsilon);
}
var batchNorm4d;
var init_batchnorm4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/batchnorm4d.js"() {
    init_tensor_util_env();
    init_util();
    init_batchnorm();
    init_operation();
    batchNorm4d = /* @__PURE__ */ op({ batchNorm4d_ });
  }
});
function bincount_(x, weights, size) {
  const $x = convertToTensor(x, "x", "bincount");
  const $weights = convertToTensor(weights, "weights", "bincount");
  assert($x.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${$x.dtype}`);
  assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert($weights.size === $x.size || $weights.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = { x: $x, weights: $weights };
  const attrs = { size };
  return ENGINE.runKernel(Bincount, inputs, attrs);
}
var bincount;
var init_bincount = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/bincount.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    bincount = /* @__PURE__ */ op({ bincount_ });
  }
});
function broadcastTo_(x, shape) {
  let input2 = convertToTensor(x, "broadcastTo", "x");
  const xShape = input2.shape;
  assertNonNegativeIntegerDimensions(shape);
  if (shape.length < input2.rank) {
    throw new Error(`broadcastTo(): shape.length=${shape.length} < input.rank=${input2.rank}.`);
  }
  if (shape.length > input2.rank) {
    const newShape = input2.shape.slice();
    while (newShape.length < shape.length) {
      newShape.unshift(1);
    }
    input2 = reshape(input2, newShape);
  }
  const inputShape = input2.shape;
  const reps = Array.from(shape);
  for (let i = shape.length - 1; i >= 0; i--) {
    if (inputShape[i] === shape[i]) {
      reps[i] = 1;
    } else if (input2.shape[i] !== 1) {
      throw new Error(`broadcastTo(): [${xShape}] cannot be broadcast to [${shape}].`);
    }
  }
  const axes = reps.map((n, i) => n > 1 ? i : -1).filter((i) => i >= 0);
  if (axes.length === 0) {
    return clone6(input2);
  }
  const inputs = { x: input2 };
  const attrs = { reps };
  return ENGINE.runKernel(Tile, inputs, attrs);
}
var broadcastTo;
var init_broadcast_to = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_to.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util_base();
    init_clone();
    init_operation();
    init_reshape();
    broadcastTo = /* @__PURE__ */ op({ broadcastTo_ });
  }
});
function ceil_(x) {
  const $x = convertToTensor(x, "x", "ceil", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Ceil, inputs);
}
var ceil2;
var init_ceil = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ceil.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    ceil2 = /* @__PURE__ */ op({ ceil_ });
  }
});
function fill(shape, value, dtype) {
  assertNonNegativeIntegerDimensions(shape);
  const attrs = { shape, value, dtype };
  return ENGINE.runKernel(Fill, {}, attrs);
}
var init_fill = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fill.js"() {
    init_engine();
    init_kernel_names();
    init_util_base();
  }
});
function clipByValue_(x, clipValueMin, clipValueMax) {
  const $x = convertToTensor(x, "x", "clipByValue");
  assert(clipValueMin <= clipValueMax, () => `Error in clip: min (${clipValueMin}) must be less than or equal to max (${clipValueMax}).`);
  if (clipValueMin === clipValueMax) {
    return fill($x.shape, clipValueMin, $x.dtype);
  }
  const inputs = { x: $x };
  const attrs = { clipValueMin, clipValueMax };
  return ENGINE.runKernel(ClipByValue, inputs, attrs);
}
var clipByValue;
var init_clip_by_value = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/clip_by_value.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_fill();
    init_operation();
    clipByValue = /* @__PURE__ */ op({ clipByValue_ });
  }
});
function concat1d_(tensors) {
  return concat(
    tensors,
    0
    /* axis */
  );
}
var concat1d;
var init_concat_1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_1d.js"() {
    init_concat();
    init_operation();
    concat1d = /* @__PURE__ */ op({ concat1d_ });
  }
});
function concat2d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat2d;
var init_concat_2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_2d.js"() {
    init_concat();
    init_operation();
    concat2d = /* @__PURE__ */ op({ concat2d_ });
  }
});
function concat3d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat3d;
var init_concat_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_3d.js"() {
    init_concat();
    init_operation();
    concat3d = /* @__PURE__ */ op({ concat3d_ });
  }
});
function concat4d_(tensors, axis) {
  return concat(tensors, axis);
}
var concat4d;
var init_concat_4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_4d.js"() {
    init_concat();
    init_operation();
    concat4d = /* @__PURE__ */ op({ concat4d_ });
  }
});
function conv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  checkPadOnDimRoundingMode("conv2d", pad2, dimRoundingMode);
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert(inDepth === $filter.shape[2], () => `Error in conv2d: depth of input (${inDepth}) must match input depth for filter ${$filter.shape[2]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert(stridesOrDilationsArePositive(dilations), () => "Error in conv2D: Dilated rates should be larger than 0.");
  assert(stridesOrDilationsArePositive(strides), () => "Error in conv2D: Strides should be larger than 0.");
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
  const res = ENGINE.runKernel(Conv2D, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2d;
var init_conv2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv2d = /* @__PURE__ */ op({ conv2d_ });
  }
});
function conv1d_(x, filter, stride, pad2, dataFormat = "NWC", dilation = 1, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv1d");
  const $filter = convertToTensor(filter, "filter", "conv1d");
  let x3D = $x;
  let reshapedTo3D = false;
  if ($x.rank === 2) {
    reshapedTo3D = true;
    x3D = reshape($x, [1, $x.shape[0], $x.shape[1]]);
  }
  assert(x3D.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${x3D.rank}.`);
  assert($filter.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${$filter.rank}.`);
  checkPadOnDimRoundingMode("conv1d", pad2, dimRoundingMode);
  assert(x3D.shape[2] === $filter.shape[1], () => `Error in conv1d: depth of input (${x3D.shape[2]}) must match input depth for filter ${$filter.shape[1]}.`);
  assert(eitherStridesOrDilationsAreOne(stride, dilation), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${stride} and dilation '${dilation}'`);
  assert(stridesOrDilationsArePositive(dilation), () => "Error in conv1D: Dilated rates should be larger than 0.");
  assert(stridesOrDilationsArePositive(stride), () => "Error in conv1D: Stride should be larger than 0.");
  assert(dataFormat === "NWC", () => `Error in conv1d: got dataFormat of ${dataFormat} but only NWC is currently supported.`);
  const filter4D = reshape($filter, [1, $filter.shape[0], $filter.shape[1], $filter.shape[2]]);
  const input4D = reshape(x3D, [x3D.shape[0], 1, x3D.shape[1], x3D.shape[2]]);
  const strides = [1, stride];
  const dilations = [1, dilation];
  const conv2dDataFormat = "NHWC";
  const res = conv2d(input4D, filter4D, strides, pad2, conv2dDataFormat, dilations, dimRoundingMode);
  if (reshapedTo3D) {
    return reshape(res, [res.shape[2], res.shape[3]]);
  }
  return reshape(res, [res.shape[0], res.shape[2], res.shape[3]]);
}
var conv1d;
var init_conv1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv1d.js"() {
    init_tensor_util_env();
    init_util();
    init_conv2d();
    init_conv_util();
    init_operation();
    init_reshape();
    conv1d = /* @__PURE__ */ op({ conv1d_ });
  }
});
function conv2DBackpropInput_(xShape, dy, filter, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
  assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape4D = xShape;
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
    xShape4D = [1, xShape[0], xShape[1], xShape[2]];
  }
  assert(xShape4D.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${xShape4D.length}.`);
  assert(dy4D.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${dy4D.rank}`);
  assert(filter.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${filter.rank}`);
  const inDepth = dataFormat === "NHWC" ? xShape4D[3] : xShape4D[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert(inDepth === filter.shape[2], () => `Error in conv2dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[2]}.`);
  assert(outDepth === filter.shape[3], () => `Error in conv2dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[3]}.`);
  checkPadOnDimRoundingMode("conv2dDerInput", pad2, dimRoundingMode);
  const inputs = { dy: dy4D, filter };
  const attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, inputShape: xShape4D };
  const res = ENGINE.runKernel(Conv2DBackpropInput, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var conv2DBackpropInput;
var init_conv2d_backprop_input = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv2DBackpropInput = /* @__PURE__ */ op({ conv2DBackpropInput_ });
  }
});
function conv2dTranspose_(x, filter, outputShape, strides, pad2, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "conv2dTranspose");
  const $filter = convertToTensor(filter, "filter", "conv2dTranspose");
  return conv2DBackpropInput(outputShape, $x, $filter, strides, pad2, "NHWC", dimRoundingMode);
}
var conv2dTranspose;
var init_conv2d_transpose = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_transpose.js"() {
    init_tensor_util_env();
    init_conv2d_backprop_input();
    init_operation();
    conv2dTranspose = /* @__PURE__ */ op({ conv2dTranspose_ });
  }
});
function conv3d_(x, filter, strides, pad2, dataFormat = "NDHWC", dilations = [1, 1, 1]) {
  const $x = convertToTensor(x, "x", "conv3d");
  const $filter = convertToTensor(filter, "filter", "conv3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${x5D.rank}.`);
  assert($filter.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${$filter.rank}.`);
  assert(x5D.shape[4] === $filter.shape[3], () => `Error in conv3d: depth of input (${x5D.shape[4]}) must match input depth for filter ${$filter.shape[3]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  assert(dataFormat === "NDHWC", () => `Error in conv3d: got dataFormat of ${dataFormat} but only NDHWC is currently supported.`);
  assert(stridesOrDilationsArePositive(dilations), () => "Error in conv3D: Dilated rates should be larger than 0.");
  assert(stridesOrDilationsArePositive(strides), () => "Error in conv3D: Strides should be larger than 0.");
  const inputs = { x: x5D, filter: $filter };
  const attrs = { strides, pad: pad2, dataFormat, dilations };
  const res = ENGINE.runKernel(Conv3D, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3d;
var init_conv3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv3d = /* @__PURE__ */ op({ conv3d_ });
  }
});
function conv3DBackpropInput_(xShape, dy, filter, strides, pad2) {
  assert(xShape.length === dy.rank, () => `Length of inShape (${xShape.length}) and rank of dy (${dy.rank}) must match`);
  let xShape5D = xShape;
  let dy5D = dy;
  let reshapedTo5D = false;
  if (dy.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
    xShape5D = [1, xShape[0], xShape[1], xShape[2], xShape[3]];
  }
  const inDepth = xShape5D[4];
  const outDepth = dy5D.shape[4];
  assert(xShape5D.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${xShape5D.length}.`);
  assert(dy5D.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${dy5D.rank}`);
  assert(filter.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${filter.rank}`);
  assert(inDepth === filter.shape[3], () => `Error in conv3dDerInput: depth of input (${inDepth}) must match input depth for filter ${filter.shape[3]}.`);
  assert(outDepth === filter.shape[4], () => `Error in conv3dDerInput: depth of output (${outDepth}) must match output depth for filter ${filter.shape[4]}.`);
  const inputs = { dy: dy5D, filter };
  const attrs = { pad: pad2, strides, inputShape: xShape5D };
  const res = ENGINE.runKernel(Conv3DBackpropInputV2, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var conv3DBackpropInput;
var init_conv3d_backprop_input = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    init_reshape();
    conv3DBackpropInput = /* @__PURE__ */ op({ conv3DBackpropInput_ });
  }
});
function conv3dTranspose_(x, filter, outputShape, strides, pad2) {
  const $x = convertToTensor(x, "x", "conv3dTranspose");
  const $filter = convertToTensor(filter, "filter", "conv3dTranspose");
  return conv3DBackpropInput(outputShape, $x, $filter, strides, pad2);
}
var conv3dTranspose;
var init_conv3d_transpose = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_transpose.js"() {
    init_tensor_util_env();
    init_conv3d_backprop_input();
    init_operation();
    conv3dTranspose = /* @__PURE__ */ op({ conv3dTranspose_ });
  }
});
function cos_(x) {
  const $x = convertToTensor(x, "x", "cos", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Cos, inputs);
}
var cos;
var init_cos = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cos.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cos = /* @__PURE__ */ op({ cos_ });
  }
});
function cosh_(x) {
  const $x = convertToTensor(x, "x", "cosh", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Cosh, inputs);
}
var cosh;
var init_cosh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cosh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cosh = /* @__PURE__ */ op({ cosh_ });
  }
});
function cumprod_(x, axis = 0, exclusive = false, reverse4 = false) {
  const $x = convertToTensor(x, "x", "cumprod");
  const inputs = { x: $x };
  const attrs = { axis, exclusive, reverse: reverse4 };
  return ENGINE.runKernel(Cumprod, inputs, attrs);
}
var cumprod;
var init_cumprod = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cumprod.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cumprod = /* @__PURE__ */ op({ cumprod_ });
  }
});
function cumsum_(x, axis = 0, exclusive = false, reverse4 = false) {
  const $x = convertToTensor(x, "x", "cumsum");
  const inputs = { x: $x };
  const attrs = { axis, exclusive, reverse: reverse4 };
  return ENGINE.runKernel(Cumsum, inputs, attrs);
}
var cumsum;
var init_cumsum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/cumsum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    cumsum = /* @__PURE__ */ op({ cumsum_ });
  }
});
function denseBincount_(x, weights, size, binaryOutput = false) {
  const $x = convertToTensor(x, "x", "denseBincount");
  const $weights = convertToTensor(weights, "weights", "denseBincount");
  assert($x.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${$x.dtype}`);
  assert($x.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${$x.rank}.`);
  assert(size >= 0, () => `size must be non-negative, but got ${size}.`);
  assert($weights.size === $x.size || $weights.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${$x.shape}, weights shape: ${$weights.shape}.`);
  const inputs = { x: $x, weights: $weights };
  const attrs = { size, binaryOutput };
  return ENGINE.runKernel(DenseBincount, inputs, attrs);
}
var denseBincount;
var init_dense_bincount = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dense_bincount.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    denseBincount = /* @__PURE__ */ op({ denseBincount_ });
  }
});
function depthToSpace_(x, blockSize, dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "depthToSpace", "float32");
  const inputHeight = dataFormat === "NHWC" ? $x.shape[1] : $x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? $x.shape[2] : $x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? $x.shape[3] : $x.shape[1];
  assert(blockSize > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);
  assert(inputHeight * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputHeight} and ${blockSize}  for depthToSpace with input shape
    ${$x.shape}`);
  assert(inputWidth * blockSize >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${inputWidth} and ${blockSize} for depthToSpace with input shape
        ${$x.shape}`);
  assert(inputDepth % (blockSize * blockSize) === 0, () => `Dimension size must be evenly divisible by ${blockSize * blockSize} but is ${inputDepth} for depthToSpace with input shape ${$x.shape}`);
  const inputs = { x: $x };
  const attrs = { blockSize, dataFormat };
  return ENGINE.runKernel(DepthToSpace, inputs, attrs);
}
var depthToSpace;
var init_depth_to_space = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depth_to_space.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    depthToSpace = /* @__PURE__ */ op({ depthToSpace_ });
  }
});
function depthwiseConv2d_(x, filter, strides, pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode) {
  const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  const inChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert(inChannels === $filter.shape[2], () => `Error in depthwiseConv2d: number of input channels (${inChannels}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad2, dataFormat, dilations, dimRoundingMode };
  const res = ENGINE.runKernel(DepthwiseConv2dNative, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2d;
var init_depthwise_conv2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    depthwiseConv2d = /* @__PURE__ */ op({ depthwiseConv2d_ });
  }
});
function dilation2d_(x, filter, strides, pad2, dilations = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "dilation2d");
  const $filter = convertToTensor(filter, "filter", "dilation2d");
  assert($x.rank === 3 || $x.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${$x.rank}.`);
  assert($filter.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${$filter.rank}.`);
  assert(dataFormat === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${dataFormat}`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
    reshapedTo4D = true;
  }
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in dilation2d:  input and filter must have the same depth: ${x4D.shape[3]} vs ${$filter.shape[2]}`);
  const inputs = { x: x4D, filter: $filter };
  const attrs = { strides, pad: pad2, dilations };
  const res = ENGINE.runKernel(Dilation2D, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var dilation2d;
var init_dilation2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dilation2d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    dilation2d = /* @__PURE__ */ op({ dilation2d_ });
  }
});
var broadcast_util_exports = {};
__export2(broadcast_util_exports, {
  assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
  getBroadcastDims: () => getBroadcastDims,
  getReductionAxes: () => getReductionAxes
});
function getBroadcastDims(inShape, outShape) {
  const inRank = inShape.length;
  const dims = [];
  for (let i = 0; i < inRank; i++) {
    const dim = inRank - 1 - i;
    const a = inShape[dim] || 1;
    const b = outShape[outShape.length - 1 - i] || 1;
    if (b > 1 && a === 1) {
      dims.unshift(dim);
    }
  }
  return dims;
}
function getReductionAxes(inShape, outShape) {
  const result = [];
  for (let i = 0; i < outShape.length; i++) {
    const inDim = inShape[inShape.length - i - 1];
    const outAxis = outShape.length - i - 1;
    const outDim = outShape[outAxis];
    if (inDim == null || inDim === 1 && outDim > 1) {
      result.unshift(outAxis);
    }
  }
  return result;
}
function assertAndGetBroadcastShape(shapeA, shapeB) {
  const result = [];
  const l = Math.max(shapeA.length, shapeB.length);
  for (let i = 0; i < l; i++) {
    let a = shapeA[shapeA.length - i - 1];
    if (a == null) {
      a = 1;
    }
    let b = shapeB[shapeB.length - i - 1];
    if (b == null) {
      b = 1;
    }
    if (a === 1) {
      result.unshift(b);
    } else if (b === 1) {
      result.unshift(a);
    } else if (a !== b) {
      const errMsg = `Operands could not be broadcast together with shapes ${shapeA} and ${shapeB}.`;
      throw Error(errMsg);
    } else {
      result.unshift(a);
    }
  }
  return result;
}
var init_broadcast_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/broadcast_util.js"() {
  }
});
function equal_(a, b) {
  let $a = convertToTensor(a, "a", "equal", "string_or_numeric");
  let $b = convertToTensor(b, "b", "equal", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Equal, inputs);
}
var equal;
var init_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    equal = /* @__PURE__ */ op({ equal_ });
  }
});
function where_(condition, a, b) {
  const $a = convertToTensor(a, "a", "where");
  const $b = convertToTensor(b, "b", "where");
  const $condition = convertToTensor(condition, "condition", "where", "bool");
  const broadcastShape = assertAndGetBroadcastShape(assertAndGetBroadcastShape($condition.shape, $a.shape), $b.shape);
  const $broadcastedCondition = broadcastTo($condition, broadcastShape);
  const $broadcastedA = broadcastTo($a, broadcastShape);
  const $broadcastedB = broadcastTo($b, broadcastShape);
  const inputs = {
    condition: $broadcastedCondition,
    t: $broadcastedA,
    e: $broadcastedB
  };
  return ENGINE.runKernel(Select, inputs);
}
var where;
var init_where = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/where.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_broadcast_to();
    init_broadcast_util();
    init_operation();
    where = /* @__PURE__ */ op({ where_ });
  }
});
function zerosLike_(x) {
  const $x = convertToTensor(x, "x", "zerosLike");
  const inputs = { x: $x };
  return ENGINE.runKernel(ZerosLike, inputs);
}
var zerosLike;
var init_zeros_like = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/zeros_like.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    zerosLike = /* @__PURE__ */ op({ zerosLike_ });
  }
});
function divNoNan_(a, b) {
  let $a = convertToTensor(a, "a", "div");
  let $b = convertToTensor(b, "b", "div");
  [$a, $b] = makeTypesMatch($a, $b);
  const divResult = div2($a, $b);
  const zeros3 = zerosLike(divResult);
  const bEqualsZero = equal($b, zeros3);
  return where(bEqualsZero, zeros3, divResult);
}
var divNoNan;
var init_div_no_nan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/div_no_nan.js"() {
    init_tensor_util();
    init_tensor_util_env();
    init_div();
    init_equal();
    init_operation();
    init_where();
    init_zeros_like();
    divNoNan = /* @__PURE__ */ op({ divNoNan_ });
  }
});
function dot_(t1, t2) {
  const $t1 = convertToTensor(t1, "t1", "dot");
  const $t2 = convertToTensor(t2, "t2", "dot");
  assert(($t1.rank === 1 || $t1.rank === 2) && ($t2.rank === 1 || $t2.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${$t1.rank} and ${$t2.rank}.`);
  const t1Inner = $t1.rank === 1 ? $t1.size : $t1.shape[1];
  const t2Inner = $t2.rank === 1 ? $t2.size : $t2.shape[0];
  assert(t1Inner === t2Inner, () => `Error in dot: inner dimensions of inputs must match, but got ${t1Inner} and ${t2Inner}.`);
  if ($t1.rank === 1 && $t2.rank === 1) {
    const t12D = reshape($t1, [1, -1]);
    const t22D = reshape($t2, [-1, 1]);
    const t1t2 = matMul(t12D, t22D);
    return reshape(t1t2, []);
  } else if ($t1.rank === 1 && $t2.rank === 2) {
    const t12D = reshape($t1, [1, -1]);
    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul(t12D, t22D);
    return reshape(t1t2, [t1t2.size]);
  } else if ($t1.rank === 2 && $t2.rank === 1) {
    const t22D = reshape($t2, [-1, 1]);
    const t1t2 = matMul($t1, t22D);
    return reshape(t1t2, [t1t2.size]);
  } else {
    const t22D = reshape($t2, [$t2.shape[0], $t2.shape[1]]);
    const t1t2 = matMul($t1, t22D);
    return t1t2;
  }
}
var dot5;
var init_dot = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dot.js"() {
    init_tensor_util_env();
    init_util();
    init_mat_mul();
    init_operation();
    init_reshape();
    dot5 = /* @__PURE__ */ op({ dot_ });
  }
});
function elu_(x) {
  const $x = convertToTensor(x, "x", "elu", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Elu, inputs);
}
var elu;
var init_elu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/elu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    elu = /* @__PURE__ */ op({ elu_ });
  }
});
function erf_(x) {
  let $x = convertToTensor(x, "x", "erf");
  assert($x.dtype === "int32" || $x.dtype === "float32", () => "Input dtype must be `int32` or `float32`.");
  if ($x.dtype === "int32") {
    $x = cast($x, "float32");
  }
  const inputs = { x: $x };
  return ENGINE.runKernel(Erf, inputs);
}
var erf;
var init_erf = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/erf.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_cast();
    init_operation();
    erf = /* @__PURE__ */ op({ erf_ });
  }
});
function axesAreInnerMostDims(axes, rank) {
  for (let i = 0; i < axes.length; ++i) {
    if (axes[axes.length - i - 1] !== rank - 1 - i) {
      return false;
    }
  }
  return true;
}
function combineLocations(outputLoc, reduceLoc, axes) {
  const rank = outputLoc.length + reduceLoc.length;
  const loc = [];
  let outIdx = 0;
  let reduceIdx = 0;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      loc.push(outputLoc[outIdx++]);
    } else {
      loc.push(reduceLoc[reduceIdx++]);
    }
  }
  return loc;
}
function computeOutAndReduceShapes(aShape, axes) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (axes.indexOf(dim) === -1) {
      outShape.push(aShape[dim]);
    }
  }
  const reduceShape = axes.map((dim) => aShape[dim]);
  return [outShape, reduceShape];
}
function expandShapeToKeepDim(shape, axes) {
  const reduceSubShape = axes.map((x) => 1);
  return combineLocations(shape, reduceSubShape, axes);
}
function assertAxesAreInnerMostDims(msg, axes, rank) {
  assert(axesAreInnerMostDims(axes, rank), () => `${msg} supports only inner-most axes for now. Got axes ${axes} and rank-${rank} input.`);
}
function getAxesPermutation(axes, rank) {
  if (axesAreInnerMostDims(axes, rank)) {
    return null;
  }
  const result = [];
  for (let i = 0; i < rank; ++i) {
    if (axes.indexOf(i) === -1) {
      result.push(i);
    }
  }
  axes.forEach((axis) => result.push(axis));
  return result;
}
function getUndoAxesPermutation(axes) {
  return axes.map((axis, i) => [i, axis]).sort((a, b) => a[1] - b[1]).map((x) => x[0]);
}
function getInnerMostAxes(numAxes, rank) {
  const res = [];
  for (let i = rank - numAxes; i < rank; ++i) {
    res.push(i);
  }
  return res;
}
var init_axis_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/axis_util.js"() {
    init_util();
  }
});
function max_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "max");
  const inputs = { x: $x };
  const attrs = { reductionIndices: axis, keepDims };
  return ENGINE.runKernel(Max, inputs, attrs);
}
var max2;
var init_max = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    max2 = /* @__PURE__ */ op({ max_ });
  }
});
function min_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "min");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Min, inputs, attrs);
}
var min2;
var init_min = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/min.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    min2 = /* @__PURE__ */ op({ min_ });
  }
});
function pow_(base, exp4) {
  let $base = convertToTensor(base, "base", "pow");
  let $exp = convertToTensor(exp4, "exp", "pow");
  [$base, $exp] = makeTypesMatch($base, $exp);
  const inputs = { a: $base, b: $exp };
  return ENGINE.runKernel(Pow, inputs);
}
var pow2;
var init_pow = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pow.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    pow2 = /* @__PURE__ */ op({ pow_ });
  }
});
function scalar(value, dtype) {
  if ((isTypedArray(value) && dtype !== "string" || Array.isArray(value)) && dtype !== "complex64") {
    throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  }
  if (dtype === "string" && isTypedArray(value) && !(value instanceof Uint8Array)) {
    throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  }
  const shape = [];
  const inferredShape = [];
  return makeTensor(value, shape, inferredShape, dtype);
}
var init_scalar = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/scalar.js"() {
    init_util();
    init_tensor_ops_util();
  }
});
function sqrt_(x) {
  const $x = convertToTensor(x, "x", "sqrt", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sqrt, inputs);
}
var sqrt;
var init_sqrt = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sqrt.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sqrt = /* @__PURE__ */ op({ sqrt_ });
  }
});
function square_(x) {
  const $x = convertToTensor(x, "x", "square");
  const attrs = {};
  return ENGINE.runKernel("Square", { x: $x }, attrs);
}
var square;
var init_square = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/square.js"() {
    init_engine();
    init_tensor_util_env();
    init_operation();
    square = /* @__PURE__ */ op({ square_ });
  }
});
function sum_(x, axis = null, keepDims = false) {
  let $x = convertToTensor(x, "x", "sum");
  if ($x.dtype === "bool") {
    $x = cast($x, "int32");
  }
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Sum, inputs, attrs);
}
var sum2;
var init_sum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_cast();
    init_operation();
    sum2 = /* @__PURE__ */ op({ sum_ });
  }
});
function norm_(x, ord = "euclidean", axis = null, keepDims = false) {
  x = convertToTensor(x, "x", "norm");
  const norm2 = normImpl(x, ord, axis);
  let keepDimsShape = norm2.shape;
  if (keepDims) {
    const axes = parseAxisParam(axis, x.shape);
    keepDimsShape = expandShapeToKeepDim(norm2.shape, axes);
  }
  return reshape(norm2, keepDimsShape);
}
function normImpl(x, p2, axis = null) {
  if (x.rank === 0) {
    return abs(x);
  }
  if (x.rank !== 1 && axis === null) {
    return normImpl(reshape(x, [-1]), p2, axis);
  }
  if (x.rank === 1 || typeof axis === "number" || Array.isArray(axis) && axis.length === 1) {
    if (p2 === 1) {
      return sum2(abs(x), axis);
    }
    if (p2 === Infinity) {
      return max2(abs(x), axis);
    }
    if (p2 === -Infinity) {
      return min2(abs(x), axis);
    }
    if (p2 === "euclidean" || p2 === 2) {
      return sqrt(sum2(pow2(abs(x), scalar(2, "int32")), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p2}`);
  }
  if (Array.isArray(axis) && axis.length === 2) {
    if (p2 === 1) {
      return max2(sum2(abs(x), axis[0]), axis[1] - 1);
    }
    if (p2 === Infinity) {
      return max2(sum2(abs(x), axis[1]), axis[0]);
    }
    if (p2 === -Infinity) {
      return min2(sum2(abs(x), axis[1]), axis[0]);
    }
    if (p2 === "fro" || p2 === "euclidean") {
      return sqrt(sum2(square(x), axis));
    }
    throw new Error(`Error in norm: invalid ord value: ${p2}`);
  }
  throw new Error(`Error in norm: invalid axis: ${axis}`);
}
var norm;
var init_norm = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/norm.js"() {
    init_tensor_util_env();
    init_util();
    init_abs();
    init_axis_util();
    init_max();
    init_min();
    init_operation();
    init_pow();
    init_reshape();
    init_scalar();
    init_sqrt();
    init_square();
    init_sum();
    norm = /* @__PURE__ */ op({ norm_ });
  }
});
function euclideanNorm_(x, axis = null, keepDims = false) {
  return norm(x, "euclidean", axis, keepDims);
}
var euclideanNorm;
var init_euclidean_norm = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/euclidean_norm.js"() {
    init_norm();
    init_operation();
    euclideanNorm = /* @__PURE__ */ op({ euclideanNorm_ });
  }
});
function exp_(x) {
  const $x = convertToTensor(x, "x", "exp");
  const inputs = { x: $x };
  return ENGINE.runKernel(Exp, inputs);
}
var exp2;
var init_exp = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/exp.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    exp2 = /* @__PURE__ */ op({ exp_ });
  }
});
function expandDims_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "expandDims", "string_or_numeric");
  assert(axis <= $x.rank, () => "Axis must be <= rank of the tensor");
  const inputs = { input: $x };
  const attrs = { dim: axis };
  return ENGINE.runKernel(ExpandDims, inputs, attrs);
}
var expandDims;
var init_expand_dims = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/expand_dims.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    expandDims = /* @__PURE__ */ op({ expandDims_ });
  }
});
function expm1_(x) {
  const $x = convertToTensor(x, "x", "expm1");
  const inputs = { x: $x };
  return ENGINE.runKernel(Expm1, inputs);
}
var expm1;
var init_expm1 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/expm1.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    expm1 = /* @__PURE__ */ op({ expm1_ });
  }
});
function tile_(x, reps) {
  const $x = convertToTensor(x, "x", "tile", "string_or_numeric");
  assert($x.rank === reps.length, () => `Error in transpose: rank of input ${$x.rank} must match length of reps ${reps}.`);
  const inputs = { x: $x };
  const attrs = { reps };
  return ENGINE.runKernel(Tile, inputs, attrs);
}
var tile;
var init_tile = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tile.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    tile = /* @__PURE__ */ op({ tile_ });
  }
});
function eye_(numRows, numColumns, batchShape, dtype = "float32") {
  if (numColumns == null) {
    numColumns = numRows;
  }
  const buff = buffer([numRows, numColumns], dtype);
  const n = numRows <= numColumns ? numRows : numColumns;
  for (let i = 0; i < n; ++i) {
    buff.set(1, i, i);
  }
  const out = reshape(buff.toTensor(), [numRows, numColumns]);
  if (batchShape == null) {
    return out;
  } else {
    if (batchShape.length === 1) {
      return tile(expandDims(out, 0), [batchShape[0], 1, 1]);
    } else if (batchShape.length === 2) {
      return tile(expandDims(expandDims(out, 0), 0), [batchShape[0], batchShape[1], 1, 1]);
    } else if (batchShape.length === 3) {
      return tile(expandDims(expandDims(expandDims(out, 0), 0), 0), [
        batchShape[0],
        batchShape[1],
        batchShape[2],
        1,
        1
      ]);
    } else {
      throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${batchShape.length}D.`);
    }
  }
}
var eye;
var init_eye = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/eye.js"() {
    init_buffer();
    init_expand_dims();
    init_operation();
    init_reshape();
    init_tile();
    eye = /* @__PURE__ */ op({ eye_ });
  }
});
function floor_(x) {
  const $x = convertToTensor(x, "x", "floor", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Floor, inputs);
}
var floor2;
var init_floor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/floor.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    floor2 = /* @__PURE__ */ op({ floor_ });
  }
});
function gather_(x, indices, axis = 0, batchDims = 0) {
  const $x = convertToTensor(x, "x", "gather");
  const $indices = convertToTensor(indices, "indices", "gather", "int32");
  const inputs = { x: $x, indices: $indices };
  const attrs = { axis, batchDims };
  return ENGINE.runKernel(GatherV2, inputs, attrs);
}
var gather;
var init_gather = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/gather.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    gather = /* @__PURE__ */ op({ gather_ });
  }
});
function greater_(a, b) {
  let $a = convertToTensor(a, "a", "greater", "string_or_numeric");
  let $b = convertToTensor(b, "b", "greater", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Greater, inputs);
}
var greater;
var init_greater = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/greater.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    greater = /* @__PURE__ */ op({ greater_ });
  }
});
function greaterEqual_(a, b) {
  let $a = convertToTensor(a, "a", "greaterEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "greaterEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(GreaterEqual, inputs);
}
var greaterEqual;
var init_greater_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/greater_equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    greaterEqual = /* @__PURE__ */ op({ greaterEqual_ });
  }
});
function imag_(input2) {
  const $input = convertToTensor(input2, "input", "imag");
  const inputs = { input: $input };
  return ENGINE.runKernel(Imag, inputs);
}
var imag;
var init_imag = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/imag.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    imag = /* @__PURE__ */ op({ imag_ });
  }
});
function isFinite_(x) {
  const $x = convertToTensor(x, "x", "isFinite");
  const inputs = { x: $x };
  return ENGINE.runKernel(IsFinite, inputs);
}
var isFinite2;
var init_is_finite = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/is_finite.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    isFinite2 = /* @__PURE__ */ op({ isFinite_ });
  }
});
function isInf_(x) {
  const $x = convertToTensor(x, "x", "isInf");
  const inputs = { x: $x };
  return ENGINE.runKernel(IsInf, inputs);
}
var isInf;
var init_is_inf = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/is_inf.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    isInf = /* @__PURE__ */ op({ isInf_ });
  }
});
function isNaN_(x) {
  const $x = convertToTensor(x, "x", "isNaN");
  const inputs = { x: $x };
  return ENGINE.runKernel(IsNan, inputs);
}
var isNaN2;
var init_is_nan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/is_nan.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    isNaN2 = /* @__PURE__ */ op({ isNaN_ });
  }
});
function leakyRelu_(x, alpha = 0.2) {
  const $x = convertToTensor(x, "x", "leakyRelu");
  const inputs = { x: $x };
  const attrs = { alpha };
  return ENGINE.runKernel(LeakyRelu, inputs, attrs);
}
var leakyRelu;
var init_leaky_relu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/leaky_relu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    leakyRelu = /* @__PURE__ */ op({ leakyRelu_ });
  }
});
function less_(a, b) {
  let $a = convertToTensor(a, "a", "less", "string_or_numeric");
  let $b = convertToTensor(b, "b", "less", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Less, inputs);
}
var less;
var init_less = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/less.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    less = /* @__PURE__ */ op({ less_ });
  }
});
function lessEqual_(a, b) {
  let $a = convertToTensor(a, "a", "lessEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "lessEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(LessEqual, inputs);
}
var lessEqual;
var init_less_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/less_equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    lessEqual = /* @__PURE__ */ op({ lessEqual_ });
  }
});
function localResponseNormalization_(x, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
  const $x = convertToTensor(x, "x", "localResponseNormalization");
  assert($x.rank === 4 || $x.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${$x.rank}.`);
  assert(isInt(depthRadius), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${depthRadius}.`);
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  const inputs = { x: x4D };
  const attrs = { depthRadius, bias, alpha, beta };
  const res = ENGINE.runKernel(LRN, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  } else {
    return res;
  }
}
var localResponseNormalization;
var init_local_response_normalization = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    localResponseNormalization = /* @__PURE__ */ op({ localResponseNormalization_ });
  }
});
function log_(x) {
  const $x = convertToTensor(x, "x", "log", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Log, inputs);
}
var log2;
var init_log2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    log2 = /* @__PURE__ */ op({ log_ });
  }
});
function log1p_(x) {
  const $x = convertToTensor(x, "x", "log1p");
  const inputs = { x: $x };
  return ENGINE.runKernel(Log1p, inputs);
}
var log1p;
var init_log1p = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log1p.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    log1p = /* @__PURE__ */ op({ log1p_ });
  }
});
function variableGrads(f, varList) {
  assert(isFunction(f), () => "The f passed in variableGrads(f) must be a function");
  assert(varList == null || Array.isArray(varList) && varList.every((v) => v instanceof Variable), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  const specifiedVarList = varList != null;
  if (!specifiedVarList) {
    varList = [];
    for (const varName in ENGINE.registeredVariables) {
      varList.push(ENGINE.registeredVariables[varName]);
    }
  }
  const specifiedNonTrainable = specifiedVarList ? varList.filter((variable2) => !variable2.trainable) : null;
  const originalVarCount = varList.length;
  varList = varList.filter((variable2) => variable2.trainable);
  assert(varList.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${originalVarCount} variables is trainable.`);
  const allowNoGradients = true;
  const { value, grads } = ENGINE.gradients(f, varList, null, allowNoGradients);
  assert(grads.some((g) => g != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().");
  assert(value.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${value.rank} tensor`);
  const namedGrads = {};
  varList.forEach((v, i) => {
    if (grads[i] != null) {
      namedGrads[v.name] = grads[i];
    }
  });
  if (specifiedNonTrainable != null) {
    specifiedNonTrainable.forEach((v) => namedGrads[v.name] = null);
  }
  return { value, grads: namedGrads };
}
function customGrad(f) {
  return ENGINE.customGrad(f);
}
var init_gradients = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients.js"() {
    init_engine();
    init_tensor();
    init_util();
  }
});
function neg_(x) {
  const $x = convertToTensor(x, "x", "neg");
  const inputs = { x: $x };
  return ENGINE.runKernel(Neg, inputs);
}
var neg;
var init_neg = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/neg.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    neg = /* @__PURE__ */ op({ neg_ });
  }
});
function softplus_(x) {
  const $x = convertToTensor(x, "x", "softplus");
  const inputs = { x: $x };
  return ENGINE.runKernel(Softplus, inputs);
}
var softplus;
var init_softplus = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/softplus.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    softplus = /* @__PURE__ */ op({ softplus_ });
  }
});
function logSigmoid_(x) {
  const $x = convertToTensor(x, "x", "logSigmoid");
  const customOp = customGrad((x2) => {
    const value = neg(softplus(neg(x2)));
    const gradFunc = (dy) => {
      const derX = mul5(dy, sigmoid(neg(x2)));
      return derX;
    };
    return { value, gradFunc };
  });
  return customOp($x);
}
var logSigmoid;
var init_log_sigmoid = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log_sigmoid.js"() {
    init_gradients();
    init_tensor_util_env();
    init_mul();
    init_neg();
    init_operation();
    init_sigmoid();
    init_softplus();
    logSigmoid = /* @__PURE__ */ op({ logSigmoid_ });
  }
});
function sub_(a, b) {
  let $a = convertToTensor(a, "a", "sub");
  let $b = convertToTensor(b, "b", "sub");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Sub, inputs);
}
var sub3;
var init_sub = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sub.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    sub3 = /* @__PURE__ */ op({ sub_ });
  }
});
function logSoftmax_(logits, axis = -1) {
  const $logits = convertToTensor(logits, "logits", "logSoftmax");
  if (axis === -1) {
    axis = $logits.rank - 1;
  }
  if (axis !== $logits.rank - 1) {
    throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and axis was ${axis}`);
  }
  const customOp = customGrad((logits2, save) => {
    const keepDims = true;
    const xMax = max2(logits2, axis, true);
    const shifted = sub3(logits2, xMax);
    const value = sub3(cast(shifted, "float32"), log2(sum2(exp2(shifted), axis, keepDims)));
    save([value]);
    const gradFunc = (dy, saved) => {
      const [value2] = saved;
      const keepDims2 = true;
      const softmax4 = exp2(value2);
      return sub3(dy, mul5(sum2(dy, axis, keepDims2), softmax4));
    };
    return { value, gradFunc };
  });
  return customOp($logits);
}
var logSoftmax;
var init_log_softmax = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log_softmax.js"() {
    init_gradients();
    init_tensor_util_env();
    init_cast();
    init_exp();
    init_log2();
    init_max();
    init_mul();
    init_operation();
    init_sub();
    init_sum();
    logSoftmax = /* @__PURE__ */ op({ logSoftmax_ });
  }
});
function logSumExp_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "logSumExp");
  const axes = parseAxisParam(axis, $x.shape);
  const xMax = max2(
    $x,
    axes,
    true
    /* keepDims */
  );
  const a = sub3($x, xMax);
  const b = exp2(a);
  const c = sum2(b, axes);
  const d = log2(c);
  const res = add22(reshape(xMax, d.shape), d);
  if (keepDims) {
    const newShape = expandShapeToKeepDim(res.shape, axes);
    return reshape(res, newShape);
  }
  return res;
}
var logSumExp;
var init_log_sum_exp = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/log_sum_exp.js"() {
    init_tensor_util_env();
    init_util();
    init_add();
    init_axis_util();
    init_exp();
    init_log2();
    init_max();
    init_operation();
    init_reshape();
    init_sub();
    init_sum();
    logSumExp = /* @__PURE__ */ op({ logSumExp_ });
  }
});
function logicalAnd_(a, b) {
  const $a = convertToTensor(a, "a", "logicalAnd", "bool");
  const $b = convertToTensor(b, "b", "logicalAnd", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(LogicalAnd, inputs);
}
var logicalAnd;
var init_logical_and = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_and.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    logicalAnd = /* @__PURE__ */ op({ logicalAnd_ });
  }
});
function logicalNot_(x) {
  const $x = convertToTensor(x, "x", "logicalNot", "bool");
  const inputs = { x: $x };
  return ENGINE.runKernel(LogicalNot, inputs);
}
var logicalNot;
var init_logical_not = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_not.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    logicalNot = /* @__PURE__ */ op({ logicalNot_ });
  }
});
function logicalOr_(a, b) {
  const $a = convertToTensor(a, "a", "logicalOr", "bool");
  const $b = convertToTensor(b, "b", "logicalOr", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(LogicalOr, inputs);
}
var logicalOr;
var init_logical_or = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_or.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    logicalOr = /* @__PURE__ */ op({ logicalOr_ });
  }
});
function logicalXor_(a, b) {
  const $a = convertToTensor(a, "a", "logicalXor", "bool");
  const $b = convertToTensor(b, "b", "logicalXor", "bool");
  assertAndGetBroadcastShape($a.shape, $b.shape);
  return logicalAnd(logicalOr(a, b), logicalNot(logicalAnd(a, b)));
}
var logicalXor;
var init_logical_xor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/logical_xor.js"() {
    init_tensor_util_env();
    init_broadcast_util();
    init_logical_and();
    init_logical_not();
    init_logical_or();
    init_operation();
    logicalXor = /* @__PURE__ */ op({ logicalXor_ });
  }
});
var init_search_sorted = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/search_sorted.js"() {
    init_engine();
  }
});
function maxPool_(x, filterSize, strides, pad2, dimRoundingMode) {
  const $x = convertToTensor(x, "x", "maxPool");
  const dilations = 1;
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x4D.rank}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  checkPadOnDimRoundingMode("maxPool", pad2, dimRoundingMode);
  const inputs = { x: x4D };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
  const res = ENGINE.runKernel(MaxPool, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var maxPool;
var init_max_pool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    maxPool = /* @__PURE__ */ op({ maxPool_ });
  }
});
function maxPool3d_(x, filterSize = [1, 1, 1], strides, pad2, dimRoundingMode, dataFormat = "NDHWC") {
  const $x = convertToTensor(x, "x", "maxPool3d");
  let x5D = $x;
  let reshapedTo5D = false;
  if ($x.rank === 4) {
    reshapedTo5D = true;
    x5D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2], $x.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${x5D.rank}.`);
  assert(dataFormat === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${dataFormat}`);
  checkPadOnDimRoundingMode("maxPool3d", pad2, dimRoundingMode);
  const inputs = { x: x5D };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat };
  const res = ENGINE.runKernel(MaxPool3D, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var maxPool3d;
var init_max_pool_3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    maxPool3d = /* @__PURE__ */ op({ maxPool3d_ });
  }
});
function maximum_(a, b) {
  let $a = convertToTensor(a, "a", "maximum");
  let $b = convertToTensor(b, "b", "maximum");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "bool") {
    $a = cast($a, "int32");
    $b = cast($b, "int32");
  }
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Maximum, inputs);
}
var maximum;
var init_maximum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/maximum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_cast();
    init_operation();
    maximum = /* @__PURE__ */ op({ maximum_ });
  }
});
function mean_(x, axis = null, keepDims = false) {
  const $x = convertToTensor(x, "x", "mean");
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Mean, inputs, attrs);
}
var mean;
var init_mean = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mean.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    mean = /* @__PURE__ */ op({ mean_ });
  }
});
function zeros(shape, dtype = "float32") {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype === "complex64") {
    const real4 = zeros(shape, "float32");
    const imag4 = zeros(shape, "float32");
    return complex(real4, imag4);
  }
  const values = makeZerosTypedArray(sizeFromShape(shape), dtype);
  return ENGINE.makeTensor(values, shape, dtype);
}
var init_zeros = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/zeros.js"() {
    init_engine();
    init_util();
    init_complex();
  }
});
function ones2(shape, dtype = "float32") {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype === "complex64") {
    const real4 = ones2(shape, "float32");
    const imag4 = zeros(shape, "float32");
    return complex(real4, imag4);
  }
  const values = makeOnesTypedArray(sizeFromShape(shape), dtype);
  return ENGINE.makeTensor(values, shape, dtype);
}
var init_ones = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ones.js"() {
    init_engine();
    init_util();
    init_util_base();
    init_complex();
    init_zeros();
  }
});
function minimum_(a, b) {
  let $a = convertToTensor(a, "a", "minimum");
  let $b = convertToTensor(b, "b", "minimum");
  [$a, $b] = makeTypesMatch($a, $b);
  if ($a.dtype === "bool") {
    $a = cast($a, "int32");
    $b = cast($b, "int32");
  }
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Minimum, inputs);
}
var minimum;
var init_minimum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/minimum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_cast();
    init_operation();
    minimum = /* @__PURE__ */ op({ minimum_ });
  }
});
function mirrorPad_(x, paddings, mode) {
  assert(mode === "reflect" || mode === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${mode}.`);
  const $x = convertToTensor(x, "x", "mirrorPad");
  if ($x.rank === 0) {
    throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  }
  assert(paddings.length === $x.rank, () => `Padding doesn't match input. Must be ${$x.rank}. Got ${paddings.length}.`);
  const shapeOffset = mode === "reflect" ? 1 : 0;
  for (let i = 0; i < $x.rank; i++) {
    assert(paddings[i].length === 2, () => `Invalid number of paddings. Must be length of 2 each.`);
    assert(paddings[i][0] >= 0 && paddings[i][0] <= $x.shape[i] - shapeOffset && paddings[i][1] >= 0 && paddings[i][1] <= $x.shape[i] - shapeOffset, () => `Padding in dimension ${i} cannot be greater than or equal to ${$x.shape[i] - shapeOffset} or less than 0 for input of shape ${$x.shape}`);
  }
  const attrs = { paddings, mode };
  const inputs = { x: $x };
  return ENGINE.runKernel(MirrorPad, inputs, attrs);
}
var mirrorPad;
var init_mirror_pad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mirror_pad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    mirrorPad = /* @__PURE__ */ op({ mirrorPad_ });
  }
});
function mod_(a, b) {
  let $a = convertToTensor(a, "a", "mod");
  let $b = convertToTensor(b, "b", "mod");
  [$a, $b] = makeTypesMatch($a, $b);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(Mod, inputs);
}
var mod;
var init_mod = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/mod.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_operation();
    mod = /* @__PURE__ */ op({ mod_ });
  }
});
function moments_(x, axis = null, keepDims = false) {
  x = convertToTensor(x, "x", "moments");
  const axes = parseAxisParam(axis, x.shape);
  const xMean = mean(x, axes, keepDims);
  let keepDimsShape = xMean.shape;
  if (!keepDims) {
    keepDimsShape = expandShapeToKeepDim(xMean.shape, axes);
  }
  const devSquared = square(sub3(cast(x, "float32"), reshape(xMean, keepDimsShape)));
  const variance = mean(devSquared, axes, keepDims);
  return { mean: xMean, variance };
}
var moments;
var init_moments = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/moments.js"() {
    init_tensor_util_env();
    init_util();
    init_axis_util();
    init_cast();
    init_mean();
    init_operation();
    init_reshape();
    init_square();
    init_sub();
    moments = /* @__PURE__ */ op({ moments_ });
  }
});
function notEqual_(a, b) {
  let $a = convertToTensor(a, "a", "notEqual", "string_or_numeric");
  let $b = convertToTensor(b, "b", "notEqual", "string_or_numeric");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  return ENGINE.runKernel(NotEqual, inputs);
}
var notEqual;
var init_not_equal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/not_equal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    notEqual = /* @__PURE__ */ op({ notEqual_ });
  }
});
function oneHot_(indices, depth, onValue = 1, offValue = 0, dtype = "int32") {
  if (depth < 2) {
    throw new Error(`Error in oneHot: depth must be >=2, but it is ${depth}`);
  }
  const $indices = convertToTensor(indices, "indices", "oneHot", "int32");
  const inputs = { indices: $indices };
  const attrs = { dtype, depth, onValue, offValue };
  return ENGINE.runKernel(OneHot, inputs, attrs);
}
var oneHot;
var init_one_hot = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/one_hot.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    oneHot = /* @__PURE__ */ op({ oneHot_ });
  }
});
function onesLike_(x) {
  const $x = convertToTensor(x, "x", "onesLike");
  const inputs = { x: $x };
  return ENGINE.runKernel(OnesLike, inputs);
}
var onesLike;
var init_ones_like = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ones_like.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    onesLike = /* @__PURE__ */ op({ onesLike_ });
  }
});
function pad_(x, paddings, constantValue = 0) {
  const $x = convertToTensor(x, "x", "pad");
  if ($x.rank === 0) {
    throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  }
  const attrs = { paddings, constantValue };
  const inputs = { x: $x };
  return ENGINE.runKernel(PadV2, inputs, attrs);
}
var pad;
var init_pad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    pad = /* @__PURE__ */ op({ pad_ });
  }
});
function spaceToBatchND_(x, blockShape, paddings) {
  const $x = convertToTensor(x, "x", "spaceToBatchND");
  assert($x.rank >= 1 + blockShape.length, () => `input rank ${$x.rank} should be > than [blockShape] ${blockShape.length}`);
  assert(paddings.length === blockShape.length, () => `paddings.shape[0] ${paddings.length} must be equal to [blockShape] ${blockShape.length}`);
  assert($x.shape.reduce((a, b, i) => {
    if (i > 0 && i <= blockShape.length) {
      return a && (b + paddings[i - 1][0] + paddings[i - 1][1]) % blockShape[i - 1] === 0;
    }
    return a;
  }, true), () => `input spatial dimensions ${$x.shape.slice(1)} with paddings ${paddings.toString()} must be divisible by blockShapes ${blockShape.toString()}`);
  const inputs = { x: $x };
  const attrs = { blockShape, paddings };
  return ENGINE.runKernel(SpaceToBatchND, inputs, attrs);
}
var spaceToBatchND;
var init_space_to_batch_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    spaceToBatchND = /* @__PURE__ */ op({ spaceToBatchND_ });
  }
});
function pool_(input2, windowShape, poolingType, pad2, dilations, strides, dimRoundingMode) {
  if (dilations == null) {
    dilations = [1, 1];
  }
  if (strides == null) {
    strides = 1;
  }
  if (pad2 === 0) {
    pad2 = "valid";
  }
  const $x = convertToTensor(input2, "x", "maxPool");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in pool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = computePool2DInfo(x4D.shape, windowShape, strides, dilations, pad2);
  const dilation = [convInfo.dilationHeight, convInfo.dilationWidth];
  let basePadding;
  if (pad2 === "same") {
    basePadding = withSpaceToBatchBasePaddings([convInfo.filterHeight, convInfo.filterWidth], dilation);
  } else {
    basePadding = [[0, 0], [0, 0]];
  }
  const isDilationOne = dilation[0] === 1 && dilation[1] === 1;
  const [adjustedPadding, adjustedCrops] = requiredSpaceToBatchPaddings([convInfo.inHeight, convInfo.inWidth], dilation, basePadding);
  const convertedPad = isDilationOne ? pad2 : "valid";
  const convertedX = isDilationOne ? x4D : spaceToBatchND(x4D, dilation, adjustedPadding);
  const forwardOp = poolingType === "avg" ? () => avgPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode) : () => maxPool(convertedX, windowShape, strides, convertedPad, dimRoundingMode);
  const y = forwardOp();
  const res = isDilationOne ? y : batchToSpaceND(y, dilation, adjustedCrops);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
function requiredSpaceToBatchPaddings(inputShape, blockShape, basePadding) {
  const padStart = basePadding.map((b) => b[0]);
  const origPadEnd = basePadding.map((b) => b[1]);
  const fullInputShape = inputShape.concat(padStart, origPadEnd);
  const padEndExtra = blockShape.map((b, i) => (b - fullInputShape[i] % b) % b);
  const padEnd = origPadEnd.map((s, i) => s + padEndExtra[i]);
  const paddings = blockShape.map((_, i) => [padStart[i], padEnd[i]]);
  const crops = blockShape.map((_, i) => [0, padEndExtra[i]]);
  return [paddings, crops];
}
function withSpaceToBatchBasePaddings(filterShape, dilation) {
  const dilatedFilterShape = filterShape.map((s, i) => {
    return s + (s - 1) * (dilation[i] - 1);
  });
  const padExtraShape = dilatedFilterShape.map((s) => s - 1);
  const padExtraStart = padExtraShape.map((s) => Math.floor(s / 2));
  const padExtraEnd = padExtraShape.map((s, i) => s - padExtraStart[i]);
  return padExtraShape.map((_, i) => {
    return [padExtraStart[i], padExtraEnd[i]];
  });
}
var pool;
var init_pool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/pool.js"() {
    init_tensor_util_env();
    init_util();
    init_avg_pool();
    init_batch_to_space_nd();
    init_conv_util();
    init_max_pool();
    init_operation();
    init_reshape();
    init_space_to_batch_nd();
    pool = /* @__PURE__ */ op({ pool_ });
  }
});
function prelu_(x, alpha) {
  const $x = convertToTensor(x, "x", "prelu");
  const $alpha = convertToTensor(alpha, "alpha", "prelu");
  const inputs = { x: $x, alpha: $alpha };
  return ENGINE.runKernel(Prelu, inputs);
}
var prelu;
var init_prelu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/prelu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    prelu = /* @__PURE__ */ op({ prelu_ });
  }
});
function prod_(x, axis = null, keepDims = false) {
  let $x = convertToTensor(x, "x", "prod");
  if ($x.dtype === "bool") {
    $x = cast($x, "int32");
  }
  const inputs = { x: $x };
  const attrs = { axis, keepDims };
  return ENGINE.runKernel(Prod, inputs, attrs);
}
var prod;
var init_prod = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/prod.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_cast();
    init_operation();
    prod = /* @__PURE__ */ op({ prod_ });
  }
});
var require_alea = __commonJS({
  "node_modules/seedrandom/lib/alea.js"(exports, module) {
    (function(global2, module2, define2) {
      function Alea(seed) {
        var me = this, mash = Mash();
        me.next = function() {
          var t = 2091639 * me.s0 + me.c * 23283064365386963e-26;
          me.s0 = me.s1;
          me.s1 = me.s2;
          return me.s2 = t - (me.c = t | 0);
        };
        me.c = 1;
        me.s0 = mash(" ");
        me.s1 = mash(" ");
        me.s2 = mash(" ");
        me.s0 -= mash(seed);
        if (me.s0 < 0) {
          me.s0 += 1;
        }
        me.s1 -= mash(seed);
        if (me.s1 < 0) {
          me.s1 += 1;
        }
        me.s2 -= mash(seed);
        if (me.s2 < 0) {
          me.s2 += 1;
        }
        mash = null;
      }
      function copy6(f, t) {
        t.c = f.c;
        t.s0 = f.s0;
        t.s1 = f.s1;
        t.s2 = f.s2;
        return t;
      }
      function impl(seed, opts) {
        var xg = new Alea(seed), state = opts && opts.state, prng = xg.next;
        prng.int32 = function() {
          return xg.next() * 4294967296 | 0;
        };
        prng.double = function() {
          return prng() + (prng() * 2097152 | 0) * 11102230246251565e-32;
        };
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy6(state, xg);
          prng.state = function() {
            return copy6(xg, {});
          };
        }
        return prng;
      }
      function Mash() {
        var n = 4022871197;
        var mash = function(data) {
          data = String(data);
          for (var i = 0; i < data.length; i++) {
            n += data.charCodeAt(i);
            var h = 0.02519603282416938 * n;
            n = h >>> 0;
            h -= n;
            h *= n;
            n = h >>> 0;
            h -= n;
            n += h * 4294967296;
          }
          return (n >>> 0) * 23283064365386963e-26;
        };
        return mash;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.alea = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});
var require_xor128 = __commonJS({
  "node_modules/seedrandom/lib/xor128.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.next = function() {
          var t = me.x ^ me.x << 11;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          return me.w ^= me.w >>> 19 ^ t ^ t >>> 8;
        };
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy6(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy6(state, xg);
          prng.state = function() {
            return copy6(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor128 = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});
var require_xorwow = __commonJS({
  "node_modules/seedrandom/lib/xorwow.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var t = me.x ^ me.x >>> 2;
          me.x = me.y;
          me.y = me.z;
          me.z = me.w;
          me.w = me.v;
          return (me.d = me.d + 362437 | 0) + (me.v = me.v ^ me.v << 4 ^ (t ^ t << 1)) | 0;
        };
        me.x = 0;
        me.y = 0;
        me.z = 0;
        me.w = 0;
        me.v = 0;
        if (seed === (seed | 0)) {
          me.x = seed;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 64; k++) {
          me.x ^= strseed.charCodeAt(k) | 0;
          if (k == strseed.length) {
            me.d = me.x << 10 ^ me.x >>> 4;
          }
          me.next();
        }
      }
      function copy6(f, t) {
        t.x = f.x;
        t.y = f.y;
        t.z = f.z;
        t.w = f.w;
        t.v = f.v;
        t.d = f.d;
        return t;
      }
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy6(state, xg);
          prng.state = function() {
            return copy6(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorwow = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});
var require_xorshift7 = __commonJS({
  "node_modules/seedrandom/lib/xorshift7.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var X = me.x, i = me.i, t, v, w;
          t = X[i];
          t ^= t >>> 7;
          v = t ^ t << 24;
          t = X[i + 1 & 7];
          v ^= t ^ t >>> 10;
          t = X[i + 3 & 7];
          v ^= t ^ t >>> 3;
          t = X[i + 4 & 7];
          v ^= t ^ t << 7;
          t = X[i + 7 & 7];
          t = t ^ t << 13;
          v ^= t ^ t << 9;
          X[i] = v;
          me.i = i + 1 & 7;
          return v;
        };
        function init(me2, seed2) {
          var j, w, X = [];
          if (seed2 === (seed2 | 0)) {
            w = X[0] = seed2;
          } else {
            seed2 = "" + seed2;
            for (j = 0; j < seed2.length; ++j) {
              X[j & 7] = X[j & 7] << 15 ^ seed2.charCodeAt(j) + X[j + 1 & 7] << 13;
            }
          }
          while (X.length < 8)
            X.push(0);
          for (j = 0; j < 8 && X[j] === 0; ++j)
            ;
          if (j == 8)
            w = X[7] = -1;
          else
            w = X[j];
          me2.x = X;
          me2.i = 0;
          for (j = 256; j > 0; --j) {
            me2.next();
          }
        }
        init(me, seed);
      }
      function copy6(f, t) {
        t.x = f.x.slice();
        t.i = f.i;
        return t;
      }
      function impl(seed, opts) {
        if (seed == null)
          seed = +/* @__PURE__ */ new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.x)
            copy6(state, xg);
          prng.state = function() {
            return copy6(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xorshift7 = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});
var require_xor4096 = __commonJS({
  "node_modules/seedrandom/lib/xor4096.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this;
        me.next = function() {
          var w = me.w, X = me.X, i = me.i, t, v;
          me.w = w = w + 1640531527 | 0;
          v = X[i + 34 & 127];
          t = X[i = i + 1 & 127];
          v ^= v << 13;
          t ^= t << 17;
          v ^= v >>> 15;
          t ^= t >>> 12;
          v = X[i] = v ^ t;
          me.i = i;
          return v + (w ^ w >>> 16) | 0;
        };
        function init(me2, seed2) {
          var t, v, i, j, w, X = [], limit = 128;
          if (seed2 === (seed2 | 0)) {
            v = seed2;
            seed2 = null;
          } else {
            seed2 = seed2 + "\0";
            v = 0;
            limit = Math.max(limit, seed2.length);
          }
          for (i = 0, j = -32; j < limit; ++j) {
            if (seed2)
              v ^= seed2.charCodeAt((j + 32) % seed2.length);
            if (j === 0)
              w = v;
            v ^= v << 10;
            v ^= v >>> 15;
            v ^= v << 4;
            v ^= v >>> 13;
            if (j >= 0) {
              w = w + 1640531527 | 0;
              t = X[j & 127] ^= v + w;
              i = 0 == t ? i + 1 : 0;
            }
          }
          if (i >= 128) {
            X[(seed2 && seed2.length || 0) & 127] = -1;
          }
          i = 127;
          for (j = 4 * 128; j > 0; --j) {
            v = X[i + 34 & 127];
            t = X[i = i + 1 & 127];
            v ^= v << 13;
            t ^= t << 17;
            v ^= v >>> 15;
            t ^= t >>> 12;
            X[i] = v ^ t;
          }
          me2.w = w;
          me2.X = X;
          me2.i = i;
        }
        init(me, seed);
      }
      function copy6(f, t) {
        t.i = f.i;
        t.w = f.w;
        t.X = f.X.slice();
        return t;
      }
      ;
      function impl(seed, opts) {
        if (seed == null)
          seed = +/* @__PURE__ */ new Date();
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (state.X)
            copy6(state, xg);
          prng.state = function() {
            return copy6(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.xor4096 = impl;
      }
    })(
      exports,
      // window object or global
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});
var require_tychei = __commonJS({
  "node_modules/seedrandom/lib/tychei.js"(exports, module) {
    (function(global2, module2, define2) {
      function XorGen(seed) {
        var me = this, strseed = "";
        me.next = function() {
          var b = me.b, c = me.c, d = me.d, a = me.a;
          b = b << 25 ^ b >>> 7 ^ c;
          c = c - d | 0;
          d = d << 24 ^ d >>> 8 ^ a;
          a = a - b | 0;
          me.b = b = b << 20 ^ b >>> 12 ^ c;
          me.c = c = c - d | 0;
          me.d = d << 16 ^ c >>> 16 ^ a;
          return me.a = a - b | 0;
        };
        me.a = 0;
        me.b = 0;
        me.c = 2654435769 | 0;
        me.d = 1367130551;
        if (seed === Math.floor(seed)) {
          me.a = seed / 4294967296 | 0;
          me.b = seed | 0;
        } else {
          strseed += seed;
        }
        for (var k = 0; k < strseed.length + 20; k++) {
          me.b ^= strseed.charCodeAt(k) | 0;
          me.next();
        }
      }
      function copy6(f, t) {
        t.a = f.a;
        t.b = f.b;
        t.c = f.c;
        t.d = f.d;
        return t;
      }
      ;
      function impl(seed, opts) {
        var xg = new XorGen(seed), state = opts && opts.state, prng = function() {
          return (xg.next() >>> 0) / 4294967296;
        };
        prng.double = function() {
          do {
            var top = xg.next() >>> 11, bot = (xg.next() >>> 0) / 4294967296, result = (top + bot) / (1 << 21);
          } while (result === 0);
          return result;
        };
        prng.int32 = xg.next;
        prng.quick = prng;
        if (state) {
          if (typeof state == "object")
            copy6(state, xg);
          prng.state = function() {
            return copy6(xg, {});
          };
        }
        return prng;
      }
      if (module2 && module2.exports) {
        module2.exports = impl;
      } else if (define2 && define2.amd) {
        define2(function() {
          return impl;
        });
      } else {
        this.tychei = impl;
      }
    })(
      exports,
      typeof module == "object" && module,
      // present in node.js
      typeof define == "function" && define
      // present with an AMD loader
    );
  }
});
var require_crypto = __commonJS({
  "(disabled):crypto"() {
  }
});
var require_seedrandom = __commonJS({
  "node_modules/seedrandom/seedrandom.js"(exports, module) {
    (function(global2, pool3, math2) {
      var width = 256, chunks = 6, digits = 52, rngname = "random", startdenom = math2.pow(width, chunks), significance = math2.pow(2, digits), overflow = significance * 2, mask = width - 1, nodecrypto;
      function seedrandom5(seed, options, callback) {
        var key = [];
        options = options == true ? { entropy: true } : options || {};
        var shortseed = mixkey(flatten3(
          options.entropy ? [seed, tostring(pool3)] : seed == null ? autoseed() : seed,
          3
        ), key);
        var arc4 = new ARC4(key);
        var prng = function() {
          var n = arc4.g(chunks), d = startdenom, x = 0;
          while (n < significance) {
            n = (n + x) * width;
            d *= width;
            x = arc4.g(1);
          }
          while (n >= overflow) {
            n /= 2;
            d /= 2;
            x >>>= 1;
          }
          return (n + x) / d;
        };
        prng.int32 = function() {
          return arc4.g(4) | 0;
        };
        prng.quick = function() {
          return arc4.g(4) / 4294967296;
        };
        prng.double = prng;
        mixkey(tostring(arc4.S), pool3);
        return (options.pass || callback || function(prng2, seed2, is_math_call, state) {
          if (state) {
            if (state.S) {
              copy6(state, arc4);
            }
            prng2.state = function() {
              return copy6(arc4, {});
            };
          }
          if (is_math_call) {
            math2[rngname] = prng2;
            return seed2;
          } else
            return prng2;
        })(
          prng,
          shortseed,
          "global" in options ? options.global : this == math2,
          options.state
        );
      }
      function ARC4(key) {
        var t, keylen = key.length, me = this, i = 0, j = me.i = me.j = 0, s = me.S = [];
        if (!keylen) {
          key = [keylen++];
        }
        while (i < width) {
          s[i] = i++;
        }
        for (i = 0; i < width; i++) {
          s[i] = s[j = mask & j + key[i % keylen] + (t = s[i])];
          s[j] = t;
        }
        (me.g = function(count2) {
          var t2, r = 0, i2 = me.i, j2 = me.j, s2 = me.S;
          while (count2--) {
            t2 = s2[i2 = mask & i2 + 1];
            r = r * width + s2[mask & (s2[i2] = s2[j2 = mask & j2 + t2]) + (s2[j2] = t2)];
          }
          me.i = i2;
          me.j = j2;
          return r;
        })(width);
      }
      function copy6(f, t) {
        t.i = f.i;
        t.j = f.j;
        t.S = f.S.slice();
        return t;
      }
      ;
      function flatten3(obj, depth) {
        var result = [], typ = typeof obj, prop;
        if (depth && typ == "object") {
          for (prop in obj) {
            try {
              result.push(flatten3(obj[prop], depth - 1));
            } catch (e) {
            }
          }
        }
        return result.length ? result : typ == "string" ? obj : obj + "\0";
      }
      function mixkey(seed, key) {
        var stringseed = seed + "", smear, j = 0;
        while (j < stringseed.length) {
          key[mask & j] = mask & (smear ^= key[mask & j] * 19) + stringseed.charCodeAt(j++);
        }
        return tostring(key);
      }
      function autoseed() {
        try {
          var out;
          if (nodecrypto && (out = nodecrypto.randomBytes)) {
            out = out(width);
          } else {
            out = new Uint8Array(width);
            (global2.crypto || global2.msCrypto).getRandomValues(out);
          }
          return tostring(out);
        } catch (e) {
          var browser = global2.navigator, plugins = browser && browser.plugins;
          return [+/* @__PURE__ */ new Date(), global2, plugins, global2.screen, tostring(pool3)];
        }
      }
      function tostring(a) {
        return String.fromCharCode.apply(0, a);
      }
      mixkey(math2.random(), pool3);
      if (typeof module == "object" && module.exports) {
        module.exports = seedrandom5;
        try {
          nodecrypto = require_crypto();
        } catch (ex) {
        }
      } else if (typeof define == "function" && define.amd) {
        define(function() {
          return seedrandom5;
        });
      } else {
        math2["seed" + rngname] = seedrandom5;
      }
    })(
      // global: `self` in browsers (including strict mode and web workers),
      // otherwise `this` in Node and other environments
      typeof self !== "undefined" ? self : exports,
      [],
      // pool: entropy pool starts empty
      Math
      // math: package containing random, pow, and seedrandom
    );
  }
});
var require_seedrandom2 = __commonJS({
  "node_modules/seedrandom/index.js"(exports, module) {
    var alea5 = require_alea();
    var xor128 = require_xor128();
    var xorwow = require_xorwow();
    var xorshift7 = require_xorshift7();
    var xor4096 = require_xor4096();
    var tychei = require_tychei();
    var sr = require_seedrandom();
    sr.alea = alea5;
    sr.xor128 = xor128;
    sr.xorwow = xorwow;
    sr.xorshift7 = xorshift7;
    sr.xor4096 = xor4096;
    sr.tychei = tychei;
    module.exports = sr;
  }
});
var seedrandom;
var MPRandGauss;
var UniformRandom;
var init_rand_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rand_util.js"() {
    seedrandom = __toESM(require_seedrandom2());
    MPRandGauss = class {
      constructor(mean3, stdDeviation, dtype, truncated, seed) {
        this.mean = mean3;
        this.stdDev = stdDeviation;
        this.dtype = dtype;
        this.nextVal = NaN;
        this.truncated = truncated;
        if (this.truncated) {
          this.upper = this.mean + this.stdDev * 2;
          this.lower = this.mean - this.stdDev * 2;
        }
        const seedValue = seed ? seed : Math.random();
        this.random = seedrandom.alea(seedValue.toString());
      }
      /** Returns next sample from a Gaussian distribution. */
      nextValue() {
        if (!isNaN(this.nextVal)) {
          const value = this.nextVal;
          this.nextVal = NaN;
          return value;
        }
        let resultX, resultY;
        let isValid = false;
        while (!isValid) {
          let v1, v2, s;
          do {
            v1 = 2 * this.random() - 1;
            v2 = 2 * this.random() - 1;
            s = v1 * v1 + v2 * v2;
          } while (s >= 1 || s === 0);
          const mul22 = Math.sqrt(-2 * Math.log(s) / s);
          resultX = this.mean + this.stdDev * v1 * mul22;
          resultY = this.mean + this.stdDev * v2 * mul22;
          if (!this.truncated || this.isValidTruncated(resultX)) {
            isValid = true;
          }
        }
        if (!this.truncated || this.isValidTruncated(resultY)) {
          this.nextVal = this.convertValue(resultY);
        }
        return this.convertValue(resultX);
      }
      /** Handles proper rounding for non-floating-point numbers. */
      convertValue(value) {
        if (this.dtype == null || this.dtype === "float32") {
          return value;
        }
        return Math.round(value);
      }
      /** Returns true if less than 2-standard-deviations from the mean. */
      isValidTruncated(value) {
        return value <= this.upper && value >= this.lower;
      }
    };
    UniformRandom = class {
      constructor(min5 = 0, max5 = 1, dtype, seed) {
        this.canReturnFloat = () => this.dtype == null || this.dtype === "float32";
        this.min = min5;
        this.range = max5 - min5;
        this.dtype = dtype;
        if (seed == null) {
          seed = Math.random();
        }
        if (typeof seed === "number") {
          seed = seed.toString();
        }
        if (!this.canReturnFloat() && this.range <= 1) {
          throw new Error(`The difference between ${min5} - ${max5} <= 1 and dtype is not float`);
        }
        this.random = seedrandom.alea(seed);
      }
      convertValue(value) {
        if (this.canReturnFloat()) {
          return value;
        }
        return Math.round(value);
      }
      nextValue() {
        return this.convertValue(this.min + this.range * this.random());
      }
    };
  }
});
function randomNormal_(shape, mean3 = 0, stdDev = 1, dtype, seed) {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type ${dtype}`);
  }
  const randGauss = new MPRandGauss(mean3, stdDev, dtype, false, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var randomNormal;
var init_random_normal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_normal.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    randomNormal = /* @__PURE__ */ op({ randomNormal_ });
  }
});
function randomUniform_(shape, minval = 0, maxval = 1, dtype = "float32", seed) {
  assertNonNegativeIntegerDimensions(shape);
  const res = buffer(shape, dtype);
  const random3 = new UniformRandom(minval, maxval, null, seed);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = random3.nextValue();
  }
  return res.toTensor();
}
var randomUniform;
var init_random_uniform = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/random_uniform.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    randomUniform = /* @__PURE__ */ op({ randomUniform_ });
  }
});
function range(start, stop, step4 = 1, dtype = "float32") {
  if (step4 === 0) {
    throw new Error("Cannot have a step of zero");
  }
  const attrs = { start, stop, step: step4, dtype };
  return ENGINE.runKernel(Range, {}, attrs);
}
var init_range = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/range.js"() {
    init_engine();
    init_kernel_names();
  }
});
function real_(input2) {
  const $input = convertToTensor(input2, "input", "real");
  const inputs = { input: $input };
  return ENGINE.runKernel(Real, inputs);
}
var real;
var init_real = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/real.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    real = /* @__PURE__ */ op({ real_ });
  }
});
function reciprocal_(x) {
  const $x = convertToTensor(x, "x", "reciprocal");
  const inputs = { x: $x };
  return ENGINE.runKernel(Reciprocal, inputs);
}
var reciprocal;
var init_reciprocal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reciprocal.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    reciprocal = /* @__PURE__ */ op({ reciprocal_ });
  }
});
function relu_(x) {
  const $x = convertToTensor(x, "x", "relu");
  const inputs = { x: $x };
  return ENGINE.runKernel(Relu, inputs);
}
var relu;
var init_relu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/relu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    relu = /* @__PURE__ */ op({ relu_ });
  }
});
function relu6_(x) {
  const $x = convertToTensor(x, "x", "relu6");
  const inputs = { x: $x };
  return ENGINE.runKernel(Relu6, inputs);
}
var relu6;
var init_relu6 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/relu6.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    relu6 = /* @__PURE__ */ op({ relu6_ });
  }
});
function reverse_(x, axis) {
  const $x = convertToTensor(x, "x", "reverse");
  const inputs = { x: $x };
  const attrs = { dims: axis };
  return ENGINE.runKernel(Reverse, inputs, attrs);
}
var reverse;
var init_reverse = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reverse.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    reverse = /* @__PURE__ */ op({ reverse_ });
  }
});
function round_(x) {
  const $x = convertToTensor(x, "x", "round");
  const inputs = { x: $x };
  return ENGINE.runKernel(Round, inputs);
}
var round22;
var init_round = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/round.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    round22 = /* @__PURE__ */ op({ round_ });
  }
});
function rsqrt_(x) {
  const $x = convertToTensor(x, "x", "rsqrt", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Rsqrt, inputs);
}
var rsqrt;
var init_rsqrt = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rsqrt.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    rsqrt = /* @__PURE__ */ op({ rsqrt_ });
  }
});
function selu_(x) {
  const $x = convertToTensor(x, "x", "selu");
  const inputs = { x: $x };
  return ENGINE.runKernel(Selu, inputs);
}
var selu;
var init_selu = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/selu.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    selu = /* @__PURE__ */ op({ selu_ });
  }
});
function separableConv2d_(x, depthwiseFilter, pointwiseFilter, strides, pad2, dilation = [1, 1], dataFormat = "NHWC") {
  const $x = convertToTensor(x, "x", "separableConv2d");
  const $depthwiseFilter = convertToTensor(depthwiseFilter, "depthwiseFilter", "separableConv2d");
  const $pointwiseFilter = convertToTensor(pointwiseFilter, "pointwiseFilter", "separableConv2d");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  if (dataFormat === "NCHW") {
    throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  }
  assert(x4D.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($depthwiseFilter.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert($pointwiseFilter.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${$depthwiseFilter.rank}.`);
  assert($pointwiseFilter.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${$pointwiseFilter.shape[0]}.`);
  assert($pointwiseFilter.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${$pointwiseFilter.shape[1]}.`);
  const inChannels = $depthwiseFilter.shape[2];
  const channelMultiplier = $depthwiseFilter.shape[3];
  assert($pointwiseFilter.shape[2] === inChannels * channelMultiplier, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${inChannels * channelMultiplier}, but got ${$pointwiseFilter.shape[2]}.`);
  const depthwise = depthwiseConv2d(x4D, $depthwiseFilter, strides, pad2, dataFormat, dilation);
  const pointwiseStride = 1;
  const res = conv2d(depthwise, $pointwiseFilter, pointwiseStride, "valid", dataFormat);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var separableConv2d;
var init_separable_conv2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/separable_conv2d.js"() {
    init_tensor_util_env();
    init_util();
    init_conv2d();
    init_depthwise_conv2d();
    init_operation();
    init_reshape();
    separableConv2d = /* @__PURE__ */ op({ separableConv2d_ });
  }
});
function sign_(x) {
  const $x = convertToTensor(x, "x", "sign");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sign, inputs);
}
var sign;
var init_sign = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sign.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sign = /* @__PURE__ */ op({ sign_ });
  }
});
function sin_(x) {
  const $x = convertToTensor(x, "x", "sin", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sin, inputs);
}
var sin;
var init_sin = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sin.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sin = /* @__PURE__ */ op({ sin_ });
  }
});
function sinh_(x) {
  const $x = convertToTensor(x, "x", "sinh");
  const inputs = { x: $x };
  return ENGINE.runKernel(Sinh, inputs);
}
var sinh;
var init_sinh = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sinh.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    sinh = /* @__PURE__ */ op({ sinh_ });
  }
});
function slice1d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice1d");
  assert($x.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, [begin], [size]);
}
var slice1d;
var init_slice1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice1d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice1d = /* @__PURE__ */ op({ slice1d_ });
  }
});
function slice2d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice2d");
  assert($x.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice2d;
var init_slice2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice2d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice2d = /* @__PURE__ */ op({ slice2d_ });
  }
});
function slice3d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice3d");
  assert($x.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice3d;
var init_slice3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice3d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice3d = /* @__PURE__ */ op({ slice3d_ });
  }
});
function slice4d_(x, begin, size) {
  const $x = convertToTensor(x, "x", "slice4d");
  assert($x.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${$x.rank} tensor`);
  return slice($x, begin, size);
}
var slice4d;
var init_slice4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice4d.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_slice();
    slice4d = /* @__PURE__ */ op({ slice4d_ });
  }
});
function softmax_(logits, dim = -1) {
  const $logits = convertToTensor(logits, "logits", "softmax", "float32");
  if (dim === -1) {
    dim = $logits.rank - 1;
  }
  if (dim !== $logits.rank - 1) {
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${$logits.rank} and dim was ${dim}`);
  }
  const inputs = { logits: $logits };
  const attrs = { dim };
  return ENGINE.runKernel(Softmax, inputs, attrs);
}
var softmax;
var init_softmax = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/softmax.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    softmax = /* @__PURE__ */ op({ softmax_ });
  }
});
function fft_(input2) {
  assert(input2.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${input2.dtype}.`);
  const inputs = { input: input2 };
  return ENGINE.runKernel(FFT, inputs);
}
var fft;
var init_fft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/fft.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    fft = /* @__PURE__ */ op({ fft_ });
  }
});
function ifft_(input2) {
  assert(input2.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${input2.dtype}.`);
  const inputs = { input: input2 };
  return ENGINE.runKernel(IFFT, inputs);
}
var ifft;
var init_ifft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/ifft.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    ifft = /* @__PURE__ */ op({ ifft_ });
  }
});
function irfft_(input2) {
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = input2.size / innerDimensionSize;
  let ret;
  if (innerDimensionSize <= 2) {
    const complexInput = reshape(input2, [batch, innerDimensionSize]);
    ret = ifft(complexInput);
  } else {
    const outputShape = [batch, 2 * (innerDimensionSize - 1)];
    const realInput = reshape(real(input2), [batch, innerDimensionSize]);
    const imagInput = reshape(imag(input2), [batch, innerDimensionSize]);
    const realConjugate = reverse(slice(realInput, [0, 1], [batch, innerDimensionSize - 2]), 1);
    const imagConjugate = mul5(reverse(slice(imagInput, [0, 1], [batch, innerDimensionSize - 2]), 1), scalar(-1));
    const r = concat([realInput, realConjugate], 1);
    const i = concat([imagInput, imagConjugate], 1);
    const complexInput = reshape(complex(r, i), [outputShape[0], outputShape[1]]);
    ret = ifft(complexInput);
  }
  ret = real(ret);
  if (input2.rank === 3 && input2.shape[0] !== 0) {
    const temp = ret;
    const batch2 = input2.shape[0];
    ret = reshape(ret, [batch2, ret.shape[0] / batch2, ret.shape[1]]);
    temp.dispose();
  }
  return ret;
}
var irfft;
var init_irfft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/irfft.js"() {
    init_complex();
    init_concat();
    init_imag();
    init_mul();
    init_operation();
    init_real();
    init_reshape();
    init_reverse();
    init_scalar();
    init_slice();
    init_ifft();
    irfft = /* @__PURE__ */ op({ irfft_ });
  }
});
function split_(x, numOrSizeSplits, axis = 0) {
  const $x = convertToTensor(x, "x", "split");
  const inputs = { x: $x };
  const attr = { numOrSizeSplits, axis };
  return ENGINE.runKernel(SplitV, inputs, attr);
}
var split;
var init_split = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/split.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    split = /* @__PURE__ */ op({ split_ });
  }
});
function rfft_(input2, fftLength) {
  assert(input2.dtype === "float32", () => `The dtype for rfft() must be real value but got ${input2.dtype}`);
  let innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = input2.size / innerDimensionSize;
  let adjustedInput;
  if (fftLength != null && fftLength < innerDimensionSize) {
    const begin = input2.shape.map((v) => 0);
    const size = input2.shape.map((v) => v);
    size[input2.shape.length - 1] = fftLength;
    adjustedInput = slice(input2, begin, size);
    innerDimensionSize = fftLength;
  } else if (fftLength != null && fftLength > innerDimensionSize) {
    const zerosShape = input2.shape.map((v) => v);
    zerosShape[input2.shape.length - 1] = fftLength - innerDimensionSize;
    adjustedInput = concat([input2, zeros(zerosShape)], input2.shape.length - 1);
    innerDimensionSize = fftLength;
  } else {
    adjustedInput = input2;
  }
  const zerosInput = zerosLike(adjustedInput);
  const complexInput = reshape(complex(adjustedInput, zerosInput), [batch, innerDimensionSize]);
  const ret = fft(complexInput);
  const half = Math.floor(innerDimensionSize / 2) + 1;
  const realValues = real(ret);
  const imagValues = imag(ret);
  const realComplexConjugate = split(realValues, [half, innerDimensionSize - half], realValues.shape.length - 1);
  const imagComplexConjugate = split(imagValues, [half, innerDimensionSize - half], imagValues.shape.length - 1);
  const outputShape = adjustedInput.shape.slice();
  outputShape[adjustedInput.shape.length - 1] = half;
  return reshape(complex(realComplexConjugate[0], imagComplexConjugate[0]), outputShape);
}
var rfft;
var init_rfft = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/spectral/rfft.js"() {
    init_util();
    init_complex();
    init_concat();
    init_imag();
    init_operation();
    init_real();
    init_reshape();
    init_slice();
    init_split();
    init_zeros();
    init_zeros_like();
    init_fft();
    rfft = /* @__PURE__ */ op({ rfft_ });
  }
});
function squaredDifference_(a, b) {
  let $a = convertToTensor(a, "a", "squaredDifference");
  let $b = convertToTensor(b, "b", "squaredDifference");
  [$a, $b] = makeTypesMatch($a, $b);
  assertAndGetBroadcastShape($a.shape, $b.shape);
  const inputs = { a: $a, b: $b };
  const attrs = {};
  return ENGINE.runKernel(SquaredDifference, inputs, attrs);
}
var squaredDifference;
var init_squared_difference = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/squared_difference.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_broadcast_util();
    init_operation();
    squaredDifference = /* @__PURE__ */ op({ squaredDifference_ });
  }
});
function squeeze_(x, axis) {
  const $x = convertToTensor(x, "x", "squeeze", "string_or_numeric");
  return reshape($x, squeezeShape($x.shape, axis).newShape);
}
var squeeze;
var init_squeeze = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/squeeze.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    squeeze = /* @__PURE__ */ op({ squeeze_ });
  }
});
function stack_(tensors, axis = 0) {
  const $tensors = convertToTensorArray(tensors, "tensors", "stack", "string_or_numeric");
  assert($tensors.length >= 1, () => "Pass at least one tensor to tf.stack");
  if ($tensors.length > 0) {
    assert(axis <= $tensors[0].rank, () => "Axis must be <= rank of the tensor");
  }
  const inputs = $tensors;
  const attrs = { axis };
  return ENGINE.runKernel(Pack, inputs, attrs);
}
var stack;
var init_stack = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/stack.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    stack = /* @__PURE__ */ op({ stack_ });
  }
});
function step_(x, alpha = 0) {
  const $x = convertToTensor(x, "x", "step");
  const inputs = { x: $x };
  const attrs = { alpha };
  return ENGINE.runKernel(Step, inputs, attrs);
}
var step;
var init_step = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/step.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    step = /* @__PURE__ */ op({ step_ });
  }
});
function stridedSlice_(x, begin, end, strides, beginMask = 0, endMask = 0, ellipsisMask = 0, newAxisMask = 0, shrinkAxisMask = 0) {
  const $x = convertToTensor(x, "x", "stridedSlice", "string_or_numeric");
  const inputs = { x: $x };
  const attrs = {
    begin,
    end,
    strides,
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  };
  return ENGINE.runKernel(StridedSlice, inputs, attrs);
}
var stridedSlice;
var init_strided_slice = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/strided_slice.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    stridedSlice = /* @__PURE__ */ op({ stridedSlice_ });
  }
});
function tan_(x) {
  const $x = convertToTensor(x, "x", "tan", "float32");
  const inputs = { x: $x };
  return ENGINE.runKernel(Tan, inputs);
}
var tan;
var init_tan = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tan.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    tan = /* @__PURE__ */ op({ tan_ });
  }
});
function tensor1d(values, dtype) {
  assertNonNull(values);
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 1) {
    throw new Error("tensor1d() requires values to be a flat/TypedArray");
  }
  const shape = null;
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor1d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});
function tensor2d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 2) {
    throw new Error("tensor2d() requires shape to have two numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 2 && inferredShape.length !== 1) {
    throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor2d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});
function tensor3d(values, shape, dtype) {
  assertNonNull(values);
  if (shape != null && shape.length !== 3) {
    throw new Error("tensor3d() requires shape to have three numbers");
  }
  const inferredShape = inferShape(values, dtype);
  if (inferredShape.length !== 3 && inferredShape.length !== 1) {
    throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  }
  if (inferredShape.length === 1 && shape == null) {
    throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  }
  return makeTensor(values, shape, inferredShape, dtype);
}
var init_tensor3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/tensor3d.js"() {
    init_tensor_util_env();
    init_util();
    init_tensor_ops_util();
  }
});
function topk_(x, k = 1, sorted = true) {
  const $x = convertToTensor(x, "x", "topk");
  if ($x.rank === 0) {
    throw new Error("topk() expects the input to be of rank 1 or higher");
  }
  const lastDim = $x.shape[$x.shape.length - 1];
  if (k < 0) {
    throw new Error(`'k' passed to topk() must be >= 0 but got ${k}`);
  }
  if (k > lastDim) {
    throw new Error(`'k' passed to topk() must be <= the last dimension (${lastDim}) but got ${k}`);
  }
  const inputs = { x: $x };
  const attrs = { k, sorted };
  const [values, indices] = ENGINE.runKernel(TopK, inputs, attrs);
  return { values, indices };
}
var topk;
var init_topk = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/topk.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_operation();
    topk = /* @__PURE__ */ op({ topk_ });
  }
});
function truncatedNormal_(shape, mean3 = 0, stdDev = 1, dtype, seed) {
  assertNonNegativeIntegerDimensions(shape);
  if (dtype != null && dtype === "bool") {
    throw new Error(`Unsupported data type $ { dtype }`);
  }
  const randGauss = new MPRandGauss(mean3, stdDev, dtype, true, seed);
  const res = buffer(shape, dtype);
  for (let i = 0; i < res.values.length; i++) {
    res.values[i] = randGauss.nextValue();
  }
  return res.toTensor();
}
var truncatedNormal;
var init_truncated_normal = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/truncated_normal.js"() {
    init_util_base();
    init_buffer();
    init_operation();
    init_rand_util();
    truncatedNormal = /* @__PURE__ */ op({ truncatedNormal_ });
  }
});
function unique_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "unique", "string_or_numeric");
  assert($x.rank > 0, () => "The input tensor must be at least 1D");
  const inputs = { x: $x };
  const attrs = { axis };
  const [values, indices] = ENGINE.runKernel(Unique, inputs, attrs);
  return { values, indices };
}
var unique;
var init_unique = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/unique.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    unique = /* @__PURE__ */ op({ unique_ });
  }
});
function unsortedSegmentSum_(x, segmentIds, numSegments) {
  const $x = convertToTensor(x, "x", "unsortedSegmentSum");
  const $segmentIds = convertToTensor(segmentIds, "segmentIds", "unsortedSegmentSum", "int32");
  assert(isInt(numSegments), () => "numSegments must be of dtype int");
  const inputs = { x: $x, segmentIds: $segmentIds };
  const attrs = { numSegments };
  return ENGINE.runKernel(UnsortedSegmentSum, inputs, attrs);
}
var unsortedSegmentSum;
var init_unsorted_segment_sum = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    unsortedSegmentSum = /* @__PURE__ */ op({ unsortedSegmentSum_ });
  }
});
function unstack_(x, axis = 0) {
  const $x = convertToTensor(x, "x", "unstack", "string_or_numeric");
  assert(axis >= -$x.shape.length && axis < $x.shape.length, () => `Axis = ${axis} is not in [-${$x.shape.length}, ${$x.shape.length})`);
  const inputs = { value: $x };
  const attrs = { axis };
  return ENGINE.runKernel(Unpack, inputs, attrs);
}
var unstack;
var init_unstack = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/unstack.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    unstack = /* @__PURE__ */ op({ unstack_ });
  }
});
function variable(initialValue, trainable = true, name, dtype) {
  return ENGINE.makeVariable(initialValue, trainable, name, dtype);
}
var init_variable = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/variable.js"() {
    init_engine();
  }
});
function whereImpl(condShape, condVals) {
  const indices = [];
  for (let i = 0; i < condVals.length; i++) {
    if (condVals[i]) {
      indices.push(i);
    }
  }
  const inBuffer = buffer(condShape, "int32");
  const out = buffer([indices.length, condShape.length], "int32");
  for (let i = 0; i < indices.length; i++) {
    const loc = inBuffer.indexToLoc(indices[i]);
    const offset = i * condShape.length;
    out.values.set(loc, offset);
  }
  return out.toTensor();
}
var init_where_impl = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/where_impl.js"() {
    init_buffer();
  }
});
var init_boolean_mask = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/boolean_mask.js"() {
  }
});
function transpose_(x, perm, conjugate3) {
  const $x = convertToTensor(x, "x", "transpose");
  if (perm == null) {
    perm = $x.shape.map((s, i) => i).reverse();
  }
  assert($x.rank === perm.length, () => `Error in transpose: rank of input ${$x.rank} must match length of perm ${perm}.`);
  perm.forEach((axis) => {
    assert(axis >= 0 && axis < $x.rank, () => `All entries in 'perm' must be between 0 and ${$x.rank - 1} but got ${perm}`);
  });
  if ($x.rank <= 1) {
    return $x.clone();
  }
  const inputs = { x: $x };
  const attrs = { perm };
  if ($x.dtype === "complex64") {
    return tidy(() => {
      let $real = real($x);
      let $imag = imag($x);
      $real = ENGINE.runKernel(Transpose, { x: $real }, attrs);
      $imag = ENGINE.runKernel(Transpose, { x: $imag }, attrs);
      if (conjugate3) {
        $imag = neg($imag);
      }
      return complex($real, $imag);
    });
  }
  return ENGINE.runKernel(Transpose, inputs, attrs);
}
var transpose2;
var init_transpose = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/transpose.js"() {
    init_engine();
    init_globals();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_complex();
    init_imag();
    init_neg();
    init_operation();
    init_real();
    transpose2 = /* @__PURE__ */ op({ transpose_ });
  }
});
var init_moving_average = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/moving_average.js"() {
  }
});
function validateUpdateShape(shape, indices, updates) {
  const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;
  const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;
  const shapeError = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${updates.shape}, indices.shape: ${indices.shape}, shape: ${shape}, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;
  if (updates.rank < batchDim) {
    throw new Error(shapeError + ` update.rank < ${batchDim}. `);
  }
  if (shape.length < sliceDim + (updates.rank - batchDim)) {
    throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);
  }
  if (updates.rank !== batchDim + shape.length - sliceDim) {
    throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);
  }
  for (let d = 0; d < batchDim; ++d) {
    if (updates.shape[d] !== indices.shape[d]) {
      throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);
    }
  }
  for (let d = 0; d < updates.rank - batchDim; ++d) {
    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {
      throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);
    }
  }
}
function validateInput(updates, indices, shape) {
  if (indices.rank < 1) {
    throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${indices.rank}.`);
  }
  if (updates.rank < 1) {
    throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${updates.rank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);
  }
  if (shape.length < 1) {
    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);
  }
  if (shape.length === 0) {
    if (indices.size === 0) {
      throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);
    }
    if (updates.size === 0) {
      throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);
    }
  }
  validateUpdateShape(shape, indices, updates);
}
function calculateShapes(updates, indices, shape) {
  const indicesRank = indices.shape.length;
  const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1;
  const totalNd = shape.length;
  let sliceSize = 1;
  for (let i = sliceRank; i < totalNd; ++i) {
    sliceSize *= shape[i];
  }
  const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;
  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;
  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];
  const outputSize = sizeFromShape(shape);
  return { sliceRank, numUpdates, sliceSize, strides, outputSize };
}
var init_scatter_nd_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js"() {
    init_util();
  }
});
var init_scatter_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd.js"() {
    init_engine();
  }
});
var init_sparse_to_dense = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js"() {
    init_engine();
  }
});
var init_gather_nd = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd.js"() {
    init_engine();
  }
});
function getNoiseShape(x, noiseShape) {
  if (noiseShape == null) {
    return x.shape.slice();
  }
  if (arraysEqual(x.shape, noiseShape)) {
    return noiseShape;
  }
  if (x.shape.length === noiseShape.length) {
    const newDimension = [];
    for (let i = 0; i < x.shape.length; i++) {
      if (noiseShape[i] == null && x.shape[i] != null) {
        newDimension.push(x.shape[i]);
      } else {
        newDimension.push(noiseShape[i]);
      }
    }
    return newDimension;
  }
  return noiseShape;
}
var init_dropout_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dropout_util.js"() {
    init_util();
  }
});
function dropout_(x, rate, noiseShape, seed) {
  const $x = convertToTensor(x, "x", "dropout");
  assert($x.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${$x.dtype} tensor instead.`);
  assert(rate >= 0 && rate < 1, () => `rate must be a float in the range [0, 1), but got ${rate}.`);
  if (rate === 0) {
    return x instanceof Tensor ? $x.clone() : $x;
  }
  const $noiseShape = getNoiseShape($x, noiseShape);
  const keepProb = 1 - rate;
  const multiplier = div2(floor2(add22(randomUniform($noiseShape, 0, 1, "float32", seed), keepProb)), keepProb);
  return mul5($x, multiplier);
}
var dropout;
var init_dropout = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/dropout.js"() {
    init_tensor();
    init_tensor_util_env();
    init_util();
    init_add();
    init_div();
    init_dropout_util();
    init_floor();
    init_mul();
    init_operation();
    init_random_uniform();
    dropout = /* @__PURE__ */ op({ dropout_ });
  }
});
var init_signal_ops_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/signal_ops_util.js"() {
  }
});
var init_in_top_k = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/in_top_k.js"() {
  }
});
function conv2DBackpropFilter_(x, dy, filterShape, strides, pad2, dataFormat = "NHWC", dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${x4D.shape}.`);
  assert(dy4D.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${dy4D.shape}.`);
  assert(filterShape.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${filterShape}.`);
  const inDepth = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  const outDepth = dataFormat === "NHWC" ? dy4D.shape[3] : dy4D.shape[1];
  assert(inDepth === filterShape[2], () => `Error in conv2dDerFilter: depth of input ${inDepth}) must match input depth in filter (${filterShape[2]}.`);
  assert(outDepth === filterShape[3], () => `Error in conv2dDerFilter: depth of dy (${outDepth}) must match output depth for filter (${filterShape[3]}).`);
  checkPadOnDimRoundingMode("conv2dDerFilter", pad2, dimRoundingMode);
  const inputs = { x: x4D, dy: dy4D };
  const attrs = { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape };
  return ENGINE.runKernel(Conv2DBackpropFilter, inputs, attrs);
}
var conv2DBackpropFilter;
var init_conv2d_backprop_filter = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    conv2DBackpropFilter = /* @__PURE__ */ op({ conv2DBackpropFilter_ });
  }
});
function getFusedDyActivation(dy, y, activation) {
  if (activation == null || activation === "linear") {
    return dy;
  }
  if (activation === "relu") {
    return mul5(dy, step(y));
  }
  throw new Error(`Cannot compute gradient for fused activation ${activation}.`);
}
function getFusedBiasGradient(bias, dyActivation) {
  let res = dyActivation;
  const reduceAxes = getReductionAxes(bias.shape, dyActivation.shape);
  if (reduceAxes.length > 0) {
    res = sum2(res, reduceAxes);
  }
  return reshape(res, bias.shape);
}
function applyActivation(x, activation, preluActivationWeights, leakyreluAlpha) {
  if (activation === "linear") {
    return x;
  } else if (activation === "relu") {
    return relu(x);
  } else if (activation === "elu") {
    return elu(x);
  } else if (activation === "relu6") {
    return relu6(x);
  } else if (activation === "prelu") {
    return prelu(x, preluActivationWeights);
  } else if (activation === "leakyrelu") {
    return leakyRelu(x, leakyreluAlpha);
  } else if (activation === "sigmoid") {
    return sigmoid(x);
  }
  throw new Error(`Unknown fused activation ${activation}.`);
}
var shouldFuse;
var init_fused_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused_util.js"() {
    init_broadcast_util();
    init_elu();
    init_leaky_relu();
    init_mul();
    init_prelu();
    init_relu();
    init_relu6();
    init_reshape();
    init_sigmoid();
    init_step();
    init_sum();
    shouldFuse = (gradientDepth, activation) => {
      const gradientMode = gradientDepth > 0;
      return !gradientMode || activation === "linear";
    };
  }
});
function fusedConv2d_({ x, filter, strides, pad: pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
  activation = activation || "linear";
  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
    assert(dataFormat === "NHWC", () => `Error in fused conv2d: got dataFormat of ${dataFormat} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);
    let result = conv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add22(result, bias);
    }
    return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor(x, "x", "conv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "conv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  checkPadOnDimRoundingMode("fused conv2d", pad2, dimRoundingMode);
  const inputChannels = dataFormat === "NHWC" ? x4D.shape[3] : x4D.shape[1];
  assert($filter.shape[2] === inputChannels, () => `Error in conv2d: depth of input (${inputChannels}) must match input depth for filter ${$filter.shape[2]}.`);
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad2, dimRoundingMode);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch($bias, $x);
    if (dataFormat === "NHWC") {
      assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
    } else {
      assert($bias.shape.length <= 1, () => `Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${$bias.shape.length}.`);
      assert($bias.shape.length === 0 || $bias.shape[0] === convInfo.outChannels || $bias.shape[0] === 1, () => `Error in fused conv2d: bias shape (${$bias.shape}) is not compatible with the number of output channels (${convInfo.outChannels})`);
    }
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    const alphaShape = preluActivationWeights.shape;
    assert(alphaShape.length <= 1 || alphaShape.length === 3, () => `Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${alphaShape.length}.`);
    if (alphaShape.length === 1) {
      assert(alphaShape[0] === 1 || alphaShape[0] === convInfo.outChannels, () => `Error in fused conv2d: PReLU activation weights (${alphaShape}) is not compatible with the number of output channels (${convInfo.outChannels}).`);
    } else if (alphaShape.length === 3) {
      try {
        assertAndGetBroadcastShape(alphaShape, convInfo.outShape);
      } catch (e) {
        const errMsg = `Error in fused conv2d: PReLU activation weights (${alphaShape}) is not compatible with the output shape of the conv2d (${convInfo.outShape}).`;
        throw Error(errMsg);
      }
    }
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused conv2d");
  }
  const grad = (dy, saved) => {
    assert(dataFormat === "NHWC", () => `Error in gradient of fused conv2D: got dataFormat of ${dataFormat} but only NHWC is currently supported.`);
    const [$filter2, x4D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation(dy, y, activation);
    assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
    const xDer = conv2DBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2);
    const filterDer = conv2DBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2);
    const der = [xDer, filterDer];
    if ($bias2 != null) {
      const biasDer = getFusedBiasGradient($bias2, dyActivation);
      der.push(biasDer);
    }
    return der;
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((x4D2, filter2, save) => {
      let res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(FusedConv2D, inputs, attrs)
      );
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
      let res = ENGINE.runKernel(FusedConv2D, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var conv2d2;
var init_conv2d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused/conv2d.js"() {
    init_engine();
    init_gradients();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_broadcast_util();
    init_conv2d();
    init_conv2d_backprop_filter();
    init_conv2d_backprop_input();
    init_conv_util();
    init_fused_util();
    init_operation();
    init_reshape();
    conv2d2 = /* @__PURE__ */ op({ fusedConv2d_ });
  }
});
function depthwiseConv2dNativeBackpropFilter_(x, dy, filterShape, strides, pad2, dilations = [1, 1], dimRoundingMode) {
  let x4D = x;
  if (x.rank === 3) {
    x4D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2]]);
  }
  let dy4D = dy;
  if (dy4D.rank === 3) {
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = { x: x4D, dy: dy4D };
  const attrs = { strides, pad: pad2, dimRoundingMode, dilations, filterShape };
  return ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, inputs, attrs);
}
var depthwiseConv2dNativeBackpropFilter;
var init_depthwise_conv2d_native_backprop_filter = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js"() {
    init_engine();
    init_kernel_names();
    init_operation();
    init_reshape();
    depthwiseConv2dNativeBackpropFilter = op({ depthwiseConv2dNativeBackpropFilter_ });
  }
});
function depthwiseConv2dNativeBackpropInput_(xShape, dy, filter, strides, pad2, dilations = [1, 1], dimRoundingMode) {
  let dy4D = dy;
  let reshapedTo4D = false;
  if (dy.rank === 3) {
    reshapedTo4D = true;
    dy4D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2]]);
  }
  const inputs = { dy: dy4D, filter };
  const attrs = { strides, pad: pad2, dimRoundingMode, dilations, inputShape: xShape };
  const res = (
    // tslint:disable-next-line: no-unnecessary-type-assertion
    ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, inputs, attrs)
  );
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var depthwiseConv2dNativeBackpropInput;
var init_depthwise_conv2d_native_backprop_input = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js"() {
    init_engine();
    init_kernel_names();
    init_operation();
    init_reshape();
    depthwiseConv2dNativeBackpropInput = op({ depthwiseConv2dNativeBackpropInput_ });
  }
});
function fusedDepthwiseConv2d_({ x, filter, strides, pad: pad2, dataFormat = "NHWC", dilations = [1, 1], dimRoundingMode, bias, activation = "linear", preluActivationWeights, leakyreluAlpha }) {
  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
    let result = depthwiseConv2d(x, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
    if (bias != null) {
      result = add22(result, bias);
    }
    return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
  }
  const $x = convertToTensor(x, "x", "depthwiseConv2d", "float32");
  const $filter = convertToTensor(filter, "filter", "depthwiseConv2d", "float32");
  let x4D = $x;
  let reshapedTo4D = false;
  if ($x.rank === 3) {
    reshapedTo4D = true;
    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);
  }
  assert(x4D.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${x4D.rank}.`);
  assert($filter.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${$filter.rank}.`);
  assert(x4D.shape[3] === $filter.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${x4D.shape[3]}) must match the inChannels dimension in filter ${$filter.shape[2]}.`);
  if (dilations == null) {
    dilations = [1, 1];
  }
  assert(eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  checkPadOnDimRoundingMode("fused depthwiseConv2d", pad2, dimRoundingMode);
  const convInfo = computeConv2DInfo(
    x4D.shape,
    $filter.shape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused conv2d");
    [$bias] = makeTypesMatch($bias, $x);
    assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused depthwiseConv2d");
  }
  const grad = (dy, saved) => {
    assert(tupleValuesAreOne(dilations), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${dilations}'`);
    const [$filter2, x4D2, y, bias2] = saved;
    const dyActivation = getFusedDyActivation(dy, y, activation);
    const xDer = depthwiseConv2dNativeBackpropInput(x4D2.shape, dyActivation, $filter2, strides, pad2, dilations, dimRoundingMode);
    const filterDer = depthwiseConv2dNativeBackpropFilter(x4D2, dyActivation, $filter2.shape, strides, pad2, dilations, dimRoundingMode);
    if (bias2 != null) {
      const biasDer = getFusedBiasGradient($bias, dyActivation);
      return [xDer, filterDer, biasDer];
    }
    return [xDer, filterDer];
  };
  const inputs = {
    x: x4D,
    filter: $filter,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = {
    strides,
    pad: pad2,
    dataFormat,
    dilations,
    dimRoundingMode,
    activation,
    leakyreluAlpha
  };
  if (bias == null) {
    const customOp = customGrad((x4D2, filter2, save) => {
      let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
      save([filter2, x4D2, res]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad };
    });
    return customOp(x4D, $filter);
  } else {
    const customOpWithBias = customGrad((x4D2, filter2, bias2, save) => {
      let res = ENGINE.runKernel(FusedDepthwiseConv2D, inputs, attrs);
      save([filter2, x4D2, res, bias2]);
      if (reshapedTo4D) {
        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
      }
      return { value: res, gradFunc: grad };
    });
    return customOpWithBias(x4D, $filter, $bias);
  }
}
var depthwiseConv2d2;
var init_depthwise_conv2d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js"() {
    init_engine();
    init_gradients();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_broadcast_util();
    init_conv_util();
    init_depthwise_conv2d();
    init_depthwise_conv2d_native_backprop_filter();
    init_depthwise_conv2d_native_backprop_input();
    init_fused_util();
    init_operation();
    init_reshape();
    depthwiseConv2d2 = /* @__PURE__ */ op({ fusedDepthwiseConv2d_ });
  }
});
function fusedMatMul_({ a, b, transposeA = false, transposeB = false, bias, activation = "linear", preluActivationWeights, leakyreluAlpha = 0.2 }) {
  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {
    let result = matMul(a, b, transposeA, transposeB);
    if (bias != null) {
      result = add22(result, bias);
    }
    return applyActivation(result, activation, preluActivationWeights, leakyreluAlpha);
  }
  let $a = convertToTensor(a, "a", "fused matMul");
  let $b = convertToTensor(b, "b", "fused matMul");
  [$a, $b] = makeTypesMatch($a, $b);
  const innerShapeA = transposeA ? $a.shape[$a.rank - 2] : $a.shape[$a.rank - 1];
  const innerShapeB = transposeB ? $b.shape[$b.rank - 1] : $b.shape[$b.rank - 2];
  const outerShapeA = transposeA ? $a.shape[$a.rank - 1] : $a.shape[$a.rank - 2];
  const outerShapeB = transposeB ? $b.shape[$b.rank - 2] : $b.shape[$b.rank - 1];
  const outerDimsA = $a.shape.slice(0, -2);
  const outerDimsB = $b.shape.slice(0, -2);
  const batchDimA = sizeFromShape(outerDimsA);
  const batchDimB = sizeFromShape(outerDimsB);
  assert(innerShapeA === innerShapeB, () => `Error in fused matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${$a.shape} and ${$b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const outShapeOuterDims = assertAndGetBroadcastShape($a.shape.slice(0, -2), $b.shape.slice(0, -2));
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  const a3D = transposeA ? reshape($a, [batchDimA, innerShapeA, outerShapeA]) : reshape($a, [batchDimA, outerShapeA, innerShapeA]);
  const b3D = transposeB ? reshape($b, [batchDimB, outerShapeB, innerShapeB]) : reshape($b, [batchDimB, innerShapeB, outerShapeB]);
  let $bias;
  if (bias != null) {
    $bias = convertToTensor(bias, "bias", "fused matMul");
    [$bias] = makeTypesMatch($bias, $a);
    assertAndGetBroadcastShape(outShape, $bias.shape);
  }
  let $preluActivationWeights;
  if (preluActivationWeights != null) {
    $preluActivationWeights = convertToTensor(preluActivationWeights, "prelu weights", "fused matMul");
  }
  const grad = (dy, saved) => {
    const [a3D2, b3D2, y, $bias2] = saved;
    const dyActivation = getFusedDyActivation(reshape(dy, y.shape), y, activation);
    let aDer;
    let bDer;
    if (!transposeA && !transposeB) {
      aDer = matMul(dyActivation, b3D2, false, true);
      bDer = matMul(a3D2, dyActivation, true, false);
    } else if (!transposeA && transposeB) {
      aDer = matMul(dyActivation, b3D2, false, false);
      bDer = matMul(dyActivation, a3D2, true, false);
    } else if (transposeA && !transposeB) {
      aDer = matMul(b3D2, dyActivation, false, true);
      bDer = matMul(a3D2, dyActivation, false, false);
    } else {
      aDer = matMul(b3D2, dyActivation, true, true);
      bDer = matMul(dyActivation, a3D2, true, true);
    }
    if (bias != null) {
      const biasDer = getFusedBiasGradient($bias2, dyActivation);
      return [aDer, bDer, biasDer];
    } else {
      return [aDer, bDer];
    }
  };
  const inputs = {
    a: a3D,
    b: b3D,
    bias: $bias,
    preluActivationWeights: $preluActivationWeights
  };
  const attrs = { transposeA, transposeB, activation, leakyreluAlpha };
  if (bias == null) {
    const customOp = customGrad((a3D2, b3D2, save) => {
      const res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(_FusedMatMul, inputs, attrs)
      );
      save([a3D2, b3D2, res]);
      return { value: reshape(res, outShape), gradFunc: grad };
    });
    return customOp(a3D, b3D);
  } else {
    const customOpWithBias = customGrad((a3D2, b3D2, $bias2, save) => {
      const res = (
        // tslint:disable-next-line: no-unnecessary-type-assertion
        ENGINE.runKernel(_FusedMatMul, inputs, attrs)
      );
      save([a3D2, b3D2, res, $bias2]);
      return { value: reshape(res, outShape), gradFunc: grad };
    });
    return customOpWithBias(a3D, b3D, $bias);
  }
}
var matMul2;
var init_mat_mul2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js"() {
    init_engine();
    init_gradients();
    init_kernel_names();
    init_tensor_util();
    init_tensor_util_env();
    init_util();
    init_add();
    init_broadcast_util();
    init_fused_util();
    init_mat_mul();
    init_operation();
    init_reshape();
    matMul2 = /* @__PURE__ */ op({ fusedMatMul_ });
  }
});
var fused_ops_exports = {};
__export2(fused_ops_exports, {
  conv2d: () => conv2d2,
  depthwiseConv2d: () => depthwiseConv2d2,
  matMul: () => matMul2
});
var init_fused_ops = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused_ops.js"() {
    init_conv2d2();
    init_depthwise_conv2d2();
    init_mat_mul2();
  }
});
function cropAndResize_(image2, boxes, boxInd, cropSize, method = "bilinear", extrapolationValue = 0) {
  const $image = convertToTensor(image2, "image", "cropAndResize");
  const $boxes = convertToTensor(boxes, "boxes", "cropAndResize", "float32");
  const $boxInd = convertToTensor(boxInd, "boxInd", "cropAndResize", "int32");
  const numBoxes = $boxes.shape[0];
  assert($image.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${$image.rank}.`);
  assert($boxes.rank === 2 && $boxes.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${numBoxes},4] but had shape ${$boxes.shape}.`);
  assert($boxInd.rank === 1 && $boxInd.shape[0] === numBoxes, () => `Error in cropAndResize: boxInd must be have size [${numBoxes}] but had shape ${$boxes.shape}.`);
  assert(cropSize.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${cropSize.length}.`);
  assert(cropSize[0] >= 1 && cropSize[1] >= 1, () => `cropSize must be atleast [1,1], but was ${cropSize}`);
  assert(method === "bilinear" || method === "nearest", () => `method must be bilinear or nearest, but was ${method}`);
  const inputs = { image: $image, boxes: $boxes, boxInd: $boxInd };
  const attrs = { method, extrapolationValue, cropSize };
  const res = ENGINE.runKernel(CropAndResize, inputs, attrs);
  return res;
}
var cropAndResize;
var init_crop_and_resize = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    cropAndResize = /* @__PURE__ */ op({ cropAndResize_ });
  }
});
function flipLeftRight_(image2) {
  const $image = convertToTensor(image2, "image", "flipLeftRight", "float32");
  assert($image.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = { image: $image };
  const res = ENGINE.runKernel(FlipLeftRight, inputs, {});
  return res;
}
var flipLeftRight;
var init_flip_left_right = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    flipLeftRight = /* @__PURE__ */ op({ flipLeftRight_ });
  }
});
function grayscaleToRGB_(image2) {
  const $image = convertToTensor(image2, "image", "grayscaleToRGB");
  const lastDimsIdx = $image.rank - 1;
  const lastDims = $image.shape[lastDimsIdx];
  assert($image.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${$image.rank}.`);
  assert(lastDims === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${lastDims}.`);
  const reps = new Array($image.rank);
  reps.fill(1, 0, lastDimsIdx);
  reps[lastDimsIdx] = 3;
  return tile($image, reps);
}
var grayscaleToRGB;
var init_grayscale_to_rgb = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js"() {
    init_tensor_util_env();
    init_util();
    init_operation();
    init_tile();
    grayscaleToRGB = /* @__PURE__ */ op({ grayscaleToRGB_ });
  }
});
function rotateWithOffset_(image2, radians, fillValue = 0, center = 0.5) {
  const $image = convertToTensor(image2, "image", "rotateWithOffset", "float32");
  assert($image.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${$image.rank}.`);
  const inputs = { image: $image };
  const attrs = { radians, fillValue, center };
  const res = ENGINE.runKernel(RotateWithOffset, inputs, attrs);
  return res;
}
var rotateWithOffset;
var init_rotate_with_offset = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    rotateWithOffset = /* @__PURE__ */ op({ rotateWithOffset_ });
  }
});
function nonMaxSuppSanityCheck(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  if (iouThreshold == null) {
    iouThreshold = 0.5;
  }
  if (scoreThreshold == null) {
    scoreThreshold = Number.NEGATIVE_INFINITY;
  }
  if (softNmsSigma == null) {
    softNmsSigma = 0;
  }
  const numBoxes = boxes.shape[0];
  maxOutputSize = Math.min(maxOutputSize, numBoxes);
  assert(0 <= iouThreshold && iouThreshold <= 1, () => `iouThreshold must be in [0, 1], but was '${iouThreshold}'`);
  assert(boxes.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${boxes.rank}'`);
  assert(boxes.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${boxes.shape[1]}`);
  assert(scores.rank === 1, () => "scores must be a 1D tensor");
  assert(scores.shape[0] === numBoxes, () => `scores has incompatible shape with boxes. Expected ${numBoxes}, but was ${scores.shape[0]}`);
  assert(0 <= softNmsSigma && softNmsSigma <= 1, () => `softNmsSigma must be in [0, 1], but was '${softNmsSigma}'`);
  return { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
}
var init_nonmax_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/nonmax_util.js"() {
    init_util();
  }
});
function nonMaxSuppression_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression", "float32");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression", "float32");
  const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const attrs = { maxOutputSize, iouThreshold, scoreThreshold };
  return ENGINE.runKernel(NonMaxSuppressionV3, { boxes: $boxes, scores: $scores }, attrs);
}
var nonMaxSuppression;
var init_non_max_suppression = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_nonmax_util();
    init_operation();
    nonMaxSuppression = /* @__PURE__ */ op({ nonMaxSuppression_ });
  }
});
function binaryInsert(arr, element, comparator) {
  const index = binarySearch(arr, element, comparator);
  const insertionPoint = index < 0 ? -(index + 1) : index;
  arr.splice(insertionPoint, 0, element);
}
function binarySearch(arr, target, comparator) {
  return binarySearch_(arr, target, comparator || defaultComparator);
}
function defaultComparator(a, b) {
  return a > b ? 1 : a < b ? -1 : 0;
}
function binarySearch_(arr, target, comparator) {
  let left = 0;
  let right = arr.length;
  let middle = 0;
  let found = false;
  while (left < right) {
    middle = left + (right - left >>> 1);
    const compareResult = comparator(target, arr[middle]);
    if (compareResult > 0) {
      left = middle + 1;
    } else {
      right = middle;
      found = !compareResult;
    }
  }
  return found ? left : -left - 1;
}
var init_non_max_suppression_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js"() {
  }
});
function nonMaxSuppressionV3Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold) {
  return nonMaxSuppressionImpl_(
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    0
    /* softNmsSigma */
  );
}
function nonMaxSuppressionV4Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize) {
  return nonMaxSuppressionImpl_(
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    0,
    false,
    padToMaxOutputSize,
    true
    /* returnValidOutputs */
  );
}
function nonMaxSuppressionV5Impl(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma) {
  return nonMaxSuppressionImpl_(
    boxes,
    scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    softNmsSigma,
    true
    /* returnScoresTensor */
  );
}
function nonMaxSuppressionImpl_(boxes, scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma, returnScoresTensor = false, padToMaxOutputSize = false, returnValidOutputs = false) {
  const candidates = [];
  for (let i = 0; i < scores.length; i++) {
    if (scores[i] > scoreThreshold) {
      candidates.push({ score: scores[i], boxIndex: i, suppressBeginIndex: 0 });
    }
  }
  candidates.sort(ascendingComparator);
  const scale22 = softNmsSigma > 0 ? -0.5 / softNmsSigma : 0;
  const selectedIndices = [];
  const selectedScores = [];
  while (selectedIndices.length < maxOutputSize && candidates.length > 0) {
    const candidate = candidates.pop();
    const { score: originalScore, boxIndex, suppressBeginIndex } = candidate;
    if (originalScore < scoreThreshold) {
      break;
    }
    let ignoreCandidate = false;
    for (let j = selectedIndices.length - 1; j >= suppressBeginIndex; --j) {
      const iou = intersectionOverUnion(boxes, boxIndex, selectedIndices[j]);
      if (iou >= iouThreshold) {
        ignoreCandidate = true;
        break;
      }
      candidate.score = candidate.score * suppressWeight(iouThreshold, scale22, iou);
      if (candidate.score <= scoreThreshold) {
        break;
      }
    }
    candidate.suppressBeginIndex = selectedIndices.length;
    if (!ignoreCandidate) {
      if (candidate.score === originalScore) {
        selectedIndices.push(boxIndex);
        selectedScores.push(candidate.score);
      } else if (candidate.score > scoreThreshold) {
        binaryInsert(candidates, candidate, ascendingComparator);
      }
    }
  }
  const validOutputs = selectedIndices.length;
  const elemsToPad = maxOutputSize - validOutputs;
  if (padToMaxOutputSize && elemsToPad > 0) {
    selectedIndices.push(...new Array(elemsToPad).fill(0));
    selectedScores.push(...new Array(elemsToPad).fill(0));
  }
  const result = { selectedIndices };
  if (returnScoresTensor) {
    result["selectedScores"] = selectedScores;
  }
  if (returnValidOutputs) {
    result["validOutputs"] = validOutputs;
  }
  return result;
}
function intersectionOverUnion(boxes, i, j) {
  const iCoord = boxes.subarray(i * 4, i * 4 + 4);
  const jCoord = boxes.subarray(j * 4, j * 4 + 4);
  const yminI = Math.min(iCoord[0], iCoord[2]);
  const xminI = Math.min(iCoord[1], iCoord[3]);
  const ymaxI = Math.max(iCoord[0], iCoord[2]);
  const xmaxI = Math.max(iCoord[1], iCoord[3]);
  const yminJ = Math.min(jCoord[0], jCoord[2]);
  const xminJ = Math.min(jCoord[1], jCoord[3]);
  const ymaxJ = Math.max(jCoord[0], jCoord[2]);
  const xmaxJ = Math.max(jCoord[1], jCoord[3]);
  const areaI = (ymaxI - yminI) * (xmaxI - xminI);
  const areaJ = (ymaxJ - yminJ) * (xmaxJ - xminJ);
  if (areaI <= 0 || areaJ <= 0) {
    return 0;
  }
  const intersectionYmin = Math.max(yminI, yminJ);
  const intersectionXmin = Math.max(xminI, xminJ);
  const intersectionYmax = Math.min(ymaxI, ymaxJ);
  const intersectionXmax = Math.min(xmaxI, xmaxJ);
  const intersectionArea = Math.max(intersectionYmax - intersectionYmin, 0) * Math.max(intersectionXmax - intersectionXmin, 0);
  return intersectionArea / (areaI + areaJ - intersectionArea);
}
function suppressWeight(iouThreshold, scale22, iou) {
  const weight = Math.exp(scale22 * iou * iou);
  return iou <= iouThreshold ? weight : 0;
}
function ascendingComparator(c1, c2) {
  return c1.score - c2.score || c1.score === c2.score && c2.boxIndex - c1.boxIndex;
}
var init_non_max_suppression_impl = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js"() {
    init_non_max_suppression_util();
  }
});
async function nonMaxSuppressionAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
  const inputs = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold);
  maxOutputSize = inputs.maxOutputSize;
  iouThreshold = inputs.iouThreshold;
  scoreThreshold = inputs.scoreThreshold;
  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
  const boxesVals = boxesAndScores[0];
  const scoresVals = boxesAndScores[1];
  const { selectedIndices } = nonMaxSuppressionV3Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return tensor1d(selectedIndices, "int32");
}
var nonMaxSuppressionAsync;
var init_non_max_suppression_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js"() {
    init_non_max_suppression_impl();
    init_tensor_util_env();
    init_nonmax_util();
    init_tensor1d();
    nonMaxSuppressionAsync = nonMaxSuppressionAsync_;
  }
});
function nonMaxSuppressionWithScore_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const inputs = { boxes: $boxes, scores: $scores };
  const attrs = { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma };
  const result = ENGINE.runKernel(NonMaxSuppressionV5, inputs, attrs);
  return { selectedIndices: result[0], selectedScores: result[1] };
}
var nonMaxSuppressionWithScore;
var init_non_max_suppression_with_score = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_nonmax_util();
    init_operation();
    nonMaxSuppressionWithScore = /* @__PURE__ */ op({ nonMaxSuppressionWithScore_ });
  }
});
async function nonMaxSuppressionWithScoreAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, softNmsSigma = 0) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
  const params = nonMaxSuppSanityCheck($boxes, $scores, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  maxOutputSize = params.maxOutputSize;
  iouThreshold = params.iouThreshold;
  scoreThreshold = params.scoreThreshold;
  softNmsSigma = params.softNmsSigma;
  const boxesAndScores = await Promise.all([$boxes.data(), $scores.data()]);
  const boxesVals = boxesAndScores[0];
  const scoresVals = boxesAndScores[1];
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return {
    selectedIndices: tensor1d(selectedIndices, "int32"),
    selectedScores: tensor1d(selectedScores)
  };
}
var nonMaxSuppressionWithScoreAsync;
var init_non_max_suppression_with_score_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js"() {
    init_non_max_suppression_impl();
    init_tensor_util_env();
    init_nonmax_util();
    init_tensor1d();
    nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;
  }
});
function nonMaxSuppressionPadded_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppression");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppression");
  const params = nonMaxSuppSanityCheck(
    $boxes,
    $scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    null
    /* softNmsSigma */
  );
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const inputs = { boxes: $boxes, scores: $scores };
  const attrs = {
    maxOutputSize: $maxOutputSize,
    iouThreshold: $iouThreshold,
    scoreThreshold: $scoreThreshold,
    padToMaxOutputSize
  };
  const result = ENGINE.runKernel(NonMaxSuppressionV4, inputs, attrs);
  return { selectedIndices: result[0], validOutputs: result[1] };
}
var nonMaxSuppressionPadded;
var init_non_max_suppression_padded = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_nonmax_util();
    init_operation();
    nonMaxSuppressionPadded = /* @__PURE__ */ op({ nonMaxSuppressionPadded_ });
  }
});
async function nonMaxSuppressionPaddedAsync_(boxes, scores, maxOutputSize, iouThreshold = 0.5, scoreThreshold = Number.NEGATIVE_INFINITY, padToMaxOutputSize = false) {
  const $boxes = convertToTensor(boxes, "boxes", "nonMaxSuppressionAsync");
  const $scores = convertToTensor(scores, "scores", "nonMaxSuppressionAsync");
  const params = nonMaxSuppSanityCheck(
    $boxes,
    $scores,
    maxOutputSize,
    iouThreshold,
    scoreThreshold,
    null
    /* softNmsSigma */
  );
  const $maxOutputSize = params.maxOutputSize;
  const $iouThreshold = params.iouThreshold;
  const $scoreThreshold = params.scoreThreshold;
  const [boxesVals, scoresVals] = await Promise.all([$boxes.data(), $scores.data()]);
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl(boxesVals, scoresVals, $maxOutputSize, $iouThreshold, $scoreThreshold, padToMaxOutputSize);
  if ($boxes !== boxes) {
    $boxes.dispose();
  }
  if ($scores !== scores) {
    $scores.dispose();
  }
  return {
    selectedIndices: tensor1d(selectedIndices, "int32"),
    validOutputs: scalar(validOutputs, "int32")
  };
}
var nonMaxSuppressionPaddedAsync;
var init_non_max_suppression_padded_async = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js"() {
    init_non_max_suppression_impl();
    init_tensor_util_env();
    init_nonmax_util();
    init_scalar();
    init_tensor1d();
    nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;
  }
});
function resizeBilinear_(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor(images, "images", "resizeBilinear");
  assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert(size.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${size}.`);
  assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = { images: batchImages };
  const attrs = { alignCorners, halfPixelCenters, size };
  const res = ENGINE.runKernel(ResizeBilinear, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeBilinear;
var init_resize_bilinear = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    resizeBilinear = /* @__PURE__ */ op({ resizeBilinear_ });
  }
});
function resizeNearestNeighbor_(images, size, alignCorners = false, halfPixelCenters = false) {
  const $images = convertToTensor(images, "images", "resizeNearestNeighbor");
  assert($images.rank === 3 || $images.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${$images.rank}.`);
  assert(size.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${size}.`);
  assert($images.dtype === "float32" || $images.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype");
  assert(halfPixelCenters === false || alignCorners === false, () => `Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.`);
  let batchImages = $images;
  let reshapedTo4D = false;
  if ($images.rank === 3) {
    reshapedTo4D = true;
    batchImages = reshape($images, [1, $images.shape[0], $images.shape[1], $images.shape[2]]);
  }
  const [] = size;
  const inputs = { images: batchImages };
  const attrs = { alignCorners, halfPixelCenters, size };
  const res = ENGINE.runKernel(ResizeNearestNeighbor, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var resizeNearestNeighbor;
var init_resize_nearest_neighbor = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    resizeNearestNeighbor = /* @__PURE__ */ op({ resizeNearestNeighbor_ });
  }
});
function threshold_(image2, method = "binary", inverted = false, threshValue = 0.5) {
  const $image = convertToTensor(image2, "image", "threshold");
  const RED_INTENCITY_COEF = 0.2989;
  const GREEN_INTENCITY_COEF = 0.587;
  const BLUE_INTENCITY_COEF = 0.114;
  const totalPixelsInImage = $image.shape[0] * $image.shape[1];
  let $threshold = mul5(tensor1d([threshValue]), 255);
  let r, g, b, grayscale;
  assert($image.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${$image.rank}.`);
  assert($image.shape[2] === 3 || $image.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${$image.shape[2]}.`);
  assert($image.dtype === "int32" || $image.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${$image.dtype}.`);
  assert(method === "otsu" || method === "binary", () => `Method must be binary or otsu, but was ${method}`);
  if ($image.shape[2] === 3) {
    [r, g, b] = split($image, [1, 1, 1], -1);
    const $r = mul5(r, RED_INTENCITY_COEF);
    const $g = mul5(g, GREEN_INTENCITY_COEF);
    const $b = mul5(b, BLUE_INTENCITY_COEF);
    grayscale = add22(add22($r, $g), $b);
  } else {
    grayscale = image2;
  }
  if (method === "otsu") {
    const $histogram = bincount(cast(round22(grayscale), "int32"), tensor([]), 256);
    $threshold = otsu($histogram, totalPixelsInImage);
  }
  const invCondition = inverted ? lessEqual(grayscale, $threshold) : greater(grayscale, $threshold);
  const result = cast(mul5(invCondition, 255), "int32");
  return result;
}
function otsu(histogram, total) {
  let bestThresh = tensor1d([-1]);
  let bestInBetVar = tensor1d([0]);
  let cInBetVar = tensor1d([0]);
  let classFirst, classSecond, meanFirst, meanSec, weightForeground, weightBack;
  for (let index = 0; index < histogram.size - 1; index++) {
    classFirst = slice(histogram, 0, index + 1);
    classSecond = slice(histogram, index + 1);
    weightForeground = div2(sum2(classFirst), total);
    weightBack = div2(sum2(classSecond), total);
    const meanFirstDivA = sum2(mul5(classFirst, range(0, classFirst.size)));
    meanFirst = div2(meanFirstDivA, sum2(classFirst));
    const meanSecFill = fill(classSecond.shape, classFirst.size);
    const meanSecAdd = add22(range(0, classSecond.size), meanSecFill);
    const meanSecMul = mul5(classSecond, meanSecAdd);
    meanSec = div2(sum2(meanSecMul), sum2(classSecond));
    const cInBetVarSubA = sub3(meanFirst, meanSec);
    const cInBetVarSubB = sub3(meanFirst, meanSec);
    const cInBetVarMul = mul5(weightForeground, weightBack);
    cInBetVar = mul5(mul5(cInBetVarMul, cInBetVarSubA), cInBetVarSubB);
    const condition = greater(cInBetVar, bestInBetVar);
    bestInBetVar = where(condition, cInBetVar, bestInBetVar);
    bestThresh = where(condition, tensor1d([index]), bestThresh);
  }
  return bestThresh;
}
var threshold;
var init_threshold = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/threshold.js"() {
    init_tensor1d();
    init_operation();
    init_cast();
    init_split();
    init_bincount();
    init_less_equal();
    init_greater();
    init_sum();
    init_add();
    init_mul();
    init_div();
    init_sub();
    init_round();
    init_where();
    init_fill();
    init_slice();
    init_range();
    init_tensor2();
    init_util();
    init_tensor_util_env();
    threshold = /* @__PURE__ */ op({ threshold_ });
  }
});
function transform_(image2, transforms, interpolation = "nearest", fillMode = "constant", fillValue = 0, outputShape) {
  const $image = convertToTensor(image2, "image", "transform", "float32");
  const $transforms = convertToTensor(transforms, "transforms", "transform", "float32");
  assert($image.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${$image.rank}.`);
  assert($transforms.rank === 2 && ($transforms.shape[0] === $image.shape[0] || $transforms.shape[0] === 1) && $transforms.shape[1] === 8, () => `Error in transform: Input transform should be batch x 8 or 1 x 8`);
  assert(outputShape == null || outputShape.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${outputShape}.`);
  const inputs = { image: $image, transforms: $transforms };
  const attrs = { interpolation, fillMode, fillValue, outputShape };
  return ENGINE.runKernel(Transform, inputs, attrs);
}
var transform;
var init_transform = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/image/transform.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    transform = /* @__PURE__ */ op({ transform_ });
  }
});
function bandPart_(a, numLower, numUpper) {
  assert(numLower % 1 === 0, () => `bandPart(): numLower must be an integer, got ${numLower}.`);
  assert(numUpper % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${numUpper}.`);
  const $a = convertToTensor(a, "a", "bandPart");
  assert($a.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${$a.rank}.`);
  const shape = $a.shape;
  const [M, N] = $a.shape.slice(-2);
  if (!(numLower <= M)) {
    throw new Error(`bandPart(): numLower (${numLower}) must not be greater than the number of rows (${M}).`);
  }
  if (!(numUpper <= N)) {
    throw new Error(`bandPart(): numUpper (${numUpper}) must not be greater than the number of columns (${N}).`);
  }
  if (numLower < 0) {
    numLower = M;
  }
  if (numUpper < 0) {
    numUpper = N;
  }
  const i = reshape(range(0, M, 1, "int32"), [-1, 1]);
  const j = range(0, N, 1, "int32");
  const ij = sub3(i, j);
  const inBand = logicalAnd(lessEqual(ij, scalar(+numLower, "int32")), greaterEqual(ij, scalar(-numUpper, "int32")));
  const zero2 = zeros([M, N], $a.dtype);
  return reshape(stack(unstack(reshape($a, [-1, M, N])).map((mat) => where(inBand, mat, zero2))), shape);
}
var bandPart;
var init_band_part = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/band_part.js"() {
    init_tensor_util_env();
    init_util();
    init_greater_equal();
    init_less_equal();
    init_logical_and();
    init_operation();
    init_range();
    init_reshape();
    init_scalar();
    init_stack();
    init_sub();
    init_unstack();
    init_where();
    init_zeros();
    bandPart = /* @__PURE__ */ op({ bandPart_ });
  }
});
function gramSchmidt_(xs) {
  let inputIsTensor2D;
  if (Array.isArray(xs)) {
    inputIsTensor2D = false;
    assert(xs != null && xs.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    const dim = xs[0].shape[0];
    for (let i = 1; i < xs.length; ++i) {
      assert(xs[i].shape[0] === dim, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${xs[i].shape[0]} vs. ${dim})`);
    }
  } else {
    inputIsTensor2D = true;
    xs = split(xs, xs.shape[0], 0).map((x) => squeeze(x, [0]));
  }
  assert(xs.length <= xs[0].shape[0], () => `Gram-Schmidt: Number of vectors (${xs.length}) exceeds number of dimensions (${xs[0].shape[0]}).`);
  const ys = [];
  const xs1d = xs;
  for (let i = 0; i < xs.length; ++i) {
    ys.push(ENGINE.tidy(() => {
      let x = xs1d[i];
      if (i > 0) {
        for (let j = 0; j < i; ++j) {
          const proj = mul5(sum2(mul5(ys[j], x)), ys[j]);
          x = sub3(x, proj);
        }
      }
      return div2(x, norm(x, "euclidean"));
    }));
  }
  if (inputIsTensor2D) {
    return stack(ys, 0);
  } else {
    return ys;
  }
}
var gramSchmidt;
var init_gram_schmidt = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js"() {
    init_engine();
    init_util();
    init_div();
    init_mul();
    init_norm();
    init_operation();
    init_split();
    init_squeeze();
    init_stack();
    init_sub();
    init_sum();
    gramSchmidt = /* @__PURE__ */ op({ gramSchmidt_ });
  }
});
function qr_(x, fullMatrices = false) {
  assert(x.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${x.rank}`);
  if (x.rank === 2) {
    return qr2d(x, fullMatrices);
  } else {
    const outerDimsProd = x.shape.slice(0, x.shape.length - 2).reduce((value, prev) => value * prev);
    const x2ds = unstack(reshape(x, [
      outerDimsProd,
      x.shape[x.shape.length - 2],
      x.shape[x.shape.length - 1]
    ]), 0);
    const q2ds = [];
    const r2ds = [];
    x2ds.forEach((x2d) => {
      const [q2d, r2d] = qr2d(x2d, fullMatrices);
      q2ds.push(q2d);
      r2ds.push(r2d);
    });
    const q = reshape(stack(q2ds, 0), x.shape);
    const r = reshape(stack(r2ds, 0), x.shape);
    return [q, r];
  }
}
function qr2d(x, fullMatrices = false) {
  return ENGINE.tidy(() => {
    assert(x.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${x.shape.length}D Tensor.`);
    const m = x.shape[0];
    const n = x.shape[1];
    let q = eye(m);
    let r = clone6(x);
    const one2D = tensor2d([[1]], [1, 1]);
    let w = clone6(one2D);
    const iters = m >= n ? n : m;
    for (let j = 0; j < iters; ++j) {
      const rTemp = r;
      const wTemp = w;
      const qTemp = q;
      [w, r, q] = ENGINE.tidy(() => {
        const rjEnd1 = slice(r, [j, j], [m - j, 1]);
        const normX = norm(rjEnd1);
        const rjj = slice(r, [j, j], [1, 1]);
        const s = where(greater(rjj, 0), tensor2d([[-1]]), tensor2d([[1]]));
        const u1 = sub3(rjj, mul5(s, normX));
        const wPre = div2(rjEnd1, u1);
        if (wPre.shape[0] === 1) {
          w = clone6(one2D);
        } else {
          w = concat([
            one2D,
            slice(wPre, [1, 0], [wPre.shape[0] - 1, wPre.shape[1]])
          ], 0);
        }
        const tau = neg(div2(matMul(s, u1), normX));
        const rjEndAll = slice(r, [j, 0], [m - j, n]);
        const tauTimesW = mul5(tau, w);
        const wT = transpose2(w);
        if (j === 0) {
          r = sub3(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
        } else {
          const rTimesTau = sub3(rjEndAll, matMul(tauTimesW, matMul(wT, rjEndAll)));
          r = concat([slice(r, [0, 0], [j, n]), rTimesTau], 0);
        }
        const tawTimesWT = transpose2(tauTimesW);
        const qAllJEnd = slice(q, [0, j], [m, q.shape[1] - j]);
        if (j === 0) {
          q = sub3(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
        } else {
          const qTimesTau = sub3(qAllJEnd, matMul(matMul(qAllJEnd, w), tawTimesWT));
          q = concat([slice(q, [0, 0], [m, j]), qTimesTau], 1);
        }
        return [w, r, q];
      });
      dispose([rTemp, wTemp, qTemp]);
    }
    if (!fullMatrices && m > n) {
      q = slice(q, [0, 0], [m, n]);
      r = slice(r, [0, 0], [n, n]);
    }
    return [q, r];
  });
}
var qr;
var init_qr = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/linalg/qr.js"() {
    init_engine();
    init_globals();
    init_util();
    init_clone();
    init_concat();
    init_div();
    init_eye();
    init_greater();
    init_mat_mul();
    init_mul();
    init_neg();
    init_norm();
    init_operation();
    init_reshape();
    init_slice();
    init_stack();
    init_sub();
    init_tensor2d();
    init_transpose();
    init_unstack();
    init_where();
    qr = /* @__PURE__ */ op({ qr_ });
  }
});
var image;
var linalg;
var init_ops = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ops.js"() {
    init_abs();
    init_acos();
    init_acosh();
    init_add();
    init_all();
    init_any();
    init_arg_max();
    init_asin();
    init_asinh();
    init_atan();
    init_atanh();
    init_avg_pool();
    init_avg_pool_3d();
    init_batchnorm2d();
    init_batchnorm3d();
    init_batchnorm4d();
    init_broadcast_to();
    init_buffer();
    init_cast();
    init_ceil();
    init_clip_by_value();
    init_clone();
    init_concat();
    init_concat_1d();
    init_concat_2d();
    init_concat_3d();
    init_concat_4d();
    init_conv1d();
    init_conv2d();
    init_conv2d_transpose();
    init_conv3d();
    init_conv3d_transpose();
    init_cos();
    init_cosh();
    init_dense_bincount();
    init_depthwise_conv2d();
    init_div();
    init_elu();
    init_equal();
    init_erf();
    init_exp();
    init_expand_dims();
    init_expm1();
    init_eye();
    init_fill();
    init_floor();
    init_gather();
    init_greater();
    init_greater_equal();
    init_is_finite();
    init_is_inf();
    init_is_nan();
    init_leaky_relu();
    init_log2();
    init_log1p();
    init_log_sigmoid();
    init_log_softmax();
    init_logical_and();
    init_mat_mul();
    init_max();
    init_max_pool();
    init_max_pool_3d();
    init_maximum();
    init_mean();
    init_min();
    init_minimum();
    init_moments();
    init_mul();
    init_neg();
    init_not_equal();
    init_one_hot();
    init_ones();
    init_ones_like();
    init_pad();
    init_prelu();
    init_random_normal();
    init_random_uniform();
    init_range();
    init_reciprocal();
    init_relu();
    init_reshape();
    init_reverse();
    init_round();
    init_rsqrt();
    init_scalar();
    init_selu();
    init_separable_conv2d();
    init_sigmoid();
    init_sign();
    init_sin();
    init_sinh();
    init_slice();
    init_slice1d();
    init_slice2d();
    init_slice3d();
    init_slice4d();
    init_softmax();
    init_softplus();
    init_fft();
    init_ifft();
    init_irfft();
    init_rfft();
    init_split();
    init_sqrt();
    init_square();
    init_squeeze();
    init_stack();
    init_step();
    init_strided_slice();
    init_sub();
    init_sum();
    init_tan();
    init_tanh();
    init_tensor2();
    init_tensor1d();
    init_tile();
    init_truncated_normal();
    init_unstack();
    init_variable();
    init_where();
    init_zeros();
    init_zeros_like();
    init_boolean_mask();
    init_transpose();
    init_norm();
    init_moving_average();
    init_scatter_nd();
    init_search_sorted();
    init_sparse_to_dense();
    init_gather_nd();
    init_dropout();
    init_signal_ops_util();
    init_in_top_k();
    init_fused_ops();
    init_crop_and_resize();
    init_flip_left_right();
    init_grayscale_to_rgb();
    init_rotate_with_offset();
    init_non_max_suppression();
    init_non_max_suppression_async();
    init_non_max_suppression_with_score();
    init_non_max_suppression_with_score_async();
    init_non_max_suppression_padded();
    init_non_max_suppression_padded_async();
    init_resize_bilinear();
    init_resize_nearest_neighbor();
    init_threshold();
    init_transform();
    init_band_part();
    init_gram_schmidt();
    init_qr();
    image = {
      flipLeftRight,
      grayscaleToRGB,
      resizeNearestNeighbor,
      resizeBilinear,
      rotateWithOffset,
      cropAndResize,
      nonMaxSuppression,
      nonMaxSuppressionAsync,
      nonMaxSuppressionWithScore,
      nonMaxSuppressionWithScoreAsync,
      nonMaxSuppressionPadded,
      nonMaxSuppressionPaddedAsync,
      threshold,
      transform
    };
    linalg = {
      bandPart,
      gramSchmidt,
      qr
    };
  }
});
var serialization_exports = {};
__export2(serialization_exports, {
  Serializable: () => Serializable,
  SerializationMap: () => SerializationMap,
  registerClass: () => registerClass
});
function registerClass(cls) {
  assert(cls.className != null, () => `Class being registered does not have the static className property defined.`);
  assert(typeof cls.className === "string", () => `className is required to be a string, but got type ` + typeof cls.className);
  assert(cls.className.length > 0, () => `Class being registered has an empty-string as its className, which is disallowed.`);
  SerializationMap.register(cls);
}
var Serializable;
var SerializationMap;
var init_serialization = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/serialization.js"() {
    init_util();
    Serializable = class {
      /**
       * Return the class name for this class to use in serialization contexts.
       *
       * Generally speaking this will be the same thing that constructor.name
       * would have returned.  However, the class name needs to be robust
       * against minification for serialization/deserialization to work properly.
       *
       * There's also places such as initializers.VarianceScaling, where
       * implementation details between different languages led to different
       * class hierarchies and a non-leaf node is used for serialization purposes.
       */
      getClassName() {
        return this.constructor.className;
      }
      /**
       * Creates an instance of T from a ConfigDict.
       *
       * This works for most descendants of serializable.  A few need to
       * provide special handling.
       * @param cls A Constructor for the class to instantiate.
       * @param config The Configuration for the object.
       */
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config);
      }
    };
    SerializationMap = class {
      constructor() {
        this.classNameMap = {};
      }
      /**
       * Returns the singleton instance of the map.
       */
      static getMap() {
        if (SerializationMap.instance == null) {
          SerializationMap.instance = new SerializationMap();
        }
        return SerializationMap.instance;
      }
      /**
       * Registers the class as serializable.
       */
      static register(cls) {
        SerializationMap.getMap().classNameMap[cls.className] = [cls, cls.fromConfig];
      }
    };
  }
});
var Optimizer;
var init_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer.js"() {
    init_globals();
    init_gradients();
    init_ops();
    init_serialization();
    Optimizer = class extends Serializable {
      /**
       * Executes `f()` and minimizes the scalar output of `f()` by computing
       * gradients of y with respect to the list of trainable variables provided by
       * `varList`. If no list is provided, it defaults to all trainable variables.
       *
       * @param f The function to execute and whose output to minimize.
       * @param returnCost Whether to return the scalar cost value produced by
       * executing `f()`.
       * @param varList An optional list of variables to update. If specified, only
       * the trainable variables in varList will be updated by minimize. Defaults to
       * all trainable variables.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers'}
       */
      minimize(f, returnCost = false, varList) {
        const { value, grads } = this.computeGradients(f, varList);
        if (varList != null) {
          const gradArray = varList.map((v) => ({ name: v.name, tensor: grads[v.name] }));
          this.applyGradients(gradArray);
        } else {
          this.applyGradients(grads);
        }
        dispose(grads);
        if (returnCost) {
          return value;
        } else {
          value.dispose();
          return null;
        }
      }
      /**
       * The number of iterations that this optimizer instance has been invoked for.
       */
      get iterations() {
        if (this.iterations_ == null) {
          this.iterations_ = 0;
        }
        return this.iterations_;
      }
      incrementIterations() {
        this.iterations_ = this.iterations + 1;
      }
      /**
       * Executes f() and computes the gradient of the scalar output of f() with
       * respect to the list of trainable variables provided by `varList`. If no
       * list is provided, it defaults to all trainable variables.
       *
       * @param f The function to execute and whose output to use for computing
       * gradients with respect to variables.
       * @param varList An optional list of variables to compute gradients with
       * respect to. If specified, only the trainable variables in varList will have
       * gradients computed with respect to. Defaults to all trainable variables.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers'}
       */
      computeGradients(f, varList) {
        return variableGrads(f, varList);
      }
      /**
       * Dispose the variables (if any) owned by this optimizer instance.
       */
      dispose() {
        if (this.iterations_ != null) {
          dispose(this.iterations_);
        }
      }
      async saveIterations() {
        if (this.iterations_ == null) {
          this.iterations_ = 0;
        }
        return {
          name: "iter",
          // TODO(cais): Use 'int64' type when available.
          tensor: scalar(this.iterations_, "int32")
        };
      }
      async getWeights() {
        throw new Error("getWeights() is not implemented for this optimizer yet.");
      }
      async setWeights(weightValues) {
        throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
      }
      /**
       * Extract the first element of the weight values and set it
       * as the iterations counter variable of this instance of optimizer.
       *
       * @param weightValues
       * @returns Weight values with the first element consumed and excluded.
       */
      async extractIterations(weightValues) {
        this.iterations_ = (await weightValues[0].tensor.data())[0];
        return weightValues.slice(1);
      }
    };
    Object.defineProperty(Optimizer, Symbol.hasInstance, {
      value: (instance) => {
        return instance.minimize != null && instance.computeGradients != null && instance.applyGradients != null;
      }
    });
  }
});
var AdadeltaOptimizer;
var init_adadelta_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_mul();
    init_ops();
    init_square();
    init_zeros_like();
    init_optimizer();
    AdadeltaOptimizer = class extends Optimizer {
      constructor(learningRate, rho, epsilon3 = null) {
        super();
        this.learningRate = learningRate;
        this.rho = rho;
        this.epsilon = epsilon3;
        this.accumulatedGrads = [];
        this.accumulatedUpdates = [];
        if (epsilon3 == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
      }
      /** @nocollapse */
      static get className() {
        return "Adadelta";
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          const trainable = false;
          if (this.accumulatedGrads[i] == null) {
            this.accumulatedGrads[i] = {
              originalName: `${name}/accum_grad`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedUpdates[i] == null) {
            this.accumulatedUpdates[i] = {
              originalName: `${name}/accum_var`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const accumulatedGrad = this.accumulatedGrads[i].variable;
          const accumulatedUpdate = this.accumulatedUpdates[i].variable;
          tidy(() => {
            const newAccumulatedGrad = add22(mul5(accumulatedGrad, this.rho), mul5(square(gradient), 1 - this.rho));
            const updates = mul5(div2(sqrt(add22(accumulatedUpdate, this.epsilon)), sqrt(add22(accumulatedGrad, this.epsilon))), gradient);
            const newAccumulatedUpdate = add22(mul5(accumulatedUpdate, this.rho), mul5(square(updates), 1 - this.rho));
            accumulatedGrad.assign(newAccumulatedGrad);
            accumulatedUpdate.assign(newAccumulatedUpdate);
            const newValue = add22(mul5(updates, -this.learningRate), value);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      dispose() {
        if (this.accumulatedUpdates != null) {
          dispose(this.accumulatedGrads.map((v) => v.variable));
          dispose(this.accumulatedUpdates.map((v) => v.variable));
        }
      }
      async getWeights() {
        const variables = [...this.accumulatedGrads, ...this.accumulatedUpdates];
        return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
      }
      async setWeights(weightValues) {
        weightValues = await this.extractIterations(weightValues);
        const variableCount = weightValues.length / 2;
        const trainable = false;
        this.accumulatedGrads = weightValues.slice(0, variableCount).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
        this.accumulatedUpdates = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "rho": this.rho,
          "epsilon": this.epsilon
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["rho"], config["epsilon"]);
      }
    };
  }
});
var AdagradOptimizer;
var init_adagrad_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_fill();
    init_mul();
    init_sqrt();
    init_square();
    init_optimizer();
    AdagradOptimizer = class extends Optimizer {
      constructor(learningRate, initialAccumulatorValue = 0.1) {
        super();
        this.learningRate = learningRate;
        this.initialAccumulatorValue = initialAccumulatorValue;
        this.accumulatedGrads = [];
      }
      /** @nocollapse */
      static get className() {
        return "Adagrad";
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          if (this.accumulatedGrads[i] == null) {
            const trainable = false;
            this.accumulatedGrads[i] = {
              originalName: `${name}/accumulator`,
              variable: tidy(() => fill(value.shape, this.initialAccumulatorValue).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const accumulatedGrad = this.accumulatedGrads[i].variable;
          tidy(() => {
            const newAccumulatedGrad = add22(accumulatedGrad, square(gradient));
            accumulatedGrad.assign(newAccumulatedGrad);
            const newValue = add22(mul5(div2(gradient, sqrt(add22(newAccumulatedGrad, ENGINE.backend.epsilon()))), -this.learningRate), value);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      dispose() {
        if (this.accumulatedGrads != null) {
          dispose(this.accumulatedGrads.map((v) => v.variable));
        }
      }
      async getWeights() {
        return [await this.saveIterations()].concat(this.accumulatedGrads.map((v) => ({ name: v.originalName, tensor: v.variable })));
      }
      async setWeights(weightValues) {
        weightValues = await this.extractIterations(weightValues);
        const trainable = false;
        this.accumulatedGrads = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "initialAccumulatorValue": this.initialAccumulatorValue
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["initialAccumulatorValue"]);
      }
    };
  }
});
var AdamOptimizer;
var init_adam_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_mul();
    init_pow();
    init_scalar();
    init_sqrt();
    init_square();
    init_sub();
    init_zeros_like();
    init_optimizer();
    AdamOptimizer = class extends Optimizer {
      constructor(learningRate, beta1, beta2, epsilon3 = null) {
        super();
        this.learningRate = learningRate;
        this.beta1 = beta1;
        this.beta2 = beta2;
        this.epsilon = epsilon3;
        this.accumulatedFirstMoment = [];
        this.accumulatedSecondMoment = [];
        tidy(() => {
          this.accBeta1 = scalar(beta1).variable();
          this.accBeta2 = scalar(beta2).variable();
        });
        if (epsilon3 == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
      }
      /** @nocollapse */
      static get className() {
        return "Adam";
      }
      applyGradients(variableGradients) {
        const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
        tidy(() => {
          const oneMinusAccBeta1 = sub3(1, this.accBeta1);
          const oneMinusAccBeta2 = sub3(1, this.accBeta2);
          varNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            const trainable = false;
            if (this.accumulatedFirstMoment[i] == null) {
              this.accumulatedFirstMoment[i] = {
                originalName: `${name}/m`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            if (this.accumulatedSecondMoment[i] == null) {
              this.accumulatedSecondMoment[i] = {
                originalName: `${name}/v`,
                variable: tidy(() => zerosLike(value).variable(trainable))
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const firstMoment = this.accumulatedFirstMoment[i].variable;
            const secondMoment = this.accumulatedSecondMoment[i].variable;
            const newFirstMoment = add22(mul5(firstMoment, this.beta1), mul5(gradient, 1 - this.beta1));
            const newSecondMoment = add22(mul5(secondMoment, this.beta2), mul5(square(gradient), 1 - this.beta2));
            const biasCorrectedFirstMoment = div2(newFirstMoment, oneMinusAccBeta1);
            const biasCorrectedSecondMoment = div2(newSecondMoment, oneMinusAccBeta2);
            firstMoment.assign(newFirstMoment);
            secondMoment.assign(newSecondMoment);
            const newValue = add22(mul5(div2(biasCorrectedFirstMoment, add22(sqrt(biasCorrectedSecondMoment), this.epsilon)), -this.learningRate), value);
            value.assign(newValue);
          });
          this.accBeta1.assign(mul5(this.accBeta1, this.beta1));
          this.accBeta2.assign(mul5(this.accBeta2, this.beta2));
        });
        this.incrementIterations();
      }
      dispose() {
        this.accBeta1.dispose();
        this.accBeta2.dispose();
        if (this.accumulatedFirstMoment != null) {
          dispose(this.accumulatedFirstMoment.map((v) => v.variable));
        }
        if (this.accumulatedSecondMoment != null) {
          dispose(this.accumulatedSecondMoment.map((v) => v.variable));
        }
      }
      async getWeights() {
        const variables = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
        return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
      }
      async setWeights(weightValues) {
        weightValues = await this.extractIterations(weightValues);
        tidy(() => {
          this.accBeta1.assign(pow2(this.beta1, this.iterations_ + 1));
          this.accBeta2.assign(pow2(this.beta2, this.iterations_ + 1));
        });
        const variableCount = weightValues.length / 2;
        const trainable = false;
        this.accumulatedFirstMoment = weightValues.slice(0, variableCount).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
        this.accumulatedSecondMoment = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "beta1": this.beta1,
          "beta2": this.beta2,
          "epsilon": this.epsilon
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"]);
      }
    };
  }
});
var AdamaxOptimizer;
var init_adamax_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js"() {
    init_engine();
    init_globals();
    init_abs();
    init_add();
    init_div();
    init_maximum();
    init_mul();
    init_scalar();
    init_sub();
    init_zeros_like();
    init_optimizer();
    AdamaxOptimizer = class extends Optimizer {
      constructor(learningRate, beta1, beta2, epsilon3 = null, decay = 0) {
        super();
        this.learningRate = learningRate;
        this.beta1 = beta1;
        this.beta2 = beta2;
        this.epsilon = epsilon3;
        this.decay = decay;
        this.accumulatedFirstMoment = [];
        this.accumulatedWeightedInfNorm = [];
        tidy(() => {
          this.iteration = scalar(0).variable();
          this.accBeta1 = scalar(beta1).variable();
        });
        if (epsilon3 == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
      }
      /** @nocollapse */
      static get className() {
        return "Adamax";
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        tidy(() => {
          const oneMinusAccBeta1 = sub3(1, this.accBeta1);
          const lr = div2(-this.learningRate, add22(mul5(this.iteration, this.decay), 1));
          variableNames.forEach((name, i) => {
            const value = ENGINE.registeredVariables[name];
            const trainable = false;
            if (this.accumulatedFirstMoment[i] == null) {
              this.accumulatedFirstMoment[i] = {
                originalName: `${name}/m`,
                variable: zerosLike(value).variable(trainable)
              };
            }
            if (this.accumulatedWeightedInfNorm[i] == null) {
              this.accumulatedWeightedInfNorm[i] = {
                originalName: `${name}/v`,
                variable: zerosLike(value).variable(trainable)
              };
            }
            const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
            if (gradient == null) {
              return;
            }
            const firstMoment = this.accumulatedFirstMoment[i].variable;
            const weightedInfNorm = this.accumulatedWeightedInfNorm[i].variable;
            const newFirstMoment = add22(mul5(firstMoment, this.beta1), mul5(gradient, 1 - this.beta1));
            const ut0 = mul5(weightedInfNorm, this.beta2);
            const ut1 = abs(gradient);
            const newWeightedInfNorm = maximum(ut0, ut1);
            firstMoment.assign(newFirstMoment);
            weightedInfNorm.assign(newWeightedInfNorm);
            const newValue = add22(mul5(div2(lr, oneMinusAccBeta1), div2(newFirstMoment, add22(newWeightedInfNorm, this.epsilon))), value);
            value.assign(newValue);
          });
          this.iteration.assign(add22(this.iteration, 1));
          this.accBeta1.assign(mul5(this.accBeta1, this.beta1));
        });
        this.incrementIterations();
      }
      dispose() {
        this.accBeta1.dispose();
        this.iteration.dispose();
        if (this.accumulatedFirstMoment != null) {
          dispose(this.accumulatedFirstMoment.map((v) => v.variable));
        }
        if (this.accumulatedWeightedInfNorm != null) {
          dispose(this.accumulatedWeightedInfNorm.map((v) => v.variable));
        }
      }
      async getWeights() {
        throw new Error("getWeights() is not implemented for Adamax yet.");
      }
      async setWeights(weightValues) {
        throw new Error("setWeights() is not implemented for Adamax yet.");
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "beta1": this.beta1,
          "beta2": this.beta2,
          "epsilon": this.epsilon,
          "decay": this.decay
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["beta1"], config["beta2"], config["epsilon"], config["decay"]);
      }
    };
  }
});
var SGDOptimizer;
var init_sgd_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_mul();
    init_scalar();
    init_optimizer();
    SGDOptimizer = class extends Optimizer {
      constructor(learningRate) {
        super();
        this.learningRate = learningRate;
        this.setLearningRate(learningRate);
      }
      /** @nocollapse */
      static get className() {
        return "SGD";
      }
      applyGradients(variableGradients) {
        const varNames = Array.isArray(variableGradients) ? variableGradients.map((v) => v.name) : Object.keys(variableGradients);
        varNames.forEach((name, i) => {
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const value = ENGINE.registeredVariables[name];
          tidy(() => {
            const newValue = add22(mul5(this.c, gradient), value);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      /**
       * Sets the learning rate of the optimizer.
       */
      setLearningRate(learningRate) {
        this.learningRate = learningRate;
        if (this.c != null) {
          this.c.dispose();
        }
        this.c = keep(scalar(-learningRate));
      }
      dispose() {
        this.c.dispose();
      }
      async getWeights() {
        return [await this.saveIterations()];
      }
      async setWeights(weightValues) {
        weightValues = await this.extractIterations(weightValues);
        if (weightValues.length !== 0) {
          throw new Error("SGD optimizer does not have settable weights.");
        }
      }
      getConfig() {
        return { "learningRate": this.learningRate };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"]);
      }
    };
  }
});
var MomentumOptimizer;
var init_momentum_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_mul();
    init_scalar();
    init_zeros_like();
    init_sgd_optimizer();
    MomentumOptimizer = class extends SGDOptimizer {
      constructor(learningRate, momentum, useNesterov = false) {
        super(learningRate);
        this.learningRate = learningRate;
        this.momentum = momentum;
        this.useNesterov = useNesterov;
        this.accumulations = [];
        this.m = scalar(this.momentum);
      }
      /** @nocollapse */
      // Name matters for Python compatibility.
      static get className() {
        return "Momentum";
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          if (this.accumulations[i] == null) {
            const trainable = false;
            this.accumulations[i] = {
              originalName: `${name}/momentum`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const accumulation = this.accumulations[i].variable;
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          tidy(() => {
            let newValue;
            const newAccumulation = add22(mul5(this.m, accumulation), gradient);
            if (this.useNesterov) {
              newValue = add22(mul5(this.c, add22(gradient, mul5(newAccumulation, this.m))), value);
            } else {
              newValue = add22(mul5(this.c, newAccumulation), value);
            }
            accumulation.assign(newAccumulation);
            value.assign(newValue);
          });
        });
        this.incrementIterations();
      }
      dispose() {
        this.m.dispose();
        if (this.accumulations != null) {
          dispose(this.accumulations.map((v) => v.variable));
        }
      }
      /**
       * Sets the momentum of the optimizer.
       *
       * @param momentum
       */
      setMomentum(momentum) {
        this.momentum = momentum;
      }
      async getWeights() {
        return [await this.saveIterations()].concat(this.accumulations.map((v) => ({ name: v.originalName, tensor: v.variable })));
      }
      async setWeights(weightValues) {
        weightValues = await this.extractIterations(weightValues);
        const trainable = false;
        this.accumulations = weightValues.map((v) => ({ originalName: v.name, variable: v.tensor.variable(trainable) }));
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "momentum": this.momentum,
          "useNesterov": this.useNesterov
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["momentum"], config["useNesterov"]);
      }
    };
  }
});
var RMSPropOptimizer;
var init_rmsprop_optimizer = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js"() {
    init_engine();
    init_globals();
    init_add();
    init_div();
    init_mul();
    init_sqrt();
    init_square();
    init_sub();
    init_zeros_like();
    init_optimizer();
    RMSPropOptimizer = class extends Optimizer {
      constructor(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
        super();
        this.learningRate = learningRate;
        this.decay = decay;
        this.momentum = momentum;
        this.epsilon = epsilon3;
        this.accumulatedMeanSquares = [];
        this.accumulatedMoments = [];
        this.accumulatedMeanGrads = [];
        this.centered = centered;
        if (epsilon3 == null) {
          this.epsilon = ENGINE.backend.epsilon();
        }
        if (learningRate == null) {
          throw new Error(`learningRate for RMSPropOptimizer must be defined.`);
        }
      }
      /** @nocollapse */
      static get className() {
        return "RMSProp";
      }
      applyGradients(variableGradients) {
        const variableNames = Array.isArray(variableGradients) ? variableGradients.map((item) => item.name) : Object.keys(variableGradients);
        variableNames.forEach((name, i) => {
          const value = ENGINE.registeredVariables[name];
          const trainable = false;
          if (this.accumulatedMeanSquares[i] == null) {
            this.accumulatedMeanSquares[i] = {
              originalName: `${name}/rms`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedMoments[i] == null) {
            this.accumulatedMoments[i] = {
              originalName: `${name}/momentum`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          if (this.accumulatedMeanGrads[i] == null && this.centered) {
            this.accumulatedMeanGrads[i] = {
              originalName: `${name}/mg`,
              variable: tidy(() => zerosLike(value).variable(trainable))
            };
          }
          const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];
          if (gradient == null) {
            return;
          }
          const accumulatedMeanSquare = this.accumulatedMeanSquares[i].variable;
          const accumulatedMoments = this.accumulatedMoments[i].variable;
          tidy(() => {
            const newAccumulatedMeanSquare = add22(mul5(accumulatedMeanSquare, this.decay), mul5(square(gradient), 1 - this.decay));
            if (this.centered) {
              const accumulatedMeanGrad = this.accumulatedMeanGrads[i].variable;
              const newAccumulatedMeanGrad = add22(mul5(accumulatedMeanGrad, this.decay), mul5(gradient, 1 - this.decay));
              const gradContribution = div2(mul5(gradient, this.learningRate), sqrt(sub3(newAccumulatedMeanSquare, add22(square(newAccumulatedMeanGrad), this.epsilon))));
              const newAccumulatedMoments = add22(mul5(accumulatedMoments, this.momentum), gradContribution);
              accumulatedMeanSquare.assign(newAccumulatedMeanSquare);
              accumulatedMeanGrad.assign(newAccumulatedMeanGrad);
              accumulatedMoments.assign(newAccumulatedMoments);
              const newValue = sub3(value, newAccumulatedMoments);
              value.assign(newValue);
            } else {
              const newAccumulatedMeanSquare2 = add22(mul5(accumulatedMeanSquare, this.decay), mul5(square(gradient), 1 - this.decay));
              const newAccumulatedMoments = add22(mul5(accumulatedMoments, this.momentum), div2(mul5(gradient, this.learningRate), sqrt(add22(newAccumulatedMeanSquare2, this.epsilon))));
              accumulatedMeanSquare.assign(newAccumulatedMeanSquare2);
              accumulatedMoments.assign(newAccumulatedMoments);
              const newValue = sub3(value, newAccumulatedMoments);
              value.assign(newValue);
            }
          });
        });
        this.incrementIterations();
      }
      dispose() {
        if (this.accumulatedMeanSquares != null) {
          dispose(this.accumulatedMeanSquares.map((v) => v.variable));
        }
        if (this.accumulatedMeanGrads != null && this.centered) {
          dispose(this.accumulatedMeanGrads.map((v) => v.variable));
        }
        if (this.accumulatedMoments != null) {
          dispose(this.accumulatedMoments.map((v) => v.variable));
        }
      }
      async getWeights() {
        const variables = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
        if (this.centered) {
          variables.push(...this.accumulatedMeanGrads);
        }
        return [await this.saveIterations()].concat(variables.map((v) => ({ name: v.originalName, tensor: v.variable })));
      }
      async setWeights(weightValues) {
        weightValues = await this.extractIterations(weightValues);
        const variableCount = this.centered ? weightValues.length / 3 : weightValues.length / 2;
        const trainable = false;
        this.accumulatedMeanSquares = weightValues.slice(0, variableCount).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
        this.accumulatedMoments = weightValues.slice(variableCount, variableCount * 2).map((v) => ({
          originalName: v.name,
          variable: v.tensor.variable(trainable)
        }));
        if (this.centered) {
          this.accumulatedMeanGrads = weightValues.slice(variableCount * 2, variableCount * 3).map((v) => ({
            originalName: v.name,
            variable: v.tensor.variable(trainable)
          }));
        }
      }
      getConfig() {
        return {
          "learningRate": this.learningRate,
          "decay": this.decay,
          "momentum": this.momentum,
          "epsilon": this.epsilon,
          "centered": this.centered
        };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config["learningRate"], config["decay"], config["momentum"], config["epsilon"], config["centered"]);
      }
    };
  }
});
function registerOptimizers() {
  for (const optimizer of OPTIMIZERS) {
    registerClass(optimizer);
  }
}
var OPTIMIZERS;
var init_register_optimizers = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js"() {
    init_adadelta_optimizer();
    init_adagrad_optimizer();
    init_adam_optimizer();
    init_adamax_optimizer();
    init_momentum_optimizer();
    init_rmsprop_optimizer();
    init_sgd_optimizer();
    init_serialization();
    OPTIMIZERS = [
      AdadeltaOptimizer,
      AdagradOptimizer,
      AdamOptimizer,
      AdamaxOptimizer,
      MomentumOptimizer,
      RMSPropOptimizer,
      SGDOptimizer
    ];
  }
});
function defer(f) {
  return new Promise((resolve) => setTimeout(resolve)).then(f);
}
function browserDownloads(fileNamePrefix = "model") {
  return new BrowserDownloads(fileNamePrefix);
}
function browserFiles(files) {
  return new BrowserFiles(files);
}
var DEFAULT_FILE_NAME_PREFIX;
var DEFAULT_JSON_EXTENSION_NAME;
var DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
var BrowserDownloads;
var BrowserFiles;
var browserDownloadsRouter;
var init_browser_files = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/browser_files.js"() {
    init_flags();
    init_environment();
    init_io_utils();
    init_router_registry();
    DEFAULT_FILE_NAME_PREFIX = "model";
    DEFAULT_JSON_EXTENSION_NAME = ".json";
    DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";
    BrowserDownloads = class {
      constructor(fileNamePrefix) {
        if (!env().getBool("IS_BROWSER")) {
          throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
        }
        if (fileNamePrefix.startsWith(BrowserDownloads.URL_SCHEME)) {
          fileNamePrefix = fileNamePrefix.slice(BrowserDownloads.URL_SCHEME.length);
        }
        if (fileNamePrefix == null || fileNamePrefix.length === 0) {
          fileNamePrefix = DEFAULT_FILE_NAME_PREFIX;
        }
        this.modelJsonFileName = fileNamePrefix + DEFAULT_JSON_EXTENSION_NAME;
        this.weightDataFileName = fileNamePrefix + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
      }
      async save(modelArtifacts) {
        if (typeof document === "undefined") {
          throw new Error("Browser downloads are not supported in this environment since `document` is not present");
        }
        const weightsURL = window.URL.createObjectURL(new Blob([modelArtifacts.weightData], { type: "application/octet-stream" }));
        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
          throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
        } else {
          const weightsManifest = [{
            paths: ["./" + this.weightDataFileName],
            weights: modelArtifacts.weightSpecs
          }];
          const modelJSON = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
          const modelJsonURL = window.URL.createObjectURL(new Blob([JSON.stringify(modelJSON)], { type: "application/json" }));
          const jsonAnchor = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
          jsonAnchor.download = this.modelJsonFileName;
          jsonAnchor.href = modelJsonURL;
          await defer(() => jsonAnchor.dispatchEvent(new MouseEvent("click")));
          if (modelArtifacts.weightData != null) {
            const weightDataAnchor = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
            weightDataAnchor.download = this.weightDataFileName;
            weightDataAnchor.href = weightsURL;
            await defer(() => weightDataAnchor.dispatchEvent(new MouseEvent("click")));
          }
          return { modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts) };
        }
      }
    };
    BrowserDownloads.URL_SCHEME = "downloads://";
    BrowserFiles = class {
      constructor(files) {
        if (files == null || files.length < 1) {
          throw new Error(`When calling browserFiles, at least 1 file is required, but received ${files}`);
        }
        this.jsonFile = files[0];
        this.weightsFiles = files.slice(1);
      }
      async load() {
        return new Promise((resolve, reject) => {
          const jsonReader = new FileReader();
          jsonReader.onload = (event) => {
            const modelJSON = JSON.parse(event.target.result);
            const modelTopology = modelJSON.modelTopology;
            if (modelTopology == null) {
              reject(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
              return;
            }
            const weightsManifest = modelJSON.weightsManifest;
            if (weightsManifest == null) {
              reject(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
              return;
            }
            if (this.weightsFiles.length === 0) {
              resolve({ modelTopology });
              return;
            }
            const modelArtifactsPromise = getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
            resolve(modelArtifactsPromise);
          };
          jsonReader.onerror = (error) => reject(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`);
          jsonReader.readAsText(this.jsonFile);
        });
      }
      loadWeights(weightsManifest) {
        const weightSpecs = [];
        const paths = [];
        for (const entry of weightsManifest) {
          weightSpecs.push(...entry.weights);
          paths.push(...entry.paths);
        }
        const pathToFile = this.checkManifestAndWeightFiles(weightsManifest);
        const promises = paths.map((path) => this.loadWeightsFile(path, pathToFile[path]));
        return Promise.all(promises).then((buffers) => [weightSpecs, concatenateArrayBuffers(buffers)]);
      }
      loadWeightsFile(path, file) {
        return new Promise((resolve, reject) => {
          const weightFileReader = new FileReader();
          weightFileReader.onload = (event) => {
            const weightData = event.target.result;
            resolve(weightData);
          };
          weightFileReader.onerror = (error) => reject(`Failed to weights data from file of path '${path}'.`);
          weightFileReader.readAsArrayBuffer(file);
        });
      }
      /**
       * Check the compatibility between weights manifest and weight files.
       */
      checkManifestAndWeightFiles(manifest) {
        const basenames = [];
        const fileNames = this.weightsFiles.map((file) => basename(file.name));
        const pathToFile = {};
        for (const group of manifest) {
          group.paths.forEach((path) => {
            const pathBasename = basename(path);
            if (basenames.indexOf(pathBasename) !== -1) {
              throw new Error(`Duplicate file basename found in weights manifest: '${pathBasename}'`);
            }
            basenames.push(pathBasename);
            if (fileNames.indexOf(pathBasename) === -1) {
              throw new Error(`Weight file with basename '${pathBasename}' is not provided.`);
            } else {
              pathToFile[path] = this.weightsFiles[fileNames.indexOf(pathBasename)];
            }
          });
        }
        if (basenames.length !== this.weightsFiles.length) {
          throw new Error(`Mismatch in the number of files in weights manifest (${basenames.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
        }
        return pathToFile;
      }
    };
    browserDownloadsRouter = (url) => {
      if (!env().getBool("IS_BROWSER")) {
        return null;
      } else {
        if (!Array.isArray(url) && url.startsWith(BrowserDownloads.URL_SCHEME)) {
          return browserDownloads(url.slice(BrowserDownloads.URL_SCHEME.length));
        } else {
          return null;
        }
      }
    };
    IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
  }
});
function monitorPromisesProgress(promises, onProgress, startFraction, endFraction) {
  checkPromises(promises);
  startFraction = startFraction == null ? 0 : startFraction;
  endFraction = endFraction == null ? 1 : endFraction;
  checkFraction(startFraction, endFraction);
  let resolvedPromise = 0;
  const registerMonitor = (promise) => {
    promise.then((value) => {
      const fraction = startFraction + ++resolvedPromise / promises.length * (endFraction - startFraction);
      onProgress(fraction);
      return value;
    });
    return promise;
  };
  function checkPromises(promises2) {
    assert(promises2 != null && Array.isArray(promises2) && promises2.length > 0, () => "promises must be a none empty array");
  }
  function checkFraction(startFraction2, endFraction2) {
    assert(startFraction2 >= 0 && startFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${startFraction2}`);
    assert(endFraction2 >= 0 && endFraction2 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${endFraction2}`);
    assert(endFraction2 >= startFraction2, () => `startFraction must be no more than endFraction, but got startFraction ${startFraction2} and endFraction ${endFraction2}`);
  }
  return Promise.all(promises.map(registerMonitor));
}
var init_progress = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/progress.js"() {
    init_util();
  }
});
async function loadWeightsAsArrayBuffer(fetchURLs, loadOptions) {
  if (loadOptions == null) {
    loadOptions = {};
  }
  const fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc;
  const requests = fetchURLs.map((fetchURL) => fetchFunc(fetchURL, loadOptions.requestInit, { isBinary: true }));
  const fetchStartFraction = 0;
  const fetchEndFraction = 0.5;
  const responses = loadOptions.onProgress == null ? await Promise.all(requests) : await monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);
  const bufferPromises = responses.map((response) => response.arrayBuffer());
  const bufferStartFraction = 0.5;
  const bufferEndFraction = 1;
  const buffers = loadOptions.onProgress == null ? await Promise.all(bufferPromises) : await monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);
  return buffers;
}
async function loadWeights(manifest, filePathPrefix = "", weightNames, requestInit) {
  const fetchWeights = (fetchUrls) => loadWeightsAsArrayBuffer(fetchUrls, { requestInit });
  const loadWeights2 = weightsLoaderFactory(fetchWeights);
  return loadWeights2(manifest, filePathPrefix, weightNames);
}
function weightsLoaderFactory(fetchWeightsFunction) {
  return async (manifest, filePathPrefix = "", weightNames) => {
    const groupIndicesToFetchMap = manifest.map(() => false);
    const groupWeightsToFetch = {};
    const weightsFound = weightNames != null ? weightNames.map(() => false) : [];
    const allManifestWeightNames = [];
    manifest.forEach((manifestGroupConfig, groupIndex) => {
      let groupOffset = 0;
      manifestGroupConfig.weights.forEach((weightsEntry) => {
        const rawDtype = "quantization" in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;
        const weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * sizeFromShape(weightsEntry.shape);
        const enqueueWeightsForFetchingFn = () => {
          groupIndicesToFetchMap[groupIndex] = true;
          if (groupWeightsToFetch[groupIndex] == null) {
            groupWeightsToFetch[groupIndex] = [];
          }
          groupWeightsToFetch[groupIndex].push({
            manifestEntry: weightsEntry,
            groupOffset,
            sizeBytes: weightsBytes
          });
        };
        if (weightNames != null) {
          weightNames.forEach((weightName, weightIndex) => {
            if (weightName === weightsEntry.name) {
              enqueueWeightsForFetchingFn();
              weightsFound[weightIndex] = true;
            }
          });
        } else {
          enqueueWeightsForFetchingFn();
        }
        allManifestWeightNames.push(weightsEntry.name);
        groupOffset += weightsBytes;
      });
    });
    if (!weightsFound.every((found) => found)) {
      const weightsNotFound = weightNames.filter((_, i) => !weightsFound[i]);
      throw new Error(`Could not find weights in manifest with names: ${weightsNotFound.join(", ")}. 
Manifest JSON has weights with names: ${allManifestWeightNames.join(", ")}.`);
    }
    const groupIndicesToFetch = groupIndicesToFetchMap.reduce((accumulator, shouldFetch, i) => {
      if (shouldFetch) {
        accumulator.push(i);
      }
      return accumulator;
    }, []);
    const fetchUrls = [];
    groupIndicesToFetch.forEach((i) => {
      manifest[i].paths.forEach((filepath) => {
        const fetchUrl = filePathPrefix + (!filePathPrefix.endsWith("/") ? "/" : "") + filepath;
        fetchUrls.push(fetchUrl);
      });
    });
    const buffers = await fetchWeightsFunction(fetchUrls);
    const weightsTensorMap = {};
    let bufferIndexOffset = 0;
    groupIndicesToFetch.forEach((i) => {
      const numBuffers = manifest[i].paths.length;
      let groupBytes = 0;
      for (let i2 = 0; i2 < numBuffers; i2++) {
        groupBytes += buffers[bufferIndexOffset + i2].byteLength;
      }
      const groupBuffer = new ArrayBuffer(groupBytes);
      const groupByteBuffer = new Uint8Array(groupBuffer);
      let groupBufferOffset = 0;
      for (let i2 = 0; i2 < numBuffers; i2++) {
        const buffer2 = new Uint8Array(buffers[bufferIndexOffset + i2]);
        groupByteBuffer.set(buffer2, groupBufferOffset);
        groupBufferOffset += buffer2.byteLength;
      }
      const weightsEntries = groupWeightsToFetch[i];
      weightsEntries.forEach((weightsEntry) => {
        const byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);
        const nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);
        for (const name in nameToTensorMap) {
          weightsTensorMap[name] = nameToTensorMap[name];
        }
      });
      bufferIndexOffset += numBuffers;
    });
    return weightsTensorMap;
  };
}
var init_weights_loader = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/weights_loader.js"() {
    init_environment();
    init_util();
    init_io_utils();
    init_progress();
    init_types2();
  }
});
function parseUrl(url) {
  const lastSlash = url.lastIndexOf("/");
  const lastSearchParam = url.lastIndexOf("?");
  const prefix = url.substring(0, lastSlash);
  const suffix = lastSearchParam > lastSlash ? url.substring(lastSearchParam) : "";
  return [prefix + "/", suffix];
}
function isHTTPScheme(url) {
  return url.match(HTTPRequest.URL_SCHEME_REGEX) != null;
}
function http(path, loadOptions) {
  return new HTTPRequest(path, loadOptions);
}
function browserHTTPRequest(path, loadOptions) {
  return http(path, loadOptions);
}
var OCTET_STREAM_MIME_TYPE;
var JSON_TYPE;
var HTTPRequest;
var httpRouter;
var init_http = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/http.js"() {
    init_environment();
    init_util();
    init_io_utils();
    init_router_registry();
    init_weights_loader();
    OCTET_STREAM_MIME_TYPE = "application/octet-stream";
    JSON_TYPE = "application/json";
    HTTPRequest = class {
      constructor(path, loadOptions) {
        this.DEFAULT_METHOD = "POST";
        if (loadOptions == null) {
          loadOptions = {};
        }
        this.weightPathPrefix = loadOptions.weightPathPrefix;
        this.onProgress = loadOptions.onProgress;
        this.weightUrlConverter = loadOptions.weightUrlConverter;
        if (loadOptions.fetchFunc != null) {
          assert(typeof loadOptions.fetchFunc === "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)");
          this.fetch = loadOptions.fetchFunc;
        } else {
          this.fetch = env().platform.fetch;
        }
        assert(path != null && path.length > 0, () => "URL path for http must not be null, undefined or empty.");
        if (Array.isArray(path)) {
          assert(path.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${path.length}).`);
        }
        this.path = path;
        if (loadOptions.requestInit != null && loadOptions.requestInit.body != null) {
          throw new Error("requestInit is expected to have no pre-existing body, but has one.");
        }
        this.requestInit = loadOptions.requestInit || {};
      }
      async save(modelArtifacts) {
        if (modelArtifacts.modelTopology instanceof ArrayBuffer) {
          throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
        }
        const init = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
        init.body = new FormData();
        const weightsManifest = [{
          paths: ["./model.weights.bin"],
          weights: modelArtifacts.weightSpecs
        }];
        const modelTopologyAndWeightManifest = getModelJSONForModelArtifacts(modelArtifacts, weightsManifest);
        init.body.append("model.json", new Blob([JSON.stringify(modelTopologyAndWeightManifest)], { type: JSON_TYPE }), "model.json");
        if (modelArtifacts.weightData != null) {
          init.body.append("model.weights.bin", new Blob([modelArtifacts.weightData], { type: OCTET_STREAM_MIME_TYPE }), "model.weights.bin");
        }
        const response = await this.fetch(this.path, init);
        if (response.ok) {
          return {
            modelArtifactsInfo: getModelArtifactsInfoForJSON(modelArtifacts),
            responses: [response]
          };
        } else {
          throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${response.status}.`);
        }
      }
      /**
       * Load model artifacts via HTTP request(s).
       *
       * See the documentation to `tf.io.http` for details on the saved
       * artifacts.
       *
       * @returns The loaded model artifacts (if loading succeeds).
       */
      async load() {
        const modelConfigRequest = await this.fetch(this.path, this.requestInit);
        if (!modelConfigRequest.ok) {
          throw new Error(`Request to ${this.path} failed with status code ${modelConfigRequest.status}. Please verify this URL points to the model JSON of the model to load.`);
        }
        let modelJSON;
        try {
          modelJSON = await modelConfigRequest.json();
        } catch (e) {
          let message = `Failed to parse model JSON of response from ${this.path}.`;
          if (this.path.endsWith(".pb")) {
            message += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.";
          } else {
            message += " Please make sure the server is serving valid JSON for this request.";
          }
          throw new Error(message);
        }
        const modelTopology = modelJSON.modelTopology;
        const weightsManifest = modelJSON.weightsManifest;
        if (modelTopology == null && weightsManifest == null) {
          throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
        }
        return getModelArtifactsForJSON(modelJSON, (weightsManifest2) => this.loadWeights(weightsManifest2));
      }
      async loadWeights(weightsManifest) {
        const weightPath = Array.isArray(this.path) ? this.path[1] : this.path;
        const [prefix, suffix] = parseUrl(weightPath);
        const pathPrefix = this.weightPathPrefix || prefix;
        const weightSpecs = getWeightSpecs(weightsManifest);
        const fetchURLs = [];
        const urlPromises = [];
        for (const weightsGroup of weightsManifest) {
          for (const path of weightsGroup.paths) {
            if (this.weightUrlConverter != null) {
              urlPromises.push(this.weightUrlConverter(path));
            } else {
              fetchURLs.push(pathPrefix + path + suffix);
            }
          }
        }
        if (this.weightUrlConverter) {
          fetchURLs.push(...await Promise.all(urlPromises));
        }
        const buffers = await loadWeightsAsArrayBuffer(fetchURLs, {
          requestInit: this.requestInit,
          fetchFunc: this.fetch,
          onProgress: this.onProgress
        });
        return [weightSpecs, concatenateArrayBuffers(buffers)];
      }
    };
    HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;
    httpRouter = (url, loadOptions) => {
      if (typeof fetch === "undefined" && (loadOptions == null || loadOptions.fetchFunc == null)) {
        return null;
      } else {
        let isHTTP = true;
        if (Array.isArray(url)) {
          isHTTP = url.every((urlItem) => isHTTPScheme(urlItem));
        } else {
          isHTTP = isHTTPScheme(url);
        }
        if (isHTTP) {
          return http(url, loadOptions);
        }
      }
      return null;
    };
    IORouterRegistry.registerSaveRouter(httpRouter);
    IORouterRegistry.registerLoadRouter(httpRouter);
  }
});
function fromMemory(modelArtifacts, weightSpecs, weightData, trainingConfig) {
  const args = arguments;
  return new PassthroughAsync(fromMemorySync(...args));
}
function fromMemorySync(modelArtifacts, weightSpecs, weightData, trainingConfig) {
  if (arguments.length === 1) {
    const isModelArtifacts = modelArtifacts.modelTopology != null || modelArtifacts.weightSpecs != null;
    if (isModelArtifacts) {
      return new PassthroughLoader(modelArtifacts);
    } else {
      console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
      return new PassthroughLoader({ modelTopology: modelArtifacts });
    }
  } else {
    console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release.");
    return new PassthroughLoader({
      modelTopology: modelArtifacts,
      weightSpecs,
      weightData,
      trainingConfig
    });
  }
}
function withSaveHandler(saveHandler) {
  return new PassthroughSaver(saveHandler);
}
function withSaveHandlerSync(saveHandler) {
  return new PassthroughSaver(saveHandler);
}
var PassthroughLoader;
var PassthroughSaver;
var PassthroughAsync;
var init_passthrough = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/passthrough.js"() {
    PassthroughLoader = class {
      constructor(modelArtifacts) {
        this.modelArtifacts = modelArtifacts;
      }
      load() {
        return this.modelArtifacts;
      }
    };
    PassthroughSaver = class {
      constructor(saveHandler) {
        this.saveHandler = saveHandler;
      }
      save(modelArtifacts) {
        return this.saveHandler(modelArtifacts);
      }
    };
    PassthroughAsync = class {
      constructor(handler) {
        if (handler.load) {
          this.load = () => Promise.resolve(handler.load());
        }
        if (handler.save) {
          this.save = (modelArtifacts) => Promise.resolve(handler.save(modelArtifacts));
        }
      }
    };
  }
});
var io_exports = {};
__export2(io_exports, {
  browserFiles: () => browserFiles,
  browserHTTPRequest: () => browserHTTPRequest,
  concatenateArrayBuffers: () => concatenateArrayBuffers,
  copyModel: () => copyModel,
  decodeWeights: () => decodeWeights,
  encodeWeights: () => encodeWeights,
  fromMemory: () => fromMemory,
  fromMemorySync: () => fromMemorySync,
  getLoadHandlers: () => getLoadHandlers,
  getModelArtifactsForJSON: () => getModelArtifactsForJSON,
  getModelArtifactsForJSONSync: () => getModelArtifactsForJSONSync,
  getModelArtifactsInfoForJSON: () => getModelArtifactsInfoForJSON,
  getSaveHandlers: () => getSaveHandlers,
  getWeightSpecs: () => getWeightSpecs,
  http: () => http,
  isHTTPScheme: () => isHTTPScheme,
  listModels: () => listModels,
  loadWeights: () => loadWeights,
  moveModel: () => moveModel,
  registerLoadRouter: () => registerLoadRouter,
  registerSaveRouter: () => registerSaveRouter,
  removeModel: () => removeModel,
  weightsLoaderFactory: () => weightsLoaderFactory,
  withSaveHandler: () => withSaveHandler,
  withSaveHandlerSync: () => withSaveHandlerSync
});
var init_io = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/io/io.js"() {
    init_indexed_db();
    init_local_storage();
    init_browser_files();
    init_http();
    init_io_utils();
    init_passthrough();
    init_router_registry();
    init_weights_loader();
    init_model_management();
  }
});
var browser_exports = {};
__export2(browser_exports, {
  fromPixels: () => fromPixels,
  fromPixelsAsync: () => fromPixelsAsync,
  toPixels: () => toPixels
});
function fromPixels_(pixels, numChannels = 3) {
  if (numChannels > 4) {
    throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  }
  if (pixels == null) {
    throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  }
  let isPixelData2 = false;
  let isImageData = false;
  let isVideo = false;
  let isImage = false;
  let isCanvasLike = false;
  let isImageBitmap = false;
  if (pixels.data instanceof Uint8Array) {
    isPixelData2 = true;
  } else if (typeof ImageData !== "undefined" && pixels instanceof ImageData) {
    isImageData = true;
  } else if (typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement) {
    isVideo = true;
  } else if (typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement) {
    isImage = true;
  } else if (pixels.getContext != null) {
    isCanvasLike = true;
  } else if (typeof ImageBitmap !== "undefined" && pixels instanceof ImageBitmap) {
    isImageBitmap = true;
  } else {
    throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${pixels.constructor.name}`);
  }
  const kernel = getKernel(FromPixels, ENGINE.backendName);
  if (kernel != null) {
    const inputs = { pixels };
    const attrs = { numChannels };
    return ENGINE.runKernel(FromPixels, inputs, attrs);
  }
  const [width, height] = isVideo ? [
    pixels.videoWidth,
    pixels.videoHeight
  ] : [pixels.width, pixels.height];
  let vals;
  if (isCanvasLike) {
    vals = // tslint:disable-next-line:no-any
    pixels.getContext("2d").getImageData(0, 0, width, height).data;
  } else if (isImageData || isPixelData2) {
    vals = pixels.data;
  } else if (isImage || isVideo || isImageBitmap) {
    if (fromPixels2DContext == null) {
      if (typeof document === "undefined") {
        if (typeof OffscreenCanvas !== "undefined" && typeof OffscreenCanvasRenderingContext2D !== "undefined") {
          fromPixels2DContext = new OffscreenCanvas(1, 1).getContext("2d");
        } else {
          throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
        }
      } else {
        fromPixels2DContext = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
      }
    }
    fromPixels2DContext.canvas.width = width;
    fromPixels2DContext.canvas.height = height;
    fromPixels2DContext.drawImage(pixels, 0, 0, width, height);
    vals = fromPixels2DContext.getImageData(0, 0, width, height).data;
  }
  let values;
  if (numChannels === 4) {
    values = new Int32Array(vals);
  } else {
    const numPixels = width * height;
    values = new Int32Array(numPixels * numChannels);
    for (let i = 0; i < numPixels; i++) {
      for (let channel = 0; channel < numChannels; ++channel) {
        values[i * numChannels + channel] = vals[i * 4 + channel];
      }
    }
  }
  const outShape = [height, width, numChannels];
  return tensor3d(values, outShape, "int32");
}
function isPixelData(pixels) {
  return pixels != null && pixels.data instanceof Uint8Array;
}
function isImageBitmapFullySupported() {
  return typeof window !== "undefined" && typeof ImageBitmap !== "undefined" && window.hasOwnProperty("createImageBitmap");
}
function isNonEmptyPixels(pixels) {
  return pixels != null && pixels.width !== 0 && pixels.height !== 0;
}
function canWrapPixelsToImageBitmap(pixels) {
  return isImageBitmapFullySupported() && !(pixels instanceof ImageBitmap) && isNonEmptyPixels(pixels) && !isPixelData(pixels);
}
async function fromPixelsAsync(pixels, numChannels = 3) {
  let inputs = null;
  if (env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(pixels)) {
    let imageBitmap;
    try {
      imageBitmap = await createImageBitmap(pixels, { premultiplyAlpha: "none" });
    } catch (e) {
      imageBitmap = null;
    }
    if (imageBitmap != null && imageBitmap.width === pixels.width && imageBitmap.height === pixels.height) {
      inputs = imageBitmap;
    } else {
      inputs = pixels;
    }
  } else {
    inputs = pixels;
  }
  return fromPixels_(inputs, numChannels);
}
async function toPixels(img, canvas) {
  let $img = convertToTensor(img, "img", "toPixels");
  if (!(img instanceof Tensor)) {
    const originalImgTensor = $img;
    $img = cast(originalImgTensor, "int32");
    originalImgTensor.dispose();
  }
  if ($img.rank !== 2 && $img.rank !== 3) {
    throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${$img.rank}.`);
  }
  const [height, width] = $img.shape.slice(0, 2);
  const depth = $img.rank === 2 ? 1 : $img.shape[2];
  if (depth > 4 || depth === 2) {
    throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${depth}`);
  }
  if ($img.dtype !== "float32" && $img.dtype !== "int32") {
    throw new Error(`Unsupported type for toPixels: ${$img.dtype}. Please use float32 or int32 tensors.`);
  }
  const data = await $img.data();
  const multiplier = $img.dtype === "float32" ? 255 : 1;
  const bytes = new Uint8ClampedArray(width * height * 4);
  for (let i = 0; i < height * width; ++i) {
    const rgba = [0, 0, 0, 255];
    for (let d = 0; d < depth; d++) {
      const value = data[i * depth + d];
      if ($img.dtype === "float32") {
        if (value < 0 || value > 1) {
          throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${value}.`);
        }
      } else if ($img.dtype === "int32") {
        if (value < 0 || value > 255) {
          throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${value}.`);
        }
      }
      if (depth === 1) {
        rgba[0] = value * multiplier;
        rgba[1] = value * multiplier;
        rgba[2] = value * multiplier;
      } else {
        rgba[d] = value * multiplier;
      }
    }
    const j = i * 4;
    bytes[j + 0] = Math.round(rgba[0]);
    bytes[j + 1] = Math.round(rgba[1]);
    bytes[j + 2] = Math.round(rgba[2]);
    bytes[j + 3] = Math.round(rgba[3]);
  }
  if (canvas != null) {
    canvas.width = width;
    canvas.height = height;
    const ctx = canvas.getContext("2d");
    const imageData = new ImageData(bytes, width, height);
    ctx.putImageData(imageData, 0, 0);
  }
  if ($img !== img) {
    $img.dispose();
  }
  return bytes;
}
var fromPixels2DContext;
var fromPixels;
var init_browser = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/browser.js"() {
    init_engine();
    init_environment();
    init_kernel_names();
    init_kernel_registry();
    init_tensor();
    init_tensor_util_env();
    init_cast();
    init_operation();
    init_tensor3d();
    fromPixels = /* @__PURE__ */ op({ fromPixels_ });
  }
});
function prepareAndValidate(tensor2, indices) {
  const tensorRank = tensor2.shape.length;
  const indicesRank = indices.shape.length;
  if (tensorRank < 1) {
    throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${tensorRank}.`);
  }
  if (indicesRank < 1) {
    throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${indicesRank}.`);
  }
  if (indices.dtype !== "int32") {
    throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${indices.dtype}.`);
  }
  if (indices.shape[indicesRank - 1] > tensorRank) {
    throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${indices.shape[indicesRank - 1]} vs. ${tensorRank}`);
  }
  if (sizeFromShape(tensor2.shape) === 0) {
    throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${tensor2.shape}.`);
  }
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  let nResult = 1;
  for (let i = 0; i < indicesShape.length - 1; ++i) {
    nResult *= indicesShape[i];
  }
  const inputShape = tensor2.shape;
  const resultShape = indicesShape.slice();
  resultShape.pop();
  let sliceSize = 1;
  for (let i = sliceRank; i < tensorRank; ++i) {
    sliceSize *= inputShape[i];
    resultShape.push(inputShape[i]);
  }
  const strides = [
    ...computeStrides(tensor2.shape).map((stride) => stride / sliceSize),
    1
  ].slice(0, sliceRank);
  return [resultShape, nResult, sliceSize, strides];
}
var init_gather_nd_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/gather_nd_util.js"() {
    init_util();
  }
});
var slice_util_exports = {};
__export2(slice_util_exports, {
  assertParamsValid: () => assertParamsValid,
  computeFlatOffset: () => computeFlatOffset,
  computeOutShape: () => computeOutShape,
  getNormalizedAxes: () => getNormalizedAxes,
  isSliceContinous: () => isSliceContinous,
  maskToAxes: () => maskToAxes,
  parseSliceParams: () => parseSliceParams,
  sliceInfo: () => sliceInfo,
  startForAxis: () => startForAxis,
  startIndicesWithElidedDims: () => startIndicesWithElidedDims,
  stopForAxis: () => stopForAxis,
  stopIndicesWithElidedDims: () => stopIndicesWithElidedDims,
  stridesForAxis: () => stridesForAxis,
  stridesWithElidedDims: () => stridesWithElidedDims
});
function assertParamsValid(input2, begin, size) {
  const inputRank = input2.shape.length;
  assert(inputRank === begin.length, () => `Error in slice${inputRank}D: Length of begin ${begin} must match the rank of the array (${inputRank}).`);
  assert(inputRank === size.length, () => `Error in slice${inputRank}D: Length of size ${size} must match the rank of the array (${inputRank}).`);
  for (let i = 0; i < inputRank; ++i) {
    assert(begin[i] + size[i] <= input2.shape[i], () => `Error in slice${inputRank}D: begin[${i}] + size[${i}] (${begin[i] + size[i]}) would overflow input.shape[${i}] (${input2.shape[i]})`);
  }
}
function maskToAxes(mask) {
  const axes = [];
  let axis = 0;
  while (mask > 0) {
    if (mask & 1) {
      axes.push(axis);
    }
    mask /= 2;
    axis++;
  }
  return axes;
}
function computeOutShape(begin, end, strides) {
  const size = [];
  for (let axis = 0; axis < begin.length; axis++) {
    size[axis] = Math.ceil((end[axis] - begin[axis]) / strides[axis]);
  }
  return size;
}
function stridesWithElidedDims(strides, ellipsisInsertionIndex, numElidedAxes, inputShape) {
  const newStrides = [...strides];
  for (let i = newStrides.length; i < inputShape.length; i++) {
    newStrides.push(1);
  }
  for (let i = 0; i < numElidedAxes; i++) {
    if (i === 0) {
      newStrides[ellipsisInsertionIndex] = 1;
    } else {
      newStrides.splice(
        ellipsisInsertionIndex,
        0,
        1
        /* element to add */
      );
      newStrides.pop();
    }
  }
  return newStrides;
}
function unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, normalizedAxis) {
  if (normalizedAxis <= ellipsisInsertionIndex) {
    return normalizedAxis;
  }
  return normalizedAxis - (numElidedAxes - 1);
}
function getElidedAxes(numElidedAxes, ellipsisInsertionIndex) {
  const elidedAxes = [];
  for (let i = 0; i < numElidedAxes; i++) {
    elidedAxes.push(ellipsisInsertionIndex + i);
  }
  return elidedAxes;
}
function getNormalizedAxes(inputShape, ellipsisAxes, numInterpolatedAxes, begin, end, strides, beginMask, endMask, ellipsisMask) {
  const inputRank = inputShape.length;
  let normalizedBegin = new Array(inputRank), normalizedEnd = new Array(inputRank), normalizedStrides = new Array(inputRank);
  if (ellipsisAxes.length && numInterpolatedAxes > 0) {
    const fullIndex = ellipsisAxes[0];
    const numElidedAxes = numInterpolatedAxes + 1;
    normalizedBegin = startIndicesWithElidedDims(beginMask, fullIndex, numElidedAxes, begin, inputShape);
    normalizedEnd = stopIndicesWithElidedDims(endMask, fullIndex, numElidedAxes, end, inputShape);
    normalizedStrides = stridesWithElidedDims(strides, fullIndex, numElidedAxes, inputShape);
  } else {
    for (let axis = 0; axis < inputRank; axis++) {
      normalizedBegin[axis] = startForAxis(beginMask, begin, strides, inputShape, axis, ellipsisMask);
      normalizedEnd[axis] = stopForAxis(endMask, end, strides, inputShape, axis, ellipsisMask);
      normalizedStrides[axis] = stridesForAxis(strides, axis, ellipsisMask);
    }
  }
  return {
    begin: normalizedBegin,
    end: normalizedEnd,
    strides: normalizedStrides
  };
}
function startIndicesWithElidedDims(beginMask, ellipsisInsertionIndex, numElidedAxes, originalBegin, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = 0;
    } else {
      const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalBegin[originalAxis];
      if (beginMask & 1 << originalAxis) {
        originalValue = 0;
      }
      newIndices[axis] = originalValue;
    }
  }
  return newIndices;
}
function stopIndicesWithElidedDims(endMask, ellipsisInsertionIndex, numElidedAxes, originalEnd, inputShape) {
  const newIndices = [...inputShape];
  const elidedAxes = getElidedAxes(numElidedAxes, ellipsisInsertionIndex);
  for (let axis = 0; axis < newIndices.length; axis++) {
    if (elidedAxes.indexOf(axis) > -1) {
      newIndices[axis] = Number.MAX_SAFE_INTEGER;
    } else {
      const originalAxis = unnormalizeAxis(ellipsisInsertionIndex, numElidedAxes, axis);
      let originalValue = originalEnd[originalAxis];
      if (endMask & 1 << originalAxis) {
        originalValue = Number.MAX_SAFE_INTEGER;
      }
      newIndices[axis] = originalValue;
    }
  }
  for (let i = 0; i < newIndices.length; i++) {
    const axisSize = inputShape[i];
    if (newIndices[i] < 0) {
      newIndices[i] += axisSize;
    }
    newIndices[i] = clamp2(0, newIndices[i], inputShape[i]);
  }
  return newIndices;
}
function stridesForAxis(strides, axis, ellipsisMask) {
  let stride = strides[axis];
  if (ellipsisMask & 1 << axis || stride == null) {
    stride = 1;
  }
  return stride;
}
function startForAxis(beginMask, startIndices, strides, inputShape, axis, ellipsisMask) {
  let start = startIndices[axis];
  const stride = strides[axis] || 1;
  if (beginMask & 1 << axis || ellipsisMask & 1 << axis || start == null) {
    if (stride > 0) {
      start = Number.MIN_SAFE_INTEGER;
    } else {
      start = Number.MAX_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (start < 0) {
    start += axisSize;
  }
  start = clamp2(0, start, axisSize - 1);
  return start;
}
function stopForAxis(endMask, stopIndices, strides, inputShape, axis, ellipsisMask) {
  let stop = stopIndices[axis];
  const stride = strides[axis] || 1;
  if (endMask & 1 << axis || ellipsisMask & 1 << axis || stop == null) {
    if (stride > 0) {
      stop = Number.MAX_SAFE_INTEGER;
    } else {
      stop = Number.MIN_SAFE_INTEGER;
    }
  }
  const axisSize = inputShape[axis];
  if (stop < 0) {
    stop += axisSize;
  }
  if (stride > 0) {
    stop = clamp2(0, stop, axisSize);
  } else {
    stop = clamp2(-1, stop, axisSize - 1);
  }
  return stop;
}
function isSliceContinous(shape, begin, size) {
  let firstNonOneAxis = size.length;
  for (let i = 0; i < size.length; i++) {
    if (size[i] > 1) {
      firstNonOneAxis = i;
      break;
    }
  }
  for (let i = firstNonOneAxis + 1; i < size.length; i++) {
    if (begin[i] > 0 || size[i] !== shape[i]) {
      return false;
    }
  }
  return true;
}
function computeFlatOffset(begin, strides) {
  let flatOffset = begin.length > 0 ? begin[begin.length - 1] : 1;
  for (let i = 0; i < begin.length - 1; i++) {
    flatOffset += begin[i] * strides[i];
  }
  return flatOffset;
}
function parseSliceParams(x, begin, size) {
  let begin_;
  const xRank = x.shape.length;
  if (typeof begin === "number") {
    begin_ = [begin, ...new Array(xRank - 1).fill(0)];
  } else if (begin.length < xRank) {
    begin_ = begin.concat(new Array(xRank - begin.length).fill(0));
  } else {
    begin_ = begin.slice();
  }
  begin_.forEach((d) => {
    assert(d !== -1, () => "slice() does not support negative begin indexing.");
  });
  let size_;
  if (size == null) {
    size_ = new Array(xRank).fill(-1);
  } else if (typeof size === "number") {
    size_ = [size, ...new Array(xRank - 1).fill(-1)];
  } else if (size.length < xRank) {
    size_ = size.concat(new Array(xRank - size.length).fill(-1));
  } else {
    size_ = size;
  }
  size_ = size_.map((d, i) => {
    if (d >= 0) {
      return d;
    } else {
      assert(d === -1, () => `Negative size values should be exactly -1 but got ${d} for the slice() size at index ${i}.`);
      return x.shape[i] - begin_[i];
    }
  });
  return [begin_, size_];
}
function sliceInfo(xShape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
  let stridesNonNull;
  if (strides == null) {
    stridesNonNull = new Array(begin.length);
    stridesNonNull.fill(1);
  } else {
    stridesNonNull = strides;
  }
  if (ellipsisMask != null && (ellipsisMask & ellipsisMask - 1) !== 0) {
    throw new Error("Multiple ellipses in slice is not allowed.");
  }
  let ellipsisSeen = false;
  const sparseSpec = {
    dims: stridesNonNull.length,
    numAddAxisAfterEllipsis: 0,
    begin: begin.slice(),
    end: end.slice(),
    strides: stridesNonNull.slice(),
    beginMask,
    endMask,
    ellipsisMask,
    newAxisMask,
    shrinkAxisMask
  };
  for (let i = 0; i < sparseSpec.dims; i++) {
    if (ellipsisSeen && (1 << i & newAxisMask) !== 0) {
      sparseSpec.numAddAxisAfterEllipsis++;
    }
    if (1 << i & ellipsisMask) {
      ellipsisSeen = true;
    }
  }
  if (!ellipsisSeen) {
    sparseSpec.ellipsisMask |= 1 << sparseSpec.dims;
    sparseSpec.dims++;
  }
  const denseSpec = {
    dims: xShape.length,
    beginMask: 0,
    endMask: 0,
    beginValid: false,
    endValid: false
  };
  buildDenseSpec(sparseSpec, denseSpec);
  let isIdentity = true;
  let sliceDim0 = true;
  let isSimpleSlice = true;
  const processingShape = [];
  const finalShape = [];
  for (let i = 0; i < xShape.length; ++i) {
    if (denseSpec.strides[i] === 0) {
      throw Error(`strides[${i}] must be non-zero`);
    }
    const shrinkI = !!(denseSpec.shrinkAxisMask & 1 << i);
    const dimI = xShape[i];
    if (dimI === -1) {
      processingShape.push(shrinkI ? 1 : -1);
      continue;
    }
    const masks = [denseSpec.beginMask & 1 << i, denseSpec.endMask & 1 << i];
    const validRange = [
      denseSpec.strides[i] > 0 ? 0 : -1,
      denseSpec.strides[i] > 0 ? dimI : dimI - 1
    ];
    if (shrinkI && denseSpec.strides[i] <= 0) {
      throw Error("only stride 1 allowed on non-range indexing.");
    }
    isSimpleSlice = isSimpleSlice && denseSpec.strides[i] === 1;
    const beginAndEndMasked = !!(denseSpec.beginMask & 1 << i && denseSpec.endMask & 1 << i);
    if (denseSpec.beginValid && denseSpec.endValid) {
      if (shrinkI) {
        const xFwd = denseSpec.begin[i] < 0 ? dimI + denseSpec.begin[i] : denseSpec.begin[i];
        denseSpec.begin[i] = xFwd;
        denseSpec.end[i] = denseSpec.begin[i] + 1;
        if (xFwd < 0 || xFwd >= dimI) {
          throw Error(`slice index ${denseSpec.begin[i]} of dimension ${i} out of bounds.`);
        }
      } else {
        denseSpec.begin[i] = canonical(denseSpec.begin[i], 0, denseSpec.strides[i], dimI, masks, validRange);
        denseSpec.end[i] = canonical(denseSpec.end[i], 1, denseSpec.strides[i], dimI, masks, validRange);
      }
      const takeAllInDimension = denseSpec.strides[i] === 1 && denseSpec.begin[i] === 0 && denseSpec.end[i] === dimI;
      isIdentity = isIdentity && takeAllInDimension;
      sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || takeAllInDimension);
    } else {
      isIdentity = isIdentity && (denseSpec.strides[i] === 1 && beginAndEndMasked);
      sliceDim0 = sliceDim0 && (i === 0 && denseSpec.strides[i] === 1 || beginAndEndMasked);
    }
    let intervalLength;
    let knownInterval = false;
    if (denseSpec.beginValid && denseSpec.endValid) {
      intervalLength = denseSpec.end[i] - denseSpec.begin[i];
      knownInterval = true;
    } else if (shrinkI) {
      intervalLength = 1;
      knownInterval = true;
    } else if (beginAndEndMasked) {
      if (dimI >= 0) {
        if (denseSpec.strides[i] < 0) {
          intervalLength = -dimI;
        } else {
          intervalLength = dimI;
        }
        knownInterval = true;
      }
    }
    if (knownInterval) {
      let sizeI;
      if (intervalLength === 0 || intervalLength < 0 !== denseSpec.strides[i] < 0) {
        sizeI = 0;
      } else {
        sizeI = Math.trunc(intervalLength / denseSpec.strides[i]) + (intervalLength % denseSpec.strides[i] !== 0 ? 1 : 0);
      }
      processingShape.push(sizeI);
    } else {
      processingShape.push(-1);
    }
  }
  for (let denseDim = 0; denseDim < denseSpec.finalShapeGatherIndices.length; ++denseDim) {
    const gatherIndex = denseSpec.finalShapeGatherIndices[denseDim];
    if (gatherIndex >= 0) {
      finalShape.push(processingShape[gatherIndex]);
    } else if (gatherIndex === NEW_AXIS) {
      finalShape.push(1);
    }
  }
  const finalShapeSparse = finalShape.filter((dim, i) => denseSpec.finalShapeGatherIndices[i] !== NEW_AXIS);
  return {
    finalShapeSparse,
    finalShape,
    isIdentity,
    sliceDim0,
    isSimpleSlice,
    begin: denseSpec.begin,
    end: denseSpec.end,
    strides: denseSpec.strides
  };
}
function buildDenseSpec(sparse, dense) {
  dense.beginMask = 0;
  dense.endMask = 0;
  dense.shrinkAxisMask = 0;
  let fullIndex = 0;
  dense.beginValid = sparse.begin != null;
  dense.endValid = sparse.end != null;
  dense.begin = new Array(dense.dims);
  dense.end = new Array(dense.dims);
  dense.strides = new Array(dense.dims);
  dense.finalShapeGatherIndices = [];
  dense.finalShapeGatherIndicesSparse = [];
  dense.inputShapeGatherIndicesSparse = new Array(dense.dims);
  for (let i = 0; i < sparse.dims; i++) {
    if (1 << i & sparse.ellipsisMask) {
      const nextIndex = Math.min(dense.dims - (sparse.dims - i) + 1 + sparse.numAddAxisAfterEllipsis, dense.dims);
      for (; fullIndex < nextIndex; fullIndex++) {
        dense.begin[fullIndex] = 0;
        dense.end[fullIndex] = 0;
        dense.strides[fullIndex] = 1;
        dense.beginMask |= 1 << fullIndex;
        dense.endMask |= 1 << fullIndex;
        dense.finalShapeGatherIndices.push(fullIndex);
        dense.finalShapeGatherIndicesSparse.push(-1);
        dense.inputShapeGatherIndicesSparse[fullIndex] = i;
      }
    } else if (1 << i & sparse.newAxisMask) {
      dense.finalShapeGatherIndices.push(NEW_AXIS);
      dense.finalShapeGatherIndicesSparse.push(-1);
    } else {
      if (fullIndex === dense.begin.length) {
        throw Error(`Index out of range using input dim ${fullIndex}; input has only ${dense.dims} dims, ${dense.begin.length}.`);
      }
      if (sparse.begin != null) {
        dense.begin[fullIndex] = sparse.begin[i];
      }
      if (sparse.end != null) {
        dense.end[fullIndex] = sparse.end[i];
      }
      dense.strides[fullIndex] = sparse.strides[i];
      if (sparse.beginMask & 1 << i) {
        dense.beginMask |= 1 << fullIndex;
      }
      if (sparse.endMask & 1 << i) {
        dense.endMask |= 1 << fullIndex;
      }
      if (sparse.shrinkAxisMask & 1 << i) {
        dense.finalShapeGatherIndices.push(SHRINK_AXIS);
        dense.finalShapeGatherIndicesSparse.push(-1);
        dense.shrinkAxisMask |= 1 << fullIndex;
      } else {
        dense.finalShapeGatherIndices.push(fullIndex);
        dense.finalShapeGatherIndicesSparse.push(i);
      }
      dense.inputShapeGatherIndicesSparse[fullIndex] = i;
      fullIndex++;
    }
  }
}
function canonical(x, c, strideI, dimI, masks, validRange) {
  if (masks[c]) {
    return strideI > 0 ? validRange[c] : validRange[c + 1 & 1];
  } else {
    const xFwd = x < 0 ? dimI + x : x;
    return xFwd < validRange[0] ? validRange[0] : xFwd > validRange[1] ? validRange[1] : xFwd;
  }
}
var NEW_AXIS;
var SHRINK_AXIS;
var init_slice_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/slice_util.js"() {
    init_util();
    NEW_AXIS = -2;
    SHRINK_AXIS = -1;
  }
});
var OptimizerConstructors;
var init_optimizer_constructors = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js"() {
    init_adadelta_optimizer();
    init_adagrad_optimizer();
    init_adam_optimizer();
    init_adamax_optimizer();
    init_momentum_optimizer();
    init_rmsprop_optimizer();
    init_sgd_optimizer();
    OptimizerConstructors = class {
      /**
       * Constructs a `tf.SGDOptimizer` that uses stochastic gradient descent.
       *
       * ```js
       * // Fit a quadratic function by learning the coefficients a, b, c.
       * const xs = tf.tensor1d([0, 1, 2, 3]);
       * const ys = tf.tensor1d([1.1, 5.9, 16.8, 33.9]);
       *
       * const a = tf.scalar(Math.random()).variable();
       * const b = tf.scalar(Math.random()).variable();
       * const c = tf.scalar(Math.random()).variable();
       *
       * // y = a * x^2 + b * x + c.
       * const f = x => a.mul(x.square()).add(b.mul(x)).add(c);
       * const loss = (pred, label) => pred.sub(label).square().mean();
       *
       * const learningRate = 0.01;
       * const optimizer = tf.train.sgd(learningRate);
       *
       * // Train the model.
       * for (let i = 0; i < 10; i++) {
       *   optimizer.minimize(() => loss(f(xs), ys));
       * }
       *
       * // Make predictions.
       * console.log(
       *     `a: ${a.dataSync()}, b: ${b.dataSync()}, c: ${c.dataSync()}`);
       * const preds = f(xs).dataSync();
       * preds.forEach((pred, i) => {
       *   console.log(`x: ${i}, pred: ${pred}`);
       * });
       * ```
       *
       * @param learningRate The learning rate to use for the SGD algorithm.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static sgd(learningRate) {
        return new SGDOptimizer(learningRate);
      }
      /**
       * Constructs a `tf.MomentumOptimizer` that uses momentum gradient
       * descent.
       *
       * See
       * [http://proceedings.mlr.press/v28/sutskever13.pdf](
       * http://proceedings.mlr.press/v28/sutskever13.pdf)
       *
       * @param learningRate The learning rate to use for the Momentum gradient
       * descent algorithm.
       * @param momentum The momentum to use for the momentum gradient descent
       * algorithm.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static momentum(learningRate, momentum, useNesterov = false) {
        return new MomentumOptimizer(learningRate, momentum, useNesterov);
      }
      /**
       * Constructs a `tf.RMSPropOptimizer` that uses RMSProp gradient
       * descent. This implementation uses plain momentum and is not centered
       * version of RMSProp.
       *
       * See
       * [http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](
       * http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
       *
       * @param learningRate The learning rate to use for the RMSProp gradient
       * descent algorithm.
       * @param decay The discounting factor for the history/coming gradient.
       * @param momentum The momentum to use for the RMSProp gradient descent
       * algorithm.
       * @param epsilon Small value to avoid zero denominator.
       * @param centered If true, gradients are normalized by the estimated
       * variance of the gradient.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static rmsprop(learningRate, decay = 0.9, momentum = 0, epsilon3 = null, centered = false) {
        return new RMSPropOptimizer(learningRate, decay, momentum, epsilon3, centered);
      }
      /**
       * Constructs a `tf.AdamOptimizer` that uses the Adam algorithm.
       * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
       *
       * @param learningRate The learning rate to use for the Adam gradient
       * descent algorithm.
       * @param beta1 The exponential decay rate for the 1st moment estimates.
       * @param beta2 The exponential decay rate for the 2nd moment estimates.
       * @param epsilon A small constant for numerical stability.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adam(learningRate = 1e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null) {
        return new AdamOptimizer(learningRate, beta1, beta2, epsilon3);
      }
      /**
       * Constructs a `tf.AdadeltaOptimizer` that uses the Adadelta algorithm.
       * See [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)
       *
       * @param learningRate The learning rate to use for the Adadelta gradient
       * descent algorithm.
       * @param rho The learning rate decay over each update.
       * @param epsilon A constant epsilon used to better condition the grad
       * update.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adadelta(learningRate = 1e-3, rho = 0.95, epsilon3 = null) {
        return new AdadeltaOptimizer(learningRate, rho, epsilon3);
      }
      /**
       * Constructs a `tf.AdamaxOptimizer` that uses the Adamax algorithm.
       * See [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
       *
       * @param learningRate The learning rate to use for the Adamax gradient
       * descent algorithm.
       * @param beta1 The exponential decay rate for the 1st moment estimates.
       * @param beta2 The exponential decay rate for the 2nd moment estimates.
       * @param epsilon A small constant for numerical stability.
       * @param decay The learning rate decay over each update.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adamax(learningRate = 2e-3, beta1 = 0.9, beta2 = 0.999, epsilon3 = null, decay = 0) {
        return new AdamaxOptimizer(learningRate, beta1, beta2, epsilon3, decay);
      }
      /**
       * Constructs a `tf.AdagradOptimizer` that uses the Adagrad algorithm.
       * See
       * [http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](
       * http://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)
       * or
       * [http://ruder.io/optimizing-gradient-descent/index.html#adagrad](
       * http://ruder.io/optimizing-gradient-descent/index.html#adagrad)
       *
       * @param learningRate The learning rate to use for the Adagrad gradient
       * descent algorithm.
       * @param initialAccumulatorValue Starting value for the accumulators, must be
       * positive.
       *
       * @doc {heading: 'Training', subheading: 'Optimizers', namespace: 'train'}
       */
      static adagrad(learningRate, initialAccumulatorValue = 0.1) {
        return new AdagradOptimizer(learningRate, initialAccumulatorValue);
      }
    };
  }
});
var train;
var init_train = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/train.js"() {
    init_optimizer_constructors();
    train = OptimizerConstructors;
  }
});
function nextFrame() {
  return new Promise((resolve) => delayCallback(() => resolve()));
}
var delayCallback;
var init_browser_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/browser_util.js"() {
    delayCallback = (() => {
      if (typeof requestAnimationFrame !== "undefined") {
        return requestAnimationFrame;
      } else if (typeof setImmediate !== "undefined") {
        return setImmediate;
      }
      return (f) => f();
    })();
  }
});
function assertParamsConsistent(shapes, axis) {
  const rank = shapes[0].length;
  shapes.forEach((shape, i) => {
    assert(shape.length === rank, () => `Error in concat${rank}D: rank of tensors[${i}] must be the same as the rank of the rest (${rank})`);
  });
  assert(axis >= 0 && axis < rank, () => `Error in concat${rank}D: axis must be between 0 and ${rank - 1}.`);
  const firstShape = shapes[0];
  shapes.forEach((shape, i) => {
    for (let r = 0; r < rank; r++) {
      assert(r === axis || shape[r] === firstShape[r], () => `Error in concat${rank}D: Shape of tensors[${i}] (${shape}) does not match the shape of the rest (${firstShape}) along the non-concatenated axis ${i}.`);
    }
  });
}
function computeOutShape2(shapes, axis) {
  const outputShape = shapes[0].slice();
  for (let i = 1; i < shapes.length; i++) {
    outputShape[axis] += shapes[i][axis];
  }
  return outputShape;
}
var init_concat_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/concat_util.js"() {
    init_util();
  }
});
var init_fused_types = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/fused_types.js"() {
  }
});
function combineRaggedTensorToTensorShapes(raggedRank, shape, valueShape) {
  let outputShape = new Array();
  if (valueShape == null && shape == null) {
    return outputShape;
  }
  if (shape == null) {
    while (outputShape.length < raggedRank + valueShape.length) {
      outputShape.push(-1);
    }
  } else {
    outputShape = shape.slice();
  }
  if (valueShape == null) {
    return outputShape;
  }
  if (raggedRank + valueShape.length !== outputShape.length) {
    throw new Error(`rt input.shape and shape=${shape} are incompatible: rt input.rank = ${raggedRank + valueShape.length}, but shape.rank = ${outputShape.length}`);
  }
  for (let i = 1; i < valueShape.length; ++i) {
    const valueDim = valueShape[i];
    const outputShapeDimIndex = outputShape[outputShape.length - valueShape.length + i];
    const outputShapeDim = outputShape[outputShapeDimIndex];
    if (valueDim >= 0) {
      if (outputShapeDim >= 0) {
        if (outputShapeDim !== valueDim) {
          throw new Error(`rt input.shape and shape=${shape} are incompatible: rt input.shape[${i + raggedRank}] = ${valueDim} but shape[${i + raggedRank}] = ${outputShapeDim}`);
        }
      } else {
        outputShape[outputShapeDimIndex] = valueDim;
      }
    }
  }
  return outputShape;
}
function getRowPartitionTypesHelper(rowPartitionTypeStrings) {
  const stringToType = {
    "FIRST_DIM_SIZE": RowPartitionType.FIRST_DIM_SIZE,
    "VALUE_ROWIDS": RowPartitionType.VALUE_ROWIDS,
    "ROW_LENGTHS": RowPartitionType.ROW_LENGTHS,
    "ROW_SPLITS": RowPartitionType.ROW_SPLITS,
    "ROW_LIMITS": RowPartitionType.ROW_LIMITS,
    "ROW_STARTS": RowPartitionType.ROW_STARTS
  };
  const result = [];
  for (const typeStr of rowPartitionTypeStrings) {
    if (typeStr in stringToType) {
      result.push(stringToType[typeStr]);
    } else {
      break;
    }
  }
  return result;
}
function getRaggedRank(rowPartitionTypes) {
  if (rowPartitionTypes.length === 0) {
    return 0;
  }
  if (rowPartitionTypes[0] === RowPartitionType.FIRST_DIM_SIZE) {
    return rowPartitionTypes.length - 1;
  }
  return rowPartitionTypes.length;
}
function validateDefaultValueShape(defaultValueShape, valueShape) {
  if (defaultValueShape == null || valueShape == null) {
    return;
  }
  const defaultNDims = defaultValueShape.length;
  const valuesNDims = valueShape.length;
  if (defaultNDims >= valuesNDims) {
    throw new Error(`defaultValue.shape=${defaultValueShape} and ragged tensor flatValues.shape=${valueShape}, are incompatible: defaultValue.rank = ${defaultNDims} must be less than ragged tensor input flatValues.rank = ${valuesNDims})`);
  }
  for (let i = 0; i < Math.min(defaultNDims, valuesNDims - 1); ++i) {
    const defaultDim = defaultValueShape[i];
    const valueDim = valueShape[i + 1];
    if (defaultDim >= 0 && valueDim >= 0 && defaultDim !== 1 && defaultDim !== valueDim) {
      throw new Error(`defaultValue.shape=${defaultValueShape}, and ragged tensor input flatValues.shape=${valueShape} are incompatible: defaultValue.shape[${i - defaultValueShape.length}] = ${defaultDim} but ragged tensor input.flatValues.shape[${i - defaultValueShape.length}] = ${valueDim}`);
    }
  }
}
var RowPartitionType;
var init_ragged_to_dense_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js"() {
    (function(RowPartitionType3) {
      RowPartitionType3[RowPartitionType3["FIRST_DIM_SIZE"] = 0] = "FIRST_DIM_SIZE";
      RowPartitionType3[RowPartitionType3["VALUE_ROWIDS"] = 1] = "VALUE_ROWIDS";
      RowPartitionType3[RowPartitionType3["ROW_LENGTHS"] = 2] = "ROW_LENGTHS";
      RowPartitionType3[RowPartitionType3["ROW_SPLITS"] = 3] = "ROW_SPLITS";
      RowPartitionType3[RowPartitionType3["ROW_LIMITS"] = 4] = "ROW_LIMITS";
      RowPartitionType3[RowPartitionType3["ROW_STARTS"] = 5] = "ROW_STARTS";
    })(RowPartitionType || (RowPartitionType = {}));
  }
});
function computeOptimalWindowSize(inSize) {
  if (inSize <= PARALLELIZE_THRESHOLD) {
    return inSize;
  }
  return nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
}
var PARALLELIZE_THRESHOLD;
var init_reduce_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/reduce_util.js"() {
    init_util();
    PARALLELIZE_THRESHOLD = 30;
  }
});
function getImageCenter(center, imageHeight, imageWidth) {
  const centerX = imageWidth * (typeof center === "number" ? center : center[0]);
  const centerY = imageHeight * (typeof center === "number" ? center : center[1]);
  return [centerX, centerY];
}
var init_rotate_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/rotate_util.js"() {
  }
});
function getReshaped(inputShape, blockShape, prod4, batchToSpace = true) {
  let reshaped = [];
  if (batchToSpace) {
    reshaped = reshaped.concat(blockShape.slice(0));
    reshaped.push(inputShape[0] / prod4);
    reshaped = reshaped.concat(inputShape.slice(1));
  } else {
    reshaped = reshaped.concat(inputShape[0]);
    const spatialLength = blockShape.length;
    for (let i = 0; i < spatialLength; ++i) {
      reshaped = reshaped.concat([inputShape[i + 1] / blockShape[i], blockShape[i]]);
    }
    reshaped = reshaped.concat(inputShape.slice(spatialLength + 1));
  }
  return reshaped;
}
function getPermuted(reshapedRank, blockShapeRank, batchToSpace = true) {
  const permuted = [];
  if (batchToSpace) {
    permuted.push(blockShapeRank);
    for (let i = blockShapeRank + 1; i < reshapedRank; ++i) {
      if (i <= 2 * blockShapeRank) {
        permuted.push(i);
        permuted.push(i - (blockShapeRank + 1));
      } else {
        permuted.push(i);
      }
    }
  } else {
    const permutedBeforeBatch = [];
    const permutedAfterBatch = [];
    for (let i = 1; i < reshapedRank; ++i) {
      if (i >= blockShapeRank * 2 + 1 || i % 2 === 1) {
        permutedAfterBatch.push(i);
      } else {
        permutedBeforeBatch.push(i);
      }
    }
    permuted.push(...permutedBeforeBatch);
    permuted.push(0);
    permuted.push(...permutedAfterBatch);
  }
  return permuted;
}
function getReshapedPermuted(inputShape, blockShape, prod4, batchToSpace = true) {
  const reshapedPermuted = [];
  if (batchToSpace) {
    reshapedPermuted.push(inputShape[0] / prod4);
  } else {
    reshapedPermuted.push(inputShape[0] * prod4);
  }
  for (let i = 1; i < inputShape.length; ++i) {
    if (i <= blockShape.length) {
      if (batchToSpace) {
        reshapedPermuted.push(blockShape[i - 1] * inputShape[i]);
      } else {
        reshapedPermuted.push(inputShape[i] / blockShape[i - 1]);
      }
    } else {
      reshapedPermuted.push(inputShape[i]);
    }
  }
  return reshapedPermuted;
}
function getSliceBeginCoords(crops, blockShape) {
  const sliceBeginCoords = [0];
  for (let i = 0; i < blockShape; ++i) {
    sliceBeginCoords.push(crops[i][0]);
  }
  return sliceBeginCoords;
}
function getSliceSize(uncroppedShape, crops, blockShape) {
  const sliceSize = uncroppedShape.slice(0, 1);
  for (let i = 0; i < blockShape; ++i) {
    sliceSize.push(uncroppedShape[i + 1] - crops[i][0] - crops[i][1]);
  }
  return sliceSize;
}
var init_array_ops_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/array_ops_util.js"() {
  }
});
var SELU_SCALEALPHA;
var SELU_SCALE;
var init_selu_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/selu_util.js"() {
    SELU_SCALEALPHA = 1.7580993408473768;
    SELU_SCALE = 1.0507009873554805;
  }
});
var ERF_P;
var ERF_A1;
var ERF_A2;
var ERF_A3;
var ERF_A4;
var ERF_A5;
var init_erf_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/erf_util.js"() {
    ERF_P = 0.3275911;
    ERF_A1 = 0.254829592;
    ERF_A2 = -0.284496736;
    ERF_A3 = 1.421413741;
    ERF_A4 = -1.453152027;
    ERF_A5 = 1.061405429;
  }
});
function mergeRealAndImagArrays(real4, imag4) {
  if (real4.length !== imag4.length) {
    throw new Error(`Cannot merge real and imag arrays of different lengths. real:${real4.length}, imag: ${imag4.length}.`);
  }
  const result = new Float32Array(real4.length * 2);
  for (let i = 0; i < result.length; i += 2) {
    result[i] = real4[i / 2];
    result[i + 1] = imag4[i / 2];
  }
  return result;
}
function splitRealAndImagArrays(complex4) {
  const real4 = new Float32Array(complex4.length / 2);
  const imag4 = new Float32Array(complex4.length / 2);
  for (let i = 0; i < complex4.length; i += 2) {
    real4[i / 2] = complex4[i];
    imag4[i / 2] = complex4[i + 1];
  }
  return { real: real4, imag: imag4 };
}
function complexWithEvenIndex(complex4) {
  const len4 = Math.ceil(complex4.length / 4);
  const real4 = new Float32Array(len4);
  const imag4 = new Float32Array(len4);
  for (let i = 0; i < complex4.length; i += 4) {
    real4[Math.floor(i / 4)] = complex4[i];
    imag4[Math.floor(i / 4)] = complex4[i + 1];
  }
  return { real: real4, imag: imag4 };
}
function complexWithOddIndex(complex4) {
  const len4 = Math.floor(complex4.length / 4);
  const real4 = new Float32Array(len4);
  const imag4 = new Float32Array(len4);
  for (let i = 2; i < complex4.length; i += 4) {
    real4[Math.floor(i / 4)] = complex4[i];
    imag4[Math.floor(i / 4)] = complex4[i + 1];
  }
  return { real: real4, imag: imag4 };
}
function getComplexWithIndex(complex4, index) {
  const real4 = complex4[index * 2];
  const imag4 = complex4[index * 2 + 1];
  return { real: real4, imag: imag4 };
}
function assignToTypedArray(data, real4, imag4, index) {
  data[index * 2] = real4;
  data[index * 2 + 1] = imag4;
}
function exponents(n, inverse2) {
  const real4 = new Float32Array(n / 2);
  const imag4 = new Float32Array(n / 2);
  for (let i = 0; i < Math.ceil(n / 2); i++) {
    const x = (inverse2 ? 2 : -2) * Math.PI * (i / n);
    real4[i] = Math.cos(x);
    imag4[i] = Math.sin(x);
  }
  return { real: real4, imag: imag4 };
}
function exponent(k, n, inverse2) {
  const x = (inverse2 ? 2 : -2) * Math.PI * (k / n);
  const real4 = Math.cos(x);
  const imag4 = Math.sin(x);
  return { real: real4, imag: imag4 };
}
var init_complex_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/complex_util.js"() {
  }
});
function decodeEinsumEquation(equation, numTensors) {
  equation = equation.replace(/\s/g, "");
  const numArrows = (equation.length - equation.replace(ARROW_REGEX, "").length) / ARROW.length;
  if (numArrows < 1) {
    throw new Error("Equations without an arrow are not supported.");
  } else if (numArrows > 1) {
    throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`);
  }
  const [inputString, outputString] = equation.split(ARROW);
  assert(inputString.indexOf(ELLIPSIS) === -1, () => `The ellipsis notation ("${ELLIPSIS}") is not supported yet.`);
  const inputTerms = inputString.split(COMMA);
  const numInputs = inputTerms.length;
  if (numTensors !== numInputs) {
    throw new Error(`Expected ${numInputs} input tensors, received ${numTensors}`);
  }
  if (numInputs > 2) {
    throw new Error("Support for more than 2 input tensors is not implemented yet.");
  }
  const allDims = [];
  for (let i = 0; i < outputString.length; ++i) {
    const dimName = outputString[i];
    if (!inputTerms.some((inputTerm) => inputTerm.indexOf(dimName) !== -1)) {
      throw new Error(`Output subscripts contain the label ${dimName} not present in the input subscripts.`);
    }
    if (allDims.indexOf(dimName) === -1) {
      allDims.push(dimName);
    }
  }
  for (let i = 0; i < inputString.length; ++i) {
    const dimName = inputString[i];
    if (allDims.indexOf(dimName) === -1 && dimName !== COMMA) {
      allDims.push(dimName);
    }
  }
  const idDims = new Array(inputTerms.length);
  for (let i = 0; i < numInputs; ++i) {
    if (new Set(inputTerms[i].split("")).size !== inputTerms[i].length) {
      throw new Error(`Found duplicate axes in input component ${inputTerms[i]}. Support for duplicate axes in input is not implemented yet.`);
    }
    idDims[i] = [];
    for (let j = 0; j < inputTerms[i].length; ++j) {
      idDims[i].push(allDims.indexOf(inputTerms[i][j]));
    }
  }
  const numDims = allDims.length;
  const numOutDims = outputString.length;
  const summedDims = [];
  for (let i = numOutDims; i < numDims; ++i) {
    summedDims.push(i);
  }
  return { allDims, summedDims, idDims };
}
function getEinsumPermutation(nDims, idDims) {
  let permutationIndices = new Array(nDims);
  permutationIndices.fill(-1);
  for (let i = 0; i < idDims.length; ++i) {
    permutationIndices[idDims[i]] = i;
  }
  const expandDims5 = [];
  for (let i = 0; i < nDims; ++i) {
    if (permutationIndices[i] === -1) {
      expandDims5.push(i);
    }
  }
  permutationIndices = permutationIndices.filter((d) => d !== -1);
  return { permutationIndices, expandDims: expandDims5 };
}
function checkEinsumDimSizes(nDims, idDims, tensors) {
  const dimSizes = new Array(nDims);
  for (let i = 0; i < tensors.length; ++i) {
    const shape = tensors[i].shape;
    for (let j = 0; j < idDims[i].length; ++j) {
      if (dimSizes[idDims[i][j]] === void 0) {
        dimSizes[idDims[i][j]] = shape[j];
      } else {
        assert(dimSizes[idDims[i][j]] === shape[j], () => `Expected dimension ${dimSizes[idDims[i][j]]} at axis ${j} of input shaped ${JSON.stringify(shape)}, but got dimension ${shape[j]}`);
      }
    }
  }
}
function getEinsumComputePath(summedDims, idDims) {
  const path = summedDims;
  const steps = [];
  let nSteps = 0;
  if (summedDims.length === 0) {
    path.push(-1);
  }
  nSteps = summedDims.length + 1;
  for (let i = 0; i < nSteps; ++i) {
    steps.push([]);
  }
  const computedTermIndices = [];
  for (let i = 0; i < path.length; ++i) {
    const summedDim = path[i];
    const termIndices = findTermsWithDim(idDims, summedDim);
    for (const termIndex of termIndices) {
      if (computedTermIndices.indexOf(termIndex) === -1) {
        steps[i].push(termIndex);
        computedTermIndices.push(termIndex);
      }
    }
  }
  return { path, steps };
}
function isIdentityPermutation(perm) {
  return perm.every((dim, index) => dim === index);
}
function findTermsWithDim(idDims, dim) {
  const termIndices = [];
  for (let i = 0; i < idDims.length; ++i) {
    if (idDims[i].length === 0 || idDims[i].indexOf(dim) !== -1 || dim === -1) {
      termIndices.push(i);
    }
  }
  return termIndices;
}
var ARROW;
var ARROW_REGEX;
var COMMA;
var ELLIPSIS;
var init_einsum_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/einsum_util.js"() {
    init_util_base();
    ARROW = "->";
    ARROW_REGEX = /->/g;
    COMMA = ",";
    ELLIPSIS = "...";
  }
});
function prepareSplitSize(x, numOrSizeSplits, axis = 0) {
  let splitSizes = [];
  if (typeof numOrSizeSplits === "number") {
    assert(x.shape[axis] % numOrSizeSplits === 0, () => "Number of splits must evenly divide the axis.");
    splitSizes = new Array(numOrSizeSplits).fill(x.shape[axis] / numOrSizeSplits);
  } else {
    const numOfNegs = numOrSizeSplits.reduce((count2, value) => {
      if (value === -1) {
        count2 += 1;
      }
      return count2;
    }, 0);
    assert(numOfNegs <= 1, () => "There should be only one negative value in split array.");
    const negIndex = numOrSizeSplits.indexOf(-1);
    if (negIndex !== -1) {
      const total = numOrSizeSplits.reduce((a, b) => b > 0 ? a + b : a);
      numOrSizeSplits[negIndex] = x.shape[axis] - total;
    }
    assert(x.shape[axis] === numOrSizeSplits.reduce((a, b) => a + b), () => "The sum of sizes must match the size of the axis dimension.");
    splitSizes = numOrSizeSplits;
  }
  return splitSizes;
}
var init_split_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/split_util.js"() {
    init_util();
  }
});
function getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesLength) {
  return `Received SparseTensor with denseShape[0] = 0 but
  indices.shape[0] = ${indicesLength}`;
}
function getSparseFillEmptyRowsNegativeIndexErrorMessage(index, value) {
  return `indices(${index}, 0) is invalid: ${value} < 0`;
}
function getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(index, value, limit) {
  return `indices(${index}, 0) is invalid: ${value} >= ${limit}`;
}
var init_sparse_fill_empty_rows_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js"() {
  }
});
function getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(dim1, dim2) {
  return `only one output dimension may be -1, not both ${dim1} and ${dim2}`;
}
function getSparseReshapeNegativeOutputDimErrorMessage(dim, value) {
  return `size ${dim} must be non-negative, not ${value}`;
}
function getSparseReshapeEmptyTensorZeroOutputDimErrorMessage() {
  return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
}
function getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape) {
  const inputSize = sizeFromShape(inputShape);
  const outputSize = sizeFromShape(outputShape);
  return `Input to reshape is a SparseTensor with ${inputSize}
  dense values, but the requested shape requires a multiple of ${outputSize}. inputShape=${inputShape} outputShape= ${outputShape}`;
}
function getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape) {
  const inputSize = sizeFromShape(inputShape);
  const outputSize = sizeFromShape(outputShape);
  return `Input to reshape is a tensor with ${inputSize} dense values, but the requested shape has ${outputSize}. inputShape=${inputShape} outputShape=${outputShape}`;
}
var init_sparse_reshape_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js"() {
    init_util();
  }
});
function getSparseSegmentReductionNegativeSegmentIdsErrorMessage() {
  return `segment ids must be >= 0`;
}
function getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage() {
  return `segment ids are not increasing`;
}
function getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(segmentId, outputRows) {
  return `Segment id ${segmentId} out of range [0, ${outputRows}), possibly because segmentIds input is not sorted.`;
}
function getSparseSegmentReductionIndicesOutOfRangeErrorMessage(index, indexValue, inputRows) {
  return `Bad: indices[${index}] == ${indexValue} out of range [0, ${inputRows})`;
}
var init_sparse_segment_reduction_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js"() {
  }
});
var segment_util_exports = {};
__export2(segment_util_exports, {
  collectGatherOpShapeInfo: () => collectGatherOpShapeInfo,
  computeOutShape: () => computeOutShape3,
  segOpComputeOptimalWindowSize: () => segOpComputeOptimalWindowSize
});
function segOpComputeOptimalWindowSize(inSize, numSegments) {
  let done = false;
  let res;
  if (inSize <= PARALLELIZE_THRESHOLD) {
    res = inSize;
    done = true;
  } else {
    res = nearestDivisor(inSize, Math.floor(Math.sqrt(inSize)));
  }
  while (!done) {
    if (res > numSegments || res === inSize) {
      done = true;
    } else {
      res = nearestDivisor(inSize, res + 1);
    }
  }
  return res;
}
function computeOutShape3(aShape, axis, numSegments) {
  const outShape = [];
  const rank = aShape.length;
  for (let dim = 0; dim < rank; dim++) {
    if (dim !== axis) {
      outShape.push(aShape[dim]);
    } else {
      outShape.push(numSegments);
    }
  }
  return outShape;
}
function collectGatherOpShapeInfo(x, indices, axis, batchDims) {
  const indicesRank = indices.shape.length;
  const xRank = x.shape.length;
  if (batchDims !== 0) {
    if (batchDims < -indicesRank || batchDims > indicesRank) {
      throw new Error(`Expect batchDims in the range of [-${indicesRank}, ${indicesRank}], but got ${batchDims}`);
    }
  }
  if (batchDims < 0) {
    batchDims += indicesRank;
  }
  if (batchDims > xRank) {
    throw new Error(`batchDims (${batchDims}) must be less than rank(x) (
    ${xRank}).`);
  }
  if (axis < batchDims) {
    throw new Error(`batchDims (${batchDims}) must be less than or equal to axis (${axis}).`);
  }
  for (let i = 0; i < batchDims; ++i) {
    if (x.shape[i] !== indices.shape[i]) {
      throw new Error(`x.shape[${i}]: ${x.shape[i]} should be equal to indices.shape[${i}]: ${indices.shape[i]}.`);
    }
  }
  const dimSize = x.shape[axis];
  const outputShape = [];
  let batchSize = 1;
  let outerSize = 1;
  let sliceSize = 1;
  for (let i = 0; i < batchDims; ++i) {
    outputShape.push(x.shape[i]);
    batchSize *= x.shape[i];
  }
  for (let i = batchDims; i < axis; i++) {
    outputShape.push(x.shape[i]);
    outerSize *= x.shape[i];
  }
  for (let i = batchDims; i < indicesRank; i++) {
    outputShape.push(indices.shape[i]);
  }
  for (let i = axis + 1; i < xRank; i++) {
    outputShape.push(x.shape[i]);
    sliceSize *= x.shape[i];
  }
  return { batchSize, sliceSize, outerSize, dimSize, outputShape };
}
var init_segment_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/segment_util.js"() {
    init_util();
    init_reduce_util();
  }
});
var backend_util_exports = {};
__export2(backend_util_exports, {
  ERF_A1: () => ERF_A1,
  ERF_A2: () => ERF_A2,
  ERF_A3: () => ERF_A3,
  ERF_A4: () => ERF_A4,
  ERF_A5: () => ERF_A5,
  ERF_P: () => ERF_P,
  PARALLELIZE_THRESHOLD: () => PARALLELIZE_THRESHOLD,
  RowPartitionType: () => RowPartitionType,
  SELU_SCALE: () => SELU_SCALE,
  SELU_SCALEALPHA: () => SELU_SCALEALPHA,
  applyActivation: () => applyActivation,
  assertAndGetBroadcastShape: () => assertAndGetBroadcastShape,
  assertAxesAreInnerMostDims: () => assertAxesAreInnerMostDims,
  assertParamsConsistent: () => assertParamsConsistent,
  assignToTypedArray: () => assignToTypedArray,
  axesAreInnerMostDims: () => axesAreInnerMostDims,
  calculateShapes: () => calculateShapes,
  checkEinsumDimSizes: () => checkEinsumDimSizes,
  checkPadOnDimRoundingMode: () => checkPadOnDimRoundingMode,
  combineLocations: () => combineLocations,
  combineRaggedTensorToTensorShapes: () => combineRaggedTensorToTensorShapes,
  complexWithEvenIndex: () => complexWithEvenIndex,
  complexWithOddIndex: () => complexWithOddIndex,
  computeConv2DInfo: () => computeConv2DInfo,
  computeConv3DInfo: () => computeConv3DInfo,
  computeDefaultPad: () => computeDefaultPad,
  computeDilation2DInfo: () => computeDilation2DInfo,
  computeOptimalWindowSize: () => computeOptimalWindowSize,
  computeOutAndReduceShapes: () => computeOutAndReduceShapes,
  computeOutShape: () => computeOutShape2,
  computePool2DInfo: () => computePool2DInfo,
  computePool3DInfo: () => computePool3DInfo,
  convertConv2DDataFormat: () => convertConv2DDataFormat,
  decodeEinsumEquation: () => decodeEinsumEquation,
  eitherStridesOrDilationsAreOne: () => eitherStridesOrDilationsAreOne,
  expandShapeToKeepDim: () => expandShapeToKeepDim,
  exponent: () => exponent,
  exponents: () => exponents,
  fromStringArrayToUint8: () => fromStringArrayToUint8,
  fromUint8ToStringArray: () => fromUint8ToStringArray,
  getAxesPermutation: () => getAxesPermutation,
  getBroadcastDims: () => getBroadcastDims,
  getComplexWithIndex: () => getComplexWithIndex,
  getEinsumComputePath: () => getEinsumComputePath,
  getEinsumPermutation: () => getEinsumPermutation,
  getFusedBiasGradient: () => getFusedBiasGradient,
  getFusedDyActivation: () => getFusedDyActivation,
  getImageCenter: () => getImageCenter,
  getInnerMostAxes: () => getInnerMostAxes,
  getPermuted: () => getPermuted,
  getRaggedRank: () => getRaggedRank,
  getReductionAxes: () => getReductionAxes,
  getReshaped: () => getReshaped,
  getReshapedPermuted: () => getReshapedPermuted,
  getRowPartitionTypesHelper: () => getRowPartitionTypesHelper,
  getSliceBeginCoords: () => getSliceBeginCoords,
  getSliceSize: () => getSliceSize,
  getSparseFillEmptyRowsIndicesDenseShapeMismatch: () => getSparseFillEmptyRowsIndicesDenseShapeMismatch,
  getSparseFillEmptyRowsNegativeIndexErrorMessage: () => getSparseFillEmptyRowsNegativeIndexErrorMessage,
  getSparseFillEmptyRowsOutOfRangeIndexErrorMessage: () => getSparseFillEmptyRowsOutOfRangeIndexErrorMessage,
  getSparseReshapeEmptyTensorZeroOutputDimErrorMessage: () => getSparseReshapeEmptyTensorZeroOutputDimErrorMessage,
  getSparseReshapeInputOutputMismatchErrorMessage: () => getSparseReshapeInputOutputMismatchErrorMessage,
  getSparseReshapeInputOutputMultipleErrorMessage: () => getSparseReshapeInputOutputMultipleErrorMessage,
  getSparseReshapeMultipleNegativeOneOutputDimErrorMessage: () => getSparseReshapeMultipleNegativeOneOutputDimErrorMessage,
  getSparseReshapeNegativeOutputDimErrorMessage: () => getSparseReshapeNegativeOutputDimErrorMessage,
  getSparseSegmentReductionIndicesOutOfRangeErrorMessage: () => getSparseSegmentReductionIndicesOutOfRangeErrorMessage,
  getSparseSegmentReductionNegativeSegmentIdsErrorMessage: () => getSparseSegmentReductionNegativeSegmentIdsErrorMessage,
  getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage: () => getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage,
  getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage: () => getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage,
  getUndoAxesPermutation: () => getUndoAxesPermutation,
  isIdentityPermutation: () => isIdentityPermutation,
  log: () => log,
  mergeRealAndImagArrays: () => mergeRealAndImagArrays,
  prepareAndValidate: () => prepareAndValidate,
  prepareSplitSize: () => prepareSplitSize,
  segment_util: () => segment_util_exports,
  shouldFuse: () => shouldFuse,
  slice_util: () => slice_util_exports,
  splitRealAndImagArrays: () => splitRealAndImagArrays,
  stridesOrDilationsArePositive: () => stridesOrDilationsArePositive,
  tupleValuesAreOne: () => tupleValuesAreOne,
  upcastType: () => upcastType,
  validateDefaultValueShape: () => validateDefaultValueShape,
  validateInput: () => validateInput,
  validateUpdateShape: () => validateUpdateShape,
  warn: () => warn
});
function fromUint8ToStringArray(vals) {
  try {
    return vals.map((val) => decodeString(val));
  } catch (err) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${err}`);
  }
}
function fromStringArrayToUint8(strings) {
  return strings.map((s) => encodeString(s));
}
var init_backend_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/backend_util.js"() {
    init_util();
    init_axis_util();
    init_broadcast_util();
    init_concat_util();
    init_conv_util();
    init_fused_util();
    init_fused_types();
    init_ragged_to_dense_util();
    init_reduce_util();
    init_slice_util();
    init_types();
    init_rotate_util();
    init_array_ops_util();
    init_gather_nd_util();
    init_scatter_nd_util();
    init_selu_util();
    init_fused_util();
    init_erf_util();
    init_log();
    init_complex_util();
    init_einsum_util();
    init_split_util();
    init_sparse_fill_empty_rows_util();
    init_sparse_reshape_util();
    init_sparse_segment_reduction_util();
    init_segment_util();
  }
});
var kernel_impls_exports = {};
__export2(kernel_impls_exports, {
  nonMaxSuppressionV3Impl: () => nonMaxSuppressionV3Impl,
  nonMaxSuppressionV4Impl: () => nonMaxSuppressionV4Impl,
  nonMaxSuppressionV5Impl: () => nonMaxSuppressionV5Impl,
  whereImpl: () => whereImpl
});
var init_kernel_impls = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/backends/kernel_impls.js"() {
    init_non_max_suppression_impl();
    init_where_impl();
  }
});
var init_base = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/base.js"() {
    init_io();
    init_broadcast_util();
    init_browser();
    init_slice_util();
    init_serialization();
    init_tensor_util();
    init_util();
    init_optimizer();
    init_tensor();
    init_types();
    init_ops();
    init_train();
    init_globals();
    init_kernel_registry();
    init_environment();
    init_browser_util();
    init_backend_util();
    init_device_util();
    init_kernel_impls();
    init_backend();
    init_kernel_names();
  }
});
var init_dist = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/index.js"() {
    init_base_side_effects();
    init_register_optimizers();
    init_base();
    registerOptimizers();
  }
});
var absGradConfig;
var init_Abs_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Abs_grad.js"() {
    init_kernel_names();
    init_cast();
    init_mul();
    init_step();
    absGradConfig = {
      kernelName: Abs,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(dy, step(cast(x, "float32"), -1)) };
      }
    };
  }
});
var acosGradConfig;
var init_Acos_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Acos_grad.js"() {
    init_kernel_names();
    init_cast();
    init_div();
    init_neg();
    init_scalar();
    init_sqrt();
    init_square();
    init_sub();
    acosGradConfig = {
      kernelName: Acos,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return {
          x: () => {
            const a = square(cast(x, "float32"));
            const b = sqrt(sub3(scalar(1), a));
            return neg(div2(dy, b));
          }
        };
      }
    };
  }
});
var acoshGradConfig;
var init_Acosh_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Acosh_grad.js"() {
    init_kernel_names();
    init_cast();
    init_div();
    init_sqrt();
    init_square();
    init_sub();
    acoshGradConfig = {
      kernelName: Acosh,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return {
          x: () => {
            const a = sqrt(sub3(square(cast(x, "float32")), 1));
            return div2(dy, a);
          }
        };
      }
    };
  }
});
var addGradConfig;
var init_Add_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Add_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_reshape();
    init_sum();
    addGradConfig = {
      kernelName: Add,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          let res = dy;
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, a.shape);
        };
        const derB = () => {
          let res = dy;
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, b.shape);
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var addNGradConfig;
var init_AddN_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/AddN_grad.js"() {
    init_kernel_names();
    addNGradConfig = {
      kernelName: AddN,
      saveAllInputs: true,
      gradFunc: (dy, saved) => {
        const ders = {};
        saved.forEach((_, i) => {
          ders[i] = () => dy.clone();
        });
        return ders;
      }
    };
  }
});
var argMaxGradConfig;
var init_ArgMax_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ArgMax_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    argMaxGradConfig = {
      kernelName: ArgMax,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => zerosLike(x) };
      }
    };
  }
});
var argMinGradConfig;
var init_ArgMin_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ArgMin_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    argMinGradConfig = {
      kernelName: ArgMin,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => zerosLike(x) };
      }
    };
  }
});
var asinGradConfig;
var init_Asin_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Asin_grad.js"() {
    init_kernel_names();
    init_cast();
    init_div();
    init_scalar();
    init_sqrt();
    init_square();
    init_sub();
    asinGradConfig = {
      kernelName: Asin,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, sqrt(sub3(scalar(1), square(cast(x, "float32"))))) };
      }
    };
  }
});
var asinhGradConfig;
var init_Asinh_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Asinh_grad.js"() {
    init_kernel_names();
    init_add();
    init_cast();
    init_div();
    init_scalar();
    init_sqrt();
    init_square();
    asinhGradConfig = {
      kernelName: Asinh,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return {
          x: () => {
            const a = sqrt(add22(scalar(1), square(cast(x, "float32"))));
            return div2(dy, a);
          }
        };
      }
    };
  }
});
var atan2GradConfig;
var init_Atan2_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Atan2_grad.js"() {
    init_kernel_names();
    init_add();
    init_broadcast_util();
    init_div();
    init_mul();
    init_neg();
    init_reshape();
    init_square();
    init_sum();
    atan2GradConfig = {
      kernelName: Atan2,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          const d = add22(square(a), square(b));
          let res = mul5(dy, div2(b, d));
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, a.shape);
        };
        const derB = () => {
          const d = add22(square(a), square(b));
          let res = neg(mul5(dy, div2(a, d)));
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, b.shape);
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var atanGradConfig;
var init_Atan_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Atan_grad.js"() {
    init_kernel_names();
    init_add();
    init_cast();
    init_div();
    init_square();
    atanGradConfig = {
      kernelName: Atan,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, add22(square(cast(x, "float32")), 1)) };
      }
    };
  }
});
var atanhGradConfig;
var init_Atanh_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Atanh_grad.js"() {
    init_kernel_names();
    init_cast();
    init_div();
    init_square();
    init_sub();
    init_scalar();
    atanhGradConfig = {
      kernelName: Atanh,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, sub3(scalar(1), square(cast(x, "float32")))) };
      }
    };
  }
});
function avgPool3dGrad_(dy, input2, filterSize, strides, pad2, dimRoundingMode) {
  const $dy = convertToTensor(dy, "dy", "avgPool3dGrad");
  const $input = convertToTensor(input2, "input", "avgPool3dGrad");
  let dy5D = $dy;
  let input5D = $input;
  let reshapedTo5D = false;
  if ($input.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);
    input5D = reshape($input, [
      1,
      $input.shape[0],
      $input.shape[1],
      $input.shape[2],
      $input.shape[3]
    ]);
  }
  assert(dy5D.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`);
  assert(input5D.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`);
  checkPadOnDimRoundingMode("avgPool3dGrad", pad2, dimRoundingMode);
  const inputs = { dy: dy5D, input: input5D };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
  const res = ENGINE.runKernel(AvgPool3DGrad, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var avgPool3dGrad;
var init_avg_pool_3d_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    avgPool3dGrad = /* @__PURE__ */ op({ avgPool3dGrad_ });
  }
});
var avgPool3DGradConfig;
var init_AvgPool3D_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/AvgPool3D_grad.js"() {
    init_kernel_names();
    init_avg_pool_3d_grad();
    avgPool3DGradConfig = {
      kernelName: AvgPool3D,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
        return {
          x: () => avgPool3dGrad(dy, x, filterSize, strides, pad2, dimRoundingMode)
        };
      }
    };
  }
});
function avgPoolGrad_(dy, input2, filterSize, strides, pad2) {
  const $dy = convertToTensor(dy, "dy", "avgPoolGrad");
  const $input = convertToTensor(input2, "input", "avgPoolGrad");
  assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);
  let input4D = $input;
  let dy4D = $dy;
  let reshapedTo4D = false;
  if ($input.rank === 3) {
    reshapedTo4D = true;
    input4D = reshape($input, [1, $input.shape[0], $input.shape[1], $input.shape[2]]);
    dy4D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2]]);
  }
  assert(dy4D.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ${dy4D.rank}.`);
  assert(input4D.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ${input4D.rank}.`);
  const inputs = { dy: dy4D, input: input4D };
  const attrs = { filterSize, strides, pad: pad2 };
  const res = ENGINE.runKernel(AvgPoolGrad, inputs, attrs);
  if (reshapedTo4D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);
  }
  return res;
}
var avgPoolGrad;
var init_avg_pool_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/avg_pool_grad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_operation();
    init_reshape();
    avgPoolGrad = /* @__PURE__ */ op({ avgPoolGrad_ });
  }
});
var avgPoolGradConfig;
var init_AvgPool_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/AvgPool_grad.js"() {
    init_kernel_names();
    init_avg_pool_grad();
    avgPoolGradConfig = {
      kernelName: AvgPool,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { filterSize, strides, pad: pad2 } = attrs;
        return { x: () => avgPoolGrad(dy, x, filterSize, strides, pad2) };
      }
    };
  }
});
var batchMatMulGradConfig;
var init_BatchMatMul_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/BatchMatMul_grad.js"() {
    init_kernel_names();
    init_mat_mul();
    batchMatMulGradConfig = {
      kernelName: BatchMatMul,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved, attrs) => {
        const [a, b] = saved;
        const { transposeA, transposeB } = attrs;
        if (!transposeA && !transposeB) {
          return {
            a: () => matMul(dy, b, false, true),
            b: () => matMul(a, dy, true, false)
          };
        } else if (!transposeA && transposeB) {
          return {
            a: () => matMul(dy, b, false, false),
            b: () => matMul(dy, a, true, false)
          };
        } else if (transposeA && !transposeB) {
          return {
            a: () => matMul(b, dy, false, true),
            b: () => matMul(a, dy, false, false)
          };
        } else {
          return {
            a: () => matMul(b, dy, true, true),
            b: () => matMul(dy, a, true, true)
          };
        }
      }
    };
  }
});
var batchToSpaceNDGradConfig;
var init_BatchToSpaceND_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/BatchToSpaceND_grad.js"() {
    init_kernel_names();
    init_space_to_batch_nd();
    batchToSpaceNDGradConfig = {
      kernelName: BatchToSpaceND,
      gradFunc: (dy, saved, attrs) => {
        const { blockShape, crops } = attrs;
        return { x: () => spaceToBatchND(dy, blockShape, crops) };
      }
    };
  }
});
var broadcastToGradConfig;
var init_BroadcastTo_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/BroadcastTo_grad.js"() {
    init_kernel_names();
    init_sum();
    broadcastToGradConfig = {
      kernelName: BroadcastTo,
      gradFunc: (dy, saved, attrs) => {
        const broadCastToAttrs = attrs;
        const inputShape = broadCastToAttrs.inputShape;
        const outputShape = broadCastToAttrs.shape;
        const reps = Array.from(outputShape);
        for (let i = inputShape.length - 1; i >= 0; i--) {
          if (inputShape[i] === outputShape[i]) {
            reps[i] = 1;
          } else if (inputShape[i] !== 1) {
            throw new Error(`broadcastTo(): [${inputShape}] cannot be broadcast to [${outputShape}].`);
          }
        }
        const axes = [];
        for (let i = 0; i < reps.length; i++) {
          if (reps[i] > 1) {
            axes.push(i);
          }
        }
        return { x: () => sum2(
          dy,
          axes,
          true
          /* keepDims */
        ) };
      }
    };
  }
});
var castGradConfig;
var init_Cast_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Cast_grad.js"() {
    init_kernel_names();
    castGradConfig = {
      kernelName: Cast,
      gradFunc: (dy) => {
        return { x: () => dy.clone() };
      }
    };
  }
});
var ceilGradConfig;
var init_Ceil_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Ceil_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    ceilGradConfig = {
      kernelName: Ceil,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var clipByValueGradConfig;
var init_ClipByValue_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ClipByValue_grad.js"() {
    init_kernel_names();
    init_greater_equal();
    init_less_equal();
    init_logical_and();
    init_where();
    init_zeros_like();
    clipByValueGradConfig = {
      kernelName: ClipByValue,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { clipValueMin, clipValueMax } = attrs;
        return {
          x: () => where(logicalAnd(greaterEqual(x, clipValueMin), lessEqual(x, clipValueMax)), dy, zerosLike(dy))
        };
      }
    };
  }
});
var complexAbsGradConfig;
var init_ComplexAbs_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ComplexAbs_grad.js"() {
    init_kernel_names();
    init_Abs_grad();
    complexAbsGradConfig = {
      kernelName: ComplexAbs,
      inputsToSave: ["x"],
      gradFunc: absGradConfig.gradFunc
    };
  }
});
var concatGradConfig;
var init_Concat_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Concat_grad.js"() {
    init_kernel_names();
    init_split();
    init_util();
    concatGradConfig = {
      kernelName: Concat,
      saveAllInputs: true,
      gradFunc: (dy, saved, attrs) => {
        const shapes = saved.map((t) => t.shape);
        const { axis } = attrs;
        const $axis = parseAxisParam(axis, saved[0].shape)[0];
        const sizeSplits = shapes.map((s) => s[$axis]);
        const derTensors = split(dy, sizeSplits, $axis);
        return derTensors.map((t) => () => t);
      }
    };
  }
});
var conv2DGradConfig;
var init_Conv2D_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Conv2D_grad.js"() {
    init_kernel_names();
    init_conv2d_backprop_filter();
    init_conv2d_backprop_input();
    init_conv_util();
    init_util();
    conv2DGradConfig = {
      kernelName: Conv2D,
      inputsToSave: ["x", "filter"],
      gradFunc: (dy, saved, attrs) => {
        const [x4D, $filter] = saved;
        const { dilations, strides, pad: pad2, dataFormat } = attrs;
        assert(tupleValuesAreOne(dilations), () => `Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
        return {
          x: () => conv2DBackpropInput(x4D.shape, dy, $filter, strides, pad2, dataFormat),
          filter: () => conv2DBackpropFilter(x4D, dy, $filter.shape, strides, pad2, dataFormat)
        };
      }
    };
  }
});
var conv2DBackpropInputGradConfig;
var init_Conv2DBackpropInput_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Conv2DBackpropInput_grad.js"() {
    init_kernel_names();
    init_conv2d();
    init_conv2d_backprop_filter();
    conv2DBackpropInputGradConfig = {
      kernelName: Conv2DBackpropInput,
      inputsToSave: ["dy", "filter"],
      gradFunc: (ddx, saved, attrs) => {
        const [dy, filter] = saved;
        const { strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
        return {
          dy: () => conv2d(ddx, filter, strides, pad2, dataFormat, 1, dimRoundingMode),
          filter: () => conv2DBackpropFilter(ddx, dy, filter.shape, strides, pad2, dataFormat, dimRoundingMode)
        };
      }
    };
  }
});
function conv3DBackpropFilter_(x, dy, filterShape, strides, pad2) {
  let x5D = x;
  if (x.rank === 4) {
    x5D = reshape(x, [1, x.shape[0], x.shape[1], x.shape[2], x.shape[3]]);
  }
  let dy5D = dy;
  if (dy5D.rank === 4) {
    dy5D = reshape(dy, [1, dy.shape[0], dy.shape[1], dy.shape[2], dy.shape[3]]);
  }
  assert(x5D.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ${x5D.shape}.`);
  assert(dy5D.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ${dy5D.shape}.`);
  assert(filterShape.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ${filterShape}.`);
  assert(x5D.shape[4] === filterShape[3], () => `Error in conv3dDerFilter: depth of input ${x5D.shape[4]}) must match input depth in filter (${filterShape[3]}.`);
  assert(dy5D.shape[4] === filterShape[4], () => `Error in conv3dDerFilter: depth of dy (${dy5D.shape[4]}) must match output depth for filter (${filterShape[4]}).`);
  const inputs = { x: x5D, dy: dy5D };
  const attrs = { strides, pad: pad2, filterShape };
  return ENGINE.runKernel(Conv3DBackpropFilterV2, inputs, attrs);
}
var conv3DBackpropFilter;
var init_conv3d_backprop_filter = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js"() {
    init_engine();
    init_kernel_names();
    init_util();
    init_operation();
    init_reshape();
    conv3DBackpropFilter = /* @__PURE__ */ op({ conv3DBackpropFilter_ });
  }
});
var conv3DGradConfig;
var init_Conv3D_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Conv3D_grad.js"() {
    init_kernel_names();
    init_conv3d_backprop_filter();
    init_conv3d_backprop_input();
    init_conv_util();
    init_util();
    conv3DGradConfig = {
      kernelName: Conv3D,
      inputsToSave: ["x", "filter"],
      gradFunc: (dy, saved, attrs) => {
        const { dilations, strides, pad: pad2 } = attrs;
        assert(tupleValuesAreOne(dilations), () => `Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${dilations}'`);
        const [x5D, $filter] = saved;
        return {
          x: () => conv3DBackpropInput(x5D.shape, dy, $filter, strides, pad2),
          filter: () => conv3DBackpropFilter(x5D, dy, $filter.shape, strides, pad2)
        };
      }
    };
  }
});
var cosGradConfig;
var init_Cos_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Cos_grad.js"() {
    init_kernel_names();
    init_cast();
    init_mul();
    init_neg();
    init_sin();
    cosGradConfig = {
      kernelName: Cos,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(neg(sin(cast(x, "float32"))), dy) };
      }
    };
  }
});
var coshGradConfig;
var init_Cosh_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Cosh_grad.js"() {
    init_kernel_names();
    init_cast();
    init_mul();
    init_sinh();
    coshGradConfig = {
      kernelName: Cosh,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(sinh(cast(x, "float32")), dy) };
      }
    };
  }
});
var cumsumGradConfig;
var init_Cumsum_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Cumsum_grad.js"() {
    init_kernel_names();
    init_axis_util();
    init_cumsum();
    init_transpose();
    cumsumGradConfig = {
      kernelName: Cumsum,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { axis, exclusive, reverse: reverse4 } = attrs;
        return {
          x: () => {
            const permutation = getAxesPermutation([axis], x.rank);
            let out = cumsum(dy, axis, exclusive, !reverse4);
            if (permutation != null) {
              out = transpose2(out, permutation);
            }
            return out;
          }
        };
      }
    };
  }
});
var depthwiseConv2dNativeGradConfig;
var init_DepthwiseConv2dNative_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/DepthwiseConv2dNative_grad.js"() {
    init_kernel_names();
    init_conv_util();
    init_depthwise_conv2d_native_backprop_filter();
    init_depthwise_conv2d_native_backprop_input();
    init_util();
    depthwiseConv2dNativeGradConfig = {
      kernelName: DepthwiseConv2dNative,
      inputsToSave: ["x", "filter"],
      gradFunc: (dy, saved, attrs) => {
        const { dilations, strides, pad: pad2, dimRoundingMode } = attrs;
        const $dilations = dilations == null ? [1, 1] : dilations;
        assert(tupleValuesAreOne($dilations), () => `Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${$dilations}'`);
        const [x, filter] = saved;
        assert(x.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${x.rank}.`);
        assert(filter.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${filter.rank}.`);
        assert(x.shape[3] === filter.shape[2], () => `Error in gradient of depthwiseConv2d: number of input channels (${x.shape[3]}) must match the inChannels dimension in filter ${filter.shape[2]}.`);
        assert(eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${strides} and dilations '${$dilations}'.`);
        checkPadOnDimRoundingMode("depthwiseConv2d", pad2, dimRoundingMode);
        return {
          x: () => depthwiseConv2dNativeBackpropInput(x.shape, dy, filter, strides, pad2, $dilations, dimRoundingMode),
          filter: () => depthwiseConv2dNativeBackpropFilter(x, dy, filter.shape, strides, pad2, $dilations, dimRoundingMode)
        };
      }
    };
  }
});
var dilation2dGradConfig;
var init_Dilation2D_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Dilation2D_grad.js"() {
    init_engine();
    init_kernel_names();
    dilation2dGradConfig = {
      kernelName: Dilation2D,
      inputsToSave: ["x", "filter"],
      gradFunc: (dy, saved, attrs) => {
        const [x, filter] = saved;
        const inputInputs = { x, filter, dy };
        const filterInputs = { x, filter, dy };
        return {
          x: () => ENGINE.runKernel(Dilation2DBackpropInput, inputInputs, attrs),
          filter: () => ENGINE.runKernel(Dilation2DBackpropFilter, filterInputs, attrs)
        };
      }
    };
  }
});
var eluGradConfig;
var init_Elu_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Elu_grad.js"() {
    init_engine();
    init_kernel_names();
    eluGradConfig = {
      kernelName: Elu,
      outputsToSave: [true],
      gradFunc: (dy, saved) => {
        const [y] = saved;
        const inputs = { dy, y };
        return { x: () => ENGINE.runKernel(EluGrad, inputs) };
      }
    };
  }
});
var erfGradConfig;
var init_Erf_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Erf_grad.js"() {
    init_kernel_names();
    init_exp();
    init_mul();
    init_neg();
    init_square();
    erfGradConfig = {
      kernelName: Erf,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        const a = mul5(exp2(neg(square(x))), 2 / Math.sqrt(Math.PI));
        return { x: () => mul5(dy, a) };
      }
    };
  }
});
var expGradConfig;
var init_Exp_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Exp_grad.js"() {
    init_kernel_names();
    init_mul();
    expGradConfig = {
      kernelName: Exp,
      outputsToSave: [true],
      gradFunc: (dy, saved) => {
        const [y] = saved;
        return { x: () => mul5(dy, y) };
      }
    };
  }
});
var expandDimsGradConfig;
var init_ExpandDims_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ExpandDims_grad.js"() {
    init_kernel_names();
    init_reshape();
    expandDimsGradConfig = {
      kernelName: ExpandDims,
      inputsToSave: ["input"],
      gradFunc: (dy, saved) => {
        const [input2] = saved;
        return { input: () => reshape(dy, input2.shape) };
      }
    };
  }
});
var expm1GradConfig;
var init_Expm1_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Expm1_grad.js"() {
    init_kernel_names();
    init_exp();
    init_mul();
    expm1GradConfig = {
      kernelName: Expm1,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(dy, exp2(x)) };
      }
    };
  }
});
var floorGradConfig;
var init_Floor_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Floor_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    floorGradConfig = {
      kernelName: Floor,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var floorDivGradConfig;
var init_FloorDiv_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/FloorDiv_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_cast();
    init_div();
    init_mul();
    init_neg();
    init_reshape();
    init_square();
    init_sum();
    floorDivGradConfig = {
      kernelName: FloorDiv,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          const res = div2(dy, cast(b, "float32"));
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            return reshape(sum2(res, reduceAxes), a.shape);
          }
          return res;
        };
        const derB = () => {
          let res = mul5(dy, cast(a, "float32"));
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            res = reshape(sum2(res, reduceAxes), b.shape);
          }
          const tmp = square(b);
          return neg(div2(res, cast(tmp, "float32")));
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var fusedBatchNormGradConfig;
var init_FusedBatchNorm_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/FusedBatchNorm_grad.js"() {
    init_kernel_names();
    init_add();
    init_broadcast_util();
    init_mul();
    init_reshape();
    init_rsqrt();
    init_scalar();
    init_sub();
    init_sum();
    init_tile();
    fusedBatchNormGradConfig = {
      kernelName: FusedBatchNorm,
      inputsToSave: ["x", "mean", "variance", "scale"],
      gradFunc: (dy, saved, attrs) => {
        const { varianceEpsilon } = attrs;
        const [x, mean3, variance, scale22] = saved;
        const scaleValue = scale22 == null ? scalar(1) : scale22;
        const reductionAxes = getReductionAxes(mean3.shape, x.shape);
        const tileShape = [];
        if (mean3.rank === 1) {
          for (let i = 0; i < x.shape.length - 1; ++i) {
            tileShape.push(x.shape[i]);
          }
          tileShape.push(1);
        }
        const xMinusMean = sub3(x, mean3);
        const dyTimesScaleValue = mul5(dy, scaleValue);
        const oneOverSqrtVariance = rsqrt(add22(variance, scalar(varianceEpsilon)));
        const minusHalfRCube = mul5(mul5(mul5(oneOverSqrtVariance, oneOverSqrtVariance), oneOverSqrtVariance), scalar(-0.5));
        const derX = () => {
          if (mean3.rank === 1) {
            return reshape(mul5(mul5(dy, tile(reshape(oneOverSqrtVariance, [1, 1, 1, mean3.shape[0]]), tileShape)), scaleValue), x.shape);
          } else {
            return reshape(mul5(mul5(dy, oneOverSqrtVariance), scaleValue), x.shape);
          }
        };
        const derMean = () => {
          let meanDer = mul5(mul5(oneOverSqrtVariance, scalar(-1)), dyTimesScaleValue);
          if (mean3.rank === 1) {
            meanDer = sum2(meanDer, reductionAxes);
          }
          return reshape(meanDer, mean3.shape);
        };
        const derVariance = () => {
          let varianceDer = mul5(mul5(minusHalfRCube, xMinusMean), dyTimesScaleValue);
          if (mean3.rank === 1) {
            varianceDer = sum2(varianceDer, reductionAxes);
          }
          return reshape(varianceDer, mean3.shape);
        };
        const derScale = () => {
          const xMinusMean2TimesRsqrt = mul5(xMinusMean, oneOverSqrtVariance);
          let scaleDer = mul5(dy, xMinusMean2TimesRsqrt);
          if (mean3.rank === 1) {
            scaleDer = sum2(scaleDer, reductionAxes);
          }
          return reshape(scaleDer, mean3.shape);
        };
        const derOffset = () => {
          let offsetDer = dy;
          if (mean3.rank === 1) {
            offsetDer = sum2(offsetDer, reductionAxes);
          }
          return reshape(offsetDer, mean3.shape);
        };
        return {
          x: derX,
          mean: derMean,
          variance: derVariance,
          scale: derScale,
          offset: derOffset
        };
      }
    };
  }
});
function arrayRange(start, stop) {
  const result = [];
  for (let i = start; i < stop; ++i) {
    result.push(i);
  }
  return result;
}
function arrayConcat(arrays) {
  const result = [];
  for (let i = 0; i < arrays.length; ++i) {
    for (let j = 0; j < arrays[i].length; ++j) {
      result.push(arrays[i][j]);
    }
  }
  return result;
}
var gatherGradConfig;
var init_GatherV2_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/GatherV2_grad.js"() {
    init_kernel_names();
    init_axis_util();
    init_reshape();
    init_transpose();
    init_unsorted_segment_sum();
    init_util();
    gatherGradConfig = {
      kernelName: GatherV2,
      inputsToSave: ["x", "indices"],
      gradFunc: (dy, saved, attrs) => {
        const [x, indices] = saved;
        const { axis } = attrs;
        const parsedAxis = parseAxisParam(axis, x.shape)[0];
        const derX = () => {
          const paramsShape = x.shape;
          const indicesSize = indices.size;
          const outerShape = paramsShape.slice(0, parsedAxis);
          const outerDims = outerShape.length;
          const innerShape = paramsShape.slice(axis, paramsShape.length).slice(1);
          const innerDims = innerShape.length;
          const outerAxesIndices = arrayRange(0, outerDims);
          const innerAxesIndices = arrayRange(outerDims + 1, outerDims + 1 + innerDims);
          const valuesShape = arrayConcat([outerShape, [indicesSize], innerShape]);
          const values = reshape(dy, valuesShape);
          const reshapedIndices = reshape(indices, [indicesSize]);
          const transposeDims = arrayConcat([[outerDims], outerAxesIndices, innerAxesIndices]);
          const valuesTranspose = transpose2(values, transposeDims);
          let paramsGrad = unsortedSegmentSum(valuesTranspose, reshapedIndices, x.shape[parsedAxis]);
          const invertTransposeDims = getUndoAxesPermutation(transposeDims);
          paramsGrad = transpose2(paramsGrad, invertTransposeDims);
          return paramsGrad;
        };
        return { x: derX, indices: () => indices };
      }
    };
  }
});
var greaterEqualGradConfig;
var init_GreaterEqual_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/GreaterEqual_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    greaterEqualGradConfig = {
      kernelName: GreaterEqual,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        return { a: () => zerosLike(a), b: () => zerosLike(b) };
      }
    };
  }
});
var identityGradConfig;
var init_Identity_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Identity_grad.js"() {
    init_kernel_names();
    init_cast();
    identityGradConfig = {
      kernelName: Identity,
      gradFunc: (dy) => {
        return { x: () => cast(dy, "float32") };
      }
    };
  }
});
var isFiniteGradConfig;
var init_IsFinite_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/IsFinite_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    isFiniteGradConfig = {
      kernelName: IsFinite,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var isInfGradConfig;
var init_IsInf_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/IsInf_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    isInfGradConfig = {
      kernelName: IsInf,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var isNanGradConfig;
var init_IsNan_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/IsNan_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    isNanGradConfig = {
      kernelName: IsNan,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var leakyReluGradConfig;
var init_LeakyRelu_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/LeakyRelu_grad.js"() {
    init_kernel_names();
    init_greater();
    init_mul();
    init_where();
    leakyReluGradConfig = {
      kernelName: LeakyRelu,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { alpha } = attrs;
        const mask = greater(x, 0);
        return { x: () => where(mask, dy, mul5(dy, alpha)) };
      }
    };
  }
});
var log1pGradConfig;
var init_Log1p_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Log1p_grad.js"() {
    init_kernel_names();
    init_add();
    init_div();
    log1pGradConfig = {
      kernelName: Log1p,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, add22(x, 1)) };
      }
    };
  }
});
var logGradConfig;
var init_Log_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Log_grad.js"() {
    init_kernel_names();
    init_cast();
    init_div();
    logGradConfig = {
      kernelName: Log,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, cast(x, "float32")) };
      }
    };
  }
});
var logSoftmaxGradConfig;
var init_LogSoftmax_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/LogSoftmax_grad.js"() {
    init_kernel_names();
    init_exp();
    init_mul();
    init_sub();
    init_sum();
    logSoftmaxGradConfig = {
      kernelName: LogSoftmax,
      inputsToSave: [],
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const [value] = saved;
        const { axis } = attrs;
        return {
          logits: () => {
            const keepDims = true;
            const softmax4 = exp2(value);
            return sub3(dy, mul5(sum2(dy, axis, keepDims), softmax4));
          }
        };
      }
    };
  }
});
function localResponseNormalizationBackprop_(x, y, dy, depthRadius = 5, bias = 1, alpha = 1, beta = 0.5) {
  const inputs = { x, y, dy };
  const attrs = { depthRadius, bias, alpha, beta };
  return ENGINE.runKernel(LRNGrad, inputs, attrs);
}
var localResponseNormalizationBackprop;
var init_local_response_normalization_backprop = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/local_response_normalization_backprop.js"() {
    init_engine();
    init_kernel_names();
    init_operation();
    localResponseNormalizationBackprop = op({ localResponseNormalizationBackprop_ });
  }
});
var lrnGradConfig;
var init_LRN_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/LRN_grad.js"() {
    init_kernel_names();
    init_local_response_normalization_backprop();
    lrnGradConfig = {
      kernelName: LRN,
      inputsToSave: ["x"],
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const [x, y] = saved;
        const { depthRadius, bias, alpha, beta } = attrs;
        return {
          x: () => localResponseNormalizationBackprop(x, y, dy, depthRadius, bias, alpha, beta)
        };
      }
    };
  }
});
function gradForMinAndMax(dy, y, xOrig, origAxes) {
  if (y.rank < xOrig.rank) {
    y = reshape(y, expandShapeToKeepDim(y.shape, origAxes));
  }
  if (dy.rank < xOrig.rank) {
    dy = reshape(dy, expandShapeToKeepDim(dy.shape, origAxes));
  }
  return {
    x: () => {
      const dx = mul5(dy, cast(equal(xOrig, y), dy.dtype));
      return dx;
    }
  };
}
var init_min_max_grad_util = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/min_max_grad_util.js"() {
    init_axis_util();
    init_cast();
    init_equal();
    init_mul();
    init_reshape();
  }
});
var maxGradConfig;
var init_Max_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Max_grad.js"() {
    init_kernel_names();
    init_util();
    init_min_max_grad_util();
    maxGradConfig = {
      kernelName: Max,
      inputsToSave: ["x"],
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const maxAttrs = attrs;
        const { reductionIndices } = maxAttrs;
        const x = saved[0];
        const y = saved[1];
        const origAxes = parseAxisParam(reductionIndices, x.shape);
        const maxGrad = gradForMinAndMax(dy, y, x, origAxes);
        return {
          x: () => {
            return maxGrad["x"]();
          }
        };
      }
    };
  }
});
var maximumGradConfig;
var init_Maximum_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Maximum_grad.js"() {
    init_kernel_names();
    init_cast();
    init_greater_equal();
    init_less();
    init_mul();
    maximumGradConfig = {
      kernelName: Maximum,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const derA = () => mul5(dy, cast(greaterEqual(a, b), "float32"));
        const derB = () => mul5(dy, cast(less(a, b), "float32"));
        return { a: derA, b: derB };
      }
    };
  }
});
function maxPool3dGrad_(dy, input2, output, filterSize, strides, pad2, dimRoundingMode) {
  const $dy = convertToTensor(dy, "dy", "maxPool3dGrad");
  const $input = convertToTensor(input2, "input", "maxPool3dGrad");
  const $output = convertToTensor(output, "output", "maxPool3dGrad");
  let dy5D = $dy;
  let input5D = $input;
  let output5D = $output;
  let reshapedTo5D = false;
  if ($input.rank === 4) {
    reshapedTo5D = true;
    dy5D = reshape($dy, [1, $dy.shape[0], $dy.shape[1], $dy.shape[2], $dy.shape[3]]);
    input5D = reshape($input, [
      1,
      $input.shape[0],
      $input.shape[1],
      $input.shape[2],
      $input.shape[3]
    ]);
    output5D = reshape($output, [
      1,
      $output.shape[0],
      $output.shape[1],
      $output.shape[2],
      $output.shape[3]
    ]);
  }
  assert(dy5D.rank === 5, () => `Error in maxPool3dGrad: dy must be rank 5 but got rank ${dy5D.rank}.`);
  assert(input5D.rank === 5, () => `Error in maxPool3dGrad: input must be rank 5 but got rank ${input5D.rank}.`);
  assert(output5D.rank === 5, () => `Error in maxPool3dGrad: output must be rank 5 but got rank ${output5D.rank}.`);
  checkPadOnDimRoundingMode("maxPool3dGrad", pad2, dimRoundingMode);
  const inputs = { dy: dy5D, input: input5D, output: output5D };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
  const res = ENGINE.runKernel(MaxPool3DGrad, inputs, attrs);
  if (reshapedTo5D) {
    return reshape(res, [res.shape[1], res.shape[2], res.shape[3], res.shape[4]]);
  }
  return res;
}
var maxPool3dGrad;
var init_max_pool_3d_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_3d_grad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    init_reshape();
    maxPool3dGrad = /* @__PURE__ */ op({ maxPool3dGrad_ });
  }
});
var maxPool3DGradConfig;
var init_MaxPool3D_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/MaxPool3D_grad.js"() {
    init_kernel_names();
    init_max_pool_3d_grad();
    maxPool3DGradConfig = {
      kernelName: MaxPool3D,
      inputsToSave: ["x"],
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const [x, y] = saved;
        const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
        return {
          x: () => maxPool3dGrad(dy, x, y, filterSize, strides, pad2, dimRoundingMode)
        };
      }
    };
  }
});
function maxPoolGrad_(dy, input2, output, filterSize, strides, pad2, dimRoundingMode) {
  const $dy = convertToTensor(dy, "dy", "maxPoolGrad");
  const $input = convertToTensor(input2, "input", "maxPoolGrad");
  const $output = convertToTensor(output, "output", "maxPoolGrad");
  assert($input.rank === $dy.rank, () => `Rank of input (${$input.rank}) does not match rank of dy (${$dy.rank})`);
  assert($dy.rank === 4, () => `Error in maxPoolGrad: dy must be rank 4 but got rank ${$dy.rank}.`);
  assert($input.rank === 4, () => `Error in maxPoolGrad: input must be rank 4 but got rank ${$input.rank}.`);
  checkPadOnDimRoundingMode("maxPoolGrad", pad2, dimRoundingMode);
  const inputs = { dy: $dy, input: $input, output: $output };
  const attrs = { filterSize, strides, pad: pad2, dimRoundingMode };
  return ENGINE.runKernel(MaxPoolGrad, inputs, attrs);
}
var maxPoolGrad;
var init_max_pool_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/ops/max_pool_grad.js"() {
    init_engine();
    init_kernel_names();
    init_tensor_util_env();
    init_util();
    init_conv_util();
    init_operation();
    maxPoolGrad = /* @__PURE__ */ op({ maxPoolGrad_ });
  }
});
var maxPoolGradConfig;
var init_MaxPool_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/MaxPool_grad.js"() {
    init_kernel_names();
    init_max_pool_grad();
    maxPoolGradConfig = {
      kernelName: MaxPool,
      inputsToSave: ["x"],
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const [x, y] = saved;
        const { filterSize, strides, pad: pad2 } = attrs;
        return {
          x: () => maxPoolGrad(dy, x, y, filterSize, strides, pad2)
        };
      }
    };
  }
});
var meanGradConfig;
var init_Mean_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Mean_grad.js"() {
    init_kernel_names();
    init_axis_util();
    init_div();
    init_mul();
    init_ones();
    init_reshape();
    init_util();
    meanGradConfig = {
      kernelName: Mean,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { axis } = attrs;
        const axes = parseAxisParam(axis, x.shape);
        const shapes = computeOutAndReduceShapes(x.shape, axes);
        const reduceShape = shapes[1];
        const reduceSize = sizeFromShape(reduceShape);
        const derX = () => {
          const expandedDyShape = x.shape.slice();
          axes.forEach((axis2) => {
            expandedDyShape[axis2] = 1;
          });
          const expandedDy = reshape(dy, expandedDyShape);
          const res = div2(mul5(expandedDy, ones2(x.shape, "float32")), reduceSize);
          return res;
        };
        return { x: derX };
      }
    };
  }
});
var minGradConfig;
var init_Min_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Min_grad.js"() {
    init_kernel_names();
    init_util();
    init_min_max_grad_util();
    minGradConfig = {
      kernelName: Min,
      inputsToSave: ["x"],
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const minAttrs = attrs;
        const { axis } = minAttrs;
        const [x, y] = saved;
        const origAxes = parseAxisParam(axis, x.shape);
        const minGrad = gradForMinAndMax(dy, y, x, origAxes);
        return {
          x: () => {
            return minGrad["x"]();
          }
        };
      }
    };
  }
});
var minimumGradConfig;
var init_Minimum_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Minimum_grad.js"() {
    init_kernel_names();
    init_cast();
    init_greater();
    init_less_equal();
    init_mul();
    minimumGradConfig = {
      kernelName: Minimum,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const derA = () => mul5(dy, cast(lessEqual(a, b), "float32"));
        const derB = () => mul5(dy, cast(greater(a, b), "float32"));
        return { a: derA, b: derB };
      }
    };
  }
});
var mirrorPadGradConfig;
var init_MirrorPad_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/MirrorPad_grad.js"() {
    init_kernel_names();
    init_slice();
    mirrorPadGradConfig = {
      kernelName: MirrorPad,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const x = saved[0];
        const { paddings } = attrs;
        const begin = paddings.map((p2) => p2[0]);
        return { x: () => slice(dy, begin, x.shape) };
      }
    };
  }
});
var modGradConfig;
var init_Mod_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Mod_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_div();
    init_floor();
    init_mul();
    init_neg();
    init_reshape();
    init_sum();
    modGradConfig = {
      kernelName: Mod,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            return reshape(sum2(dy, reduceAxes), a.shape);
          }
          return dy;
        };
        const derB = () => {
          const res = mul5(dy, neg(floor2(div2(a, b))));
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            return reshape(sum2(res, reduceAxes), b.shape);
          }
          return res;
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var multiplyGradConfig;
var init_Multiply_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Multiply_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_cast();
    init_mul();
    init_reshape();
    init_sum();
    multiplyGradConfig = {
      kernelName: Multiply,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          const res = mul5(dy, cast(b, "float32"));
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            return reshape(sum2(res, reduceAxes), a.shape);
          }
          return res;
        };
        const derB = () => {
          const res = mul5(dy, cast(a, "float32"));
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            return reshape(sum2(res, reduceAxes), b.shape);
          }
          return res;
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var negGradConfig;
var init_Neg_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Neg_grad.js"() {
    init_kernel_names();
    init_neg();
    negGradConfig = {
      kernelName: Neg,
      gradFunc: (dy) => {
        return { x: () => neg(dy) };
      }
    };
  }
});
var oneHotGradConfig;
var init_OneHot_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/OneHot_grad.js"() {
    init_kernel_names();
    init_zeros();
    oneHotGradConfig = {
      kernelName: OneHot,
      inputsToSave: ["indices"],
      gradFunc: (dy, saved) => {
        const indices = saved[0];
        return { indices: () => zeros(indices.shape, "float32") };
      }
    };
  }
});
var onesLikeGradConfig;
var init_OnesLike_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/OnesLike_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    onesLikeGradConfig = {
      kernelName: OnesLike,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var packGradConfig;
var init_Pack_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Pack_grad.js"() {
    init_kernel_names();
    init_unstack();
    packGradConfig = {
      kernelName: Pack,
      saveAllInputs: true,
      gradFunc: (dy, saved, attrs) => {
        const { axis } = attrs;
        const derTensors = unstack(dy, axis);
        return derTensors.map((t) => () => t);
      }
    };
  }
});
var padV2GradConfig;
var init_PadV2_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/PadV2_grad.js"() {
    init_kernel_names();
    init_slice();
    padV2GradConfig = {
      kernelName: PadV2,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const x = saved[0];
        const { paddings } = attrs;
        const begin = paddings.map((p2) => p2[0]);
        return { x: () => slice(dy, begin, x.shape) };
      }
    };
  }
});
var powGradConfig;
var init_Pow_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Pow_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_cast();
    init_greater();
    init_log2();
    init_mul();
    init_pow();
    init_reshape();
    init_scalar();
    init_sub();
    init_sum();
    init_where();
    init_zeros_like();
    powGradConfig = {
      kernelName: Pow,
      inputsToSave: ["a", "b"],
      outputsToSave: [true],
      gradFunc: (dy, saved) => {
        const [a, b, y] = saved;
        const base = a;
        const exp4 = b;
        const outShape = assertAndGetBroadcastShape(base.shape, exp4.shape);
        const derBase = () => {
          const expFloat = cast(exp4, "float32");
          let res = mul5(dy, mul5(expFloat, pow2(base, sub3(expFloat, scalar(1)))));
          const reduceAxes = getReductionAxes(base.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, base.shape);
        };
        const derExp = () => {
          const condition = greater(base, 0);
          const logBase = where(condition, log2(base), zerosLike(base));
          let res = mul5(dy, mul5(y, logBase));
          const reduceAxes = getReductionAxes(exp4.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, exp4.shape);
        };
        return { a: derBase, b: derExp };
      }
    };
  }
});
var preluGradConfig;
var init_Prelu_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Prelu_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_greater();
    init_mul();
    init_reshape();
    init_sum();
    init_where();
    init_zeros_like();
    preluGradConfig = {
      kernelName: Prelu,
      inputsToSave: ["x", "alpha"],
      gradFunc: (dy, saved) => {
        const [x, alpha] = saved;
        const mask = greater(x, 0);
        return {
          x: () => where(mask, dy, mul5(dy, alpha)),
          alpha: () => {
            let res = where(mask, zerosLike(dy), mul5(dy, x));
            const reduceAxes = getReductionAxes(alpha.shape, dy.shape);
            if (reduceAxes.length > 0) {
              res = sum2(res, reduceAxes);
            }
            return reshape(res, alpha.shape);
          }
        };
      }
    };
  }
});
function prodGradFn_(x, dy, axis) {
  const expandedYShape = x.shape.slice();
  expandedYShape[axis] = 1;
  const expandedDy = reshape(dy, expandedYShape);
  const xCumProd = cumprod(x, axis, true, false);
  const xCumRevProd = cumprod(x, axis, true, true);
  const dx = mul5(xCumProd, xCumRevProd);
  return mul5(expandedDy, dx);
}
function prodsGradFn_(x, dy, axis) {
  const xRank = x.shape.length;
  const finalProdAxis = xRank - axis.length;
  const xPermutation = backend_util_exports.getAxesPermutation(axis, xRank);
  let permutedX = x;
  if (xPermutation != null) {
    permutedX = transpose2(x, xPermutation);
  }
  const newShape = permutedX.shape.slice();
  const removedShape = newShape.splice(xRank - axis.length, axis.length);
  const endPartShape = removedShape.reduce((p2, c) => p2 * c, 1);
  newShape.push(endPartShape);
  const reshapedPermutedX = permutedX.reshape(newShape);
  let prodGrad = prodGradFn_(reshapedPermutedX, dy, finalProdAxis);
  prodGrad = prodGrad.reshape(permutedX.shape);
  if (xPermutation != null) {
    const undoPermutation = backend_util_exports.getUndoAxesPermutation(xPermutation);
    prodGrad = transpose2(prodGrad, undoPermutation);
  }
  return prodGrad;
}
var prodGradConfig;
var init_Prod_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Prod_grad.js"() {
    init_base();
    init_kernel_names();
    init_cumprod();
    init_mul();
    init_reshape();
    init_transpose();
    prodGradConfig = {
      kernelName: Prod,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { axis } = attrs;
        let axisArr = [];
        if (axis === void 0 || axis === null) {
          axisArr = x.shape.map((_, i) => i);
        } else if (typeof axis === "number") {
          axisArr = [axis];
        } else {
          axisArr = axis;
        }
        return { x: () => prodsGradFn_(x, dy, axisArr) };
      }
    };
  }
});
var divGradConfig;
var init_RealDiv_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/RealDiv_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_cast();
    init_div();
    init_mul();
    init_neg();
    init_reshape();
    init_square();
    init_sum();
    divGradConfig = {
      kernelName: RealDiv,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          const res = div2(dy, cast(b, "float32"));
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            return reshape(sum2(res, reduceAxes), a.shape);
          }
          return res;
        };
        const derB = () => {
          let res = mul5(dy, cast(a, "float32"));
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            res = reshape(sum2(res, reduceAxes), b.shape);
          }
          const tmp = square(b);
          return neg(div2(res, cast(tmp, "float32")));
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var reciprocalGradConfig;
var init_Reciprocal_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Reciprocal_grad.js"() {
    init_kernel_names();
    init_div();
    init_neg();
    init_square();
    reciprocalGradConfig = {
      kernelName: Reciprocal,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, neg(square(x))) };
      }
    };
  }
});
var relu6GradConfig;
var init_Relu6_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Relu6_grad.js"() {
    init_kernel_names();
    init_cast();
    init_less_equal();
    init_mul();
    init_step();
    relu6GradConfig = {
      kernelName: Relu6,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        const mask = mul5(lessEqual(x, 6), step(x));
        return { x: () => mul5(dy, cast(mask, "float32")) };
      }
    };
  }
});
var reluGradConfig;
var init_Relu_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Relu_grad.js"() {
    init_kernel_names();
    init_cast();
    init_mul();
    init_step();
    reluGradConfig = {
      kernelName: Relu,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(dy, cast(step(x), "float32")) };
      }
    };
  }
});
var reshapeGradConfig;
var init_Reshape_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Reshape_grad.js"() {
    init_kernel_names();
    init_reshape();
    reshapeGradConfig = {
      kernelName: Reshape,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => reshape(dy, x.shape) };
      }
    };
  }
});
var resizeBilinearGradConfig;
var init_ResizeBilinear_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ResizeBilinear_grad.js"() {
    init_engine();
    init_kernel_names();
    resizeBilinearGradConfig = {
      kernelName: ResizeBilinear,
      inputsToSave: ["images"],
      gradFunc: (dy, saved, attrs) => {
        const [images] = saved;
        const inputs = { dy, images };
        const imagesDer = () => (
          // tslint:disable-next-line: no-unnecessary-type-assertion
          ENGINE.runKernel(ResizeBilinearGrad, inputs, attrs)
        );
        return { images: imagesDer };
      }
    };
  }
});
var resizeNearestNeighborGradConfig;
var init_ResizeNearestNeighbor_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ResizeNearestNeighbor_grad.js"() {
    init_engine();
    init_kernel_names();
    resizeNearestNeighborGradConfig = {
      kernelName: ResizeNearestNeighbor,
      inputsToSave: ["images"],
      gradFunc: (dy, saved, attrs) => {
        const [images] = saved;
        const inputs = { dy, images };
        const imagesDer = () => (
          // tslint:disable-next-line: no-unnecessary-type-assertion
          ENGINE.runKernel(ResizeNearestNeighborGrad, inputs, attrs)
        );
        return { images: imagesDer };
      }
    };
  }
});
var reverseGradConfig;
var init_Reverse_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Reverse_grad.js"() {
    init_kernel_names();
    init_reverse();
    init_util();
    reverseGradConfig = {
      kernelName: Reverse,
      gradFunc: (dy, saved, attrs) => {
        const { dims } = attrs;
        const axes = parseAxisParam(dims, dy.shape);
        return { x: () => reverse(dy, axes) };
      }
    };
  }
});
var roundGradConfig;
var init_Round_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Round_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    roundGradConfig = {
      kernelName: Round,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var rsqrtGradConfig;
var init_Rsqrt_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Rsqrt_grad.js"() {
    init_kernel_names();
    init_div();
    init_mul();
    init_neg();
    init_pow();
    rsqrtGradConfig = {
      kernelName: Rsqrt,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => neg(div2(dy, mul5(pow2(x, 1.5), 2))) };
      }
    };
  }
});
var selectGradConfig;
var init_Select_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Select_grad.js"() {
    init_kernel_names();
    init_cast();
    init_logical_not();
    init_mul();
    init_zeros_like();
    selectGradConfig = {
      kernelName: Select,
      inputsToSave: ["condition"],
      gradFunc: (dy, saved) => {
        const [condition] = saved;
        return {
          // TODO(julianoks): Return null for condition gradient
          // when backprop supports it.
          condition: () => cast(zerosLike(condition), "float32"),
          t: () => mul5(dy, cast(condition, dy.dtype)),
          e: () => mul5(dy, cast(logicalNot(condition), dy.dtype))
        };
      }
    };
  }
});
var seluGradConfig;
var init_Selu_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Selu_grad.js"() {
    init_kernel_names();
    init_cast();
    init_exp();
    init_greater();
    init_mul();
    init_scalar();
    init_selu_util();
    init_where();
    seluGradConfig = {
      kernelName: Selu,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return {
          x: () => {
            const mask = greater(x, scalar(0));
            const scaleAlpha2 = scalar(SELU_SCALEALPHA);
            const scale22 = scalar(SELU_SCALE);
            const greaterThanZeroDer = mul5(dy, scale22);
            const lessEqualZeroDer = mul5(mul5(dy, scaleAlpha2), exp2(cast(x, "float32")));
            return where(mask, greaterThanZeroDer, lessEqualZeroDer);
          }
        };
      }
    };
  }
});
var sigmoidGradConfig;
var init_Sigmoid_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sigmoid_grad.js"() {
    init_kernel_names();
    init_mul();
    init_scalar();
    init_sub();
    sigmoidGradConfig = {
      kernelName: Sigmoid,
      outputsToSave: [true],
      gradFunc: (dy, saved) => {
        const [y] = saved;
        return { x: () => mul5(dy, mul5(y, sub3(scalar(1), y))) };
      }
    };
  }
});
var signGradConfig;
var init_Sign_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sign_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    signGradConfig = {
      kernelName: Sign,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var sinGradConfig;
var init_Sin_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sin_grad.js"() {
    init_kernel_names();
    init_cast();
    init_cos();
    init_mul();
    sinGradConfig = {
      kernelName: Sin,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(cos(cast(x, "float32")), dy) };
      }
    };
  }
});
var sinhGradConfig;
var init_Sinh_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sinh_grad.js"() {
    init_kernel_names();
    init_cast();
    init_cosh();
    init_mul();
    sinhGradConfig = {
      kernelName: Sinh,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(cosh(cast(x, "float32")), dy) };
      }
    };
  }
});
var sliceGradConfig;
var init_Slice_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Slice_grad.js"() {
    init_kernel_names();
    init_pad();
    init_slice_util();
    sliceGradConfig = {
      kernelName: Slice,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { begin, size } = attrs;
        const inputShape = x.shape;
        const [begin_, size_] = parseSliceParams(x, begin, size);
        const paddings = [];
        for (let i = 0; i < dy.rank; i++) {
          paddings.push([begin_[i], inputShape[i] - begin_[i] - size_[i]]);
        }
        return { x: () => pad(dy, paddings) };
      }
    };
  }
});
var softmaxGradConfig;
var init_Softmax_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Softmax_grad.js"() {
    init_kernel_names();
    init_mul();
    init_sub();
    init_sum();
    softmaxGradConfig = {
      kernelName: Softmax,
      outputsToSave: [true],
      gradFunc: (dy, saved, attrs) => {
        const [y] = saved;
        const { dim } = attrs;
        const keepDims = true;
        const dyTimesY = mul5(dy, y);
        return {
          logits: () => sub3(dyTimesY, mul5(sum2(dyTimesY, [dim], keepDims), y))
        };
      }
    };
  }
});
var softplusGradConfig;
var init_Softplus_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Softplus_grad.js"() {
    init_kernel_names();
    init_mul();
    init_sigmoid();
    softplusGradConfig = {
      kernelName: Softplus,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(dy, sigmoid(x)) };
      }
    };
  }
});
var spaceToBatchNDGradConfig;
var init_SpaceToBatchND_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/SpaceToBatchND_grad.js"() {
    init_kernel_names();
    init_batch_to_space_nd();
    spaceToBatchNDGradConfig = {
      kernelName: SpaceToBatchND,
      gradFunc: (dy, saved, attrs) => {
        const { blockShape, paddings } = attrs;
        return { x: () => batchToSpaceND(dy, blockShape, paddings) };
      }
    };
  }
});
var splitVGradConfig;
var init_SplitV_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/SplitV_grad.js"() {
    init_kernel_names();
    init_concat();
    splitVGradConfig = {
      kernelName: SplitV,
      gradFunc: (dy, saved, attrs) => {
        const { axis } = attrs;
        return { x: () => concat(dy, axis) };
      }
    };
  }
});
var sqrtGradConfig;
var init_Sqrt_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sqrt_grad.js"() {
    init_kernel_names();
    init_cast();
    init_div();
    init_mul();
    init_sqrt();
    sqrtGradConfig = {
      kernelName: Sqrt,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, mul5(sqrt(cast(x, "float32")), 2)) };
      }
    };
  }
});
var squareGradConfig;
var init_Square_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Square_grad.js"() {
    init_kernel_names();
    init_cast();
    init_mul();
    squareGradConfig = {
      kernelName: Square,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => mul5(dy, mul5(cast(x, "float32"), 2)) };
      }
    };
  }
});
var squaredDifferenceGradConfig;
var init_SquaredDifference_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js"() {
    init_kernel_names();
    init_mul();
    init_scalar();
    init_sub();
    squaredDifferenceGradConfig = {
      kernelName: SquaredDifference,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const two = scalar(2);
        const derA = () => mul5(dy, mul5(two, sub3(a, b)));
        const derB = () => mul5(dy, mul5(two, sub3(b, a)));
        return { a: derA, b: derB };
      }
    };
  }
});
var stepGradConfig;
var init_Step_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Step_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    stepGradConfig = {
      kernelName: Step,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var subGradConfig;
var init_Sub_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sub_grad.js"() {
    init_kernel_names();
    init_broadcast_util();
    init_neg();
    init_reshape();
    init_sum();
    subGradConfig = {
      kernelName: Sub,
      inputsToSave: ["a", "b"],
      gradFunc: (dy, saved) => {
        const [a, b] = saved;
        const outShape = assertAndGetBroadcastShape(a.shape, b.shape);
        const derA = () => {
          let res = dy;
          const reduceAxes = getReductionAxes(a.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(res, a.shape);
        };
        const derB = () => {
          let res = dy;
          const reduceAxes = getReductionAxes(b.shape, outShape);
          if (reduceAxes.length > 0) {
            res = sum2(res, reduceAxes);
          }
          return reshape(neg(res), b.shape);
        };
        return { a: derA, b: derB };
      }
    };
  }
});
var sumGradConfig;
var init_Sum_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Sum_grad.js"() {
    init_kernel_names();
    init_mul();
    init_ones();
    init_reshape();
    init_util();
    sumGradConfig = {
      kernelName: Sum,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const expandedDyShape = x.shape.slice();
        const { axis } = attrs;
        const axes = parseAxisParam(axis, x.shape);
        axes.forEach((axis2) => {
          expandedDyShape[axis2] = 1;
        });
        const expandedDy = reshape(dy, expandedDyShape);
        const derX = mul5(expandedDy, ones2(x.shape, "float32"));
        return { x: () => derX };
      }
    };
  }
});
var tanGradConfig;
var init_Tan_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Tan_grad.js"() {
    init_kernel_names();
    init_cos();
    init_div();
    init_square();
    tanGradConfig = {
      kernelName: Tan,
      inputsToSave: ["x"],
      gradFunc: (dy, saved) => {
        const [x] = saved;
        return { x: () => div2(dy, square(cos(x))) };
      }
    };
  }
});
var tanhGradConfig;
var init_Tanh_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Tanh_grad.js"() {
    init_kernel_names();
    init_mul();
    init_scalar();
    init_square();
    init_sub();
    tanhGradConfig = {
      kernelName: Tanh,
      outputsToSave: [true],
      gradFunc: (dy, saved) => {
        const [y] = saved;
        return { x: () => mul5(sub3(scalar(1), square(y)), dy) };
      }
    };
  }
});
var tileGradConfig;
var init_Tile_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Tile_grad.js"() {
    init_kernel_names();
    init_add();
    init_slice();
    init_zeros_like();
    tileGradConfig = {
      kernelName: Tile,
      inputsToSave: ["x"],
      gradFunc: (dy, saved, attrs) => {
        const [x] = saved;
        const { reps } = attrs;
        const derX = () => {
          let xGrad = zerosLike(x);
          if (x.rank === 1) {
            for (let i = 0; i < reps[0]; ++i) {
              xGrad = add22(xGrad, slice(dy, [i * x.shape[0]], [x.shape[0]]));
            }
          } else if (x.rank === 2) {
            for (let i = 0; i < reps[0]; ++i) {
              for (let j = 0; j < reps[1]; ++j) {
                xGrad = add22(xGrad, slice(dy, [i * x.shape[0], j * x.shape[1]], [
                  x.shape[0],
                  x.shape[1]
                ]));
              }
            }
          } else if (x.rank === 3) {
            for (let i = 0; i < reps[0]; ++i) {
              for (let j = 0; j < reps[1]; ++j) {
                for (let k = 0; k < reps[2]; ++k) {
                  xGrad = add22(xGrad, slice(dy, [i * x.shape[0], j * x.shape[1], k * x.shape[2]], [x.shape[0], x.shape[1], x.shape[2]]));
                }
              }
            }
          } else if (x.rank === 4) {
            for (let i = 0; i < reps[0]; ++i) {
              for (let j = 0; j < reps[1]; ++j) {
                for (let k = 0; k < reps[2]; ++k) {
                  for (let l = 0; l < reps[3]; ++l) {
                    xGrad = add22(xGrad, slice(dy, [
                      i * x.shape[0],
                      j * x.shape[1],
                      k * x.shape[2],
                      l * x.shape[3]
                    ], [x.shape[0], x.shape[1], x.shape[2], x.shape[3]]));
                  }
                }
              }
            }
          } else {
            throw new Error(`Gradient for tile operation is not implemented for rank-${x.rank} tensors yet.`);
          }
          return xGrad;
        };
        return { x: derX };
      }
    };
  }
});
var transposeGradConfig;
var init_Transpose_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Transpose_grad.js"() {
    init_kernel_names();
    init_axis_util();
    init_transpose();
    transposeGradConfig = {
      kernelName: Transpose,
      gradFunc: (dy, saved, attrs) => {
        const transposeAttrs = attrs;
        const { perm } = transposeAttrs;
        const undoPerm = getUndoAxesPermutation(perm);
        return { x: () => transpose2(dy, undoPerm) };
      }
    };
  }
});
var unpackGradConfig;
var init_Unpack_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/Unpack_grad.js"() {
    init_kernel_names();
    init_stack();
    unpackGradConfig = {
      kernelName: Unpack,
      gradFunc: (dy, saved, attrs) => {
        const unpackAttrs = attrs;
        const { axis } = unpackAttrs;
        return { value: () => stack(dy, axis) };
      }
    };
  }
});
function gatherDropNegatives(x, indices) {
  const zeroClippedIndices = maximum(indices, zerosLike(indices));
  const gathered = gather(x, zeroClippedIndices);
  let isPositive = greaterEqual(indices, scalar(0, "int32"));
  const numIters = gathered.rank - isPositive.rank;
  for (let i = 0; i < numIters; ++i) {
    isPositive = expandDims(isPositive, i + 1);
  }
  isPositive = logicalAnd(isPositive, ones2(gathered.shape, "bool"));
  const zeroSlice = zerosLike(gathered);
  return where(isPositive, gathered, zeroSlice);
}
var unsortedSegmentSumGradConfig;
var init_UnsortedSegmentSum_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/UnsortedSegmentSum_grad.js"() {
    init_kernel_names();
    init_expand_dims();
    init_gather();
    init_greater_equal();
    init_logical_and();
    init_maximum();
    init_ones();
    init_scalar();
    init_where();
    init_zeros_like();
    unsortedSegmentSumGradConfig = {
      kernelName: UnsortedSegmentSum,
      inputsToSave: ["segmentIds"],
      gradFunc: (dy, saved) => {
        const [segmentIds] = saved;
        const derX = () => {
          return gatherDropNegatives(dy, segmentIds);
        };
        return { x: derX };
      }
    };
  }
});
var zerosLikeGradConfig;
var init_ZerosLike_grad = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/gradients/ZerosLike_grad.js"() {
    init_kernel_names();
    init_zeros_like();
    zerosLikeGradConfig = {
      kernelName: ZerosLike,
      gradFunc: (dy) => {
        return { x: () => zerosLike(dy) };
      }
    };
  }
});
var gradConfigs;
var init_register_all_gradients = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/register_all_gradients.js"() {
    init_Abs_grad();
    init_Acos_grad();
    init_Acosh_grad();
    init_Add_grad();
    init_AddN_grad();
    init_ArgMax_grad();
    init_ArgMin_grad();
    init_Asin_grad();
    init_Asinh_grad();
    init_Atan2_grad();
    init_Atan_grad();
    init_Atanh_grad();
    init_AvgPool3D_grad();
    init_AvgPool_grad();
    init_BatchMatMul_grad();
    init_BatchToSpaceND_grad();
    init_BroadcastTo_grad();
    init_Cast_grad();
    init_Ceil_grad();
    init_ClipByValue_grad();
    init_ComplexAbs_grad();
    init_Concat_grad();
    init_Conv2D_grad();
    init_Conv2DBackpropInput_grad();
    init_Conv3D_grad();
    init_Cos_grad();
    init_Cosh_grad();
    init_Cumsum_grad();
    init_DepthwiseConv2dNative_grad();
    init_Dilation2D_grad();
    init_Elu_grad();
    init_Erf_grad();
    init_Exp_grad();
    init_ExpandDims_grad();
    init_Expm1_grad();
    init_Floor_grad();
    init_FloorDiv_grad();
    init_FusedBatchNorm_grad();
    init_GatherV2_grad();
    init_GreaterEqual_grad();
    init_Identity_grad();
    init_IsFinite_grad();
    init_IsInf_grad();
    init_IsNan_grad();
    init_LeakyRelu_grad();
    init_Log1p_grad();
    init_Log_grad();
    init_LogSoftmax_grad();
    init_LRN_grad();
    init_Max_grad();
    init_Maximum_grad();
    init_MaxPool3D_grad();
    init_MaxPool_grad();
    init_Mean_grad();
    init_Min_grad();
    init_Minimum_grad();
    init_MirrorPad_grad();
    init_Mod_grad();
    init_Multiply_grad();
    init_Neg_grad();
    init_OneHot_grad();
    init_OnesLike_grad();
    init_Pack_grad();
    init_PadV2_grad();
    init_Pow_grad();
    init_Prelu_grad();
    init_Prod_grad();
    init_RealDiv_grad();
    init_Reciprocal_grad();
    init_Relu6_grad();
    init_Relu_grad();
    init_Reshape_grad();
    init_ResizeBilinear_grad();
    init_ResizeNearestNeighbor_grad();
    init_Reverse_grad();
    init_Round_grad();
    init_Rsqrt_grad();
    init_Select_grad();
    init_Selu_grad();
    init_Sigmoid_grad();
    init_Sign_grad();
    init_Sin_grad();
    init_Sinh_grad();
    init_Slice_grad();
    init_Softmax_grad();
    init_Softplus_grad();
    init_SpaceToBatchND_grad();
    init_SplitV_grad();
    init_Sqrt_grad();
    init_Square_grad();
    init_SquaredDifference_grad();
    init_Step_grad();
    init_Sub_grad();
    init_Sum_grad();
    init_Tan_grad();
    init_Tanh_grad();
    init_Tile_grad();
    init_Transpose_grad();
    init_Unpack_grad();
    init_UnsortedSegmentSum_grad();
    init_ZerosLike_grad();
    init_kernel_registry();
    gradConfigs = [
      absGradConfig,
      acosGradConfig,
      acoshGradConfig,
      addGradConfig,
      addNGradConfig,
      argMaxGradConfig,
      argMinGradConfig,
      asinGradConfig,
      asinhGradConfig,
      atan2GradConfig,
      atanGradConfig,
      atanhGradConfig,
      avgPool3DGradConfig,
      avgPoolGradConfig,
      batchMatMulGradConfig,
      batchToSpaceNDGradConfig,
      broadcastToGradConfig,
      castGradConfig,
      ceilGradConfig,
      clipByValueGradConfig,
      complexAbsGradConfig,
      concatGradConfig,
      conv2DBackpropInputGradConfig,
      conv2DGradConfig,
      conv3DGradConfig,
      cosGradConfig,
      coshGradConfig,
      cumsumGradConfig,
      depthwiseConv2dNativeGradConfig,
      dilation2dGradConfig,
      divGradConfig,
      eluGradConfig,
      erfGradConfig,
      expGradConfig,
      expandDimsGradConfig,
      expm1GradConfig,
      floorDivGradConfig,
      floorGradConfig,
      fusedBatchNormGradConfig,
      gatherGradConfig,
      greaterEqualGradConfig,
      identityGradConfig,
      isFiniteGradConfig,
      isInfGradConfig,
      isNanGradConfig,
      leakyReluGradConfig,
      log1pGradConfig,
      logGradConfig,
      logSoftmaxGradConfig,
      lrnGradConfig,
      maxGradConfig,
      maxGradConfig,
      maximumGradConfig,
      maxPool3DGradConfig,
      maxPoolGradConfig,
      meanGradConfig,
      minGradConfig,
      minimumGradConfig,
      mirrorPadGradConfig,
      modGradConfig,
      multiplyGradConfig,
      negGradConfig,
      oneHotGradConfig,
      onesLikeGradConfig,
      packGradConfig,
      padV2GradConfig,
      padV2GradConfig,
      powGradConfig,
      preluGradConfig,
      prodGradConfig,
      reciprocalGradConfig,
      relu6GradConfig,
      reluGradConfig,
      reshapeGradConfig,
      resizeBilinearGradConfig,
      resizeNearestNeighborGradConfig,
      reverseGradConfig,
      roundGradConfig,
      rsqrtGradConfig,
      selectGradConfig,
      seluGradConfig,
      sigmoidGradConfig,
      signGradConfig,
      sinGradConfig,
      sinhGradConfig,
      sliceGradConfig,
      softmaxGradConfig,
      softplusGradConfig,
      spaceToBatchNDGradConfig,
      spaceToBatchNDGradConfig,
      splitVGradConfig,
      splitVGradConfig,
      sqrtGradConfig,
      squaredDifferenceGradConfig,
      squareGradConfig,
      stepGradConfig,
      subGradConfig,
      sumGradConfig,
      tanGradConfig,
      tanhGradConfig,
      tileGradConfig,
      transposeGradConfig,
      unpackGradConfig,
      unsortedSegmentSumGradConfig,
      zerosLikeGradConfig
    ];
    for (const gradientConfig of gradConfigs) {
      registerGradient(gradientConfig);
    }
  }
});
var init_abs2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/abs.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.abs = function() {
      this.throwIfDisposed();
      return abs(this);
    };
  }
});
var init_acos2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/acos.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.acos = function() {
      this.throwIfDisposed();
      return acos(this);
    };
  }
});
var init_acosh2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/acosh.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.acosh = function() {
      this.throwIfDisposed();
      return acosh(this);
    };
  }
});
var init_add2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/add.js"() {
    init_add();
    init_tensor();
    getGlobalTensorClass().prototype.add = function(b) {
      this.throwIfDisposed();
      return add22(this, b);
    };
  }
});
var init_all2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/all.js"() {
    init_all();
    init_tensor();
    getGlobalTensorClass().prototype.all = function(axis, keepDims) {
      this.throwIfDisposed();
      return all(this, axis, keepDims);
    };
  }
});
var init_any2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/any.js"() {
    init_any();
    init_tensor();
    getGlobalTensorClass().prototype.any = function(axis, keepDims) {
      this.throwIfDisposed();
      return any(this, axis, keepDims);
    };
  }
});
var init_arg_max2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/arg_max.js"() {
    init_arg_max();
    init_tensor();
    getGlobalTensorClass().prototype.argMax = function(axis) {
      this.throwIfDisposed();
      return argMax(this, axis);
    };
  }
});
var init_arg_min2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/arg_min.js"() {
    init_arg_min();
    init_tensor();
    getGlobalTensorClass().prototype.argMin = function(axis) {
      this.throwIfDisposed();
      return argMin(this, axis);
    };
  }
});
var init_as_scalar = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as_scalar.js"() {
    init_reshape();
    init_tensor();
    init_util();
    getGlobalTensorClass().prototype.asScalar = function() {
      this.throwIfDisposed();
      assert(this.size === 1, () => "The array must have only 1 element.");
      return reshape(this, []);
    };
  }
});
var init_as_type = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as_type.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.asType = function(dtype) {
      this.throwIfDisposed();
      return cast(this, dtype);
    };
  }
});
var init_as1d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as1d.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.as1D = function() {
      this.throwIfDisposed();
      return reshape(this, [this.size]);
    };
  }
});
var init_as2d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as2d.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.as2D = function(rows, columns) {
      this.throwIfDisposed();
      return reshape(this, [rows, columns]);
    };
  }
});
var init_as3d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as3d.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.as3D = function(rows, columns, depth) {
      this.throwIfDisposed();
      return reshape(this, [rows, columns, depth]);
    };
  }
});
var init_as4d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as4d.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.as4D = function(rows, columns, depth, depth2) {
      this.throwIfDisposed();
      return reshape(this, [rows, columns, depth, depth2]);
    };
  }
});
var init_as5d = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/as5d.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.as5D = function(rows, columns, depth, depth2, depth3) {
      this.throwIfDisposed();
      return reshape(this, [rows, columns, depth, depth2, depth3]);
    };
  }
});
var init_asin2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/asin.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.asin = function() {
      this.throwIfDisposed();
      return asin(this);
    };
  }
});
var init_asinh2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/asinh.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.asinh = function() {
      this.throwIfDisposed();
      return asinh(this);
    };
  }
});
var init_atan3 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atan.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.atan = function() {
      this.throwIfDisposed();
      return atan(this);
    };
  }
});
var init_atan22 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atan2.js"() {
    init_atan2();
    init_tensor();
    getGlobalTensorClass().prototype.atan2 = function(b) {
      this.throwIfDisposed();
      return atan2(this, b);
    };
  }
});
var init_atanh2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/atanh.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.atanh = function() {
      this.throwIfDisposed();
      return atanh(this);
    };
  }
});
var init_avg_pool2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/avg_pool.js"() {
    init_avg_pool();
    init_tensor();
    getGlobalTensorClass().prototype.avgPool = function(filterSize, strides, pad2, dimRoundingMode) {
      this.throwIfDisposed();
      return avgPool(this, filterSize, strides, pad2, dimRoundingMode);
    };
  }
});
var init_batch_to_space_nd2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/batch_to_space_nd.js"() {
    init_batch_to_space_nd();
    init_tensor();
    getGlobalTensorClass().prototype.batchToSpaceND = function(blockShape, crops) {
      this.throwIfDisposed();
      return batchToSpaceND(this, blockShape, crops);
    };
  }
});
var init_batchnorm2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/batchnorm.js"() {
    init_batchnorm();
    init_tensor();
    getGlobalTensorClass().prototype.batchNorm = function(mean3, variance, offset, scale22, varianceEpsilon) {
      this.throwIfDisposed();
      return batchNorm(this, mean3, variance, offset, scale22, varianceEpsilon);
    };
  }
});
var init_broadcast_to2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/broadcast_to.js"() {
    init_broadcast_to();
    init_tensor();
    getGlobalTensorClass().prototype.broadcastTo = function(shape) {
      this.throwIfDisposed();
      return broadcastTo(this, shape);
    };
  }
});
var init_cast2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cast.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.cast = function(dtype) {
      this.throwIfDisposed();
      return cast(this, dtype);
    };
  }
});
var init_ceil2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ceil.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.ceil = function() {
      this.throwIfDisposed();
      return ceil2(this);
    };
  }
});
var init_clip_by_value2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/clip_by_value.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.clipByValue = function(min5, max5) {
      this.throwIfDisposed();
      return clipByValue(this, min5, max5);
    };
  }
});
var init_concat2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/concat.js"() {
    init_concat();
    init_tensor();
    getGlobalTensorClass().prototype.concat = function(x, axis) {
      this.throwIfDisposed();
      if (x instanceof Tensor) {
        x = [x];
      }
      return concat([this, ...x], axis);
    };
  }
});
var init_conv1d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv1d.js"() {
    init_conv1d();
    init_tensor();
    getGlobalTensorClass().prototype.conv1d = function(filter, stride, pad2, dataFormat, dilation, dimRoundingMode) {
      this.throwIfDisposed();
      return conv1d(this, filter, stride, pad2, dataFormat, dilation, dimRoundingMode);
    };
  }
});
var init_conv2d_transpose2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv2d_transpose.js"() {
    init_conv2d_transpose();
    init_tensor();
    getGlobalTensorClass().prototype.conv2dTranspose = function(filter, outputShape, strides, pad2, dimRoundingMode) {
      this.throwIfDisposed();
      return conv2dTranspose(this, filter, outputShape, strides, pad2, dimRoundingMode);
    };
  }
});
var init_conv2d3 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/conv2d.js"() {
    init_conv2d();
    init_tensor();
    getGlobalTensorClass().prototype.conv2d = function(filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      this.throwIfDisposed();
      return conv2d(this, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
    };
  }
});
var init_cos2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cos.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.cos = function() {
      this.throwIfDisposed();
      return cos(this);
    };
  }
});
var init_cosh2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cosh.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.cosh = function() {
      this.throwIfDisposed();
      return cosh(this);
    };
  }
});
var init_cumprod2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cumprod.js"() {
    init_cumprod();
    init_tensor();
    getGlobalTensorClass().prototype.cumprod = function(axis, exclusive, reverse4) {
      this.throwIfDisposed();
      return cumprod(this, axis, exclusive, reverse4);
    };
  }
});
var init_cumsum2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/cumsum.js"() {
    init_cumsum();
    init_tensor();
    getGlobalTensorClass().prototype.cumsum = function(axis, exclusive, reverse4) {
      this.throwIfDisposed();
      return cumsum(this, axis, exclusive, reverse4);
    };
  }
});
var init_depth_to_space2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/depth_to_space.js"() {
    init_depth_to_space();
    init_tensor();
    getGlobalTensorClass().prototype.depthToSpace = function(blockSize, dataFormat) {
      this.throwIfDisposed();
      return depthToSpace(this, blockSize, dataFormat);
    };
  }
});
var init_depthwise_conv2d3 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/depthwise_conv2d.js"() {
    init_depthwise_conv2d();
    init_tensor();
    getGlobalTensorClass().prototype.depthwiseConv2d = function(filter, strides, pad2, dataFormat, dilations, dimRoundingMode) {
      this.throwIfDisposed();
      return depthwiseConv2d(this, filter, strides, pad2, dataFormat, dilations, dimRoundingMode);
    };
  }
});
var init_dilation2d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/dilation2d.js"() {
    init_dilation2d();
    init_tensor();
    getGlobalTensorClass().prototype.dilation2d = function(filter, strides, pad2, dilations, dataFormat) {
      this.throwIfDisposed();
      return dilation2d(this, filter, strides, pad2, dilations, dataFormat);
    };
  }
});
var init_div_no_nan2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/div_no_nan.js"() {
    init_div_no_nan();
    init_tensor();
    getGlobalTensorClass().prototype.divNoNan = function(b) {
      this.throwIfDisposed();
      return divNoNan(this, b);
    };
  }
});
var init_div2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/div.js"() {
    init_div();
    init_tensor();
    getGlobalTensorClass().prototype.div = function(b) {
      this.throwIfDisposed();
      return div2(this, b);
    };
  }
});
var init_dot2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/dot.js"() {
    init_dot();
    init_tensor();
    getGlobalTensorClass().prototype.dot = function(b) {
      this.throwIfDisposed();
      return dot5(this, b);
    };
  }
});
var init_elu2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/elu.js"() {
    init_elu();
    init_tensor();
    getGlobalTensorClass().prototype.elu = function() {
      this.throwIfDisposed();
      return elu(this);
    };
  }
});
var init_equal2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/equal.js"() {
    init_equal();
    init_tensor();
    getGlobalTensorClass().prototype.equal = function(b) {
      this.throwIfDisposed();
      return equal(this, b);
    };
  }
});
var init_erf2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/erf.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.erf = function() {
      this.throwIfDisposed();
      return erf(this);
    };
  }
});
var init_euclidean_norm2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/euclidean_norm.js"() {
    init_euclidean_norm();
    init_tensor();
    getGlobalTensorClass().prototype.euclideanNorm = function(axis, keepDims) {
      this.throwIfDisposed();
      return euclideanNorm(this, axis, keepDims);
    };
  }
});
var init_exp2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/exp.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.exp = function() {
      this.throwIfDisposed();
      return exp2(this);
    };
  }
});
var init_expand_dims2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/expand_dims.js"() {
    init_expand_dims();
    init_tensor();
    getGlobalTensorClass().prototype.expandDims = function(axis) {
      this.throwIfDisposed();
      return expandDims(this, axis);
    };
  }
});
var init_expm12 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/expm1.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.expm1 = function() {
      this.throwIfDisposed();
      return expm1(this);
    };
  }
});
var init_fft2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/fft.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.fft = function() {
      this.throwIfDisposed();
      return fft(this);
    };
  }
});
var init_flatten = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/flatten.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.flatten = function() {
      this.throwIfDisposed();
      return reshape(this, [this.size]);
    };
  }
});
var init_floor2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/floor.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.floor = function() {
      this.throwIfDisposed();
      return floor2(this);
    };
  }
});
var init_floorDiv2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/floorDiv.js"() {
    init_floorDiv();
    init_tensor();
    getGlobalTensorClass().prototype.floorDiv = function(b) {
      this.throwIfDisposed();
      return floorDiv(this, b);
    };
  }
});
var init_gather2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/gather.js"() {
    init_gather();
    init_tensor();
    getGlobalTensorClass().prototype.gather = function(indices, axis) {
      this.throwIfDisposed();
      return gather(this, indices, axis);
    };
  }
});
var init_greater_equal2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/greater_equal.js"() {
    init_greater_equal();
    init_tensor();
    getGlobalTensorClass().prototype.greaterEqual = function(b) {
      this.throwIfDisposed();
      return greaterEqual(this, b);
    };
  }
});
var init_greater2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/greater.js"() {
    init_greater();
    init_tensor();
    getGlobalTensorClass().prototype.greater = function(b) {
      this.throwIfDisposed();
      return greater(this, b);
    };
  }
});
var init_ifft2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ifft.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.ifft = function() {
      this.throwIfDisposed();
      return ifft(this);
    };
  }
});
var init_irfft2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/irfft.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.irfft = function() {
      this.throwIfDisposed();
      return irfft(this);
    };
  }
});
var init_is_finite2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_finite.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.isFinite = function() {
      this.throwIfDisposed();
      return isFinite2(this);
    };
  }
});
var init_is_inf2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_inf.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.isInf = function() {
      this.throwIfDisposed();
      return isInf(this);
    };
  }
});
var init_is_nan2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/is_nan.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.isNaN = function() {
      this.throwIfDisposed();
      return isNaN2(this);
    };
  }
});
var init_leaky_relu2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/leaky_relu.js"() {
    init_leaky_relu();
    init_tensor();
    getGlobalTensorClass().prototype.leakyRelu = function(alpha) {
      this.throwIfDisposed();
      return leakyRelu(this, alpha);
    };
  }
});
var init_less_equal2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/less_equal.js"() {
    init_less_equal();
    init_tensor();
    getGlobalTensorClass().prototype.lessEqual = function(b) {
      this.throwIfDisposed();
      return lessEqual(this, b);
    };
  }
});
var init_less2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/less.js"() {
    init_less();
    init_tensor();
    getGlobalTensorClass().prototype.less = function(b) {
      this.throwIfDisposed();
      return less(this, b);
    };
  }
});
var init_local_response_normalization2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/local_response_normalization.js"() {
    init_local_response_normalization();
    init_tensor();
    getGlobalTensorClass().prototype.localResponseNormalization = function(depthRadius, bias, alpha, beta) {
      this.throwIfDisposed();
      return localResponseNormalization(this, depthRadius, bias, alpha, beta);
    };
  }
});
var init_log_sigmoid2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_sigmoid.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.logSigmoid = function() {
      this.throwIfDisposed();
      return logSigmoid(this);
    };
  }
});
var init_log_softmax2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_softmax.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.logSoftmax = function(axis) {
      this.throwIfDisposed();
      return logSoftmax(this, axis);
    };
  }
});
var init_log_sum_exp2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log_sum_exp.js"() {
    init_log_sum_exp();
    init_tensor();
    getGlobalTensorClass().prototype.logSumExp = function(axis, keepDims) {
      this.throwIfDisposed();
      return logSumExp(this, axis, keepDims);
    };
  }
});
var init_log3 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.log = function() {
      this.throwIfDisposed();
      return log2(this);
    };
  }
});
var init_log1p2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/log1p.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.log1p = function() {
      this.throwIfDisposed();
      return log1p(this);
    };
  }
});
var init_logical_and2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_and.js"() {
    init_logical_and();
    init_tensor();
    getGlobalTensorClass().prototype.logicalAnd = function(b) {
      this.throwIfDisposed();
      return logicalAnd(this, b);
    };
  }
});
var init_logical_not2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_not.js"() {
    init_logical_not();
    init_tensor();
    getGlobalTensorClass().prototype.logicalNot = function() {
      this.throwIfDisposed();
      return logicalNot(this);
    };
  }
});
var init_logical_or2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_or.js"() {
    init_logical_or();
    init_tensor();
    getGlobalTensorClass().prototype.logicalOr = function(b) {
      this.throwIfDisposed();
      return logicalOr(this, b);
    };
  }
});
var init_logical_xor2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/logical_xor.js"() {
    init_logical_xor();
    init_tensor();
    getGlobalTensorClass().prototype.logicalXor = function(b) {
      this.throwIfDisposed();
      return logicalXor(this, b);
    };
  }
});
var init_mat_mul3 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mat_mul.js"() {
    init_mat_mul();
    init_tensor();
    getGlobalTensorClass().prototype.matMul = function(b, transposeA, transposeB) {
      this.throwIfDisposed();
      return matMul(this, b, transposeA, transposeB);
    };
  }
});
var init_max_pool2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/max_pool.js"() {
    init_max_pool();
    init_tensor();
    getGlobalTensorClass().prototype.maxPool = function(filterSize, strides, pad2, dimRoundingMode) {
      this.throwIfDisposed();
      return maxPool(this, filterSize, strides, pad2, dimRoundingMode);
    };
  }
});
var init_max2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/max.js"() {
    init_max();
    init_tensor();
    getGlobalTensorClass().prototype.max = function(axis, keepDims) {
      this.throwIfDisposed();
      return max2(this, axis, keepDims);
    };
  }
});
var init_maximum2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/maximum.js"() {
    init_maximum();
    init_tensor();
    getGlobalTensorClass().prototype.maximum = function(b) {
      this.throwIfDisposed();
      return maximum(this, b);
    };
  }
});
var init_mean2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mean.js"() {
    init_mean();
    init_tensor();
    getGlobalTensorClass().prototype.mean = function(axis, keepDims) {
      this.throwIfDisposed();
      return mean(this, axis, keepDims);
    };
  }
});
var init_min2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/min.js"() {
    init_min();
    init_tensor();
    getGlobalTensorClass().prototype.min = function(axis, keepDims) {
      this.throwIfDisposed();
      return min2(this, axis, keepDims);
    };
  }
});
var init_minimum2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/minimum.js"() {
    init_minimum();
    init_tensor();
    getGlobalTensorClass().prototype.minimum = function(b) {
      this.throwIfDisposed();
      return minimum(this, b);
    };
  }
});
var init_mirror_pad2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mirror_pad.js"() {
    init_mirror_pad();
    init_tensor();
    getGlobalTensorClass().prototype.mirrorPad = function(paddings, mode) {
      this.throwIfDisposed();
      return mirrorPad(this, paddings, mode);
    };
  }
});
var init_mod2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mod.js"() {
    init_mod();
    init_tensor();
    getGlobalTensorClass().prototype.mod = function(b) {
      this.throwIfDisposed();
      return mod(this, b);
    };
  }
});
var init_mul2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/mul.js"() {
    init_mul();
    init_tensor();
    getGlobalTensorClass().prototype.mul = function(b) {
      this.throwIfDisposed();
      return mul5(this, b);
    };
  }
});
var init_neg2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/neg.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.neg = function() {
      this.throwIfDisposed();
      return neg(this);
    };
  }
});
var init_norm2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/norm.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.norm = function(ord, axis, keepDims) {
      this.throwIfDisposed();
      return norm(this, ord, axis, keepDims);
    };
  }
});
var init_not_equal2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/not_equal.js"() {
    init_not_equal();
    init_tensor();
    getGlobalTensorClass().prototype.notEqual = function(b) {
      this.throwIfDisposed();
      return notEqual(this, b);
    };
  }
});
var init_one_hot2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/one_hot.js"() {
    init_one_hot();
    init_tensor();
    getGlobalTensorClass().prototype.oneHot = function(depth, onValue = 1, offValue = 0) {
      this.throwIfDisposed();
      return oneHot(this, depth, onValue, offValue);
    };
  }
});
var init_ones_like2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/ones_like.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.onesLike = function() {
      this.throwIfDisposed();
      return onesLike(this);
    };
  }
});
var init_pad2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pad.js"() {
    init_pad();
    init_tensor();
    getGlobalTensorClass().prototype.pad = function(paddings, constantValue) {
      this.throwIfDisposed();
      return pad(this, paddings, constantValue);
    };
  }
});
var init_pool2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pool.js"() {
    init_pool();
    init_tensor();
    getGlobalTensorClass().prototype.pool = function(windowShape, poolingType, padding, dilationRate, strides, dimRoundingMode) {
      this.throwIfDisposed();
      return pool(this, windowShape, poolingType, padding, dilationRate, strides, dimRoundingMode);
    };
  }
});
var init_pow2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/pow.js"() {
    init_pow();
    init_tensor();
    getGlobalTensorClass().prototype.pow = function(exp4) {
      this.throwIfDisposed();
      return pow2(this, exp4);
    };
  }
});
var init_prelu2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/prelu.js"() {
    init_prelu();
    init_tensor();
    getGlobalTensorClass().prototype.prelu = function(alpha) {
      this.throwIfDisposed();
      return prelu(this, alpha);
    };
  }
});
var init_prod2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/prod.js"() {
    init_prod();
    init_tensor();
    getGlobalTensorClass().prototype.prod = function(axis, keepDims) {
      this.throwIfDisposed();
      return prod(this, axis, keepDims);
    };
  }
});
var init_reciprocal2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reciprocal.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.reciprocal = function() {
      this.throwIfDisposed();
      return reciprocal(this);
    };
  }
});
var init_relu2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/relu.js"() {
    init_relu();
    init_tensor();
    getGlobalTensorClass().prototype.relu = function() {
      this.throwIfDisposed();
      return relu(this);
    };
  }
});
var init_relu62 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/relu6.js"() {
    init_relu6();
    init_tensor();
    getGlobalTensorClass().prototype.relu6 = function() {
      this.throwIfDisposed();
      return relu6(this);
    };
  }
});
var init_reshape_as = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reshape_as.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.reshapeAs = function(x) {
      this.throwIfDisposed();
      return reshape(this, x.shape);
    };
  }
});
var init_reshape2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reshape.js"() {
    init_reshape();
    init_tensor();
    getGlobalTensorClass().prototype.reshape = function(shape) {
      this.throwIfDisposed();
      return reshape(this, shape);
    };
  }
});
var init_resize_bilinear2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/resize_bilinear.js"() {
    init_resize_bilinear();
    init_tensor();
    getGlobalTensorClass().prototype.resizeBilinear = function(newShape2D, alignCorners, halfPixelCenters) {
      this.throwIfDisposed();
      return resizeBilinear(this, newShape2D, alignCorners, halfPixelCenters);
    };
  }
});
var init_resize_nearest_neighbor2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/resize_nearest_neighbor.js"() {
    init_resize_nearest_neighbor();
    init_tensor();
    getGlobalTensorClass().prototype.resizeNearestNeighbor = function(newShape2D, alignCorners, halfFloatCenters) {
      this.throwIfDisposed();
      return resizeNearestNeighbor(this, newShape2D, alignCorners, halfFloatCenters);
    };
  }
});
var init_reverse2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/reverse.js"() {
    init_reverse();
    init_tensor();
    getGlobalTensorClass().prototype.reverse = function(axis) {
      this.throwIfDisposed();
      return reverse(this, axis);
    };
  }
});
var init_rfft2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/rfft.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.rfft = function() {
      this.throwIfDisposed();
      return rfft(this);
    };
  }
});
var init_round2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/round.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.round = function() {
      this.throwIfDisposed();
      return round22(this);
    };
  }
});
var init_rsqrt2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/rsqrt.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.rsqrt = function() {
      this.throwIfDisposed();
      return rsqrt(this);
    };
  }
});
var init_selu2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/selu.js"() {
    init_selu();
    init_tensor();
    getGlobalTensorClass().prototype.selu = function() {
      this.throwIfDisposed();
      return selu(this);
    };
  }
});
var init_separable_conv2d2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/separable_conv2d.js"() {
    init_separable_conv2d();
    init_tensor();
    getGlobalTensorClass().prototype.separableConv2d = function(depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat) {
      this.throwIfDisposed();
      return separableConv2d(this, depthwiseFilter, pointwiseFilter, strides, pad2, dilation, dataFormat);
    };
  }
});
var init_sigmoid2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sigmoid.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.sigmoid = function() {
      this.throwIfDisposed();
      return sigmoid(this);
    };
  }
});
var init_sign2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sign.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.sign = function() {
      this.throwIfDisposed();
      return sign(this);
    };
  }
});
var init_sin2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sin.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.sin = function() {
      this.throwIfDisposed();
      return sin(this);
    };
  }
});
var init_sinh2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sinh.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.sinh = function() {
      this.throwIfDisposed();
      return sinh(this);
    };
  }
});
var init_slice2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/slice.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.slice = function(begin, size) {
      this.throwIfDisposed();
      return slice(this, begin, size);
    };
  }
});
var init_softmax2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/softmax.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.softmax = function(dim) {
      this.throwIfDisposed();
      return softmax(this, dim);
    };
  }
});
var init_softplus2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/softplus.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.softplus = function() {
      this.throwIfDisposed();
      return softplus(this);
    };
  }
});
var init_space_to_batch_nd2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/space_to_batch_nd.js"() {
    init_space_to_batch_nd();
    init_tensor();
    getGlobalTensorClass().prototype.spaceToBatchND = function(blockShape, paddings) {
      this.throwIfDisposed();
      return spaceToBatchND(this, blockShape, paddings);
    };
  }
});
var init_split2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/split.js"() {
    init_split();
    init_tensor();
    getGlobalTensorClass().prototype.split = function(numOrSizeSplits, axis) {
      this.throwIfDisposed();
      return split(this, numOrSizeSplits, axis);
    };
  }
});
var init_sqrt2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sqrt.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.sqrt = function() {
      this.throwIfDisposed();
      return sqrt(this);
    };
  }
});
var init_square2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/square.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.square = function() {
      this.throwIfDisposed();
      return square(this);
    };
  }
});
var init_squared_difference2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js"() {
    init_squared_difference();
    init_tensor();
    getGlobalTensorClass().prototype.squaredDifference = function(b) {
      this.throwIfDisposed();
      return squaredDifference(this, b);
    };
  }
});
var init_squeeze2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/squeeze.js"() {
    init_squeeze();
    init_tensor();
    getGlobalTensorClass().prototype.squeeze = function(axis) {
      this.throwIfDisposed();
      return squeeze(this, axis);
    };
  }
});
var init_stack2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/stack.js"() {
    init_stack();
    init_tensor();
    getGlobalTensorClass().prototype.stack = function(x, axis) {
      this.throwIfDisposed();
      const tensorsToBeStacked = x instanceof Tensor ? [this, x] : [this, ...x];
      return stack(tensorsToBeStacked, axis);
    };
  }
});
var init_step2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/step.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.step = function(alpha) {
      this.throwIfDisposed();
      return step(this, alpha);
    };
  }
});
var init_strided_slice2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/strided_slice.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.stridedSlice = function(begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask) {
      this.throwIfDisposed();
      return stridedSlice(this, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
    };
  }
});
var init_sub2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sub.js"() {
    init_sub();
    init_tensor();
    getGlobalTensorClass().prototype.sub = function(b) {
      this.throwIfDisposed();
      return sub3(this, b);
    };
  }
});
var init_sum2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/sum.js"() {
    init_sum();
    init_tensor();
    getGlobalTensorClass().prototype.sum = function(axis, keepDims) {
      this.throwIfDisposed();
      return sum2(this, axis, keepDims);
    };
  }
});
var init_tan2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tan.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.tan = function() {
      this.throwIfDisposed();
      return tan(this);
    };
  }
});
var init_tanh2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tanh.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.tanh = function() {
      this.throwIfDisposed();
      return tanh2(this);
    };
  }
});
var init_tile2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/tile.js"() {
    init_tile();
    init_tensor();
    getGlobalTensorClass().prototype.tile = function(reps) {
      this.throwIfDisposed();
      return tile(this, reps);
    };
  }
});
var init_to_bool = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_bool.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.toBool = function() {
      this.throwIfDisposed();
      return cast(this, "bool");
    };
  }
});
var init_to_float = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_float.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.toFloat = function() {
      this.throwIfDisposed();
      return cast(this, "float32");
    };
  }
});
var init_to_int = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/to_int.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.toInt = function() {
      this.throwIfDisposed();
      return cast(this, "int32");
    };
  }
});
var init_topk2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/topk.js"() {
    init_topk();
    init_tensor();
    getGlobalTensorClass().prototype.topk = function(k, sorted) {
      this.throwIfDisposed();
      return topk(this, k, sorted);
    };
  }
});
var init_transpose2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/transpose.js"() {
    init_transpose();
    init_tensor();
    getGlobalTensorClass().prototype.transpose = function(perm) {
      this.throwIfDisposed();
      return transpose2(this, perm);
    };
  }
});
var init_unique2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unique.js"() {
    init_unique();
    init_tensor();
    getGlobalTensorClass().prototype.unique = function(axis) {
      this.throwIfDisposed();
      return unique(this, axis);
    };
  }
});
var init_unsorted_segment_sum2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unsorted_segment_sum.js"() {
    init_unsorted_segment_sum();
    init_tensor();
    getGlobalTensorClass().prototype.unsortedSegmentSum = function(segmentIds, numSegments) {
      this.throwIfDisposed();
      return unsortedSegmentSum(this, segmentIds, numSegments);
    };
  }
});
var init_unstack2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/unstack.js"() {
    init_unstack();
    init_tensor();
    getGlobalTensorClass().prototype.unstack = function(axis) {
      this.throwIfDisposed();
      return unstack(this, axis);
    };
  }
});
var init_where2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/where.js"() {
    init_where();
    init_tensor();
    getGlobalTensorClass().prototype.where = function(condition, x) {
      this.throwIfDisposed();
      return where(condition, this, x);
    };
  }
});
var init_zeros_like2 = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/zeros_like.js"() {
    init_ops();
    init_tensor();
    getGlobalTensorClass().prototype.zerosLike = function() {
      this.throwIfDisposed();
      return zerosLike(this);
    };
  }
});
var init_register_all_chained_ops = __esm({
  "node_modules/@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js"() {
    init_abs2();
    init_acos2();
    init_acosh2();
    init_add2();
    init_all2();
    init_any2();
    init_arg_max2();
    init_arg_min2();
    init_as_scalar();
    init_as_type();
    init_as1d();
    init_as2d();
    init_as3d();
    init_as4d();
    init_as5d();
    init_asin2();
    init_asinh2();
    init_atan3();
    init_atan22();
    init_atanh2();
    init_avg_pool2();
    init_batch_to_space_nd2();
    init_batchnorm2();
    init_broadcast_to2();
    init_cast2();
    init_ceil2();
    init_clip_by_value2();
    init_concat2();
    init_conv1d2();
    init_conv2d_transpose2();
    init_conv2d3();
    init_cos2();
    init_cosh2();
    init_cumprod2();
    init_cumsum2();
    init_depth_to_space2();
    init_depthwise_conv2d3();
    init_dilation2d2();
    init_div_no_nan2();
    init_div2();
    init_dot2();
    init_elu2();
    init_equal2();
    init_erf2();
    init_euclidean_norm2();
    init_exp2();
    init_expand_dims2();
    init_expm12();
    init_fft2();
    init_flatten();
    init_floor2();
    init_floorDiv2();
    init_gather2();
    init_greater_equal2();
    init_greater2();
    init_ifft2();
    init_irfft2();
    init_is_finite2();
    init_is_inf2();
    init_is_nan2();
    init_leaky_relu2();
    init_less_equal2();
    init_less2();
    init_local_response_normalization2();
    init_log_sigmoid2();
    init_log_softmax2();
    init_log_sum_exp2();
    init_log3();
    init_log1p2();
    init_logical_and2();
    init_logical_not2();
    init_logical_or2();
    init_logical_xor2();
    init_mat_mul3();
    init_max_pool2();
    init_max2();
    init_maximum2();
    init_mean2();
    init_min2();
    init_minimum2();
    init_mirror_pad2();
    init_mod2();
    init_mul2();
    init_neg2();
    init_norm2();
    init_not_equal2();
    init_one_hot2();
    init_ones_like2();
    init_pad2();
    init_pool2();
    init_pow2();
    init_prelu2();
    init_prod2();
    init_reciprocal2();
    init_relu2();
    init_relu62();
    init_reshape_as();
    init_reshape2();
    init_resize_bilinear2();
    init_resize_nearest_neighbor2();
    init_reverse2();
    init_rfft2();
    init_round2();
    init_rsqrt2();
    init_selu2();
    init_separable_conv2d2();
    init_sigmoid2();
    init_sign2();
    init_sin2();
    init_sinh2();
    init_slice2();
    init_softmax2();
    init_softplus2();
    init_space_to_batch_nd2();
    init_split2();
    init_sqrt2();
    init_square2();
    init_squared_difference2();
    init_squeeze2();
    init_stack2();
    init_step2();
    init_strided_slice2();
    init_sub2();
    init_sum2();
    init_tan2();
    init_tanh2();
    init_tile2();
    init_to_bool();
    init_to_float();
    init_to_int();
    init_topk2();
    init_transpose2();
    init_unique2();
    init_unsorted_segment_sum2();
    init_unstack2();
    init_where2();
    init_zeros_like2();
  }
});
var AttributeError;
var RuntimeError;
var ValueError;
var NotImplementedError;
var AssertionError;
var init_errors = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/errors.js"() {
    AttributeError = class extends Error {
      constructor(message) {
        super(message);
        Object.setPrototypeOf(this, AttributeError.prototype);
      }
    };
    RuntimeError = class extends Error {
      constructor(message) {
        super(message);
        Object.setPrototypeOf(this, RuntimeError.prototype);
      }
    };
    ValueError = class extends Error {
      constructor(message) {
        super(message);
        Object.setPrototypeOf(this, ValueError.prototype);
      }
    };
    NotImplementedError = class extends Error {
      constructor(message) {
        super(message);
        Object.setPrototypeOf(this, NotImplementedError.prototype);
      }
    };
    AssertionError = class extends Error {
      constructor(message) {
        super(message);
        Object.setPrototypeOf(this, AssertionError.prototype);
      }
    };
  }
});
var LruCache;
var init_executor_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/executor_utils.js"() {
    LruCache = class {
      constructor(maxEntries) {
        this.maxEntries = maxEntries || 100;
        this.cache = /* @__PURE__ */ new Map();
      }
      /**
       * Get the entry for the key and mark it as used recently.
       */
      get(key) {
        let entry;
        if (this.cache.has(key)) {
          entry = this.cache.get(key);
          this.cache.delete(key);
          this.cache.set(key, entry);
        }
        return entry;
      }
      /**
       * Put the entry into the cache. If the key already existed, mark the key as
       * used recently.
       */
      put(key, value) {
        if (this.cache.has(key)) {
          this.cache.delete(key);
        } else if (this.cache.size >= this.maxEntries) {
          const keyToDelete = this.cache.keys().next().value;
          this.cache.delete(keyToDelete);
        }
        this.cache.set(key, value);
      }
      /**
       * Get the MaxEntries of the cache.
       */
      getMaxEntries() {
        return this.maxEntries;
      }
      /**
       * Set the MaxEntries of the cache. If the maxEntries is decreased, reduce
       * entries in the cache.
       */
      setMaxEntries(maxEntries) {
        if (maxEntries < 0) {
          throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${maxEntries}.`);
        }
        if (this.maxEntries > maxEntries) {
          for (let i = 0; i < this.maxEntries - maxEntries; i++) {
            const keyToDelete = this.cache.keys().next().value;
            this.cache.delete(keyToDelete);
          }
        }
        this.maxEntries = maxEntries;
      }
    };
  }
});
function pyListRepeat(value, numValues) {
  if (Array.isArray(value)) {
    let newArray = [];
    for (let i = 0; i < numValues; i++) {
      newArray = newArray.concat(value);
    }
    return newArray;
  } else {
    const newArray = new Array(numValues);
    newArray.fill(value);
    return newArray;
  }
}
function assert2(val, message) {
  if (!val) {
    throw new AssertionError(message);
  }
}
function count(array2, refernce) {
  let counter = 0;
  for (const item of array2) {
    if (item === refernce) {
      counter++;
    }
  }
  return counter;
}
function singletonOrArray(xs) {
  if (xs.length === 1) {
    return xs[0];
  }
  return xs;
}
function toList(x) {
  if (Array.isArray(x)) {
    return x;
  }
  return [x];
}
function toSnakeCase(name) {
  const intermediate = name.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2");
  const insecure = intermediate.replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  if (insecure[0] !== "_") {
    return insecure;
  }
  return "private" + insecure;
}
function toCamelCase(identifier) {
  if (identifier.length <= 1) {
    return identifier;
  }
  if (identifier.indexOf("_") === -1) {
    return identifier;
  }
  return identifier.replace(/[_]+(\w|$)/g, (m, p1) => p1.toUpperCase());
}
function serializeKerasObject(instance) {
  if (instance === null || instance === void 0) {
    return null;
  }
  const dict = {};
  dict["className"] = instance.getClassName();
  dict["config"] = instance.getConfig();
  return dict;
}
function convertNDArrayScalarsInConfig(config) {
  if (config == null || typeof config !== "object") {
    return;
  } else if (Array.isArray(config)) {
    config.forEach((configItem) => convertNDArrayScalarsInConfig(configItem));
  } else {
    const fields = Object.keys(config);
    for (const field of fields) {
      const value = config[field];
      if (value != null && typeof value === "object") {
        if (!Array.isArray(value) && value["type"] === "ndarray" && typeof value["value"] === "number") {
          config[field] = value["value"];
        } else {
          convertNDArrayScalarsInConfig(value);
        }
      }
    }
  }
}
function deserializeKerasObject(identifier, moduleObjects = {}, customObjects = {}, printableModuleName = "object", fastWeightInit = false) {
  if (typeof identifier === "string") {
    const functionName = identifier;
    let fn;
    if (functionName in customObjects) {
      fn = customObjects[functionName];
    } else if (functionName in _GLOBAL_CUSTOM_OBJECTS) {
      fn = _GLOBAL_CUSTOM_OBJECTS[functionName];
    } else {
      fn = moduleObjects[functionName];
      if (fn == null) {
        throw new ValueError(`Unknown ${printableModuleName}: ${identifier}. This may be due to one of the following reasons:
1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
      }
    }
    return fn;
  } else {
    const config = identifier;
    if (config["className"] == null || config["config"] == null) {
      throw new ValueError(`${printableModuleName}: Improper config format: ${JSON.stringify(config)}.
'className' and 'config' must set.`);
    }
    const className = config["className"];
    let cls, fromConfig;
    if (className in customObjects) {
      [cls, fromConfig] = customObjects[className];
    } else if (className in _GLOBAL_CUSTOM_OBJECTS) {
      [cls, fromConfig] = _GLOBAL_CUSTOM_OBJECTS["className"];
    } else if (className in moduleObjects) {
      [cls, fromConfig] = moduleObjects[className];
    }
    if (cls == null) {
      throw new ValueError(`Unknown ${printableModuleName}: ${className}. This may be due to one of the following reasons:
1. The ${printableModuleName} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${printableModuleName} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    }
    if (fromConfig != null) {
      const customObjectsCombined = {};
      for (const key of Object.keys(_GLOBAL_CUSTOM_OBJECTS)) {
        customObjectsCombined[key] = _GLOBAL_CUSTOM_OBJECTS[key];
      }
      for (const key of Object.keys(customObjects)) {
        customObjectsCombined[key] = customObjects[key];
      }
      const nestedConfig = config["config"];
      nestedConfig["customObjects"] = customObjectsCombined;
      const backupCustomObjects = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);
      for (const key of Object.keys(customObjects)) {
        _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];
      }
      convertNDArrayScalarsInConfig(config["config"]);
      const returnObj = fromConfig(cls, config["config"], customObjects, fastWeightInit);
      _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, backupCustomObjects);
      return returnObj;
    } else {
      const backupCustomObjects = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);
      for (const key of Object.keys(customObjects)) {
        _GLOBAL_CUSTOM_OBJECTS[key] = customObjects[key];
      }
      const returnObj = new cls(config["config"]);
      _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, backupCustomObjects);
      return returnObj;
    }
  }
}
function numberCompare(a, b) {
  return a < b ? -1 : a > b ? 1 : 0;
}
function reverseNumberCompare(a, b) {
  return -1 * numberCompare(a, b);
}
function unique2(xs) {
  if (xs == null) {
    return xs;
  }
  const out = [];
  for (const x of xs) {
    if (out.indexOf(x) === -1) {
      out.push(x);
    }
  }
  return out;
}
function isObjectEmpty(obj) {
  if (obj == null) {
    throw new ValueError(`Invalid value in obj: ${JSON.stringify(obj)}`);
  }
  for (const key in obj) {
    if (obj.hasOwnProperty(key)) {
      return false;
    }
  }
  return true;
}
function checkStringTypeUnionValue(values, label, value) {
  if (value == null) {
    return;
  }
  if (values.indexOf(value) < 0) {
    throw new ValueError(`${value} is not a valid ${label}.  Valid values are ${values} or null/undefined.`);
  }
}
function checkArrayTypeAndLength(x, expectedType, minLength = 0, maxLength = Infinity) {
  assert2(minLength >= 0);
  assert2(maxLength >= minLength);
  return Array.isArray(x) && x.length >= minLength && x.length <= maxLength && x.every((e) => typeof e === expectedType);
}
function assertPositiveInteger(value, name) {
  if (Array.isArray(value)) {
    util_exports.assert(value.length > 0, () => `${name} is unexpectedly an empty array.`);
    value.forEach((v, i) => assertPositiveInteger(v, `element ${i + 1} of ${name}`));
  } else {
    util_exports.assert(Number.isInteger(value) && value > 0, () => `Expected ${name} to be a positive integer, but got ${formatAsFriendlyString(value)}.`);
  }
}
function formatAsFriendlyString(value) {
  if (value === null) {
    return "null";
  } else if (Array.isArray(value)) {
    return "[" + value.map((v) => formatAsFriendlyString(v)).join(",") + "]";
  } else if (typeof value === "string") {
    return `"${value}"`;
  } else {
    return `${value}`;
  }
}
function debounce(f, waitMs, nowFunc) {
  let lastTime = nowFunc != null ? nowFunc() : util_exports.now();
  let lastResult;
  const f2 = (...args) => {
    const now2 = nowFunc != null ? nowFunc() : util_exports.now();
    if (now2 - lastTime < waitMs) {
      return lastResult;
    }
    lastTime = now2;
    lastResult = f(...args);
    return lastResult;
  };
  return f2;
}
function mapActivationToFusedKernel(activationName) {
  if (activationName === "relu") {
    return "relu";
  }
  if (activationName === "linear") {
    return "linear";
  }
  if (activationName === "elu") {
    return "elu";
  }
  return null;
}
var _GLOBAL_CUSTOM_OBJECTS;
var init_generic_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/generic_utils.js"() {
    init_dist();
    init_errors();
    _GLOBAL_CUSTOM_OBJECTS = {};
  }
});
function getNextUniqueTensorId() {
  return _nextUniqueTensorId++;
}
function getUid(prefix = "") {
  if (!(prefix in _uidPrefixes)) {
    _uidPrefixes[prefix] = 0;
  }
  _uidPrefixes[prefix] += 1;
  return prefix + _uidPrefixes[prefix].toString();
}
var _nextUniqueTensorId;
var _uidPrefixes;
var init_state = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/backend/state.js"() {
    _nextUniqueTensorId = 0;
    _uidPrefixes = {};
  }
});
var VALID_DATA_FORMAT_VALUES;
var VALID_INTERPOLATION_FORMAT_VALUES;
var VALID_PADDING_MODE_VALUES;
var VALID_POOL_MODE_VALUES;
var VALID_BIDIRECTIONAL_MERGE_MODES;
var init_common = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/keras_format/common.js"() {
    VALID_DATA_FORMAT_VALUES = ["channelsFirst", "channelsLast"];
    VALID_INTERPOLATION_FORMAT_VALUES = ["nearest", "bilinear"];
    VALID_PADDING_MODE_VALUES = ["valid", "same", "causal"];
    VALID_POOL_MODE_VALUES = ["max", "avg"];
    VALID_BIDIRECTIONAL_MERGE_MODES = ["sum", "mul", "concat", "ave"];
  }
});
function checkDataFormat(value) {
  checkStringTypeUnionValue(VALID_DATA_FORMAT_VALUES, "DataFormat", value);
}
function checkInterpolationFormat(value) {
  checkStringTypeUnionValue(VALID_INTERPOLATION_FORMAT_VALUES, "InterpolationFormat", value);
}
function checkPaddingMode(value) {
  checkStringTypeUnionValue(VALID_PADDING_MODE_VALUES, "PaddingMode", value);
}
function checkPoolMode(value) {
  checkStringTypeUnionValue(VALID_POOL_MODE_VALUES, "PoolMode", value);
}
function nameScope(name, fn) {
  _nameScopeStack.push(name);
  try {
    const val = fn();
    _nameScopeStack.pop();
    return val;
  } catch (e) {
    _nameScopeStack.pop();
    throw e;
  }
}
function currentNameScopePrefix() {
  if (_nameScopeStack.length === 0) {
    return "";
  } else {
    return _nameScopeStack.join(_nameScopeDivider) + _nameScopeDivider;
  }
}
function getScopedTensorName(tensorName) {
  if (!isValidTensorName(tensorName)) {
    throw new Error("Not a valid tensor name: '" + tensorName + "'");
  }
  return currentNameScopePrefix() + tensorName;
}
function getUniqueTensorName(scopedName) {
  if (!isValidTensorName(scopedName)) {
    throw new Error("Not a valid tensor name: '" + scopedName + "'");
  }
  if (!nameMap.has(scopedName)) {
    nameMap.set(scopedName, 0);
  }
  const index = nameMap.get(scopedName);
  nameMap.set(scopedName, nameMap.get(scopedName) + 1);
  if (index > 0) {
    const result = `${scopedName}_${index}`;
    nameMap.set(result, 1);
    return result;
  } else {
    return scopedName;
  }
}
function isValidTensorName(name) {
  return !!name.match(tensorNameRegex);
}
var nameMap;
var _nameScopeStack;
var _nameScopeDivider;
var tensorNameRegex;
var init_common2 = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/common.js"() {
    init_common();
    init_generic_utils();
    nameMap = /* @__PURE__ */ new Map();
    _nameScopeStack = [];
    _nameScopeDivider = "/";
    tensorNameRegex = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
  }
});
function isInteger(x) {
  return x === parseInt(x.toString(), 10);
}
function arrayProd(array2, begin, end) {
  if (begin == null) {
    begin = 0;
  }
  if (end == null) {
    end = array2.length;
  }
  let prod4 = 1;
  for (let i = begin; i < end; ++i) {
    prod4 *= array2[i];
  }
  return prod4;
}
function min22(array2) {
  if (array2.length === 0) {
    return Number.NaN;
  }
  let min5 = Number.POSITIVE_INFINITY;
  for (let i = 0; i < array2.length; i++) {
    const value = array2[i];
    if (value < min5) {
      min5 = value;
    }
  }
  return min5;
}
function max22(array2) {
  if (array2.length === 0) {
    return Number.NaN;
  }
  let max5 = Number.NEGATIVE_INFINITY;
  for (let i = 0; i < array2.length; i++) {
    const value = array2[i];
    if (value > max5) {
      max5 = value;
    }
  }
  return max5;
}
function range2(begin, end) {
  if (end < begin) {
    throw new ValueError(`end (${end}) < begin (${begin}) is forbidden.`);
  }
  const out = [];
  for (let i = begin; i < end; ++i) {
    out.push(i);
  }
  return out;
}
var init_math_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/math_utils.js"() {
    init_errors();
  }
});
function epsilon() {
  if (_epsilon == null) {
    _epsilon = backend().epsilon();
  }
  return _epsilon;
}
function imageDataFormat() {
  return "channelsLast";
}
var _epsilon;
var init_common3 = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/backend/common.js"() {
    init_dist();
  }
});
function cast2(x, dtype) {
  return cast(x, dtype);
}
function expandDims2(x, axis = -1) {
  const outShape = x.shape.slice();
  if (axis < 0) {
    axis = outShape.length + axis + 1;
  }
  outShape.splice(axis, 0, 1);
  return reshape(x, outShape);
}
function repeat(x, n) {
  return tidy(() => {
    if (x.shape.length !== 2) {
      throw new ValueError(`repeat() expects a rank-2 tensor, but received a rank-${x.shape.length} tensor.`);
    }
    const y = expandDims2(x, 1);
    return tile2(y, [1, n, 1]);
  });
}
function flatten2(x) {
  const newShape = [arrayProd(x.shape)];
  return reshape(x, newShape);
}
function batchFlatten(x) {
  if (x.rank <= 1) {
    throw new ValueError(`batchFlatten requires a minimum rank of 2. Got rank: ${x.rank}.`);
  }
  const newShape = [x.shape[0], arrayProd(x.shape, 1)];
  return reshape(x, newShape);
}
function sliceAlongFirstAxis(array2, start, size) {
  return tidy(() => {
    switch (array2.rank) {
      case 1:
        return slice1d(array2, start, size);
      case 2:
        return slice2d(array2, [start, 0], [size, array2.shape[1]]);
      case 3:
        return slice3d(array2, [start, 0, 0], [size, array2.shape[1], array2.shape[2]]);
      case 4:
        return slice4d(array2, [start, 0, 0, 0], [size, array2.shape[1], array2.shape[2], array2.shape[3]]);
      case 5:
        return slice(array2, [start, 0, 0, 0, 0], [
          size,
          array2.shape[1],
          array2.shape[2],
          array2.shape[3],
          array2.shape[4]
        ]);
      case 6:
        return slice(array2, [start, 0, 0, 0, 0, 0], [
          size,
          array2.shape[1],
          array2.shape[2],
          array2.shape[3],
          array2.shape[4],
          array2.shape[5]
        ]);
      default:
        throw new ValueError(`sliceAlongFirstAxis() received an unsupported tensor rank: ${array2.rank}`);
    }
  });
}
function sliceAlongLastAxis(array2, start, size) {
  return tidy(() => {
    switch (array2.rank) {
      case 1:
        return slice1d(array2, start, size);
      case 2:
        return slice2d(array2, [0, start], [array2.shape[0], size]);
      case 3:
        return slice3d(array2, [0, 0, start], [array2.shape[0], array2.shape[1], size]);
      case 4:
        return slice4d(array2, [0, 0, 0, start], [array2.shape[0], array2.shape[1], array2.shape[2], size]);
      default:
        throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array2.rank}`);
    }
  });
}
function sliceAlongAxis(array2, start, size, axis) {
  return tidy(() => {
    switch (array2.rank) {
      case 1:
        return slice1d(array2, start, size);
      case 2:
        switch (axis) {
          case 1:
            return sliceAlongFirstAxis(array2, start, size);
          case 2:
            return sliceAlongLastAxis(array2, start, size);
          default:
            throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
        }
      case 3:
        switch (axis) {
          case 1:
            return sliceAlongFirstAxis(array2, start, size);
          case 2:
            return slice3d(array2, [0, start, 0], [array2.shape[0], size, array2.shape[2]]);
          case 3:
            return sliceAlongLastAxis(array2, start, size);
          default:
            throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
        }
      case 4:
        switch (axis) {
          case 1:
            return sliceAlongFirstAxis(array2, start, size);
          case 2:
            return slice4d(array2, [0, start, 0, 0], [array2.shape[0], size, array2.shape[2], array2.shape[3]]);
          case 3:
            return slice4d(array2, [0, 0, start, 0], [array2.shape[0], array2.shape[1], size, array2.shape[3]]);
          case 4:
            return sliceAlongLastAxis(array2, start, size);
          default:
            throw new ValueError(`The axis is not within the rank of the tensor ${axis}`);
        }
      default:
        throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${array2.rank}`);
    }
  });
}
function concatenate(tensors, axis = -1) {
  let rank;
  if (axis < 0) {
    rank = tensors[0].rank;
    if (rank !== 0) {
      axis = rank;
    } else {
      axis = 0;
    }
  }
  if (axis === tensors[0].rank) {
    axis = -1;
  }
  return concat(tensors, axis);
}
function concatAlongFirstAxis(a, b) {
  switch (a.rank) {
    case 1:
      return concat1d([a, b]);
    case 2:
      return concat2d([a, b], 0);
    case 3:
      return concat3d([a, b], 0);
    case 4:
      return concat4d([a, b], 0);
    default:
      throw new ValueError(`concatAlongFirstAxis() received an unsupported tensor rank: ${a.rank}`);
  }
}
function tile2(x, n) {
  if (!Array.isArray(n)) {
    n = [n];
  }
  if (x.rank !== n.length) {
    throw new ValueError(`The length of input n (${n.length}) does not match the number of dimensions in input x (${x.rank})`);
  }
  return tile(x, n);
}
function randomNormal2(shape, mean3 = 0, stddev = 1, dtype, seed) {
  return randomNormal(shape, mean3, stddev, dtype, seed);
}
function dot22(a, b, activation, bias) {
  if (a.rank < 2 || b.rank < 2) {
    throw new NotImplementedError(`dot requires both inputs to be rank >= 2 but got x shape = ${a.shape} and y shape = ${b.shape}`);
  }
  if (b.rank >= 3) {
    const xLastDim = a.shape.slice(-1)[0];
    const ySecondLastDim = b.shape.slice(-2)[0];
    if (xLastDim !== ySecondLastDim) {
      throw new NotImplementedError(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${a.shape} and  y shape = ${b.shape}`);
    }
  }
  if (a.rank === 2 && b.rank === 2) {
    const transposeA = false;
    const transposeB = false;
    return fused_ops_exports.matMul({
      a,
      b,
      transposeA,
      transposeB,
      bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,
      activation
    });
  } else {
    const aFirstDims = a.shape.slice();
    const aLastDim = aFirstDims.pop();
    a = reshape(a, [-1, aLastDim]);
    const bShape = b.shape.slice();
    const bLastDim = bShape.pop();
    const ySecondLastDim = bShape.pop();
    const yOtherDims = [...bShape, bLastDim];
    const perm = Array.from({ length: b.rank }, (_, i) => {
      if (i === 0) {
        return b.rank - 2;
      } else if (i <= b.rank - 2) {
        return i - 1;
      }
      return i;
    });
    b = reshape(transpose2(b, perm), [ySecondLastDim, -1]);
    const outputShape = [...aFirstDims, ...yOtherDims];
    const transposeA = false;
    const transposeB = false;
    return reshape(fused_ops_exports.matMul({
      a,
      b,
      transposeA,
      transposeB,
      bias: bias ? reshapeBias(a.rank, bias, imageDataFormat()) : null,
      activation
    }), outputShape);
  }
}
function gather2(reference, indices, axis) {
  return tidy(() => {
    if (Array.isArray(indices)) {
      indices = tensor1d(indices, "int32");
    } else {
      indices = cast(indices, "int32");
    }
    return gather(reference, indices, axis);
  });
}
function square2(x) {
  return mul5(x, x);
}
function reshapeBias(xRank, bias, dataFormat) {
  const biasShape = bias.shape;
  if (bias.rank !== 1 && bias.rank !== xRank) {
    throw new ValueError(`Unexpected bias dimensions: ${bias.rank}; expected it to be 1 or ${xRank}`);
  }
  if (xRank === 5) {
    if (dataFormat === "channelsFirst") {
      if (biasShape.length === 1) {
        return reshape(bias, [1, biasShape[0], 1, 1, 1]);
      } else {
        return reshape(bias, [1, biasShape[3], biasShape[0], biasShape[1], biasShape[2]]);
      }
    } else if (dataFormat === "channelsLast") {
      if (biasShape.length === 1) {
        return reshape(bias, [1, 1, 1, 1, biasShape[0]]);
      } else {
        return reshape(bias, [1].concat(biasShape));
      }
    }
  } else if (xRank === 4) {
    if (dataFormat === "channelsFirst") {
      if (biasShape.length === 1) {
        return reshape(bias, [1, biasShape[0], 1, 1]);
      } else {
        return reshape(bias, [1, biasShape[2], biasShape[0], biasShape[1]]);
      }
    } else if (dataFormat === "channelsLast") {
      if (biasShape.length === 1) {
        return reshape(bias, [1, 1, 1, biasShape[0]]);
      } else {
        return reshape(bias, [1].concat(biasShape));
      }
    }
  } else if (xRank === 3) {
    if (dataFormat === "channelsFirst") {
      if (biasShape.length === 1) {
        return reshape(bias, [1, biasShape[0], 1]);
      } else {
        return reshape(bias, [1, biasShape[1], biasShape[0]]);
      }
    } else if (dataFormat === "channelsLast") {
      if (biasShape.length === 1) {
        return reshape(bias, [1, 1, biasShape[0]]);
      } else {
        return reshape(bias, [1].concat(biasShape));
      }
    }
  } else if (xRank < 3) {
    return bias;
  }
  throw new ValueError(`Unsupported input rank by biasAdd: ${bias.rank}`);
}
function biasAdd(x, bias, dataFormat) {
  return tidy(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    return add22(x, reshapeBias(x.rank, bias, dataFormat));
  });
}
function elu2(x, alpha = 1) {
  if (alpha !== 1) {
    throw new NotImplementedError(`Support for alpha values other than 1 (${alpha}) is not implemented yet.`);
  }
  return elu(x);
}
function softsign(x) {
  return tidy(() => div2(x, add22(abs(x), 1)));
}
function dropout2(x, level, noiseShape, seed) {
  return tidy(() => dropout(x, level, noiseShape, seed));
}
function hardSigmoid(x) {
  return tidy(() => {
    const y = add22(0.5, mul5(0.2, x));
    return clipByValue(y, 0, 1);
  });
}
function inTrainPhase(x, alt, training = false) {
  return training ? x() : alt();
}
var init_tfjs_backend = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/backend/tfjs_backend.js"() {
    init_dist();
    init_dist();
    init_common2();
    init_errors();
    init_math_utils();
    init_common3();
  }
});
var VALID_FAN_MODE_VALUES;
var VALID_DISTRIBUTION_VALUES;
var init_initializer_config = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/keras_format/initializer_config.js"() {
    VALID_FAN_MODE_VALUES = ["fanIn", "fanOut", "fanAvg"];
    VALID_DISTRIBUTION_VALUES = ["normal", "uniform", "truncatedNormal"];
  }
});
function checkFanMode(value) {
  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, "FanMode", value);
}
function checkDistribution(value) {
  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, "Distribution", value);
}
function computeFans(shape, dataFormat = "channelsLast") {
  let fanIn;
  let fanOut;
  checkDataFormat(dataFormat);
  if (shape.length === 2) {
    fanIn = shape[0];
    fanOut = shape[1];
  } else if ([3, 4, 5].indexOf(shape.length) !== -1) {
    if (dataFormat === "channelsFirst") {
      const receptiveFieldSize = arrayProd(shape, 2);
      fanIn = shape[1] * receptiveFieldSize;
      fanOut = shape[0] * receptiveFieldSize;
    } else if (dataFormat === "channelsLast") {
      const receptiveFieldSize = arrayProd(shape, 0, shape.length - 2);
      fanIn = shape[shape.length - 2] * receptiveFieldSize;
      fanOut = shape[shape.length - 1] * receptiveFieldSize;
    }
  } else {
    const shapeProd = arrayProd(shape);
    fanIn = Math.sqrt(shapeProd);
    fanOut = Math.sqrt(shapeProd);
  }
  return [fanIn, fanOut];
}
function deserializeInitializer(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "initializer");
}
function serializeInitializer(initializer) {
  return serializeKerasObject(initializer);
}
function getInitializer(identifier) {
  if (typeof identifier === "string") {
    const className = identifier in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
    if (className === "GlorotNormal") {
      return new GlorotNormal();
    } else if (className === "GlorotUniform") {
      return new GlorotUniform();
    } else if (className === "HeNormal") {
      return new HeNormal();
    } else if (className === "HeUniform") {
      return new HeUniform();
    } else if (className === "LeCunNormal") {
      return new LeCunNormal();
    } else if (className === "LeCunUniform") {
      return new LeCunUniform();
    } else {
      const config = {};
      config["className"] = className;
      config["config"] = {};
      return deserializeInitializer(config);
    }
  } else if (identifier instanceof Initializer) {
    return identifier;
  } else {
    return deserializeInitializer(identifier);
  }
}
var Initializer;
var Zeros;
var Ones;
var Constant;
var RandomUniform;
var RandomNormal;
var TruncatedNormal;
var Identity2;
var VarianceScaling;
var GlorotUniform;
var GlorotNormal;
var HeNormal;
var HeUniform;
var LeCunNormal;
var LeCunUniform;
var Orthogonal;
var INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP;
var init_initializers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/initializers.js"() {
    init_dist();
    init_tfjs_backend();
    init_common2();
    init_errors();
    init_initializer_config();
    init_generic_utils();
    init_math_utils();
    Initializer = class extends serialization_exports.Serializable {
      fromConfigUsesCustomObjects() {
        return false;
      }
      getConfig() {
        return {};
      }
    };
    Zeros = class extends Initializer {
      apply(shape, dtype) {
        return zeros(shape, dtype);
      }
    };
    Zeros.className = "Zeros";
    serialization_exports.registerClass(Zeros);
    Ones = class extends Initializer {
      apply(shape, dtype) {
        return ones2(shape, dtype);
      }
    };
    Ones.className = "Ones";
    serialization_exports.registerClass(Ones);
    Constant = class extends Initializer {
      constructor(args) {
        super();
        if (typeof args !== "object") {
          throw new ValueError(`Expected argument of type ConstantConfig but got ${args}`);
        }
        if (args.value === void 0) {
          throw new ValueError(`config must have value set but got ${args}`);
        }
        this.value = args.value;
      }
      apply(shape, dtype) {
        return tidy(() => mul5(scalar(this.value), ones2(shape, dtype)));
      }
      getConfig() {
        return {
          value: this.value
        };
      }
    };
    Constant.className = "Constant";
    serialization_exports.registerClass(Constant);
    RandomUniform = class extends Initializer {
      constructor(args) {
        super();
        this.DEFAULT_MINVAL = -0.05;
        this.DEFAULT_MAXVAL = 0.05;
        this.minval = args.minval || this.DEFAULT_MINVAL;
        this.maxval = args.maxval || this.DEFAULT_MAXVAL;
        this.seed = args.seed;
      }
      apply(shape, dtype) {
        return randomUniform(shape, this.minval, this.maxval, dtype, this.seed);
      }
      getConfig() {
        return { minval: this.minval, maxval: this.maxval, seed: this.seed };
      }
    };
    RandomUniform.className = "RandomUniform";
    serialization_exports.registerClass(RandomUniform);
    RandomNormal = class extends Initializer {
      constructor(args) {
        super();
        this.DEFAULT_MEAN = 0;
        this.DEFAULT_STDDEV = 0.05;
        this.mean = args.mean || this.DEFAULT_MEAN;
        this.stddev = args.stddev || this.DEFAULT_STDDEV;
        this.seed = args.seed;
      }
      apply(shape, dtype) {
        dtype = dtype || "float32";
        if (dtype !== "float32" && dtype !== "int32") {
          throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);
        }
        return randomNormal2(shape, this.mean, this.stddev, dtype, this.seed);
      }
      getConfig() {
        return { mean: this.mean, stddev: this.stddev, seed: this.seed };
      }
    };
    RandomNormal.className = "RandomNormal";
    serialization_exports.registerClass(RandomNormal);
    TruncatedNormal = class extends Initializer {
      constructor(args) {
        super();
        this.DEFAULT_MEAN = 0;
        this.DEFAULT_STDDEV = 0.05;
        this.mean = args.mean || this.DEFAULT_MEAN;
        this.stddev = args.stddev || this.DEFAULT_STDDEV;
        this.seed = args.seed;
      }
      apply(shape, dtype) {
        dtype = dtype || "float32";
        if (dtype !== "float32" && dtype !== "int32") {
          throw new NotImplementedError(`truncatedNormal does not support dType ${dtype}.`);
        }
        return truncatedNormal(shape, this.mean, this.stddev, dtype, this.seed);
      }
      getConfig() {
        return { mean: this.mean, stddev: this.stddev, seed: this.seed };
      }
    };
    TruncatedNormal.className = "TruncatedNormal";
    serialization_exports.registerClass(TruncatedNormal);
    Identity2 = class extends Initializer {
      constructor(args) {
        super();
        this.gain = args.gain != null ? args.gain : 1;
      }
      apply(shape, dtype) {
        return tidy(() => {
          if (shape.length !== 2 || shape[0] !== shape[1]) {
            throw new ValueError("Identity matrix initializer can only be used for 2D square matrices.");
          } else {
            return mul5(this.gain, eye(shape[0]));
          }
        });
      }
      getConfig() {
        return { gain: this.gain };
      }
    };
    Identity2.className = "Identity";
    serialization_exports.registerClass(Identity2);
    VarianceScaling = class extends Initializer {
      /**
       * Constructor of VarianceScaling.
       * @throws ValueError for invalid value in scale.
       */
      constructor(args) {
        super();
        if (args.scale < 0) {
          throw new ValueError(`scale must be a positive float. Got: ${args.scale}`);
        }
        this.scale = args.scale == null ? 1 : args.scale;
        this.mode = args.mode == null ? "fanIn" : args.mode;
        checkFanMode(this.mode);
        this.distribution = args.distribution == null ? "normal" : args.distribution;
        checkDistribution(this.distribution);
        this.seed = args.seed;
      }
      apply(shape, dtype) {
        const fans = computeFans(shape);
        const fanIn = fans[0];
        const fanOut = fans[1];
        let scale22 = this.scale;
        if (this.mode === "fanIn") {
          scale22 /= Math.max(1, fanIn);
        } else if (this.mode === "fanOut") {
          scale22 /= Math.max(1, fanOut);
        } else {
          scale22 /= Math.max(1, (fanIn + fanOut) / 2);
        }
        if (this.distribution === "normal") {
          const stddev = Math.sqrt(scale22);
          dtype = dtype || "float32";
          if (dtype !== "float32" && dtype !== "int32") {
            throw new NotImplementedError(`${this.getClassName()} does not support dType ${dtype}.`);
          }
          return truncatedNormal(shape, 0, stddev, dtype, this.seed);
        } else {
          const limit = Math.sqrt(3 * scale22);
          return randomUniform(shape, -limit, limit, dtype, this.seed);
        }
      }
      getConfig() {
        return {
          scale: this.scale,
          mode: this.mode,
          distribution: this.distribution,
          seed: this.seed
        };
      }
    };
    VarianceScaling.className = "VarianceScaling";
    serialization_exports.registerClass(VarianceScaling);
    GlorotUniform = class extends VarianceScaling {
      /**
       * Constructor of GlorotUniform
       * @param scale
       * @param mode
       * @param distribution
       * @param seed
       */
      constructor(args) {
        super({
          scale: 1,
          mode: "fanAvg",
          distribution: "uniform",
          seed: args == null ? null : args.seed
        });
      }
      getClassName() {
        return VarianceScaling.className;
      }
    };
    GlorotUniform.className = "GlorotUniform";
    serialization_exports.registerClass(GlorotUniform);
    GlorotNormal = class extends VarianceScaling {
      /**
       * Constructor of GlorotNormal.
       * @param scale
       * @param mode
       * @param distribution
       * @param seed
       */
      constructor(args) {
        super({
          scale: 1,
          mode: "fanAvg",
          distribution: "normal",
          seed: args == null ? null : args.seed
        });
      }
      getClassName() {
        return VarianceScaling.className;
      }
    };
    GlorotNormal.className = "GlorotNormal";
    serialization_exports.registerClass(GlorotNormal);
    HeNormal = class extends VarianceScaling {
      constructor(args) {
        super({
          scale: 2,
          mode: "fanIn",
          distribution: "normal",
          seed: args == null ? null : args.seed
        });
      }
      getClassName() {
        return VarianceScaling.className;
      }
    };
    HeNormal.className = "HeNormal";
    serialization_exports.registerClass(HeNormal);
    HeUniform = class extends VarianceScaling {
      constructor(args) {
        super({
          scale: 2,
          mode: "fanIn",
          distribution: "uniform",
          seed: args == null ? null : args.seed
        });
      }
      getClassName() {
        return VarianceScaling.className;
      }
    };
    HeUniform.className = "HeUniform";
    serialization_exports.registerClass(HeUniform);
    LeCunNormal = class extends VarianceScaling {
      constructor(args) {
        super({
          scale: 1,
          mode: "fanIn",
          distribution: "normal",
          seed: args == null ? null : args.seed
        });
      }
      getClassName() {
        return VarianceScaling.className;
      }
    };
    LeCunNormal.className = "LeCunNormal";
    serialization_exports.registerClass(LeCunNormal);
    LeCunUniform = class extends VarianceScaling {
      constructor(args) {
        super({
          scale: 1,
          mode: "fanIn",
          distribution: "uniform",
          seed: args == null ? null : args.seed
        });
      }
      getClassName() {
        return VarianceScaling.className;
      }
    };
    LeCunUniform.className = "LeCunUniform";
    serialization_exports.registerClass(LeCunUniform);
    Orthogonal = class extends Initializer {
      constructor(args) {
        super();
        this.DEFAULT_GAIN = 1;
        this.gain = args.gain == null ? this.DEFAULT_GAIN : args.gain;
        this.seed = args.seed;
        if (this.seed != null) {
          throw new NotImplementedError("Random seed is not implemented for Orthogonal Initializer yet.");
        }
      }
      apply(shape, dtype) {
        return tidy(() => {
          if (shape.length < 2) {
            throw new NotImplementedError("Shape must be at least 2D.");
          }
          if (shape[0] * shape[1] > 2e3) {
            console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${shape[0] * shape[1]}) elements: Slowness may result.`);
          }
          const normalizedShape = shape[0] > shape[1] ? [shape[1], shape[0]] : shape;
          const a = randomNormal2(normalizedShape, 0, 1, "float32");
          let q = linalg.gramSchmidt(a);
          if (shape[0] > shape[1]) {
            q = transpose2(q);
          }
          return mul5(this.gain, q);
        });
      }
      getConfig() {
        return {
          gain: this.gain,
          seed: this.seed
        };
      }
    };
    Orthogonal.className = "Orthogonal";
    serialization_exports.registerClass(Orthogonal);
    INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
      "constant": "Constant",
      "glorotNormal": "GlorotNormal",
      "glorotUniform": "GlorotUniform",
      "heNormal": "HeNormal",
      "heUniform": "HeUniform",
      "identity": "Identity",
      "leCunNormal": "LeCunNormal",
      "leCunUniform": "LeCunUniform",
      "ones": "Ones",
      "orthogonal": "Orthogonal",
      "randomNormal": "RandomNormal",
      "randomUniform": "RandomUniform",
      "truncatedNormal": "TruncatedNormal",
      "varianceScaling": "VarianceScaling",
      "zeros": "Zeros"
    };
  }
});
function isArrayOfShapes(x) {
  return Array.isArray(x) && Array.isArray(x[0]);
}
function normalizeShapeList(x) {
  if (x.length === 0) {
    return [];
  }
  if (!Array.isArray(x[0])) {
    return [x];
  }
  return x;
}
function getExactlyOneTensor(xs) {
  let x;
  if (Array.isArray(xs)) {
    if (xs.length !== 1) {
      throw new ValueError(`Expected Tensor length to be 1; got ${xs.length}`);
    }
    x = xs[0];
  } else {
    x = xs;
  }
  return x;
}
function getExactlyOneShape(shapes) {
  if (Array.isArray(shapes) && Array.isArray(shapes[0])) {
    if (shapes.length === 1) {
      shapes = shapes;
      return shapes[0];
    } else {
      throw new ValueError(`Expected exactly 1 Shape; got ${shapes.length}`);
    }
  } else {
    return shapes;
  }
}
var init_types_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/types_utils.js"() {
    init_errors();
  }
});
function countParamsInWeights(weights) {
  let count2 = 0;
  for (const weight of weights) {
    if (weight.shape.length === 0) {
      count2 += 1;
    } else {
      count2 += weight.shape.reduce((a, b) => a * b);
    }
  }
  return count2;
}
var init_variable_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/variable_utils.js"() {
  }
});
function checkShapesMatch(x, y) {
  if (x.shape.toString() !== y.shape.toString()) {
    throw new Error("Shape mismatch: " + JSON.stringify(x.shape) + " vs. " + JSON.stringify(y.shape));
  }
}
function batchGetValue(xs) {
  return xs.map((x) => x.read());
}
function batchSetValue(variablesAndValues) {
  variablesAndValues.forEach((variableAndValue) => {
    const variable2 = variableAndValue[0];
    variable2.write(variableAndValue[1]);
  });
}
var DEFAULT_VARIABLE_NAME_PREFIX;
var LayerVariable;
var init_variables = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/variables.js"() {
    init_dist();
    init_dist();
    init_state();
    init_common2();
    init_errors();
    DEFAULT_VARIABLE_NAME_PREFIX = "Variable";
    LayerVariable = class {
      /**
       * Construct Variable from a `tf.Tensor`.
       *
       * If not explicitly named, the Variable will be given a name with the
       * prefix 'Variable'. Variable names are unique. In the case of name
       * collision, suffixies '_<num>' will be added to the name.
       *
       * @param val Initial value of the Variable.
       * @param name Name of the variable. If `null` or `undefined` is provided, it
       *   will default a name with the prefix 'Variable'.
       * @param constraint Optional, projection function to be applied to the
       * variable after optimize updates
       * @throws ValueError if `name` is `null` or `undefined`.
       */
      constructor(val, dtype = "float32", name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true, constraint = null) {
        this.dtype = dtype == null ? "float32" : dtype;
        this.shape = val.shape;
        this.id = getNextUniqueTensorId();
        name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;
        this.originalName = getScopedTensorName(name);
        this.name = getUniqueTensorName(this.originalName);
        this.trainable_ = trainable;
        this.constraint = constraint;
        this.val = variable(val, this.trainable_, this.name, this.dtype);
      }
      /**
       * Get a snapshot of the Variable's value.
       *
       * The returned value is a snapshot of the Variable's value at the time of
       * the invocation. Future mutations in the value of the tensor will only
       * be reflected by future calls to this method.
       */
      read() {
        this.assertNotDisposed();
        return this.val;
      }
      /**
       * Update the value of the Variable.
       *
       * @param newVal: The new value to update to. Must be consistent with the
       *   dtype and shape of the Variable.
       * @return This Variable.
       */
      write(newVal) {
        this.assertNotDisposed();
        checkShapesMatch(this.val, newVal);
        if (this.val.id !== newVal.id) {
          this.val.assign(newVal);
          if (this.constraint != null) {
            this.val.assign(this.constraint.apply(this.val));
          }
        }
        return this;
      }
      /**
       * Dispose this LayersVariable instance from memory.
       */
      dispose() {
        this.assertNotDisposed();
        this.val.dispose();
      }
      assertNotDisposed() {
        if (this.val.isDisposed) {
          throw new Error(`LayersVariable ${this.name} is already disposed.`);
        }
      }
      get trainable() {
        return this.trainable_;
      }
      set trainable(trainable) {
        this.trainable_ = trainable;
        this.val.trainable = trainable;
      }
    };
  }
});
function collectInputShape(inputTensors) {
  inputTensors = toList(inputTensors);
  const shapes = [];
  for (const x of inputTensors) {
    shapes.push(x.shape);
  }
  return singletonOrArray(shapes);
}
function guessOutputDType(inputTensors) {
  return "float32";
}
function getSourceInputs(tensor2, layer, nodeIndex) {
  if (layer == null || nodeIndex != null && nodeIndex > 0) {
    layer = tensor2.sourceLayer;
    nodeIndex = tensor2.nodeIndex;
  }
  if (layer.inboundNodes.length === 0) {
    return [tensor2];
  } else {
    const node = layer.inboundNodes[nodeIndex];
    if (node.inboundLayers.length === 0) {
      return node.inputTensors;
    } else {
      const sourceTensors = [];
      for (let i = 0; i < node.inboundLayers.length; i++) {
        const x = node.inputTensors[i];
        const layer2 = node.inboundLayers[i];
        const nodeIndex2 = node.nodeIndices[i];
        const previousSources = getSourceInputs(x, layer2, nodeIndex2);
        for (const x2 of previousSources) {
          if (sourceTensors.indexOf(x2) === -1) {
            sourceTensors.push(x2);
          }
        }
      }
      return sourceTensors;
    }
  }
}
var InputSpec;
var SymbolicTensor;
var _nextNodeID;
var Node;
var _nextLayerID;
var Layer;
var init_topology = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/topology.js"() {
    init_dist();
    init_state();
    init_common2();
    init_errors();
    init_initializers();
    init_generic_utils();
    init_types_utils();
    init_variable_utils();
    init_variables();
    InputSpec = class {
      constructor(args) {
        this.dtype = args.dtype;
        this.shape = args.shape;
        if (args.shape != null) {
          this.ndim = args.shape.length;
        } else {
          this.ndim = args.ndim;
        }
        this.maxNDim = args.maxNDim;
        this.minNDim = args.minNDim;
        this.axes = args.axes || {};
      }
    };
    SymbolicTensor = class {
      /**
       *
       * @param dtype
       * @param shape
       * @param sourceLayer The Layer that produced this symbolic tensor.
       * @param inputs The inputs passed to sourceLayer's __call__() method.
       * @param nodeIndex
       * @param tensorIndex
       * @param callArgs The keyword arguments passed to the __call__() method.
       * @param name
       * @param outputTensorIndex The index of this tensor in the list of outputs
       *   returned by apply().
       */
      constructor(dtype, shape, sourceLayer, inputs, callArgs, name, outputTensorIndex) {
        this.dtype = dtype;
        this.shape = shape;
        this.sourceLayer = sourceLayer;
        this.inputs = inputs;
        this.callArgs = callArgs;
        this.outputTensorIndex = outputTensorIndex;
        this.id = getNextUniqueTensorId();
        if (name != null) {
          this.originalName = getScopedTensorName(name);
          this.name = getUniqueTensorName(this.originalName);
        }
        this.rank = shape.length;
      }
    };
    _nextNodeID = 0;
    Node = class {
      constructor(args, callArgs) {
        this.callArgs = callArgs;
        this.id = _nextNodeID++;
        this.outboundLayer = args.outboundLayer;
        this.inboundLayers = args.inboundLayers;
        this.nodeIndices = args.nodeIndices;
        this.tensorIndices = args.tensorIndices;
        this.inputTensors = args.inputTensors;
        this.outputTensors = args.outputTensors;
        this.inputMasks = args.inputMasks;
        this.outputMasks = args.outputMasks;
        this.inputShapes = args.inputShapes;
        this.outputShapes = args.outputShapes;
        for (const layer of args.inboundLayers) {
          if (layer != null) {
            layer.outboundNodes.push(this);
          }
        }
        args.outboundLayer.inboundNodes.push(this);
      }
      getConfig() {
        const inboundNames = [];
        for (const layer of this.inboundLayers) {
          if (layer != null) {
            inboundNames.push(layer.name);
          } else {
            inboundNames.push(null);
          }
        }
        return {
          outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
          inboundLayers: inboundNames,
          nodeIndices: this.nodeIndices,
          tensorIndices: this.tensorIndices
        };
      }
    };
    _nextLayerID = 0;
    Layer = class extends serialization_exports.Serializable {
      constructor(args = {}) {
        super();
        this._callHook = null;
        this._addedWeightNames = [];
        this._stateful = false;
        this.id = _nextLayerID++;
        this.activityRegularizer = null;
        this.inputSpec = null;
        this.supportsMasking = false;
        this._trainableWeights = [];
        this._nonTrainableWeights = [];
        this._losses = [];
        this._updates = [];
        this._built = false;
        this.inboundNodes = [];
        this.outboundNodes = [];
        let name = args.name;
        if (!name) {
          const prefix = this.getClassName();
          name = toSnakeCase(prefix) + "_" + getUid(prefix);
        }
        this.name = name;
        this.trainable_ = args.trainable == null ? true : args.trainable;
        if (args.inputShape != null || args.batchInputShape != null) {
          let batchInputShape;
          if (args.batchInputShape != null) {
            batchInputShape = args.batchInputShape;
          } else if (args.inputShape != null) {
            let batchSize = null;
            if (args.batchSize != null) {
              batchSize = args.batchSize;
            }
            batchInputShape = [batchSize].concat(args.inputShape);
          }
          this.batchInputShape = batchInputShape;
          let dtype = args.dtype;
          if (dtype == null) {
            dtype = args.inputDType;
          }
          if (dtype == null) {
            dtype = "float32";
          }
          this.dtype = dtype;
        }
        if (args.weights != null) {
          this.initialWeights = args.weights;
        } else {
          this.initialWeights = null;
        }
        this._refCount = null;
        this.fastWeightInitDuringBuild = false;
      }
      /**
       * Converts a layer and its index to a unique (immutable type) name.
       * This function is used internally with `this.containerNodes`.
       * @param layer The layer.
       * @param nodeIndex The layer's position (e.g. via enumerate) in a list of
       *   nodes.
       *
       * @returns The unique name.
       */
      static nodeKey(layer, nodeIndex) {
        return layer.name + "_ib-" + nodeIndex.toString();
      }
      /**
       * Returns this.inboundNode at index nodeIndex.
       *
       * Porting note: This is a replacement for _get_node_attribute_at_index()
       * @param nodeIndex
       * @param attrName The name of the attribute related to request for this node.
       */
      getNodeAtIndex(nodeIndex, attrName) {
        if (this.inboundNodes.length === 0) {
          throw new RuntimeError(`The layer has never been called and thus has no defined ${attrName}.`);
        }
        if (this.inboundNodes.length <= nodeIndex) {
          throw new ValueError(`Asked to get ${attrName} at node ${nodeIndex}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
        }
        return this.inboundNodes[nodeIndex];
      }
      /**
       * Retrieves the input tensor(s) of a layer at a given node.
       *
       * @param nodeIndex Integer, index of the node from which to retrieve the
       *   attribute. E.g. `nodeIndex=0` will correspond to the first time the layer
       *   was called.
       *
       * @return A tensor (or list of tensors if the layer has multiple inputs).
       */
      getInputAt(nodeIndex) {
        return singletonOrArray(this.getNodeAtIndex(nodeIndex, "input").inputTensors);
      }
      /**
       * Retrieves the output tensor(s) of a layer at a given node.
       *
       * @param nodeIndex Integer, index of the node from which to retrieve the
       *   attribute. E.g. `nodeIndex=0` will correspond to the first time the layer
       *   was called.
       *
       * @return A tensor (or list of tensors if the layer has multiple outputs).
       */
      getOutputAt(nodeIndex) {
        return singletonOrArray(this.getNodeAtIndex(nodeIndex, "output").outputTensors);
      }
      // Properties
      /**
       * Retrieves the input tensor(s) of a layer.
       *
       * Only applicable if the layer has exactly one inbound node,
       * i.e. if it is connected to one incoming layer.
       *
       * @return Input tensor or list of input tensors.
       *
       * @exception AttributeError if the layer is connected to more than one
       *   incoming layers.
       */
      get input() {
        if (this.inboundNodes.length > 1) {
          throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
        } else if (this.inboundNodes.length === 0) {
          throw new AttributeError(`Layer ${this.name} is not connected, no input to return.`);
        }
        return singletonOrArray(this.getNodeAtIndex(0, "input").inputTensors);
      }
      /**
       * Retrieves the output tensor(s) of a layer.
       *
       * Only applicable if the layer has exactly one inbound node,
       * i.e. if it is connected to one incoming layer.
       *
       * @return Output tensor or list of output tensors.
       *
       * @exception AttributeError if the layer is connected to more than one
       *   incoming layers.
       */
      get output() {
        if (this.inboundNodes.length === 0) {
          throw new AttributeError(`Layer ${this.name} has no inbound nodes.`);
        }
        if (this.inboundNodes.length > 1) {
          throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
        }
        return singletonOrArray(this.getNodeAtIndex(0, "output").outputTensors);
      }
      get losses() {
        return this._losses;
      }
      /**
       * Retrieves the Layer's current loss values.
       *
       * Used for regularizers during training.
       */
      calculateLosses() {
        return this.losses.map((lossFn) => lossFn());
      }
      get updates() {
        return this._updates;
      }
      get built() {
        return this._built;
      }
      set built(built) {
        this._built = built;
      }
      get trainable() {
        return this.trainable_;
      }
      set trainable(trainable) {
        this._trainableWeights.forEach((w) => w.trainable = trainable);
        this.trainable_ = trainable;
      }
      get trainableWeights() {
        if (this.trainable_) {
          return this._trainableWeights.filter((w) => w.trainable);
        } else {
          return [];
        }
      }
      set trainableWeights(weights) {
        this._trainableWeights = weights;
      }
      get nonTrainableWeights() {
        if (this.trainable) {
          return this._trainableWeights.filter((w) => !w.trainable).concat(this._nonTrainableWeights);
        } else {
          return this._trainableWeights.concat(this._nonTrainableWeights);
        }
      }
      set nonTrainableWeights(weights) {
        this._nonTrainableWeights = weights;
      }
      /**
       * The concatenation of the lists trainableWeights and nonTrainableWeights
       * (in this order).
       */
      get weights() {
        return this.trainableWeights.concat(this.nonTrainableWeights);
      }
      get stateful() {
        return this._stateful;
      }
      /**
       * Reset the states of the layer.
       *
       * This method of the base Layer class is essentially a no-op.
       * Subclasses that are stateful (e.g., stateful RNNs) should override this
       * method.
       */
      resetStates() {
        if (!this.stateful) {
          throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
        }
      }
      /**
       * Checks compatibility between the layer and provided inputs.
       *
       * This checks that the tensor(s) `input`
       * verify the input assumptions of the layer
       * (if any). If not, exceptions are raised.
       *
       * @param inputs Input tensor or list of input tensors.
       *
       * @exception ValueError in case of mismatch between
       *   the provided inputs and the expectations of the layer.
       */
      assertInputCompatibility(inputs) {
        inputs = toList(inputs);
        if (this.inputSpec == null || this.inputSpec.length === 0) {
          return;
        }
        const inputSpec = toList(this.inputSpec);
        if (inputs.length !== inputSpec.length) {
          throw new ValueError(`Layer ${this.name} expects ${inputSpec.length} inputs, but it received ${inputs.length} input tensors. Input received: ${inputs}`);
        }
        for (let inputIndex = 0; inputIndex < inputs.length; inputIndex++) {
          const x = inputs[inputIndex];
          const spec = inputSpec[inputIndex];
          if (spec == null) {
            continue;
          }
          const ndim = x.rank;
          if (spec.ndim != null) {
            if (ndim !== spec.ndim) {
              throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected ndim=${spec.ndim}, found ndim=${ndim}`);
            }
          }
          if (spec.maxNDim != null) {
            if (ndim > spec.maxNDim) {
              throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected max_ndim=${spec.maxNDim}, found ndim=${ndim}`);
            }
          }
          if (spec.minNDim != null) {
            if (ndim < spec.minNDim) {
              throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected min_ndim=${spec.minNDim}, found ndim=${ndim}.`);
            }
          }
          if (spec.dtype != null) {
            if (x.dtype !== spec.dtype) {
              throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name} : expected dtype=${spec.dtype}, found dtype=${x.dtype}.`);
            }
          }
          if (spec.axes) {
            const xShape = x.shape;
            for (const key in spec.axes) {
              const axis = Number(key);
              const value = spec.axes[key];
              const xShapeAtAxis = axis >= 0 ? xShape[axis] : xShape[xShape.length + axis];
              if (value != null && [value, null].indexOf(xShapeAtAxis) === -1) {
                throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected axis ${axis} of input shape to have value ${value} but got shape ${xShape}.`);
              }
            }
          }
          if (spec.shape != null) {
            for (let i = 0; i < spec.shape.length; ++i) {
              const specDim = spec.shape[i];
              const dim = x.shape[i];
              if (specDim != null && dim != null) {
                if (specDim !== dim) {
                  throw new ValueError(`Input ${inputIndex} is incompatible with layer ${this.name}: expected shape=${spec.shape}, found shape=${x.shape}.`);
                }
              }
            }
          }
        }
      }
      /**
       * This is where the layer's logic lives.
       *
       * @param inputs Input tensor, or list/tuple of input tensors.
       * @param kwargs Additional keyword arguments.
       *
       * @return A tensor or list/tuple of tensors.
       */
      call(inputs, kwargs) {
        return inputs;
      }
      invokeCallHook(inputs, kwargs) {
        if (this._callHook != null) {
          this._callHook(inputs, kwargs);
        }
      }
      /**
       * Set call hook.
       * This is currently used for testing only.
       * @param callHook
       */
      setCallHook(callHook) {
        this._callHook = callHook;
      }
      /**
       * Clear call hook.
       * This is currently used for testing only.
       */
      clearCallHook() {
        this._callHook = null;
      }
      /**
       * Builds or executes a `Layer`'s logic.
       *
       * When called with `tf.Tensor`(s), execute the `Layer`'s computation and
       * return Tensor(s). For example:
       *
       * ```js
       * const denseLayer = tf.layers.dense({
       *   units: 1,
       *   kernelInitializer: 'zeros',
       *   useBias: false
       * });
       *
       * // Invoke the layer's apply() method with a `tf.Tensor` (with concrete
       * // numeric values).
       * const input = tf.ones([2, 2]);
       * const output = denseLayer.apply(input);
       *
       * // The output's value is expected to be [[0], [0]], due to the fact that
       * // the dense layer has a kernel initialized to all-zeros and does not have
       * // a bias.
       * output.print();
       * ```
       *
       * When called with `tf.SymbolicTensor`(s), this will prepare the layer for
       * future execution.  This entails internal book-keeping on shapes of
       * expected Tensors, wiring layers together, and initializing weights.
       *
       * Calling `apply` with `tf.SymbolicTensor`s are typically used during the
       * building of non-`tf.Sequential` models. For example:
       *
       * ```js
       * const flattenLayer = tf.layers.flatten();
       * const denseLayer = tf.layers.dense({units: 1});
       *
       * // Use tf.layers.input() to obtain a SymbolicTensor as input to apply().
       * const input = tf.input({shape: [2, 2]});
       * const output1 = flattenLayer.apply(input);
       *
       * // output1.shape is [null, 4]. The first dimension is the undetermined
       * // batch size. The second dimension comes from flattening the [2, 2]
       * // shape.
       * console.log(JSON.stringify(output1.shape));
       *
       * // The output SymbolicTensor of the flatten layer can be used to call
       * // the apply() of the dense layer:
       * const output2 = denseLayer.apply(output1);
       *
       * // output2.shape is [null, 1]. The first dimension is the undetermined
       * // batch size. The second dimension matches the number of units of the
       * // dense layer.
       * console.log(JSON.stringify(output2.shape));
       *
       * // The input and output can be used to construct a model that consists
       * // of the flatten and dense layers.
       * const model = tf.model({inputs: input, outputs: output2});
       * ```
       *
       * @param inputs a `tf.Tensor` or `tf.SymbolicTensor` or an Array of them.
       * @param kwargs Additional keyword arguments to be passed to `call()`.
       *
       * @return Output of the layer's `call` method.
       *
       * @exception ValueError error in case the layer is missing shape information
       *   for its `build` call.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      // Porting Note: This is a replacement for __call__() in Python.
      apply(inputs, kwargs) {
        kwargs = kwargs || {};
        this.assertNotDisposed();
        const inputsList = toList(inputs);
        let allAreSymbolic = true;
        for (const input2 of inputsList) {
          if (!(input2 instanceof SymbolicTensor)) {
            allAreSymbolic = false;
            break;
          }
        }
        let noneAreSymbolic = true;
        for (const input2 of inputsList) {
          if (input2 instanceof SymbolicTensor) {
            noneAreSymbolic = false;
            break;
          }
        }
        if (allAreSymbolic === noneAreSymbolic) {
          throw new ValueError("Arguments to apply() must be all SymbolicTensors or all Tensors");
        }
        return nameScope(this.name, () => {
          if (!this.built) {
            this.assertInputCompatibility(inputs);
            const inputShapes = [];
            for (const xElem of toList(inputs)) {
              inputShapes.push(xElem.shape);
            }
            this.build(singletonOrArray(inputShapes));
            this.built = true;
            if (this.initialWeights) {
              this.setWeights(this.initialWeights);
            }
            if (this._refCount === null && noneAreSymbolic) {
              this._refCount = 1;
            }
          }
          this.assertInputCompatibility(inputs);
          if (noneAreSymbolic) {
            let output = this.call(inputs, kwargs);
            const outputList = toList(output);
            const outputListCopy = [];
            for (let x of outputList) {
              if (inputsList.indexOf(x) !== -1) {
                x = x.clone();
              }
              outputListCopy.push(x);
            }
            output = singletonOrArray(outputListCopy);
            if (this.activityRegularizer != null) {
              throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
            }
            return output;
          } else {
            const inputShape = collectInputShape(inputs);
            const outputShape = this.computeOutputShape(inputShape);
            let output;
            const outputDType = guessOutputDType(inputs);
            this.warnOnIncompatibleInputShape(Array.isArray(inputs) ? inputShape[0] : inputShape);
            if (outputShape != null && outputShape.length > 0 && Array.isArray(outputShape[0])) {
              output = outputShape.map((shape, index) => new SymbolicTensor(outputDType, shape, this, toList(inputs), kwargs, this.name, index));
            } else {
              output = new SymbolicTensor(outputDType, outputShape, this, toList(inputs), kwargs, this.name);
            }
            this.addInboundNode(inputs, output, null, null, inputShape, outputShape, kwargs);
            this._refCount++;
            if (this.activityRegularizer != null) {
              throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
            }
            return output;
          }
        });
      }
      /**
       * Check compatibility between input shape and this layer's batchInputShape.
       *
       * Print warning if any incompatibility is found.
       *
       * @param inputShape Input shape to be checked.
       */
      warnOnIncompatibleInputShape(inputShape) {
        if (this.batchInputShape == null) {
          return;
        } else if (inputShape.length !== this.batchInputShape.length) {
          console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(inputShape)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
        } else {
          let dimMismatch = false;
          this.batchInputShape.forEach((dimension, i) => {
            if (dimension != null && inputShape[i] != null && inputShape[i] !== dimension) {
              dimMismatch = true;
            }
          });
          if (dimMismatch) {
            console.warn(`The shape of the input tensor (${JSON.stringify(inputShape)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`);
          }
        }
      }
      /**
       * Retrieves the output shape(s) of a layer.
       *
       * Only applicable if the layer has only one inbound node, or if all inbound
       * nodes have the same output shape.
       *
       * @returns Output shape or shapes.
       * @throws AttributeError: if the layer is connected to more than one incoming
       *   nodes.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      get outputShape() {
        if (this.inboundNodes == null || this.inboundNodes.length === 0) {
          throw new AttributeError(`The layer ${this.name} has never been called and thus has no defined output shape.`);
        }
        const allOutputShapes = [];
        for (const node of this.inboundNodes) {
          const shapeString = JSON.stringify(node.outputShapes);
          if (allOutputShapes.indexOf(shapeString) === -1) {
            allOutputShapes.push(shapeString);
          }
        }
        if (allOutputShapes.length === 1) {
          const outputShapes = this.inboundNodes[0].outputShapes;
          if (Array.isArray(outputShapes) && Array.isArray(outputShapes[0]) && outputShapes.length === 1) {
            return outputShapes[0];
          } else {
            return outputShapes;
          }
        } else {
          throw new AttributeError(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`);
        }
      }
      /**
       * Counts the total number of numbers (e.g., float32, int32) in the
       * weights.
       *
       * @returns An integer count.
       * @throws RuntimeError: If the layer is not built yet (in which case its
       *   weights are not defined yet.)
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      countParams() {
        if (!this.built) {
          throw new RuntimeError(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
        }
        return countParamsInWeights(this.weights);
      }
      /**
       * Creates the layer weights.
       *
       * Must be implemented on all layers that have weights.
       *
       * Called when apply() is called to construct the weights.
       *
       * @param inputShape A `Shape` or array of `Shape` (unused).
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      build(inputShape) {
        this.built = true;
      }
      /**
       * Returns the current values of the weights of the layer.
       *
       * @param trainableOnly Whether to get the values of only trainable weights.
       * @returns Weight values as an `Array` of `tf.Tensor`s.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      getWeights(trainableOnly = false) {
        return batchGetValue(trainableOnly ? this.trainableWeights : this.weights);
      }
      /**
       * Sets the weights of the layer, from Tensors.
       *
       * @param weights a list of Tensors. The number of arrays and their shape
       *   must match number of the dimensions of the weights of the layer (i.e.
       *   it should match the output of `getWeights`).
       *
       * @exception ValueError If the provided weights list does not match the
       *   layer's specifications.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      setWeights(weights) {
        tidy(() => {
          const params = this.weights;
          if (params.length !== weights.length) {
            throw new ValueError(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${weights.length}, but the layer was expecting ${params.length} weights. Provided weights: ${weights}...`);
          }
          if (params.length === 0) {
            return;
          }
          const weightValueTuples = [];
          const paramValues = batchGetValue(params);
          for (let i = 0; i < paramValues.length; ++i) {
            const pv = paramValues[i];
            const p2 = params[i];
            const w = weights[i];
            if (!util_exports.arraysEqual(pv.shape, w.shape)) {
              throw new ValueError(`Layer weight shape ${pv.shape} not compatible with provided weight shape ${w.shape}`);
            }
            weightValueTuples.push([p2, w]);
          }
          batchSetValue(weightValueTuples);
        });
      }
      /**
       * Adds a weight variable to the layer.
       *
       * @param name Name of the new weight variable.
       * @param shape The shape of the weight.
       * @param dtype The dtype of the weight.
       * @param initializer An initializer instance.
       * @param regularizer A regularizer instance.
       * @param trainable Whether the weight should be trained via backprop or not
       *   (assuming that the layer itself is also trainable).
       * @param constraint An optional trainable.
       * @return The created weight variable.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      addWeight(name, shape, dtype, initializer, regularizer, trainable, constraint, getInitializerFunc) {
        if (this._addedWeightNames.indexOf(name) !== -1) {
          throw new ValueError(`Duplicate weight name ${name} for layer ${this.name}`);
        }
        this._addedWeightNames.push(name);
        if (dtype == null) {
          dtype = "float32";
        }
        if (this.fastWeightInitDuringBuild) {
          initializer = getInitializerFunc != null ? getInitializerFunc() : getInitializer("zeros");
        }
        const initValue = initializer.apply(shape, dtype);
        const weight = new LayerVariable(initValue, dtype, name, trainable, constraint);
        initValue.dispose();
        if (regularizer != null) {
          this.addLoss(() => regularizer.apply(weight.read()));
        }
        if (trainable == null) {
          trainable = true;
        }
        if (trainable) {
          this._trainableWeights.push(weight);
        } else {
          this._nonTrainableWeights.push(weight);
        }
        return weight;
      }
      /**
       * Set the fast-weight-initialization flag.
       *
       * In cases where the initialized weight values will be immediately
       * overwritten by loaded weight values during model loading, setting
       * the flag to `true` saves unnecessary calls to potentially expensive
       * initializers and speeds up the loading process.
       *
       * @param value Target value of the flag.
       */
      setFastWeightInitDuringBuild(value) {
        this.fastWeightInitDuringBuild = value;
      }
      /**
       * Add losses to the layer.
       *
       * The loss may potentially be conditional on some inputs tensors,
       * for instance activity losses are conditional on the layer's inputs.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      addLoss(losses) {
        if (losses == null || Array.isArray(losses) && losses.length === 0) {
          return;
        }
        losses = toList(losses);
        if (this._losses !== void 0 && this._losses !== null) {
          this.losses.push(...losses);
        }
      }
      /**
       * Computes the output shape of the layer.
       *
       * Assumes that the layer will be built to match that input shape provided.
       *
       * @param inputShape A shape (tuple of integers) or a list of shape tuples
       *   (one per output tensor of the layer). Shape tuples can include null for
       *   free dimensions, instead of an integer.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      computeOutputShape(inputShape) {
        return inputShape;
      }
      /**
       * Computes an output mask tensor.
       *
       * @param inputs Tensor or list of tensors.
       * @param mask Tensor or list of tensors.
       *
       * @return null or a tensor (or list of tensors, one per output tensor of the
       * layer).
       */
      computeMask(inputs, mask) {
        if (!this.supportsMasking) {
          if (mask != null) {
            if (Array.isArray(mask)) {
              mask.forEach((maskElement) => {
                if (maskElement != null) {
                  throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
                }
              });
            } else {
              throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
            }
          }
          return null;
        }
        return mask;
      }
      /**
       * Internal method to create an inbound node for the layer.
       *
       * @param inputTensors List of input tensors.
       * @param outputTensors List of output tensors.
       * @param inputMasks List of input masks (a mask can be a tensor, or null).
       * @param outputMasks List of output masks (a mask can be a tensor, or null).
       * @param inputShapes List of input shape tuples.
       * @param outputShapes List of output shape tuples.
       * @param kwargs Dictionary of keyword arguments that were passed to the
       *   `call` method of the layer at the call that created the node.
       */
      addInboundNode(inputTensors, outputTensors, inputMasks, outputMasks, inputShapes, outputShapes, kwargs = null) {
        const inputTensorList = toList(inputTensors);
        outputTensors = toList(outputTensors);
        inputMasks = toList(inputMasks);
        outputMasks = toList(outputMasks);
        inputShapes = normalizeShapeList(inputShapes);
        outputShapes = normalizeShapeList(outputShapes);
        const inboundLayers = [];
        const nodeIndices = [];
        const tensorIndices = [];
        for (const x of inputTensorList) {
          inboundLayers.push(x.sourceLayer);
          nodeIndices.push(x.nodeIndex);
          tensorIndices.push(x.tensorIndex);
        }
        new Node({
          outboundLayer: this,
          inboundLayers,
          nodeIndices,
          tensorIndices,
          inputTensors: inputTensorList,
          outputTensors,
          inputMasks,
          outputMasks,
          inputShapes,
          outputShapes
        }, kwargs);
        for (let i = 0; i < outputTensors.length; i++) {
          outputTensors[i].sourceLayer = this;
          outputTensors[i].nodeIndex = this.inboundNodes.length - 1;
          outputTensors[i].tensorIndex = i;
        }
      }
      /**
       * Returns the config of the layer.
       *
       * A layer config is a TS dictionary (serializable)
       * containing the configuration of a layer.
       * The same layer can be reinstantiated later
       * (without its trained weights) from this configuration.
       *
       * The config of a layer does not include connectivity
       * information, nor the layer class name.  These are handled
       * by 'Container' (one layer of abstraction above).
       *
       * Porting Note: The TS dictionary follows TS naming standards for
       * keys, and uses tfjs-layers type-safe Enums.  Serialization methods
       * should use a helper function to convert to the pythonic storage
       * standard. (see serialization_utils.convertTsToPythonic)
       *
       * @returns TS dictionary of configuration.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      getConfig() {
        const config = { name: this.name, trainable: this.trainable };
        if (this.batchInputShape != null) {
          config["batchInputShape"] = this.batchInputShape;
        }
        if (this.dtype != null) {
          config["dtype"] = this.dtype;
        }
        return config;
      }
      /**
       * Dispose the weight variables that this Layer instance holds.
       *
       * @returns {number} Number of disposed variables.
       */
      disposeWeights() {
        this.weights.forEach((weight) => weight.dispose());
        return this.weights.length;
      }
      assertNotDisposed() {
        if (this._refCount === 0) {
          throw new Error(`Layer '${this.name}' is already disposed.`);
        }
      }
      /**
       * Attempt to dispose layer's weights.
       *
       * This method decreases the reference count of the Layer object by 1.
       *
       * A Layer is reference-counted. Its reference count is incremented by 1
       * the first item its `apply()` method is called and when it becomes a part
       * of a new `Node` (through calling the `apply()` method on a
       * `tf.SymbolicTensor`).
       *
       * If the reference count of a Layer becomes 0, all the weights will be
       * disposed and the underlying memory (e.g., the textures allocated in WebGL)
       * will be freed.
       *
       * Note: If the reference count is greater than 0 after the decrement, the
       * weights of the Layer will *not* be disposed.
       *
       * After a Layer is disposed, it cannot be used in calls such as `apply()`,
       * `getWeights()` or `setWeights()` anymore.
       *
       * @returns A DisposeResult Object with the following fields:
       *   - refCountAfterDispose: The reference count of the Container after this
       *     `dispose()` call.
       *   - numDisposedVariables: Number of `tf.Variable`s (i.e., weights) disposed
       *     during this `dispose()` call.
       * @throws {Error} If the layer is not built yet, or if the layer has already
       *   been disposed.
       *
       * @doc {heading: 'Models', 'subheading': 'Classes'}
       */
      dispose() {
        if (!this.built) {
          throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
        }
        if (this._refCount === null) {
          throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
        }
        this.assertNotDisposed();
        let numDisposedVariables = 0;
        if (--this._refCount === 0) {
          numDisposedVariables = this.disposeWeights();
        }
        return { refCountAfterDispose: this._refCount, numDisposedVariables };
      }
    };
  }
});
function Input(config) {
  if (config.batchShape == null && config.shape == null) {
    throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  }
  if (config.batchShape != null && config.shape != null) {
    throw new ValueError("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  }
  let batchShape = config.batchShape;
  if (config.shape != null && batchShape == null) {
    batchShape = [null].concat(config.shape);
  }
  let dtype = config.dtype;
  if (dtype == null) {
    dtype = "float32";
  }
  const inputLayer = new InputLayer({
    batchInputShape: batchShape,
    name: config.name,
    dtype,
    sparse: config.sparse
  });
  const outputs = inputLayer.inboundNodes[0].outputTensors;
  return outputs[0];
}
var InputLayer;
var init_input_layer = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/input_layer.js"() {
    init_dist();
    init_state();
    init_errors();
    init_topology();
    InputLayer = class extends Layer {
      constructor(args) {
        super({
          dtype: args.dtype,
          name: args.name != null ? args.name : getUid("input").toString()
        });
        if (args.batchSize == null) {
          args.batchSize = null;
        }
        if (args.sparse == null) {
          args.sparse = false;
        }
        this.trainable = false;
        this.built = true;
        this.sparse = args.sparse;
        if (args.inputShape != null && args.batchInputShape != null) {
          throw new ValueError("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
        }
        let batchInputShape = args.batchInputShape;
        if (batchInputShape == null) {
          if (args.inputShape == null) {
            throw new ValueError("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
          } else {
            batchInputShape = [args.batchSize].concat(args.inputShape);
          }
        } else {
          if (args.batchSize != null) {
            throw new ValueError("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
          }
        }
        const dtype = args.dtype || "float32";
        this.batchInputShape = batchInputShape;
        this.dtype = dtype;
        this.inputSpec = [{ shape: batchInputShape }];
        const inputTensor = new SymbolicTensor(this.dtype, this.batchInputShape, this, [], {}, this.name);
        inputTensor.nodeIndex = 0;
        inputTensor.tensorIndex = 0;
        new Node({
          outboundLayer: this,
          inboundLayers: [],
          nodeIndices: [],
          tensorIndices: [],
          inputTensors: [inputTensor],
          outputTensors: [inputTensor],
          inputMasks: [null],
          outputMasks: [null],
          inputShapes: [batchInputShape],
          outputShapes: [batchInputShape]
        });
      }
      apply(inputs, kwargs) {
        throw new ValueError(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`);
      }
      dispose() {
        return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };
      }
      getConfig() {
        return {
          batchInputShape: this.batchInputShape,
          dtype: this.dtype,
          sparse: this.sparse,
          name: this.name
        };
      }
    };
    InputLayer.className = "InputLayer";
    serialization_exports.registerClass(InputLayer);
  }
});
function assertFeedCompatibility(key, val) {
  if (key.dtype == null || key.dtype === val.dtype) {
    return val;
  }
  try {
    return cast(val, key.dtype);
  } catch (err) {
    throw new ValueError(`The dtype of the feed (${val.dtype}) can not be cast to the dtype of the key '${key.name}' (${key.dtype}).`);
  }
}
function updateCacheMaxEntries(maxEntries) {
  if (cachedSorted != null) {
    cachedSorted.setMaxEntries(maxEntries);
  }
  if (cachedRecipientCounts != null) {
    cachedRecipientCounts.setMaxEntries(maxEntries);
  }
}
function execute(fetches, feedDict, kwargs, probe) {
  const training = kwargs == null ? false : kwargs["training"];
  const arrayFetches = Array.isArray(fetches);
  const fetchArray = arrayFetches ? fetches : [fetches];
  const outputNames = fetchArray.map((t) => t.name);
  const finalOutputs = [];
  const feedNames = feedDict.names();
  for (const outputName of outputNames) {
    if (feedNames.indexOf(outputName) !== -1) {
      finalOutputs.push(feedDict.getValue(outputName));
    } else {
      finalOutputs.push(null);
    }
  }
  if (probe != null) {
    probe.maxNumTensors = -Infinity;
    probe.minNumTensors = Infinity;
  }
  const fetchAndFeedKey = outputNames.join(",") + "|" + feedDict.names().sort().join(",");
  let sorted = cachedSorted.get(fetchAndFeedKey);
  let recipientCounts;
  if (sorted == null) {
    const out = getTopologicalSortAndRecipientCounts(fetchArray, feedDict);
    sorted = out.sorted;
    recipientCounts = out.recipientCounts;
    cachedSorted.put(fetchAndFeedKey, sorted);
    cachedRecipientCounts.put(fetchAndFeedKey, recipientCounts);
  }
  recipientCounts = {};
  if (!training) {
    Object.assign(recipientCounts, cachedRecipientCounts.get(fetchAndFeedKey));
  }
  const internalFeedDict = new FeedDict(feedDict);
  for (let i = 0; i < sorted.length; ++i) {
    if (probe != null) {
      const numTensors = memory().numTensors;
      if (numTensors > probe.maxNumTensors) {
        probe.maxNumTensors = numTensors;
      }
      if (numTensors < probe.minNumTensors) {
        probe.minNumTensors = numTensors;
      }
    }
    const symbolic = sorted[i];
    const srcLayer = symbolic.sourceLayer;
    if (srcLayer instanceof InputLayer) {
      continue;
    }
    const inputValues = [];
    const inputMasks = [];
    const tensorsToDispose = [];
    let maskExists = false;
    for (const input2 of symbolic.inputs) {
      const value = internalFeedDict.getValue(input2);
      const mask = internalFeedDict.getMask(input2);
      inputValues.push(value);
      inputMasks.push(mask);
      if (mask != null) {
        maskExists = true;
      }
      if (!training) {
        recipientCounts[input2.name]--;
        if (recipientCounts[input2.name] === 0 && !feedDict.hasKey(input2) && outputNames.indexOf(input2.name) === -1 && !value.isDisposed && input2.sourceLayer.stateful !== true) {
          tensorsToDispose.push(value);
        }
      }
    }
    if (maskExists) {
      kwargs = kwargs || {};
      kwargs["mask"] = inputMasks[0];
    }
    const outputTensors = toList(srcLayer.apply(inputValues, kwargs));
    let outputMask = null;
    if (srcLayer.supportsMasking) {
      outputMask = srcLayer.computeMask(inputValues, inputMasks);
    }
    const layerOutputs = getNodeOutputs(symbolic);
    const outputSymbolicTensors = Array.isArray(layerOutputs) ? layerOutputs : [layerOutputs];
    for (let i2 = 0; i2 < outputSymbolicTensors.length; ++i2) {
      if (!internalFeedDict.hasKey(outputSymbolicTensors[i2])) {
        internalFeedDict.add(outputSymbolicTensors[i2], outputTensors[i2], Array.isArray(outputMask) ? outputMask[0] : outputMask);
      }
      const index = outputNames.indexOf(outputSymbolicTensors[i2].name);
      if (index !== -1) {
        finalOutputs[index] = outputTensors[i2];
      }
    }
    if (!training) {
      dispose(tensorsToDispose);
    }
  }
  internalFeedDict.disposeMasks();
  return arrayFetches ? finalOutputs : finalOutputs[0];
}
function getTopologicalSortAndRecipientCounts(fetches, feedDict) {
  util_exports.assert(fetches != null && fetches.length > 0, () => `Expected at least one fetch, got none`);
  let finalSorted = [];
  let finalRecipientMap = {};
  if (fetches.length === 1) {
    const out = getTopologicalSortAndRecipientCountsForOneFetch(fetches[0], feedDict);
    finalSorted = out.sorted;
    finalRecipientMap = out.recipientMap;
  } else {
    const visited = /* @__PURE__ */ new Set();
    for (const fetch4 of fetches) {
      const { sorted, recipientMap } = getTopologicalSortAndRecipientCountsForOneFetch(fetch4, feedDict);
      for (const symbolicTensor of sorted) {
        if (!visited.has(symbolicTensor.name)) {
          finalSorted.push(symbolicTensor);
          visited.add(symbolicTensor.name);
        }
      }
      for (const name in recipientMap) {
        if (finalRecipientMap[name] == null) {
          finalRecipientMap[name] = /* @__PURE__ */ new Set();
        }
        recipientMap[name].forEach((recipient) => finalRecipientMap[name].add(recipient));
      }
    }
  }
  return {
    sorted: finalSorted,
    recipientCounts: recipientMap2Counts(finalRecipientMap)
  };
}
function recipientMap2Counts(recipientMap) {
  const recipientCounts = {};
  for (const name in recipientMap) {
    recipientCounts[name] = recipientMap[name].size;
  }
  return recipientCounts;
}
function getTopologicalSortAndRecipientCountsForOneFetch(fetch4, feedDict) {
  const visited = /* @__PURE__ */ new Set();
  const sorted = [];
  const recipientMap = {};
  for (const key of feedDict.names()) {
    visited.add(key);
  }
  const stack2 = [];
  const marks = [];
  stack2.push(fetch4);
  while (stack2.length > 0) {
    const top = stack2[stack2.length - 1];
    if (visited.has(top.name)) {
      stack2.pop();
      continue;
    }
    const topIsMarked = marks[marks.length - 1] === stack2.length - 1;
    if (top.inputs.length === 0 || topIsMarked) {
      stack2.pop();
      sorted.push(top);
      visited.add(top.name);
      if (topIsMarked) {
        marks.pop();
      }
    } else {
      marks.push(stack2.length - 1);
      for (const input2 of top.inputs) {
        if (recipientMap[input2.name] == null) {
          recipientMap[input2.name] = /* @__PURE__ */ new Set();
        }
        recipientMap[input2.name].add(top.name);
        if (visited.has(input2.name)) {
          continue;
        }
        stack2.push(input2);
      }
    }
  }
  return { sorted, recipientMap };
}
function getNodeOutputs(fetch4) {
  let layerOutputs;
  if (fetch4.sourceLayer.inboundNodes.length === 1) {
    layerOutputs = fetch4.sourceLayer.output;
  } else {
    let nodeIndex = null;
    for (let i = 0; i < fetch4.sourceLayer.inboundNodes.length; ++i) {
      for (const outputTensor of fetch4.sourceLayer.inboundNodes[i].outputTensors) {
        if (outputTensor.id === fetch4.id) {
          nodeIndex = i;
          break;
        }
      }
    }
    layerOutputs = fetch4.sourceLayer.getOutputAt(nodeIndex);
  }
  return layerOutputs;
}
var FeedDict;
var cachedSorted;
var cachedRecipientCounts;
var init_executor = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/executor.js"() {
    init_dist();
    init_errors();
    init_executor_utils();
    init_generic_utils();
    init_input_layer();
    init_topology();
    FeedDict = class {
      /**
       * Constructor, optionally does copy-construction.
       * @param feeds An Array of `Feed`s, or another `FeedDict`, in which case
       *   copy-construction will be performed.
       */
      constructor(feeds) {
        this.id2Value = {};
        this.id2Mask = {};
        this.name2Id = {};
        if (feeds instanceof FeedDict) {
          for (const id in feeds.id2Value) {
            this.id2Value[id] = feeds.id2Value[id];
            if (id in feeds.id2Mask) {
              this.id2Mask[id] = feeds.id2Mask[id];
            }
          }
        } else {
          if (feeds == null) {
            return;
          }
          for (const feed of feeds) {
            this.add(feed.key, feed.value);
          }
        }
      }
      /**
       * Add a key-value pair to the FeedDict.
       *
       * @param key The key of the feed.
       * @param value The value of the tensor feed.
       * @param mask The value of the mask feed (optional).
       * @returns This `FeedDict`.
       * @throws ValueError: If the key `SymbolicTensor` already exists in the
       *   `FeedDict`.
       */
      add(key, value, mask) {
        if (this.id2Value[key.id] == null) {
          this.id2Value[key.id] = assertFeedCompatibility(key, value);
          this.name2Id[key.name] = key.id;
          if (mask != null) {
            this.id2Mask[key.id] = mask;
          }
        } else {
          throw new ValueError(`Duplicate key: name=${key.name}, id=${key.id}`);
        }
        return this;
      }
      /**
       * Add a Feed to the FeedDict.
       * @param feed The new `Feed` to add.
       * @returns This `FeedDict`.
       */
      addFeed(feed) {
        this.add(feed.key, feed.value);
      }
      /**
       * Probe whether a key already exists in the FeedDict.
       * @param key
       */
      hasKey(key) {
        return this.id2Value[key.id] != null;
      }
      /**
       * Get all the SymbolicTensor available in this FeedDict.
       */
      names() {
        return Object.keys(this.name2Id);
      }
      /**
       * Get the feed value for given key.
       * @param key The SymbolicTensor, or its name (as a string), of which the
       *     value is sought.
       * @returns If `key` exists, the corresponding feed value.
       * @throws ValueError: If `key` does not exist in this `FeedDict`.
       */
      getValue(key) {
        if (key instanceof SymbolicTensor) {
          if (this.id2Value[key.id] == null) {
            throw new ValueError(`Nonexistent key: ${key.name}`);
          } else {
            return this.id2Value[key.id];
          }
        } else {
          const id = this.name2Id[key];
          if (id == null) {
            throw new ValueError(`Feed dict has no SymbolicTensor name: ${key}`);
          }
          return this.id2Value[id];
        }
      }
      /**
       * Get the feed mask for given key.
       * @param key The SymbolicTensor, or its name (as a string), of which the
       *     value is sought.
       * @returns If `key` exists, the corresponding feed mask.
       * @throws ValueError: If `key` does not exist in this `FeedDict`.
       */
      getMask(key) {
        if (key instanceof SymbolicTensor) {
          if (this.id2Value[key.id] == null) {
            throw new ValueError(`Nonexistent key: ${key.name}`);
          } else {
            return this.id2Mask[key.id];
          }
        } else {
          const id = this.name2Id[key];
          if (id == null) {
            throw new ValueError(`Feed dict has no SymbolicTensor name: ${key}`);
          }
          return this.id2Mask[id];
        }
      }
      /** Dispose all mask Tensors held by this object. */
      disposeMasks() {
        if (this.id2Mask != null) {
          dispose(this.id2Mask);
        }
      }
    };
    cachedSorted = new LruCache();
    cachedRecipientCounts = new LruCache();
  }
});
var ENV3;
var init_flags_layers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/flags_layers.js"() {
    init_dist();
    init_executor();
    ENV3 = env();
    ENV3.registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES", () => 100, updateCacheMaxEntries);
  }
});
function calcL2Norms(w, axis) {
  return tidy(() => sqrt(sum2(mul5(w, w), axis, true)));
}
function serializeConstraint(constraint) {
  return serializeKerasObject(constraint);
}
function deserializeConstraint(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "constraint");
}
function getConstraint(identifier) {
  if (identifier == null) {
    return null;
  }
  if (typeof identifier === "string") {
    const className = identifier in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP ? CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
    const config = { className, config: {} };
    return deserializeConstraint(config);
  } else if (identifier instanceof Constraint) {
    return identifier;
  } else {
    return deserializeConstraint(identifier);
  }
}
var Constraint;
var MaxNorm;
var UnitNorm;
var NonNeg;
var MinMaxNorm;
var CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP;
var init_constraints = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/constraints.js"() {
    init_dist();
    init_dist();
    init_common3();
    init_generic_utils();
    Constraint = class extends serialization_exports.Serializable {
      getConfig() {
        return {};
      }
    };
    MaxNorm = class extends Constraint {
      constructor(args) {
        super();
        this.defaultMaxValue = 2;
        this.defaultAxis = 0;
        this.maxValue = args.maxValue != null ? args.maxValue : this.defaultMaxValue;
        this.axis = args.axis != null ? args.axis : this.defaultAxis;
      }
      apply(w) {
        return tidy(() => {
          const norms = calcL2Norms(w, this.axis);
          const desired = clipByValue(norms, 0, this.maxValue);
          return mul5(w, div2(desired, add22(epsilon(), norms)));
        });
      }
      getConfig() {
        return { maxValue: this.maxValue, axis: this.axis };
      }
    };
    MaxNorm.className = "MaxNorm";
    serialization_exports.registerClass(MaxNorm);
    UnitNorm = class extends Constraint {
      constructor(args) {
        super();
        this.defaultAxis = 0;
        this.axis = args.axis != null ? args.axis : this.defaultAxis;
      }
      apply(w) {
        return tidy(() => div2(w, add22(epsilon(), calcL2Norms(w, this.axis))));
      }
      getConfig() {
        return { axis: this.axis };
      }
    };
    UnitNorm.className = "UnitNorm";
    serialization_exports.registerClass(UnitNorm);
    NonNeg = class extends Constraint {
      apply(w) {
        return relu(w);
      }
    };
    NonNeg.className = "NonNeg";
    serialization_exports.registerClass(NonNeg);
    MinMaxNorm = class extends Constraint {
      constructor(args) {
        super();
        this.defaultMinValue = 0;
        this.defaultMaxValue = 1;
        this.defaultRate = 1;
        this.defaultAxis = 0;
        this.minValue = args.minValue != null ? args.minValue : this.defaultMinValue;
        this.maxValue = args.maxValue != null ? args.maxValue : this.defaultMaxValue;
        this.rate = args.rate != null ? args.rate : this.defaultRate;
        this.axis = args.axis != null ? args.axis : this.defaultAxis;
      }
      apply(w) {
        return tidy(() => {
          const norms = calcL2Norms(w, this.axis);
          const desired = add22(mul5(this.rate, clipByValue(norms, this.minValue, this.maxValue)), mul5(1 - this.rate, norms));
          return mul5(w, div2(desired, add22(epsilon(), norms)));
        });
      }
      getConfig() {
        return {
          minValue: this.minValue,
          maxValue: this.maxValue,
          rate: this.rate,
          axis: this.axis
        };
      }
    };
    MinMaxNorm.className = "MinMaxNorm";
    serialization_exports.registerClass(MinMaxNorm);
    CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
      "maxNorm": "MaxNorm",
      "minMaxNorm": "MinMaxNorm",
      "nonNeg": "NonNeg",
      "unitNorm": "UnitNorm"
    };
  }
});
var init_exports_constraints = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports_constraints.js"() {
    init_constraints();
  }
});
var init_exports_initializers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports_initializers.js"() {
    init_initializers();
  }
});
async function resolveScalarsInLogs(logs) {
  if (logs == null) {
    return;
  }
  const promises = [];
  const keys = [];
  const scalarsToDispose = [];
  for (const key in logs) {
    const value = logs[key];
    if (typeof value !== "number") {
      const valueScalar = value;
      promises.push(valueScalar.data());
      keys.push(key);
      scalarsToDispose.push(valueScalar);
    }
  }
  if (promises.length > 0) {
    const values = await Promise.all(promises);
    for (let i = 0; i < values.length; ++i) {
      logs[keys[i]] = values[i][0];
    }
    dispose(scalarsToDispose);
  }
}
function disposeTensorsInLogs(logs) {
  if (logs == null) {
    return;
  }
  for (const key in logs) {
    const value = logs[key];
    if (typeof value !== "number") {
      value.dispose();
    }
  }
}
var init_logs = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/logs.js"() {
    init_dist();
  }
});
function standardizeCallbacks(callbacks2, yieldEvery) {
  if (callbacks2 == null) {
    callbacks2 = {};
  }
  if (callbacks2 instanceof BaseCallback) {
    return [callbacks2];
  }
  if (Array.isArray(callbacks2) && callbacks2[0] instanceof BaseCallback) {
    return callbacks2;
  }
  const callbackConfigs = toList(callbacks2);
  return callbackConfigs.map((callbackConfig) => new CustomCallback(callbackConfig, yieldEvery));
}
function configureCallbacks(callbacks2, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics) {
  const history = new History();
  const actualCallbacks = [
    new BaseLogger(),
    ...CallbackConstructorRegistry.createCallbacks(verbose)
  ];
  if (callbacks2 != null) {
    actualCallbacks.push(...callbacks2);
  }
  actualCallbacks.push(history);
  const callbackList = new CallbackList(actualCallbacks);
  callbackList.setParams({
    epochs,
    initialEpoch,
    samples: numTrainSamples,
    steps: stepsPerEpoch,
    batchSize,
    verbose,
    doValidation,
    metrics: callbackMetrics
  });
  return { callbackList, history };
}
var ModelLoggingVerbosity;
var DEFAULT_YIELD_EVERY_MS;
var BaseCallback;
var CallbackList;
var BaseLogger;
var History;
var CustomCallback;
var CallbackConstructorRegistry;
var init_base_callbacks = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/base_callbacks.js"() {
    init_dist();
    init_errors();
    init_logs();
    init_generic_utils();
    (function(ModelLoggingVerbosity2) {
      ModelLoggingVerbosity2[ModelLoggingVerbosity2["SILENT"] = 0] = "SILENT";
      ModelLoggingVerbosity2[ModelLoggingVerbosity2["VERBOSE"] = 1] = "VERBOSE";
    })(ModelLoggingVerbosity || (ModelLoggingVerbosity = {}));
    DEFAULT_YIELD_EVERY_MS = 125;
    BaseCallback = class {
      constructor() {
        this.validationData = null;
      }
      setParams(params) {
        this.params = params;
      }
      async onEpochBegin(epoch, logs) {
      }
      async onEpochEnd(epoch, logs) {
      }
      async onBatchBegin(batch, logs) {
      }
      async onBatchEnd(batch, logs) {
      }
      async onTrainBegin(logs) {
      }
      async onTrainEnd(logs) {
      }
      // LayersModel needs to call Callback.setModel(), but cannot actually depend
      // on Callback because that creates a cyclic dependency.  Providing this no-op
      // method on BaseCallback breaks the cycle: this way LayersModel can depend on
      // BaseCallback but not on Callback.  The argument is typed as `Container`
      // (the superclass of LayersModel) to avoid recapitulating the cycle. Callback
      // overrides this method and enforces that the argument is really a
      // LayersModel.
      setModel(model2) {
      }
    };
    CallbackList = class {
      // TODO(cais): When the need arises, uncomment the following lines and
      // implement the queue for time values.
      // private deltaTBatch: number;
      // private deltaTsBatchBegin: Array<number>;
      // private deltaTsBatchEnd: Array<number>;
      /**
       * Constructor of CallbackList.
       * @param callbacks Array of `Callback` instances.
       * @param queueLength Queue length for keeping running statistics over
       *   callback execution time.
       */
      constructor(callbacks2, queueLength = 10) {
        if (callbacks2 == null) {
          callbacks2 = [];
        }
        this.callbacks = callbacks2;
        this.queueLength = queueLength;
      }
      append(callback) {
        this.callbacks.push(callback);
      }
      setParams(params) {
        for (const callback of this.callbacks) {
          callback.setParams(params);
        }
      }
      setModel(model2) {
        for (const callback of this.callbacks) {
          callback.setModel(model2);
        }
      }
      /**
       * Called at the start of an epoch.
       * @param epoch Index of epoch.
       * @param logs Dictionary of logs.
       */
      async onEpochBegin(epoch, logs) {
        if (logs == null) {
          logs = {};
        }
        for (const callback of this.callbacks) {
          await callback.onEpochBegin(epoch, logs);
        }
      }
      /**
       * Called at the end of an epoch.
       * @param epoch Index of epoch.
       * @param logs Dictionary of logs.
       */
      async onEpochEnd(epoch, logs) {
        if (logs == null) {
          logs = {};
        }
        for (const callback of this.callbacks) {
          await callback.onEpochEnd(epoch, logs);
        }
      }
      /**
       * Called  right before processing a batch.
       * @param batch Index of batch within the current epoch.
       * @param logs Dictionary of logs.
       */
      async onBatchBegin(batch, logs) {
        if (logs == null) {
          logs = {};
        }
        for (const callback of this.callbacks) {
          await callback.onBatchBegin(batch, logs);
        }
      }
      /**
       * Called at the end of a batch.
       * @param batch Index of batch within the current epoch.
       * @param logs Dictionary of logs.
       */
      async onBatchEnd(batch, logs) {
        if (logs == null) {
          logs = {};
        }
        for (const callback of this.callbacks) {
          await callback.onBatchEnd(batch, logs);
        }
      }
      /**
       * Called at the beginning of training.
       * @param logs Dictionary of logs.
       */
      async onTrainBegin(logs) {
        if (logs == null) {
          logs = {};
        }
        for (const callback of this.callbacks) {
          await callback.onTrainBegin(logs);
        }
      }
      /**
       * Called at the end of training.
       * @param logs Dictionary of logs.
       */
      async onTrainEnd(logs) {
        if (logs == null) {
          logs = {};
        }
        for (const callback of this.callbacks) {
          await callback.onTrainEnd(logs);
        }
      }
    };
    BaseLogger = class extends BaseCallback {
      constructor() {
        super();
      }
      async onEpochBegin(epoch) {
        this.seen = 0;
        this.totals = {};
      }
      async onBatchEnd(batch, logs) {
        if (logs == null) {
          logs = {};
        }
        const batchSize = logs["size"] == null ? 0 : logs["size"];
        this.seen += batchSize;
        for (const key in logs) {
          const value = logs[key];
          if (typeof value === "number") {
            if (!this.totals.hasOwnProperty(key)) {
              this.totals[key] = 0;
            }
            this.totals[key] = this.totals[key] + value * batchSize;
          } else {
            let oldTotalsToDispose;
            if (key in this.totals) {
              oldTotalsToDispose = this.totals[key];
            } else {
              this.totals[key] = 0;
            }
            const total = tidy(() => add22(this.totals[key], mul5(value, batchSize)));
            this.totals[key] = total;
            if (oldTotalsToDispose != null) {
              oldTotalsToDispose.dispose();
            }
          }
        }
      }
      async onEpochEnd(epoch, logs) {
        if (logs != null) {
          for (const key of this.params["metrics"]) {
            if (this.totals[key] == null) {
              continue;
            }
            if (typeof this.totals[key] === "number") {
              logs[key] = this.totals[key] / this.seen;
            } else {
              tidy(() => {
                const log5 = mul5(div2(1, this.seen), this.totals[key]);
                logs[key] = log5;
                this.totals[key].dispose();
                keep(logs[key]);
              });
            }
          }
        }
      }
    };
    History = class extends BaseCallback {
      async onTrainBegin(logs) {
        this.epoch = [];
        this.history = {};
      }
      async onEpochEnd(epoch, logs) {
        if (logs == null) {
          logs = {};
        }
        this.epoch.push(epoch);
        for (const key in logs) {
          if (this.history[key] == null) {
            this.history[key] = [];
          }
          this.history[key].push(logs[key]);
        }
      }
      /**
       * Await the values of all losses and metrics.
       */
      async syncData() {
        const promises = [];
        const keys = [];
        const indices = [];
        for (const key in this.history) {
          const valueArray = this.history[key];
          for (let i = 0; i < valueArray.length; ++i) {
            if (typeof valueArray[i] !== "number") {
              const valueScalar = valueArray[i];
              promises.push(valueScalar.data());
              keys.push(key);
              indices.push(i);
            }
          }
        }
        const values = await Promise.all(promises);
        for (let n = 0; n < values.length; ++n) {
          const tensorToDispose = this.history[keys[n]][indices[n]];
          tensorToDispose.dispose();
          this.history[keys[n]][indices[n]] = values[n][0];
        }
      }
    };
    CustomCallback = class extends BaseCallback {
      constructor(args, yieldEvery) {
        super();
        this.currentEpoch = 0;
        this.nowFunc = args.nowFunc;
        this.nextFrameFunc = args.nextFrameFunc || nextFrame;
        this.yieldEvery = yieldEvery || "auto";
        if (this.yieldEvery === "auto") {
          this.yieldEvery = DEFAULT_YIELD_EVERY_MS;
        }
        if (this.yieldEvery === "never" && args.onYield != null) {
          throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
        }
        if (util_exports.isNumber(this.yieldEvery)) {
          this.maybeWait = debounce(this.maybeWait.bind(this), this.yieldEvery, this.nowFunc);
        }
        this.trainBegin = args.onTrainBegin;
        this.trainEnd = args.onTrainEnd;
        this.epochBegin = args.onEpochBegin;
        this.epochEnd = args.onEpochEnd;
        this.batchBegin = args.onBatchBegin;
        this.batchEnd = args.onBatchEnd;
        this.yield = args.onYield;
      }
      async maybeWait(epoch, batch, logs) {
        const ps = [];
        if (this.yield != null) {
          await resolveScalarsInLogs(logs);
          ps.push(this.yield(epoch, batch, logs));
        }
        ps.push(this.nextFrameFunc());
        await Promise.all(ps);
      }
      async onEpochBegin(epoch, logs) {
        this.currentEpoch = epoch;
        if (this.epochBegin != null) {
          await resolveScalarsInLogs(logs);
          await this.epochBegin(epoch, logs);
        }
      }
      async onEpochEnd(epoch, logs) {
        const ps = [];
        if (this.epochEnd != null) {
          await resolveScalarsInLogs(logs);
          ps.push(this.epochEnd(epoch, logs));
        }
        if (this.yieldEvery === "epoch") {
          ps.push(this.nextFrameFunc());
        }
        await Promise.all(ps);
      }
      async onBatchBegin(batch, logs) {
        if (this.batchBegin != null) {
          await resolveScalarsInLogs(logs);
          await this.batchBegin(batch, logs);
        }
      }
      async onBatchEnd(batch, logs) {
        const ps = [];
        if (this.batchEnd != null) {
          await resolveScalarsInLogs(logs);
          ps.push(this.batchEnd(batch, logs));
        }
        if (this.yieldEvery === "batch") {
          ps.push(this.nextFrameFunc());
        } else if (util_exports.isNumber(this.yieldEvery)) {
          ps.push(this.maybeWait(this.currentEpoch, batch, logs));
        }
        await Promise.all(ps);
      }
      async onTrainBegin(logs) {
        if (this.trainBegin != null) {
          await resolveScalarsInLogs(logs);
          await this.trainBegin(logs);
        }
      }
      async onTrainEnd(logs) {
        if (this.trainEnd != null) {
          await resolveScalarsInLogs(logs);
          await this.trainEnd(logs);
        }
      }
    };
    CallbackConstructorRegistry = class {
      /**
       * Blocks public access to constructor.
       */
      constructor() {
      }
      /**
       * Register a tf.LayersModel.fit() callback constructor.
       *
       * The registered callback constructor will be used to instantiate
       * callbacks for every tf.LayersModel.fit() call afterwards.
       *
       * @param verbosityLevel Level of verbosity at which the `callbackConstructor`
       *   is to be reigstered.
       * @param callbackConstructor A no-arg constructor for `tf.Callback`.
       * @throws Error, if the same callbackConstructor has been registered before,
       *   either at the same or a different `verbosityLevel`.
       */
      static registerCallbackConstructor(verbosityLevel, callbackConstructor) {
        util_exports.assert(verbosityLevel >= 0 && Number.isInteger(verbosityLevel), () => `Verbosity level is expected to be an integer >= 0, but got ${verbosityLevel}`);
        CallbackConstructorRegistry.checkForDuplicate(callbackConstructor);
        if (CallbackConstructorRegistry.constructors[verbosityLevel] == null) {
          CallbackConstructorRegistry.constructors[verbosityLevel] = [];
        }
        CallbackConstructorRegistry.constructors[verbosityLevel].push(callbackConstructor);
      }
      static checkForDuplicate(callbackConstructor) {
        for (const levelName in CallbackConstructorRegistry.constructors) {
          const constructors = CallbackConstructorRegistry.constructors[+levelName];
          constructors.forEach((ctor) => {
            if (ctor === callbackConstructor) {
              throw new ValueError("Duplicate callback constructor.");
            }
          });
        }
      }
      /**
       * Clear all registered callback constructors.
       */
      static clear() {
        CallbackConstructorRegistry.constructors = {};
      }
      /**
       * Create callbacks using the registered callback constructors.
       *
       * Given `verbosityLevel`, all constructors registered at that level or above
       * will be called and the instantiated callbacks will be used.
       *
       * @param verbosityLevel: Level of verbosity.
       */
      static createCallbacks(verbosityLevel) {
        const constructors = [];
        for (const levelName in CallbackConstructorRegistry.constructors) {
          const level = +levelName;
          if (verbosityLevel >= level) {
            constructors.push(...CallbackConstructorRegistry.constructors[level]);
          }
        }
        return constructors.map((ctor) => new ctor());
      }
    };
    CallbackConstructorRegistry.constructors = {};
  }
});
function deserialize(config, customObjects = {}, fastWeightInit = false) {
  return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "layer", fastWeightInit);
}
var init_serialization2 = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/serialization.js"() {
    init_dist();
    init_generic_utils();
  }
});
function l2Normalize(x, axis) {
  return tidy(() => {
    if (x.dtype !== "float32") {
      x = cast(x, "float32");
    }
    const squareSum = sum2(square2(x), axis, true);
    const epsilonTensor = fill(squareSum.shape, epsilon());
    const norm2 = sqrt(maximum(squareSum, epsilonTensor));
    return div2(x, norm2);
  });
}
function meanSquaredError(yTrue, yPred) {
  return tidy(() => mean(square2(sub3(yPred, yTrue)), -1));
}
function meanAbsoluteError(yTrue, yPred) {
  return tidy(() => mean(abs(sub3(yPred, yTrue)), -1));
}
function meanAbsolutePercentageError(yTrue, yPred) {
  return tidy(() => {
    const diff = sub3(yTrue, yPred);
    const clippedTrue = clipByValue(abs(yTrue), epsilon(), Number.MAX_VALUE);
    const absResult = abs(div2(diff, clippedTrue));
    return mul5(100, mean(absResult, -1));
  });
}
function meanSquaredLogarithmicError(yTrue, yPred) {
  return tidy(() => {
    const clippedPred = clipByValue(yPred, epsilon(), Number.MAX_VALUE);
    const firstLog = log2(add22(1, clippedPred));
    const clippedTrue = clipByValue(yTrue, epsilon(), Number.MAX_VALUE);
    const secondLog = log2(add22(1, clippedTrue));
    return mean(square2(sub3(firstLog, secondLog)), -1);
  });
}
function squaredHinge(yTrue, yPred) {
  return tidy(() => {
    const maxResult = maximum(0, sub3(1, mul5(yTrue, yPred)));
    return mean(square2(maxResult), -1);
  });
}
function hinge(yTrue, yPred) {
  return tidy(() => {
    const maxResult = maximum(0, sub3(1, mul5(yTrue, yPred)));
    return mean(maxResult, -1);
  });
}
function categoricalHinge(yTrue, yPred) {
  return tidy(() => {
    const pos = sum2(mul5(yTrue, yPred), -1);
    const neg4 = max2(mul5(sub3(1, yTrue), yPred), -1);
    return maximum(0, add22(1, sub3(neg4, pos)));
  });
}
function logcosh(yTrue, yPred) {
  return tidy(() => {
    const log22 = Math.log(2);
    const predictionDiff = sub3(yPred, yTrue);
    const logcoshResult = sub3(add22(predictionDiff, softplus(mul5(-2, predictionDiff))), log22);
    return mean(logcoshResult, -1);
  });
}
function categoricalCrossentropy(target, output, fromLogits = false) {
  return tidy(() => {
    if (fromLogits) {
      output = softmax(output);
    } else {
      const outputSum = sum2(output, output.shape.length - 1, true);
      output = div2(output, outputSum);
    }
    output = clipByValue(output, epsilon(), 1 - epsilon());
    return neg(sum2(mul5(cast(target, "float32"), log2(output)), output.shape.length - 1));
  });
}
function sparseCategoricalCrossentropy(target, output, fromLogits = false) {
  return tidy(() => {
    const flatTarget = cast(floor2(flatten2(target)), "int32");
    output = clipByValue(output, epsilon(), 1 - epsilon());
    const outputShape = output.shape;
    const oneHotTarget = reshape(oneHot(flatTarget, outputShape[outputShape.length - 1]), outputShape);
    return categoricalCrossentropy(oneHotTarget, output, fromLogits);
  });
}
function sigmoidCrossEntropyWithLogits(labels, logits) {
  if (!util_exports.arraysEqual(labels.shape, logits.shape)) {
    throw new ValueError(`logits and labels must have the same shape, but got shapes ${JSON.stringify(labels.shape)} and ${JSON.stringify(logits.shape)}`);
  }
  return tidy(() => {
    const reluLogits = relu(logits);
    const negAbsLogits = neg(abs(logits));
    return add22(sub3(reluLogits, mul5(logits, labels)), log1p(exp2(negAbsLogits)));
  });
}
function binaryCrossentropy(yTrue, yPred) {
  return tidy(() => {
    let y;
    y = clipByValue(yPred, epsilon(), 1 - epsilon());
    y = log2(div2(y, sub3(1, y)));
    return mean(sigmoidCrossEntropyWithLogits(yTrue, y), -1);
  });
}
function kullbackLeiblerDivergence(yTrue, yPred) {
  return tidy(() => {
    const clippedTrue = clipByValue(yTrue, epsilon(), 1);
    const clippedPred = clipByValue(yPred, epsilon(), 1);
    return sum2(mul5(yTrue, log2(div2(clippedTrue, clippedPred))), -1);
  });
}
function poisson(yTrue, yPred) {
  return tidy(() => {
    const logPred = log2(add22(epsilon(), yPred));
    return mean(sub3(yPred, mul5(yTrue, logPred)), -1);
  });
}
function cosineProximity(yTrue, yPred) {
  return tidy(() => {
    const trueNormalized = l2Normalize(yTrue, -1);
    const predNormalized = l2Normalize(yPred, -1);
    const trueXPred = mul5(trueNormalized, predNormalized);
    return neg(sum2(trueXPred, -1));
  });
}
function get(identifierOrFn) {
  if (typeof identifierOrFn === "string") {
    if (identifierOrFn in lossesMap) {
      return lossesMap[identifierOrFn];
    }
    let errMsg = `Unknown loss ${identifierOrFn}`;
    if (identifierOrFn.toLowerCase().includes("softmaxcrossentropy")) {
      errMsg = `Unknown loss ${identifierOrFn}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`;
    }
    throw new ValueError(errMsg);
  } else {
    return identifierOrFn;
  }
}
var lossesMap;
var init_losses = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/losses.js"() {
    init_dist();
    init_dist();
    init_common3();
    init_tfjs_backend();
    init_errors();
    lossesMap = {
      meanSquaredError,
      meanAbsoluteError,
      meanAbsolutePercentageError,
      meanSquaredLogarithmicError,
      squaredHinge,
      hinge,
      categoricalHinge,
      logcosh,
      categoricalCrossentropy,
      sparseCategoricalCrossentropy,
      binaryCrossentropy,
      kullbackLeiblerDivergence,
      poisson,
      cosineProximity
    };
  }
});
function binaryAccuracy(yTrue, yPred) {
  return tidy(() => {
    const threshold3 = mul5(0.5, onesLike(yPred));
    const yPredThresholded = cast2(greater(yPred, threshold3), yTrue.dtype);
    return mean(equal(yTrue, yPredThresholded), -1);
  });
}
function categoricalAccuracy(yTrue, yPred) {
  return tidy(() => cast2(equal(argMax(yTrue, -1), argMax(yPred, -1)), "float32"));
}
function truePositives(yTrue, yPred) {
  return tidy(() => {
    return cast(sum2(logicalAnd(equal(yTrue, 1), equal(yPred, 1))), "float32");
  });
}
function falsePositives(yTrue, yPred) {
  return tidy(() => {
    return cast(sum2(logicalAnd(equal(yTrue, 0), equal(yPred, 1))), "float32");
  });
}
function precision(yTrue, yPred) {
  return tidy(() => {
    const tp = truePositives(yTrue, yPred);
    const fp = falsePositives(yTrue, yPred);
    const denominator = add22(tp, fp);
    return cast(where(greater(denominator, 0), div2(tp, denominator), 0), "float32");
  });
}
function binaryCrossentropy2(yTrue, yPred) {
  return binaryCrossentropy(yTrue, yPred);
}
function sparseCategoricalAccuracy(yTrue, yPred) {
  if (yTrue.rank === yPred.rank) {
    yTrue = squeeze(yTrue, [yTrue.rank - 1]);
  }
  yPred = argMax(yPred, -1);
  if (yPred.dtype !== yTrue.dtype) {
    yPred = cast(yPred, yTrue.dtype);
  }
  return cast(equal(yTrue, yPred), "float32");
}
function get2(identifier) {
  if (typeof identifier === "string" && identifier in metricsMap) {
    return metricsMap[identifier];
  } else if (typeof identifier !== "string" && identifier != null) {
    return identifier;
  } else {
    throw new ValueError(`Unknown metric ${identifier}`);
  }
}
function getLossOrMetricName(fn) {
  assert2(fn !== null, `Unknown LossOrMetricFn ${fn}`);
  if (typeof fn === "string") {
    return fn;
  } else {
    let fnName;
    for (const key of Object.keys(lossesMap)) {
      if (lossesMap[key] === fn) {
        fnName = key;
        break;
      }
    }
    if (fnName !== void 0) {
      return fnName;
    }
    for (const key of Object.keys(metricsMap)) {
      if (metricsMap[key] === fn) {
        fnName = key;
        break;
      }
    }
    if (fnName !== void 0) {
      return fnName;
    }
    return fn.name;
  }
}
var mse;
var MSE;
var mae;
var MAE;
var mape;
var MAPE;
var categoricalCrossentropy2;
var cosine;
var sparseCategoricalCrossentropy2;
var metricsMap;
var init_metrics = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/metrics.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_errors();
    init_losses();
    init_losses();
    init_losses();
    init_generic_utils();
    mse = meanSquaredError;
    MSE = meanSquaredError;
    mae = meanAbsoluteError;
    MAE = meanAbsoluteError;
    mape = meanAbsolutePercentageError;
    MAPE = meanAbsolutePercentageError;
    categoricalCrossentropy2 = categoricalCrossentropy;
    cosine = cosineProximity;
    sparseCategoricalCrossentropy2 = sparseCategoricalCrossentropy;
    metricsMap = {
      binaryAccuracy,
      categoricalAccuracy,
      precision,
      categoricalCrossentropy: categoricalCrossentropy2,
      sparseCategoricalCrossentropy: sparseCategoricalCrossentropy2,
      mse,
      MSE,
      mae,
      MAE,
      mape,
      MAPE,
      cosine
    };
  }
});
function getOptimizer(identifier) {
  const optimizerMap = {
    "Adagrad": () => train.adagrad(0.01),
    "Adadelta": () => train.adadelta(1, 0.95, epsilon()),
    "Adam": () => train.adam(1e-3, 0.9, 0.999, epsilon()),
    "Adamax": () => train.adamax(2e-3, 0.9, 0.999, epsilon(), 0),
    "RMSProp": () => train.rmsprop(1e-3, 0.9, 0, epsilon()),
    "SGD": () => train.sgd(0.01)
  };
  optimizerMap["adagrad"] = optimizerMap["Adagrad"];
  optimizerMap["adadelta"] = optimizerMap["Adadelta"];
  optimizerMap["adam"] = optimizerMap["Adam"];
  optimizerMap["adamax"] = optimizerMap["Adamax"];
  optimizerMap["rmsprop"] = optimizerMap["RMSProp"];
  optimizerMap["sgd"] = optimizerMap["SGD"];
  if (identifier in optimizerMap) {
    return optimizerMap[identifier]();
  }
  throw new ValueError(`Unknown Optimizer ${identifier}`);
}
var init_optimizers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/optimizers.js"() {
    init_dist();
    init_common3();
    init_errors();
  }
});
function checkUserDefinedMetadata(userDefinedMetadata, modelName, checkSize = false) {
  if (userDefinedMetadata == null || typeof userDefinedMetadata !== "object" || Object.getPrototypeOf(userDefinedMetadata) !== Object.prototype || !plainObjectCheck(userDefinedMetadata)) {
    throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
  }
  if (checkSize) {
    const out = JSON.stringify(userDefinedMetadata);
    if (out.length > MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH) {
      console.warn(`User-defined metadata of model "${modelName}" is too large in size (length=${out.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH}.`);
    }
  }
}
function plainObjectCheck(x) {
  if (x === null) {
    return true;
  } else if (typeof x === "object") {
    if (Object.getPrototypeOf(x) === Object.prototype) {
      const keys = Object.keys(x);
      for (const key of keys) {
        if (typeof key !== "string") {
          return false;
        }
        if (!plainObjectCheck(x[key])) {
          return false;
        }
      }
      return true;
    } else {
      if (Array.isArray(x)) {
        for (const item of x) {
          if (!plainObjectCheck(item)) {
            return false;
          }
        }
        return true;
      } else {
        return false;
      }
    }
  } else {
    const xType = typeof x;
    return xType === "string" || xType === "number" || xType === "boolean";
  }
}
var MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH;
var init_user_defined_metadata = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/user_defined_metadata.js"() {
    MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH = 1 * 1024 * 1024;
  }
});
function printSummary(model2, lineLength, positions, printFn = console.log) {
  const sequentialLike = isModelSequentialLike(model2);
  const toDisplay = ["Layer (type)", "Input Shape", "Output shape", "Param #"];
  if (sequentialLike) {
    lineLength = lineLength || 90;
    positions = positions || [0.32, 0.61, 0.89, 1];
  } else {
    lineLength = lineLength || 115;
    positions = positions || [0.24, 0.48, 0.7, 0.8, 1];
  }
  if (positions[positions.length - 1] <= 1) {
    positions = positions.map((p2) => Math.floor(lineLength * p2));
  }
  let relevantNodes;
  if (!sequentialLike) {
    toDisplay.push("Receives inputs");
    relevantNodes = [];
    for (const depth in model2.nodesByDepth) {
      relevantNodes.push(...model2.nodesByDepth[depth]);
    }
  }
  printFn("_".repeat(lineLength));
  printRow(toDisplay, positions, printFn);
  printFn("=".repeat(lineLength));
  const layers = model2.layers;
  for (let i = 0; i < layers.length; ++i) {
    if (sequentialLike) {
      printLayerSummary(layers[i], positions, printFn);
    } else {
      printLayerSummaryWithConnections(layers[i], positions, relevantNodes, printFn);
    }
    printFn((i === layers.length - 1 ? "=" : "_").repeat(lineLength));
  }
  model2.checkTrainableWeightsConsistency();
  const trainableCount = countTrainableParams(model2);
  const nonTrainableCount = countParamsInWeights(model2.nonTrainableWeights);
  printFn(`Total params: ${trainableCount + nonTrainableCount}`);
  printFn(`Trainable params: ${trainableCount}`);
  printFn(`Non-trainable params: ${nonTrainableCount}`);
  printFn("_".repeat(lineLength));
}
function countTrainableParams(model2) {
  let trainableCount;
  if (model2.collectedTrainableWeights != null) {
    trainableCount = countParamsInWeights(model2.collectedTrainableWeights);
  } else {
    trainableCount = countParamsInWeights(model2.trainableWeights);
  }
  return trainableCount;
}
function isModelSequentialLike(model2) {
  let sequentialLike = true;
  const nodesByDepth = [];
  const nodes = [];
  for (const depth in model2.nodesByDepth) {
    nodesByDepth.push(model2.nodesByDepth[depth]);
  }
  for (const depthNodes of nodesByDepth) {
    if (depthNodes.length > 1 || depthNodes.length === 1 && depthNodes[0].inboundLayers.length > 1) {
      sequentialLike = false;
      break;
    }
    nodes.push(...depthNodes);
  }
  if (sequentialLike) {
    for (const layer of model2.layers) {
      let flag = false;
      for (const node of layer.inboundNodes) {
        if (nodes.indexOf(node) !== -1) {
          if (flag) {
            sequentialLike = false;
            break;
          } else {
            flag = true;
          }
        }
      }
      if (!sequentialLike) {
        break;
      }
    }
  }
  return sequentialLike;
}
function printRow(fields, positions, printFn = console.log) {
  let line = "";
  for (let i = 0; i < fields.length; ++i) {
    if (i > 0) {
      line = line.slice(0, line.length - 1) + " ";
    }
    line += fields[i];
    line = line.slice(0, positions[i]);
    line += " ".repeat(positions[i] - line.length);
  }
  printFn(line);
}
function printLayerSummary(layer, positions, printFn) {
  let outputShape;
  let inputShape;
  try {
    inputShape = layer.inboundNodes.map((x) => JSON.stringify(x.inputShapes)).join(",");
  } catch (err) {
    inputShape = "multiple";
  }
  try {
    outputShape = JSON.stringify(layer.outputShape);
  } catch (err) {
    outputShape = "multiple";
  }
  const name = layer.name;
  const className = layer.getClassName();
  const fields = [
    `${name} (${className})`,
    inputShape,
    outputShape,
    layer.countParams().toString()
  ];
  printRow(fields, positions, printFn);
}
function printLayerSummaryWithConnections(layer, positions, relevantNodes, printFn) {
  let outputShape;
  let inputShape;
  try {
    inputShape = layer.inboundNodes.map((x) => JSON.stringify(x.inputShapes)).join(",");
  } catch (err) {
    inputShape = "multiple";
  }
  try {
    outputShape = JSON.stringify(layer.outputShape);
  } catch (err) {
    outputShape = "multiple";
  }
  const connections = [];
  for (const node of layer.inboundNodes) {
    if (relevantNodes != null && relevantNodes.length > 0 && relevantNodes.indexOf(node) === -1) {
      continue;
    }
    for (let i = 0; i < node.inboundLayers.length; ++i) {
      const inboundLayer = node.inboundLayers[i].name;
      const inboundLayerIndex = node.nodeIndices[i];
      const inboundTensorIndex = node.tensorIndices[i];
      connections.push(`${inboundLayer}[${inboundLayerIndex}][${inboundTensorIndex}]`);
    }
  }
  const name = layer.name;
  const className = layer.getClassName();
  const firstConnection = connections.length === 0 ? "" : connections[0];
  const fields = [
    `${name} (${className})`,
    inputShape,
    outputShape,
    layer.countParams().toString(),
    firstConnection
  ];
  printRow(fields, positions, printFn);
  for (let i = 1; i < connections.length; ++i) {
    printRow(["", "", "", "", connections[i]], positions, printFn);
  }
}
var init_layer_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/layer_utils.js"() {
    init_variable_utils();
  }
});
function isArrayItemInputOrOutputName(key, index, value) {
  return (key === "inboundNodes" || key === "outputLayers" || key === "inputLayers") && index === 0 && typeof value === "string";
}
function convertPythonicToTs(pythonicConfig, key) {
  if (pythonicConfig === null) {
    return null;
  } else if (typeof pythonicConfig === "string") {
    return toCamelCase(pythonicConfig);
  } else if (typeof pythonicConfig === "number" || typeof pythonicConfig === "boolean") {
    return pythonicConfig;
  } else if (pythonicConfig instanceof Array) {
    const tsArray = [];
    const arrayLength = pythonicConfig.length;
    for (let i = 0; i < arrayLength; ++i) {
      const item = pythonicConfig[i];
      if (isArrayItemInputOrOutputName(key, i, item)) {
        tsArray.push(item);
      } else {
        tsArray.push(convertPythonicToTs(item, key));
      }
    }
    return tsArray;
  } else {
    const tsDict = {};
    for (const pythonicKey of Object.keys(pythonicConfig)) {
      const pythonicValue = pythonicConfig[pythonicKey];
      if (pythonicKey === "name" && typeof pythonicValue === "string") {
        tsDict[pythonicKey] = pythonicValue;
      } else {
        const tsKey = toCamelCase(pythonicKey);
        tsDict[tsKey] = convertPythonicToTs(pythonicValue, tsKey);
      }
    }
    return tsDict;
  }
}
function convertTsToPythonic(tsConfig, key) {
  if (tsConfig === null || tsConfig === void 0) {
    return null;
  } else if (typeof tsConfig === "string") {
    return toSnakeCase(tsConfig);
  } else if (typeof tsConfig === "number" || typeof tsConfig === "boolean") {
    return tsConfig;
  } else if (tsConfig instanceof Array) {
    const pyArray = [];
    const arrayLength = tsConfig.length;
    for (let i = 0; i < arrayLength; ++i) {
      const item = tsConfig[i];
      if (isArrayItemInputOrOutputName(key, i, item)) {
        pyArray.push(item);
      } else {
        pyArray.push(convertTsToPythonic(item, key));
      }
    }
    return pyArray;
  } else {
    const pyDict = {};
    for (const tsKey of Object.keys(tsConfig)) {
      const tsValue = tsConfig[tsKey];
      const pyKey = toSnakeCase(tsKey);
      if ((tsKey === "name" || tsKey === "className") && typeof tsValue === "string") {
        pyDict[pyKey] = tsValue;
      } else {
        pyDict[pyKey] = convertTsToPythonic(tsValue, tsKey);
      }
    }
    return pyDict;
  }
}
var init_serialization_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/serialization_utils.js"() {
    init_generic_utils();
  }
});
var version;
var init_version = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/version.js"() {
    version = "4.2.0";
  }
});
var Container;
var init_container = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/container.js"() {
    init_dist();
    init_state();
    init_errors();
    init_serialization2();
    init_generic_utils();
    init_serialization_utils();
    init_types_utils();
    init_variables();
    init_version();
    init_executor();
    init_input_layer();
    init_topology();
    Container = class extends Layer {
      constructor(args) {
        super({});
        this.containerNodes = /* @__PURE__ */ new Set();
        this.name = args.name;
        if (this.name == null) {
          const prefix = this.getClassName().toLowerCase();
          this.name = getUid(prefix);
        }
        this.supportsMasking = false;
        this.trainable_ = true;
        if (Array.isArray(args.inputs)) {
          this.inputs = args.inputs.slice();
        } else {
          this.inputs = [args.inputs];
        }
        if (Array.isArray(args.outputs)) {
          this.outputs = args.outputs.slice();
        } else {
          this.outputs = [args.outputs];
        }
        if (unique2(this.inputs).length !== this.inputs.length) {
          throw new ValueError(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((x) => x.name)}`);
        }
        if (unique2(this.outputs).length !== this.outputs.length) {
          console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((x) => x.name)}`);
        }
        this.inputLayers = [];
        this.inputLayersNodeIndices = [];
        this.inputLayersTensorIndices = [];
        this.outputLayers = [];
        this.outputLayersNodeIndices = [];
        this.outputLayersTensorIndices = [];
        this.layers = [];
        this.internalContainerRefs = [];
        for (const x of this.outputs) {
          const layer = x.sourceLayer;
          const nodeIndex = x.nodeIndex;
          const tensorIndex = x.tensorIndex;
          this.outputLayers.push(layer);
          this.outputLayersNodeIndices.push(nodeIndex);
          this.outputLayersTensorIndices.push(tensorIndex);
        }
        for (const x of this.inputs) {
          const layer = x.sourceLayer;
          const nodeIndex = x.nodeIndex;
          const tensorIndex = x.tensorIndex;
          assert2(nodeIndex === 0, "input layer has >1 nodes");
          assert2(tensorIndex === 0, "input layer has >1 tensors");
          this.inputLayers.push(layer);
          this.inputLayersNodeIndices.push(nodeIndex);
          this.inputLayersTensorIndices.push(tensorIndex);
        }
        this.inputNames = [];
        this.outputNames = [];
        this.feedInputShapes = [];
        this.feedInputNames = [];
        this.feedOutputNames = [];
        for (let i = 0; i < this.inputLayers.length; i++) {
          const layer = this.inputLayers[i];
          if (!(layer instanceof InputLayer)) {
            throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${args.inputs}. Input ${i} (0-based) originates from layer type ${layer.getClassName()}.`);
          }
          this.inputNames.push(layer.name);
          this.feedInputShapes.push(layer.batchInputShape);
          this.feedInputNames.push(layer.name);
        }
        for (const layer of this.outputLayers) {
          this.outputNames.push(layer.name);
        }
        this.internalInputShapes = this.inputs.map((x) => x.shape);
        this.internalOutputShapes = this.outputs.map((x) => x.shape);
        const nodesDepths = {};
        const nodeIDToNode = {};
        const layersDepths = {};
        const layerIDToLayer = {};
        const layerIndices = {};
        const nodesInDecreasingDepth = [];
        const buildMapOfGraph = (tensor2, finishedNodes2, nodesInProgress2, layer, nodeIndex, tensorIndex) => {
          if (layer == null || nodeIndex == null || tensorIndex == null) {
            layer = tensor2.sourceLayer;
            nodeIndex = tensor2.nodeIndex;
            tensorIndex = tensor2.tensorIndex;
          }
          const node = layer.inboundNodes[nodeIndex];
          if (nodesInProgress2.indexOf(node) !== -1) {
            throw new RuntimeError(`The tensor ${tensor2.name} at layer "${layer.name}" is part of a cycle.`);
          }
          if (finishedNodes2.indexOf(node) !== -1) {
            return;
          }
          this.containerNodes.add(Container.nodeKey(layer, nodeIndex));
          if (!(layer.id in layerIndices)) {
            layerIndices[layer.id] = Object.keys(layerIndices).length;
          }
          if (nodesInProgress2.indexOf(node) === -1) {
            nodesInProgress2.push(node);
          }
          const numInboundLayers = node.inboundLayers.length;
          for (let i = 0; i < numInboundLayers; i++) {
            const x = node.inputTensors[i];
            const layer2 = node.inboundLayers[i];
            const nodeIndex2 = node.nodeIndices[i];
            const tensorIndex2 = node.tensorIndices[i];
            buildMapOfGraph(x, finishedNodes2, nodesInProgress2, layer2, nodeIndex2, tensorIndex2);
          }
          finishedNodes2.push(node);
          while (nodesInProgress2.indexOf(node) >= 0) {
            nodesInProgress2.splice(nodesInProgress2.indexOf(node), 1);
          }
          nodesInDecreasingDepth.push(node);
        };
        const finishedNodes = [];
        const nodesInProgress = [];
        for (const x of this.outputs) {
          buildMapOfGraph(x, finishedNodes, nodesInProgress);
        }
        const reversedNodesInDecreasingDepth = nodesInDecreasingDepth.slice().reverse();
        for (const node of reversedNodesInDecreasingDepth) {
          nodeIDToNode[node.id] = node;
          if (!(node.id in nodesDepths)) {
            nodesDepths[node.id] = 0;
          }
          let depth = nodesDepths[node.id];
          const previousDepth = layersDepths[node.outboundLayer.id] == null ? 0 : layersDepths[node.outboundLayer.id];
          depth = Math.max(depth, previousDepth);
          layersDepths[node.outboundLayer.id] = depth;
          layerIDToLayer[node.outboundLayer.id] = node.outboundLayer;
          nodesDepths[node.id] = depth;
          for (let i = 0; i < node.inboundLayers.length; i++) {
            const inboundLayer = node.inboundLayers[i];
            const nodeIndex = node.nodeIndices[i];
            const inboundNode = inboundLayer.inboundNodes[nodeIndex];
            const previousDepth2 = nodesDepths[inboundNode.id] == null ? 0 : nodesDepths[inboundNode.id];
            nodesDepths[inboundNode.id] = Math.max(depth + 1, previousDepth2);
            nodeIDToNode[inboundNode.id] = inboundNode;
          }
        }
        const nodesByDepth = {};
        for (const nodeID in nodesDepths) {
          const depth = nodesDepths[nodeID];
          if (!(depth in nodesByDepth)) {
            nodesByDepth[depth] = [];
          }
          nodesByDepth[depth].push(nodeIDToNode[nodeID]);
        }
        const layersByDepth = {};
        for (const layerID in layersDepths) {
          const depth = layersDepths[layerID];
          if (!(depth in layersByDepth)) {
            layersByDepth[depth] = [];
          }
          layersByDepth[depth].push(layerIDToLayer[layerID]);
        }
        let depthKeys = Object.keys(layersByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
        this.layers = [];
        for (const depth of depthKeys) {
          const layersForDepth = layersByDepth[depth];
          layersForDepth.sort((a, b) => {
            const aIndex = layerIndices[a.id];
            const bIndex = layerIndices[b.id];
            if (aIndex < bIndex) {
              return -1;
            }
            if (aIndex > bIndex) {
              return 1;
            }
            return 0;
          });
          for (const layer of layersForDepth) {
            if (layer instanceof Container) {
              this.internalContainerRefs.push(layer);
            }
            this.layers.push(layer);
          }
        }
        this.layersByDepth = layersByDepth;
        depthKeys = Object.keys(nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
        const computableTensors = this.inputs.slice();
        const layersWithCompleteInput = [];
        for (const depth of depthKeys) {
          for (const node of nodesByDepth[depth]) {
            const layer = node.outboundLayer;
            if (layer != null) {
              for (const x of node.inputTensors) {
                if (computableTensors.indexOf(x) === -1) {
                  throw new RuntimeError(`Graph disconnected: cannot obtain value for tensor ${x} at layer "${layer.name}". The following previous layers were accessed without issue: ${layersWithCompleteInput}`);
                }
              }
              for (const x of node.outputTensors) {
                computableTensors.push(x);
              }
              layersWithCompleteInput.push(layer.name);
            }
          }
        }
        this.nodesByDepth = nodesByDepth;
        const allNames = this.layers.map((x) => x.name);
        for (const name of allNames) {
          const numOccurrences = allNames.filter((x) => x === name).length;
          if (numOccurrences !== 1) {
            throw new RuntimeError(`The name "${name}" is used ${numOccurrences} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(allNames));
          }
        }
        this.outboundNodes = [];
        this.inboundNodes = [];
        new Node({
          outboundLayer: this,
          inboundLayers: [],
          nodeIndices: [],
          tensorIndices: [],
          inputTensors: this.inputs,
          outputTensors: this.outputs,
          inputMasks: this.inputs.map((x) => null),
          outputMasks: this.outputs.map((x) => null),
          inputShapes: this.inputs.map((x) => x.shape),
          outputShapes: this.outputs.map((x) => x.shape)
        });
        this.built = true;
        this._refCount = 1;
      }
      assertNotDisposed() {
        if (this._refCount === 0) {
          throw new Error(`Container '${this.name}' is already disposed.`);
        }
      }
      /**
       * Attempt to dispose a LayersModel's weights.
       *
       * This method decrease the reference count of the LayersModel object by 1.
       *
       * A LayersModel is reference-counted. Its reference count is incremented by 1
       * when it is first constructed and when it is used as a Layer of another
       * LayersModel.
       *
       * If the reference count of a LayersModel becomes 0, the `dispose` method of
       * all its constituent `Layer`s will be called.
       *
       * Note: If the reference count is greater than 0 after the decrement, the
       * `dispose` method of its constituent `Layer`s will *not* be called.
       *
       * After a LayersModel is disposed, it cannot be used in calls such as
       * 'predict`, `evaluate` or `fit` anymore.
       *
       * @returns A DisposeResult Object with the following fields:
       *   - refCountAfterDispose: The reference count of the LayersModel after this
       *     `dispose()` call.
       *   - numDisposedVariables: Number of `tf.Variable`s (i.e., weights) disposed
       *     during this `dispose()` call.
       * @throws {Error} If the layer is not built yet, or if the LayersModel has
       *   already been disposed.
       */
      dispose() {
        this.assertNotDisposed();
        const result = { refCountAfterDispose: null, numDisposedVariables: 0 };
        if (--this._refCount === 0) {
          for (const layer of this.layers) {
            result.numDisposedVariables += layer.dispose().numDisposedVariables;
          }
          for (const container of this.internalContainerRefs) {
            result.numDisposedVariables += container.dispose().numDisposedVariables;
          }
        }
        result.refCountAfterDispose = this._refCount;
        return result;
      }
      get trainable() {
        return this.trainable_;
      }
      set trainable(trainable) {
        this.layers.forEach((layer) => {
          layer._trainableWeights.forEach((w) => w.trainable = trainable);
        });
        this.trainable_ = trainable;
      }
      get trainableWeights() {
        if (this._trainableWeights.length > 0) {
          throw new ValueError("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
        }
        if (!this.trainable) {
          return [];
        }
        let weights = [];
        for (const layer of this.layers) {
          weights = weights.concat(layer.trainableWeights);
        }
        return weights;
      }
      get nonTrainableWeights() {
        const weights = [];
        for (const layer of this.layers) {
          weights.push(...layer.nonTrainableWeights);
        }
        if (!this.trainable) {
          const trainableWeights = [];
          for (const layer of this.layers) {
            trainableWeights.push(...layer.trainableWeights);
          }
          return trainableWeights.concat(weights);
        }
        return weights;
      }
      get weights() {
        return this.trainableWeights.concat(this.nonTrainableWeights);
      }
      /**
       * Loads all layer weights from a JSON object.
       *
       * Porting Note: HDF5 weight files cannot be directly loaded in JavaScript /
       *   TypeScript. The utility script at `scripts/pykeras.py` offers means
       *   to convert them into JSON strings compatible with this method.
       * Porting Note: TensorFlow.js Layers supports only loading by name currently.
       *
       * @param weights A JSON mapping weight names to weight values as nested
       *   arrays of numbers, or a `NamedTensorMap`, i.e., a JSON mapping weight
       *   names to `tf.Tensor` objects.
       * @param strict Require that the provided weights exactly match those
       *   required by the container.  Default: `true`.  Passing `false` means that
       *   extra weights and missing weights will be silently ignored.
       */
      loadWeights(weights, strict = true) {
        const nameToWeight = {};
        let totalWeightsCount = 0;
        for (const layer of this.layers) {
          for (const weight of layer.weights) {
            if (nameToWeight[weight.originalName] != null) {
              throw new ValueError(`Duplicate weight name: ${weight.originalName}`);
            }
            nameToWeight[weight.originalName] = weight;
            totalWeightsCount++;
          }
        }
        const weightValueTuples = [];
        for (const name in weights) {
          let validatedName = name;
          if (nameToWeight[name] == null) {
            const tokens = name.split("/");
            const shortenNameArray = tokens.slice(0, -2).concat([tokens[tokens.length - 1]]);
            validatedName = shortenNameArray.join("/");
          }
          if (nameToWeight[validatedName] != null) {
            weightValueTuples.push([nameToWeight[validatedName], weights[name]]);
          } else if (strict) {
            throw new ValueError(`Provided weight data has no target variable: ${name}`);
          }
          delete nameToWeight[validatedName];
        }
        if (strict) {
          const unsetNames = [];
          for (const name in nameToWeight) {
            unsetNames.push(name);
          }
          if (unsetNames.length > 0) {
            throw new ValueError(`${unsetNames.length} of ${totalWeightsCount} weights are not set: ${unsetNames}`);
          }
        }
        batchSetValue(weightValueTuples);
      }
      /**
       * Util shared between different serialization methods.
       * @returns LayersModel config with Keras version information added.
       */
      updatedConfig() {
        const theConfig = this.getConfig();
        const modelConfig = {};
        modelConfig["className"] = this.getClassName();
        modelConfig["config"] = theConfig;
        modelConfig["kerasVersion"] = `tfjs-layers ${version}`;
        modelConfig["backend"] = "TensorFlow.js";
        return modelConfig;
      }
      /**
       * Returns a JSON string containing the network configuration.
       *
       * To load a network from a JSON save file, use
       * models.modelFromJSON(jsonString);
       * @param extraJsonArgs Unused in tfjs-layers, maintained for PyKeras
       * @param returnString Whether the return value should be stringified
       *    (default: `true`).
       * @returns a JSON string if `returnString` (default), or a JSON object if
       *   `!returnString`.
       */
      // tslint:disable-next-line:no-any
      toJSON(unused, returnString = true) {
        const modelConfig = convertTsToPythonic(this.updatedConfig());
        return returnString ? JSON.stringify(modelConfig) : modelConfig;
      }
      /**
       * Call the model on new inputs.
       *
       * In this case `call` just reapplies all ops in the graph to the new inputs
       * (e.g. build a new computational graph from the provided inputs).
       *
       * @param inputs A tensor or list of tensors.
       * @param mask A mask or list of masks. A mask can be either a tensor or null
       *   (no mask).
       *
       * @return A tensor if there is a single output, or a list of tensors if there
       *   are more than one outputs.
       */
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = toList(inputs);
          const feedDict = new FeedDict();
          for (let i = 0; i < this.inputs.length; ++i) {
            feedDict.add(this.inputs[i], inputs[i]);
          }
          return execute(this.outputs, feedDict, kwargs);
        });
      }
      /**
       * Computes an output mask tensor.
       *
       * @param inputs Tensor or list of tensors.
       * @param mask Tensor or list of tensors.
       *
       * @return null or a tensor (or list of tensors, one per output tensor of the
       * layer).
       */
      computeMask(inputs, mask) {
        return tidy(() => {
          inputs = toList(inputs);
          let masks;
          if (mask == null) {
            masks = pyListRepeat(null, inputs.length);
          } else {
            masks = toList(mask);
          }
          return this.runInternalGraph(inputs, masks)[1];
        });
      }
      /**
       * Computes the output shape of the layer.
       *
       * Assumes that the layer will be built to match that input shape provided.
       *
       * @param inputShape A shape (tuple of integers) or a list of shape tuples
       *   (one per output tensor of the layer). Shape tuples can include null for
       *   free dimensions, instead of an integer.
       */
      computeOutputShape(inputShape) {
        const inputShapes = normalizeShapeList(inputShape);
        if (inputShapes.length !== this.inputLayers.length) {
          throw new ValueError(`Invalid inputShape argument ${inputShape}: model has ${this.inputLayers.length} tensor inputs.`);
        }
        const layersToOutputShapes = {};
        for (let i = 0; i < inputShapes.length; i++) {
          const layer = this.inputLayers[i];
          const inputShape2 = inputShapes[i];
          const shapeKey = layer.name + "_0_0";
          layersToOutputShapes[shapeKey] = inputShape2;
        }
        const depthKeys = Object.keys(this.nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
        if (depthKeys.length > 1) {
          for (const depth of depthKeys) {
            const nodes = this.nodesByDepth[depth];
            for (const node of nodes) {
              const layer = node.outboundLayer;
              if (this.inputLayers.map((x) => x.id).indexOf(layer.id) !== -1) {
                continue;
              }
              const inputShapes2 = [];
              for (let j = 0; j < node.inboundLayers.length; j++) {
                const inboundLayer = node.inboundLayers[j];
                const nodeIndex2 = node.nodeIndices[j];
                const tensorIndex = node.tensorIndices[j];
                const shapeKey = `${inboundLayer.name}_${nodeIndex2}_${tensorIndex}`;
                const inputShape2 = layersToOutputShapes[shapeKey];
                inputShapes2.push(inputShape2);
              }
              const outputShape = layer.computeOutputShape(singletonOrArray(inputShapes2));
              const outputShapes2 = normalizeShapeList(outputShape);
              const nodeIndex = layer.inboundNodes.indexOf(node);
              for (let j = 0; j < outputShapes2.length; j++) {
                const shapeKey = `${layer.name}_${nodeIndex}_${j}`;
                layersToOutputShapes[shapeKey] = outputShapes2[j];
              }
            }
          }
        }
        const outputShapes = [];
        const outputShapeKeys = [];
        for (let i = 0; i < this.outputLayers.length; i++) {
          const layer = this.outputLayers[i];
          const nodeIndex = this.outputLayersNodeIndices[i];
          const tensorIndex = this.outputLayersTensorIndices[i];
          const shapeKey = `${layer.name}_${nodeIndex}_${tensorIndex}`;
          outputShapeKeys.push(shapeKey);
        }
        for (let i = 0; i < outputShapeKeys.length; i++) {
          const key = outputShapeKeys[i];
          assert2(key in layersToOutputShapes);
          outputShapes.push(layersToOutputShapes[key]);
        }
        return singletonOrArray(outputShapes);
      }
      /**
       * Computes output tensors for new inputs.
       *
       * Note:
       *   - Expects `inputs` to be a list (potentially with 1 element).
       *
       * @param inputs List of tensors
       * @param masks List of masks (tensors or null).
       * @return Three lists: outputTensors, outputMasks, outputShapes
       */
      runInternalGraph(inputs, masks) {
        if (masks == null) {
          masks = pyListRepeat(null, inputs.length);
        }
        const tensorMap = {};
        for (let i = 0; i < this.inputs.length; ++i) {
          const x = this.inputs[i];
          const y = inputs[i];
          const mask = masks[i];
          tensorMap[x.id] = [y, mask];
        }
        const depthKeys = Object.keys(this.nodesByDepth).map((x) => parseInt(x, 10)).sort(reverseNumberCompare);
        for (const depth of depthKeys) {
          const nodes = this.nodesByDepth[depth];
          for (const node of nodes) {
            const layer = node.outboundLayer;
            const referenceInputTensors = node.inputTensors;
            const referenceOutputTensors = node.outputTensors;
            const computedData = new Array();
            for (const x of referenceInputTensors) {
              if (x.id in tensorMap) {
                computedData.push(tensorMap[x.id]);
              }
            }
            if (computedData.length === referenceInputTensors.length) {
              let kwargs = {};
              let computedTensors;
              let computedMasks;
              let outputTensors2;
              let outputMasks2;
              if (node.callArgs != null) {
                kwargs = node.callArgs;
              }
              if (computedData.length === 1) {
                const [computedTensor, computedMask] = computedData[0];
                if (kwargs["mask"] == null) {
                  kwargs["mask"] = computedMask;
                }
                outputTensors2 = toList(layer.call(computedTensor, kwargs));
                outputMasks2 = toList(layer.computeMask(computedTensor, computedMask));
                computedTensors = [computedTensor];
                computedMasks = [computedMask];
              } else {
                computedTensors = computedData.map((x) => x[0]);
                computedMasks = computedData.map((x) => x[1]);
                if (kwargs["mask"] == null) {
                  kwargs["mask"] = computedMasks;
                }
                outputTensors2 = toList(layer.call(computedTensors, kwargs));
                outputMasks2 = toList(layer.computeMask(computedTensors, computedMasks));
              }
              if (layer.activityRegularizer) {
                throw new NotImplementedError("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
              }
              for (let i = 0; i < referenceOutputTensors.length; ++i) {
                const x = referenceOutputTensors[i];
                const y = outputTensors2[i];
                const mask = outputMasks2[i];
                tensorMap[x.id] = [y, mask];
              }
            }
          }
        }
        const outputTensors = [];
        const outputMasks = [];
        const outputShapes = [];
        for (const x of this.outputs) {
          assert2(x.id in tensorMap, `Could not compute output ${x.name} : ${x.id}`);
          const [tensor2, mask] = tensorMap[x.id];
          outputShapes.push(tensor2.shape);
          outputTensors.push(tensor2);
          outputMasks.push(mask);
        }
        return [outputTensors, outputMasks, outputShapes];
      }
      /**
       * Builds a map of internal node keys to node ordering.
       * Used in serializaion a node orderings may change as unused nodes are
       * dropped. Porting Note:  This helper method was pulled out of getConfig to
       * improve readability.
       * @param layers An array of Layers in the model.
       * @returns Map of Node Keys to index order within the layer.
       */
      buildNodeConversionMap(layers) {
        const nodeConversionMap = {};
        let keptNodes;
        for (const layer of this.layers) {
          keptNodes = layer instanceof Container ? 1 : 0;
          for (let originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {
            const nodeKey = Container.nodeKey(layer, originalNodeIndex);
            if (this.containerNodes.has(nodeKey)) {
              nodeConversionMap[nodeKey] = keptNodes;
              keptNodes += 1;
            }
          }
        }
        return nodeConversionMap;
      }
      /**
       * Retrieves a layer based on either its name (unique) or index.
       *
       * Indices are based on order of horizontal graph traversal (bottom-up).
       *
       * If both `name` and `index` are specified, `index` takes precedence.
       *
       * @param name Name of layer.
       * @param index Index of layer.
       * @returns A Layer instance.
       * @throws ValueError: In case of invalid layer name or index.
       *
       * @doc {
       *    heading: 'Layers',
       *    subheading: 'Classes',
       *    namespace: 'layers',
       *    subclasses: ['LayersModel']
       * }
       */
      getLayer(name, index) {
        if (index != null) {
          if (this.layers.length <= index) {
            throw new ValueError(`Was asked to retrieve layer at index ${index}, but model only has ${this.layers.length} layer(s).`);
          } else {
            return this.layers[index];
          }
        } else {
          if (name == null) {
            throw new ValueError("Provide either a layer name or layer index");
          }
        }
        for (const layer of this.layers) {
          if (layer.name === name) {
            return layer;
          }
        }
        throw new ValueError(`No such layer: ${name}`);
      }
      /**
       * Retrieves the Container's current loss values.
       *
       * Used for regularizers during training.
       */
      calculateLosses() {
        return tidy(() => {
          const losses = [];
          for (const layer of this.layers) {
            for (let nodeIndex = 0; nodeIndex < layer.inboundNodes.length; ++nodeIndex) {
              const nodeKey = Container.nodeKey(layer, nodeIndex);
              if (this.containerNodes.has(nodeKey)) {
                losses.push(...layer.calculateLosses());
              }
            }
          }
          return losses;
        });
      }
      getConfig() {
        const config = { name: this.name };
        const nodeConversionMap = this.buildNodeConversionMap(this.layers);
        const layerConfigs = [];
        for (const layer of this.layers) {
          const layerClassName = layer.getClassName();
          const layerConfig = layer.getConfig();
          const filteredInboundNodes = [];
          for (let originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {
            const node = layer.inboundNodes[originalNodeIndex];
            const nodeKey = Container.nodeKey(layer, originalNodeIndex);
            let kwargs = {};
            if (this.containerNodes.has(nodeKey)) {
              if (node.callArgs) {
                try {
                  JSON.stringify(node.callArgs);
                  kwargs = node.callArgs;
                } catch (err) {
                  console.warn(`Layer ${layer.name} was passed non-serializable keyword arguments: ${node.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`);
                  kwargs = {};
                }
              }
              if (node.inboundLayers.length > 0) {
                const nodeData = [];
                for (let i = 0; i < node.inboundLayers.length; i++) {
                  const inboundLayer = node.inboundLayers[i];
                  const nodeIndex = node.nodeIndices[i];
                  const tensorIndex = node.tensorIndices[i];
                  const nodeKey2 = Container.nodeKey(inboundLayer, nodeIndex);
                  let newNodeIndex = nodeConversionMap[nodeKey2];
                  if (newNodeIndex == null) {
                    newNodeIndex = 0;
                  }
                  nodeData.push([inboundLayer.name, newNodeIndex, tensorIndex, kwargs]);
                }
                filteredInboundNodes.push(nodeData);
              }
            }
          }
          const dict = {};
          dict["name"] = layer.name;
          dict["className"] = layerClassName;
          dict["config"] = layerConfig;
          dict["inboundNodes"] = filteredInboundNodes;
          layerConfigs.push(dict);
        }
        config["layers"] = layerConfigs;
        const modelInputs = [];
        for (let i = 0; i < this.inputLayers.length; i++) {
          const layer = this.inputLayers[i];
          const nodeIndex = this.inputLayersNodeIndices[i];
          const nodeKey = Container.nodeKey(layer, nodeIndex);
          if (!this.containerNodes.has(nodeKey)) {
            continue;
          }
          let newNodeIndex = nodeConversionMap[nodeKey];
          if (newNodeIndex === null || newNodeIndex === void 0) {
            newNodeIndex = 0;
          }
          const tensorIndex = this.inputLayersTensorIndices[i];
          modelInputs.push([layer.name, newNodeIndex, tensorIndex]);
        }
        config["inputLayers"] = modelInputs;
        const modelOutputs = [];
        for (let i = 0; i < this.outputLayers.length; i++) {
          const layer = this.outputLayers[i];
          const nodeIndex = this.outputLayersNodeIndices[i];
          const nodeKey = Container.nodeKey(layer, nodeIndex);
          if (!this.containerNodes.has(nodeKey)) {
            continue;
          }
          let newNodeIndex = nodeConversionMap[nodeKey];
          if (newNodeIndex === null || newNodeIndex === void 0) {
            newNodeIndex = 0;
          }
          const tensorIndex = this.outputLayersTensorIndices[i];
          modelOutputs.push([layer.name, newNodeIndex, tensorIndex]);
        }
        config["outputLayers"] = modelOutputs;
        return config;
      }
      /**
       * Instantiates a LayersModel from its config (output of `get_config()`).
       * @param cls the class to create
       * @param config LayersModel config dictionary.
       * @param customObjects An optional dictionary of custom objects.
       * @param fastWeightInit Optional flag to use fast weight initialization
       *   during deserialization. This is applicable to cases in which
       *   the initialization will be immediately overwritten by loaded weight
       *   values. Default: `false`.
       * @returns A LayersModel instance.
       * @throws ValueError: In case of improperly formatted config dict.
       */
      /** @nocollapse */
      static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {
        const createdLayers = {};
        const unprocessedNodes = {};
        function addUnprocessedNode(layer, nodeData) {
          if (!(layer.name in unprocessedNodes)) {
            unprocessedNodes[layer.name] = [nodeData];
          } else {
            unprocessedNodes[layer.name].push(nodeData);
          }
        }
        function processNode(layer, nodeData) {
          const inputTensors2 = [];
          let kwargs;
          for (const inputData of nodeData) {
            const inboundLayerName = inputData[0];
            const inboundNodeIndex = inputData[1];
            const inboundTensorIndex = inputData[2];
            kwargs = inputData[3] == null ? {} : inputData[3];
            if (!(inboundLayerName in createdLayers)) {
              addUnprocessedNode(layer, nodeData);
              return;
            }
            const inboundLayer = createdLayers[inboundLayerName];
            if (inboundLayer.inboundNodes.length <= inboundNodeIndex) {
              addUnprocessedNode(layer, nodeData);
              return;
            }
            const inboundNode = inboundLayer.inboundNodes[inboundNodeIndex];
            inputTensors2.push(inboundNode.outputTensors[inboundTensorIndex]);
          }
          if (inputTensors2.length > 0) {
            layer.apply(singletonOrArray(inputTensors2), kwargs);
          }
        }
        function processLayer(layerData) {
          const layerName = layerData["name"];
          const layer = deserialize(layerData, config["customObjects"] != null ? config["customObjects"] : {});
          layer.setFastWeightInitDuringBuild(fastWeightInit);
          createdLayers[layerName] = layer;
          const inboundNodesData = layerData["inboundNodes"];
          inboundNodesData.forEach((nodeData) => {
            if (!(nodeData instanceof Array)) {
              throw new ValueError(`Corrupted configuration, expected array for nodeData: ${nodeData}`);
            }
            addUnprocessedNode(layer, nodeData);
          });
        }
        const name = config["name"];
        const layersFromConfig = config["layers"];
        for (const layerData of layersFromConfig) {
          processLayer(layerData);
        }
        while (!isObjectEmpty(unprocessedNodes)) {
          for (const layerData of layersFromConfig) {
            const layer = createdLayers[layerData["name"]];
            if (layer.name in unprocessedNodes) {
              const currentUnprocessedNodesForLayer = unprocessedNodes[layer.name];
              delete unprocessedNodes[layer.name];
              for (const nodeData of currentUnprocessedNodesForLayer) {
                processNode(layer, nodeData);
              }
            }
          }
        }
        const inputTensors = [];
        const outputTensors = [];
        const inputLayersFromConfig = config["inputLayers"];
        for (const layerData of inputLayersFromConfig) {
          const layerName = layerData[0];
          const nodeIndex = layerData[1];
          const tensorIndex = layerData[2];
          assert2(layerName in createdLayers);
          const layer = createdLayers[layerName];
          const layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;
          inputTensors.push(layerOutputTensors[tensorIndex]);
        }
        const outputLayersFromConfig = config["outputLayers"];
        for (const layerData of outputLayersFromConfig) {
          const layerName = layerData[0];
          const nodeIndex = layerData[1];
          const tensorIndex = layerData[2];
          assert2(layerName in createdLayers);
          const layer = createdLayers[layerName];
          const layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;
          outputTensors.push(layerOutputTensors[tensorIndex]);
        }
        return new cls({ inputs: inputTensors, outputs: outputTensors, name });
      }
      /**
       * Determine whether the container is stateful.
       *
       * Porting Note: this is the equivalent of the stateful @property of
       *   the Container class in PyKeras.
       */
      get stateful() {
        if (this._stateful) {
          throw new ValueError("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
        }
        for (const layer of this.layers) {
          if (layer.stateful) {
            return true;
          }
        }
        return false;
      }
      /**
       * Reset the state of all stateful constituent layers (if any).
       *
       * Examples of stateful layers include RNN layers whose `stateful` property
       * is set as `true`.
       */
      resetStates() {
        tidy(() => {
          this.layers.forEach((layer) => {
            if (layer.stateful) {
              layer.resetStates();
            }
          });
        });
      }
    };
  }
});
function standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {
  const numOutputs = outputNames.length;
  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {
    return outputNames.map((name) => null);
  }
  if (numOutputs === 1) {
    if (Array.isArray(xWeight) && xWeight.length === 1) {
      return xWeight;
    } else if (typeof xWeight === "object" && outputNames[0] in xWeight) {
      return [xWeight[outputNames[0]]];
    } else {
      return [xWeight];
    }
  }
  if (Array.isArray(xWeight)) {
    if (xWeight.length !== numOutputs) {
      throw new Error(`Provided ${weightType} is an array of ${xWeight.length} element(s), but the model has ${numOutputs} outputs. Make sure a set of weights is provided for each model output.`);
    }
    return xWeight;
  } else if (typeof xWeight === "object" && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === "object") {
    const output = [];
    outputNames.forEach((outputName) => {
      if (outputName in xWeight) {
        output.push(xWeight[outputName]);
      } else {
        output.push(null);
      }
    });
    return output;
  } else {
    throw new Error(`The model has multiple (${numOutputs}) outputs, so ${weightType} must be either an array with ${numOutputs} elements or an object with ${outputNames} keys. Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);
  }
}
function standardizeClassWeights(classWeight, outputNames) {
  return standardizeSampleOrClassWeights(classWeight, outputNames, "classWeight");
}
async function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {
  if (sampleWeight != null || sampleWeightMode != null) {
    throw new Error("Support sampleWeight is not implemented yet");
  }
  if (classWeight != null) {
    const yClasses = tidy(() => {
      if (y.shape.length === 1) {
        return clone6(y);
      } else if (y.shape.length === 2) {
        if (y.shape[1] > 1) {
          const axis = 1;
          return argMax(y, axis);
        } else if (y.shape[1] === 1) {
          return reshape(y, [y.shape[0]]);
        } else {
          throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) during handling of class weights. The size is expected to be >= 1.`);
        }
      } else {
        throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during handling of class weights. The rank is expected to be 1 or 2.`);
      }
    });
    const yClassIndices = Array.from(await yClasses.data());
    dispose(yClasses);
    const classSampleWeight = [];
    yClassIndices.forEach((classIndex) => {
      if (classWeight[classIndex] == null) {
        throw new Error(`classWeight must contain all classes in the training data. The class ${classIndex} exists in the data but not in classWeight`);
      } else {
        classSampleWeight.push(classWeight[classIndex]);
      }
    });
    return tensor1d(classSampleWeight, "float32");
  } else {
    return null;
  }
}
function computeWeightedLoss(losses, sampleWeights) {
  return mul5(losses, sampleWeights);
}
var init_training_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/training_utils.js"() {
    init_dist();
  }
});
function standardizeDataIteratorOutput(model2, iteratorOut) {
  let xs;
  let ys;
  const iteratorOutObj = iteratorOut;
  xs = iteratorOutObj["xs"];
  ys = iteratorOutObj["ys"];
  util_exports.assert(xs != null && ys != null, () => `A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${iteratorOut}`);
  const flattenedXs = flattenTensorOrArrayOrMap("input", model2.inputNames, xs);
  const flattenedYs = flattenTensorOrArrayOrMap("output", model2.outputNames, ys);
  const batchSize = flattenedXs[0].shape[0];
  util_exports.assert(flattenedXs.length === model2.inputs.length, () => `LayersModel has ${model2.inputs.length} inputs, but the dataset provides ${flattenedXs.length} inputs.  (Expected input keys: ${JSON.stringify(model2.inputNames)})`);
  util_exports.assert(flattenedYs.length === model2.outputs.length, () => `LayersModel has ${model2.outputs.length} outputs, but the dataset provides ${flattenedYs.length} outputs.  (Expected output keys: ${JSON.stringify(model2.outputNames)})`);
  for (let xIndex = 0; xIndex < flattenedXs.length; xIndex++) {
    util_exports.assert(flattenedXs[xIndex].shape[0] === batchSize, () => `Batch size mismatch: input ${model2.inputNames[xIndex]} has ${flattenedXs[xIndex].shape[0]}; expected  ${batchSize} based on input ${model2.inputNames[0]}.`);
  }
  for (let yIndex = 0; yIndex < flattenedYs.length; yIndex++) {
    util_exports.assert(flattenedYs[yIndex].shape[0] === batchSize, () => `Batch size mismatch: output ${model2.outputNames[yIndex]} has ${flattenedYs[yIndex].shape[0]}; expected  ${batchSize} based on input ${model2.inputNames[0]}.`);
  }
  return { xs: flattenedXs, ys: flattenedYs };
}
function flattenTensorOrArrayOrMap(inputOrOutput, names, values) {
  if (values instanceof Tensor) {
    return [values];
  } else if (Array.isArray(values)) {
    util_exports.assert(values.length === names.length, () => `Received an array of ${values.length} Tensors, but expected ${names.length} to match the ${inputOrOutput} keys ${names}.`);
    return values;
  } else {
    const result = [];
    for (const name of names) {
      if (values[name] == null) {
        throw new ValueError(`The feature data generated by the dataset lacks the required ${inputOrOutput} key '${name}'.`);
      }
      result.push(values[name]);
    }
    return result;
  }
}
function standardizeTensorValidationData(data) {
  if (data.length === 3) {
    throw new NotImplementedError("Validation with sample weights is not implemented yet.");
  }
  return { xs: data[0], ys: data[1] };
}
async function fitDataset(model2, dataset, args) {
  const hasBatchesPerEpoch = args.batchesPerEpoch != null;
  util_exports.assert(model2.optimizer != null, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).");
  util_exports.assert(args != null, () => `For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.`);
  util_exports.assert(args.epochs != null && args.epochs > 0 && Number.isInteger(args.epochs), () => `For fitDataset(), config.epochs is expected to be a positive integer, but got ${args.epochs}`);
  util_exports.assert(!hasBatchesPerEpoch || args.batchesPerEpoch > 0 && Number.isInteger(args.batchesPerEpoch), () => `For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${args.batchesPerEpoch}`);
  util_exports.assert(
    // tslint:disable-next-line:no-any
    args["validationSplit"] == null,
    () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead."
  );
  if (model2.isTraining) {
    throw new Error("Cannot start training because another fit() call is ongoing.");
  }
  model2.isTraining = true;
  try {
    const doValidation = args.validationData != null;
    let valXs;
    let valYs;
    if (doValidation) {
      if (isDatasetObject(args.validationData)) {
        util_exports.assert(args.validationBatches == null || args.validationBatches > 0 && Number.isInteger(args.validationBatches), () => `For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${args.validationBatches}`);
      } else {
        const validationData = standardizeTensorValidationData(args.validationData);
        valXs = validationData.xs;
        valYs = validationData.ys;
      }
    }
    const trainFunction = model2.makeTrainFunction();
    const outLabels = model2.getDedupedMetricsNames();
    let callbackMetrics;
    if (doValidation) {
      callbackMetrics = outLabels.slice().concat(outLabels.map((n) => "val_" + n));
    } else {
      callbackMetrics = outLabels.slice();
    }
    const callbacks2 = standardizeCallbacks(args.callbacks, args.yieldEvery);
    const verbose = args.verbose == null ? 1 : args.verbose;
    const { callbackList, history } = configureCallbacks(
      callbacks2,
      verbose,
      args.epochs,
      null,
      null,
      getStepsPerEpoch(dataset, args),
      null,
      // Batch size determined by the dataset itself.
      doValidation,
      callbackMetrics
    );
    callbackList.setModel(model2);
    model2.history = history;
    await callbackList.onTrainBegin();
    model2.stopTraining_ = false;
    let epoch = args.initialEpoch == null ? 0 : args.initialEpoch;
    let dataIterator = await dataset.iterator();
    while (epoch < args.epochs) {
      const epochLogs = {};
      await callbackList.onEpochBegin(epoch);
      let stepsDone = 0;
      let batchIndex = 0;
      if (!hasBatchesPerEpoch) {
        dataIterator = await dataset.iterator();
      }
      while (hasBatchesPerEpoch ? stepsDone < args.batchesPerEpoch : true) {
        const iteratorOut = await dataIterator.next();
        if (hasBatchesPerEpoch && iteratorOut.done) {
          console.warn(`You provided \`batchesPerEpoch\` as ${args.batchesPerEpoch}, but your dataset iterator ran out of data after ${stepsDone} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${args.batchesPerEpoch * args.epochs} batches). You may need to use the repeat() function when building your dataset.`);
          break;
        }
        if (iteratorOut.value != null) {
          const { xs, ys } = standardizeDataIteratorOutput(model2, iteratorOut.value);
          const batchLogs = {};
          batchLogs["batch"] = batchIndex;
          batchLogs["size"] = xs[0].shape[0];
          await callbackList.onBatchBegin(batchIndex, batchLogs);
          const sampleWeights = [];
          if (args.classWeight != null) {
            const standardClassWeights = standardizeClassWeights(args.classWeight, model2.outputNames);
            for (let i = 0; i < standardClassWeights.length; ++i) {
              sampleWeights.push(await standardizeWeights(ys[i], null, standardClassWeights[i]));
            }
          }
          const ins = xs.concat(ys).concat(sampleWeights);
          const outs = trainFunction(ins);
          dispose(ins);
          for (let i = 0; i < outLabels.length; ++i) {
            const label = outLabels[i];
            const out = outs[i];
            batchLogs[label] = out;
            keep(out);
          }
          await callbackList.onBatchEnd(batchIndex, batchLogs);
          disposeTensorsInLogs(batchLogs);
          batchIndex++;
          stepsDone++;
        }
        if (hasBatchesPerEpoch ? stepsDone >= args.batchesPerEpoch : iteratorOut.done) {
          if (doValidation) {
            let valOuts;
            if (isDatasetObject(args.validationData)) {
              valOuts = toList(await model2.evaluateDataset(args.validationData, { batches: args.validationBatches }));
            } else {
              valOuts = toList(model2.evaluate(valXs, valYs, {
                batchSize: args.validationBatchSize == null ? DEFAULT_VALIDATION_BATCH_SIZE : args.validationBatchSize,
                verbose: 0
              }));
            }
            for (let i = 0; i < model2.metricsNames.length; ++i) {
              epochLogs[`val_${model2.metricsNames[i]}`] = valOuts[i];
            }
          }
          break;
        }
        if (model2.stopTraining_) {
          break;
        }
      }
      await callbackList.onEpochEnd(epoch, epochLogs);
      epoch++;
      if (model2.stopTraining_) {
        break;
      }
    }
    await callbackList.onTrainEnd();
    await model2.history.syncData();
    return model2.history;
  } finally {
    model2.isTraining = false;
  }
}
function getStepsPerEpoch(dataset, args) {
  let stepsPerEpoch = null;
  if (args.batchesPerEpoch != null) {
    stepsPerEpoch = args.batchesPerEpoch;
  } else if (Number.isFinite(dataset.size)) {
    stepsPerEpoch = dataset.size;
  }
  return stepsPerEpoch;
}
function isDatasetObject(dataset) {
  return typeof dataset.iterator === "function";
}
function isLazyIteratorObject(iterator) {
  return typeof iterator.next === "function";
}
async function evaluateDataset(model2, dataset, args) {
  args = args || {};
  const hasBatches = args.batches != null;
  const f = model2.testFunction;
  let outs = [];
  if (args.verbose > 0) {
    throw new NotImplementedError("Verbose mode is not implemented yet.");
  }
  util_exports.assert(!hasBatches || args.batches > 0 && Number.isInteger(args.batches), () => `Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(args.batches)}`);
  const dataIterator = isLazyIteratorObject(dataset) ? dataset : await dataset.iterator();
  let numExamples = 0;
  let batch = 0;
  while (hasBatches ? batch < args.batches : true) {
    const iteratorOut = await dataIterator.next();
    outs = tidy(() => {
      if (iteratorOut.value) {
        const { xs, ys } = standardizeDataIteratorOutput(model2, iteratorOut.value);
        const xsAndYs = xs.concat(ys);
        const batchOuts = tidy(() => f(xsAndYs));
        dispose(xsAndYs);
        if (batch === 0) {
          for (let i = 0; i < batchOuts.length; ++i) {
            outs.push(scalar(0));
          }
        }
        const batchSize = xsAndYs[0].shape[0];
        for (let i = 0; i < batchOuts.length; ++i) {
          const batchOut = batchOuts[i];
          const oldScalar = outs[i];
          outs[i] = tidy(() => add22(outs[i], mul5(batchSize, batchOut)));
          if (batch > 0) {
            dispose(oldScalar);
          }
        }
        dispose(batchOuts);
        numExamples += batchSize;
        ++batch;
      }
      return outs;
    });
    if (iteratorOut.done) {
      if (hasBatches) {
        console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${args.batches} batches). You may need to use the repeat() function when building your dataset.`);
      }
      break;
    }
  }
  for (let i = 0; i < outs.length; ++i) {
    const oldScalar = outs[i];
    outs[i] = div2(outs[i], numExamples);
    dispose(oldScalar);
  }
  return singletonOrArray(outs);
}
var DEFAULT_VALIDATION_BATCH_SIZE;
var init_training_dataset = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/training_dataset.js"() {
    init_dist();
    init_dist();
    init_base_callbacks();
    init_errors();
    init_logs();
    init_generic_utils();
    init_training_utils();
    DEFAULT_VALIDATION_BATCH_SIZE = 32;
  }
});
function checkBatchSize(batchSize) {
  util_exports.assert(batchSize > 0 && Number.isInteger(batchSize), () => `batchSize is required to be a positive integer, but got ${batchSize}`);
}
function sliceArrays(arrays, start, stop) {
  if (arrays == null) {
    return [null];
  } else if (Array.isArray(arrays)) {
    return arrays.map((array2) => sliceAlongFirstAxis(array2, start, stop - start));
  } else {
    return sliceAlongFirstAxis(arrays, start, stop - start);
  }
}
function sliceArraysByIndices(arrays, indices) {
  return tidy(() => {
    if (arrays == null) {
      return null;
    } else if (Array.isArray(arrays)) {
      return arrays.map((array2) => sliceArraysByIndices(array2, indices));
    } else {
      return gather2(arrays, indices.dtype === "int32" ? indices : cast(indices, "int32"));
    }
  });
}
function makeBatches(size, batchSize) {
  const output = [];
  let batchStart = 0;
  let batchEnd = null;
  while (batchStart < size) {
    batchEnd = batchStart + batchSize;
    if (batchEnd >= size) {
      batchEnd = size;
    }
    output.push([batchStart, batchEnd]);
    batchStart = batchEnd;
  }
  return output;
}
function ensureTensorsRank2OrHigher(tensors) {
  const outs = [];
  if (tensors instanceof Tensor) {
    tensors = [tensors];
  }
  for (let i = 0; i < tensors.length; ++i) {
    const tensor2 = tensors[i];
    if (tensor2.rank === 1) {
      outs.push(expandDims2(tensor2, 1));
    } else if (tensor2.rank === 0) {
      throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
    } else {
      outs.push(tensor2);
    }
  }
  return outs;
}
function disposeNewTensors(tensors, refTensors) {
  if (tensors == null) {
    return;
  }
  const oldTensorIds = [];
  if (refTensors instanceof Tensor) {
    oldTensorIds.push(refTensors.id);
  } else if (Array.isArray(refTensors)) {
    refTensors.forEach((t) => oldTensorIds.push(t.id));
  } else if (refTensors != null) {
    for (const name in refTensors) {
      const oldTensor = refTensors[name];
      oldTensorIds.push(oldTensor.id);
    }
  }
  const tensorsToDispose = [];
  if (tensors instanceof Tensor) {
    if (oldTensorIds.indexOf(tensors.id) === -1) {
      tensorsToDispose.push(tensors);
    }
  } else if (Array.isArray(tensors)) {
    tensors.forEach((t) => {
      if (oldTensorIds.indexOf(t.id) === -1) {
        tensorsToDispose.push(t);
      }
    });
  } else if (tensors != null) {
    for (const name in tensors) {
      const tensor2 = tensors[name];
      if (oldTensorIds.indexOf(tensor2.id) === -1) {
        tensorsToDispose.push(tensor2);
      }
    }
  }
  tensorsToDispose.forEach((t) => {
    if (!t.isDisposed) {
      t.dispose();
    }
  });
}
var init_training_tensors = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/training_tensors.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
  }
});
function isDataTensor(x) {
  return x instanceof Tensor;
}
function isDataArray(x) {
  return Array.isArray(x);
}
function isDataDict(x) {
  return !isDataTensor(x) && !isDataArray(x);
}
function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = "") {
  if (names == null || names.length === 0) {
    if (data != null) {
      let gotUnexpectedData = false;
      if (isDataArray(data) && data.length > 0) {
        gotUnexpectedData = true;
      } else if (isDataDict(data)) {
        for (const key in data) {
          if (data.hasOwnProperty(key)) {
            gotUnexpectedData = true;
            break;
          }
        }
      } else {
        gotUnexpectedData = true;
      }
      if (gotUnexpectedData) {
        throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, but got ${data}`);
      }
    }
    return [];
  }
  if (data == null) {
    return names.map((name) => null);
  }
  let arrays;
  if (isDataDict(data)) {
    data = data;
    arrays = [];
    for (const name of names) {
      if (data[name] == null) {
        throw new ValueError(`No data provided for "${name}". Need data for each key in: ${names}`);
      }
      arrays.push(data[name]);
    }
  } else if (isDataArray(data)) {
    data = data;
    if (data.length !== names.length) {
      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${names.length} Tensor(s), but instead got the following list of Tensor(s): ${data}`);
    }
    arrays = data;
  } else {
    data = data;
    if (names.length > 1) {
      throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${data.shape}`);
    }
    arrays = [data];
  }
  arrays = ensureTensorsRank2OrHigher(arrays);
  if (shapes != null) {
    for (let i = 0; i < names.length; ++i) {
      if (shapes[i] == null) {
        continue;
      }
      const array2 = arrays[i];
      if (array2.shape.length !== shapes[i].length) {
        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s). but got array with shape ${array2.shape}`);
      }
      for (let j = 0; j < shapes[i].length; ++j) {
        if (j === 0 && !checkBatchAxis) {
          continue;
        }
        const dim = array2.shape[j];
        const refDim = shapes[i][j];
        if (refDim != null && refDim >= 0 && dim !== refDim) {
          throw new ValueError(`${exceptionPrefix} expected a batch of elements where each example has shape [${shapes[i].slice(1, shapes[i].length)}] (i.e.,tensor shape [*,${shapes[i].slice(1, shapes[i].length)}]) but the ${exceptionPrefix} received an input with ${array2.shape[0]} examples, each with shape [${array2.shape.slice(1, array2.shape.length)}] (tensor shape [${array2.shape}])`);
        }
      }
    }
  }
  return arrays;
}
function checkArrayLengths(inputs, targets, weights) {
  const setX = unique2(inputs.map((input2) => input2.shape[0]));
  setX.sort();
  const setY = unique2(targets.map((target) => target.shape[0]));
  setY.sort();
  if (setX.length > 1) {
    throw new ValueError(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(inputs.map((input2) => input2.shape))}`);
  }
  if (setY.length > 1) {
    throw new ValueError(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(targets.map((target) => target.shape))}`);
  }
  if (setX.length > 0 && setY.length > 0 && !util_exports.arraysEqual(setX, setY)) {
    throw new ValueError(`Input Tensors should have the same number of samples as target Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target sample(s).`);
  }
}
function checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {
  const keyLosses = [
    meanSquaredError,
    binaryCrossentropy,
    categoricalCrossentropy
  ];
  for (let i = 0; i < targets.length; ++i) {
    const y = targets[i];
    const loss = lossFns[i];
    const shape = outputShapes[i];
    if (loss == null) {
      continue;
    }
    if (loss === categoricalCrossentropy) {
      if (y.shape[y.shape.length - 1] === 1) {
        throw new ValueError(`You are passing a target array of shape ${y.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
      }
    }
    if (keyLosses.indexOf(loss) !== -1) {
      const slicedYShape = y.shape.slice(1);
      const slicedShape = shape.slice(1);
      for (let j = 0; j < slicedYShape.length; ++j) {
        const targetDim = slicedYShape[j];
        const outDim = slicedShape[j];
        if (outDim != null && targetDim !== outDim) {
          throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an output of shape ${shape}, while using a loss function that expects targets to have the same shape as the output.`);
        }
      }
    }
  }
}
function checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = "") {
  let arrays;
  if (Array.isArray(data)) {
    if (data.length !== names.length) {
      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${names.length} Tensor(s), but instead got ${data.length} Tensors(s).`);
    }
    arrays = data;
  } else {
    if (names.length > 1) {
      throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(data.shape)}.`);
    }
    arrays = [data];
  }
  if (shapes != null) {
    for (let i = 0; i < names.length; ++i) {
      if (shapes[i] == null) {
        continue;
      }
      const array2 = arrays[i];
      if (array2.shape.length !== shapes[i].length) {
        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have ${shapes[i].length} dimension(s), but got array with shape ${JSON.stringify(array2.shape)}`);
      }
      for (let j = 0; j < shapes[i].length; ++j) {
        if (j === 0 && !checkBatchAxis) {
          continue;
        }
        const dim = array2.shape[j];
        const refDim = shapes[i][j];
        if (refDim != null) {
          if (refDim !== dim) {
            throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} to have shape ${JSON.stringify(shapes[i])} but got array with shape ${JSON.stringify(array2.shape)}.`);
          }
        }
      }
    }
  }
}
function collectMetrics(metrics, outputNames) {
  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {
    return outputNames.map((name) => []);
  }
  let wrappedMetrics;
  if (typeof metrics === "string" || typeof metrics === "function") {
    wrappedMetrics = [metrics];
  } else if (Array.isArray(metrics) || typeof metrics === "object") {
    wrappedMetrics = metrics;
  } else {
    throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${metrics}`);
  }
  if (Array.isArray(wrappedMetrics)) {
    return outputNames.map((name) => wrappedMetrics);
  } else {
    const nestedMetrics = [];
    for (const name of outputNames) {
      let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];
      if (!Array.isArray(outputMetrics)) {
        outputMetrics = [outputMetrics];
      }
      nestedMetrics.push(outputMetrics);
    }
    return nestedMetrics;
  }
}
var LAYERS_MODEL_FORMAT_NAME;
var LayersModel;
var Functional;
var init_training = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/engine/training.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_base_callbacks();
    init_common2();
    init_errors();
    init_serialization2();
    init_logs();
    init_losses();
    init_metrics();
    init_optimizers();
    init_user_defined_metadata();
    init_generic_utils();
    init_layer_utils();
    init_math_utils();
    init_serialization_utils();
    init_version();
    init_container();
    init_executor();
    init_training_dataset();
    init_training_tensors();
    init_training_utils();
    LAYERS_MODEL_FORMAT_NAME = "layers-model";
    LayersModel = class extends Container {
      constructor(args) {
        super(args);
        this.isTraining = false;
      }
      /**
       * Print a text summary of the model's layers.
       *
       * The summary includes
       * - Name and type of all layers that comprise the model.
       * - Output shape(s) of the layers
       * - Number of weight parameters of each layer
       * - If the model has non-sequential-like topology, the inputs each layer
       *   receives
       * - The total number of trainable and non-trainable parameters of the model.
       *
       * ```js
       * const input1 = tf.input({shape: [10]});
       * const input2 = tf.input({shape: [20]});
       * const dense1 = tf.layers.dense({units: 4}).apply(input1);
       * const dense2 = tf.layers.dense({units: 8}).apply(input2);
       * const concat = tf.layers.concatenate().apply([dense1, dense2]);
       * const output =
       *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);
       *
       * const model = tf.model({inputs: [input1, input2], outputs: output});
       * model.summary();
       * ```
       *
       * @param lineLength Custom line length, in number of characters.
       * @param positions Custom widths of each of the columns, as either
       *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number
       *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to
       *   right-most (i.e., ending) position of a column.
       * @param printFn Custom print function. Can be used to replace the default
       *   `console.log`. For example, you can use `x => {}` to mute the printed
       *   messages in the console.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      summary(lineLength, positions, printFn = console.log) {
        if (!this.built) {
          throw new ValueError(`This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).`);
        }
        printSummary(this, lineLength, positions, printFn);
      }
      /**
       * Configures and prepares the model for training and evaluation.  Compiling
       * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`
       * or `evaluate` on an un-compiled model will throw an error.
       *
       * @param args a `ModelCompileArgs` specifying the loss, optimizer, and
       * metrics to be used for fitting and evaluating this model.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      compile(args) {
        if (args.loss == null) {
          args.loss = [];
        }
        this.loss = args.loss;
        if (typeof args.optimizer === "string") {
          this.optimizer_ = getOptimizer(args.optimizer);
          this.isOptimizerOwned = true;
        } else {
          if (!(args.optimizer instanceof Optimizer)) {
            throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);
          }
          this.optimizer_ = args.optimizer;
          this.isOptimizerOwned = false;
        }
        let lossFunctions = [];
        if (!Array.isArray(args.loss) && typeof args.loss !== "string" && typeof args.loss !== "function") {
          args.loss = args.loss;
          for (const name in args.loss) {
            if (this.outputNames.indexOf(name) === -1) {
              throw new ValueError(`Unknown entry in loss dictionary: "${name}". Only expected the following keys: ${this.outputNames}`);
            }
          }
          for (const name of this.outputNames) {
            if (args.loss[name] == null) {
              console.warn(`Output "${name}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${name} during training`);
            }
            lossFunctions.push(get(args.loss[name]));
          }
        } else if (Array.isArray(args.loss)) {
          if (args.loss.length !== this.outputs.length) {
            throw new ValueError(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${args.loss}.`);
          }
          const theLosses = args.loss;
          lossFunctions = theLosses.map((l) => get(l));
        } else {
          const lossFunction = get(args.loss);
          this.outputs.forEach((_) => {
            lossFunctions.push(lossFunction);
          });
        }
        this.lossFunctions = lossFunctions;
        this.feedOutputNames = [];
        this.feedOutputShapes = [];
        this.feedLossFns = [];
        for (let i = 0; i < this.outputs.length; ++i) {
          const shape = this.internalOutputShapes[i];
          const name = this.outputNames[i];
          this.feedOutputNames.push(name);
          this.feedOutputShapes.push(shape);
          this.feedLossFns.push(this.lossFunctions[i]);
        }
        const skipTargetIndices = [];
        this.metrics = args.metrics;
        this.metricsNames = ["loss"];
        this.metricsTensors = [];
        nameScope("loss", () => {
          for (let i = 0; i < this.outputs.length; ++i) {
            if (skipTargetIndices.indexOf(i) !== -1) {
              continue;
            }
            const weightedLoss = this.lossFunctions[i];
            if (this.outputs.length > 1) {
              this.metricsTensors.push([weightedLoss, i]);
              this.metricsNames.push(this.outputNames[i] + "_loss");
            }
          }
        });
        const nestedMetrics = collectMetrics(args.metrics, this.outputNames);
        const appendMetric = (outputIndex, metricName, metricTensor) => {
          if (this.outputNames.length > 1) {
            metricName = this.outputNames[outputIndex] + "_" + metricName;
          }
          this.metricsNames.push(metricName);
          this.metricsTensors.push([metricTensor, outputIndex]);
        };
        nameScope("metric", () => {
          for (let i = 0; i < this.outputs.length; ++i) {
            if (skipTargetIndices.indexOf(i) !== -1) {
              continue;
            }
            const outputMetrics = nestedMetrics[i];
            const handleMetrics = (metrics) => {
              const metricNamePrefix = "";
              let metricName;
              let accFn;
              let weightedMetricFn;
              for (const metric of metrics) {
                if (typeof metric === "string" && ["accuracy", "acc", "crossentropy", "ce"].indexOf(metric) !== -1) {
                  const outputShape = this.internalOutputShapes[i];
                  if (outputShape[outputShape.length - 1] === 1 || this.lossFunctions[i] === binaryCrossentropy) {
                    if (["accuracy", "acc"].indexOf(metric) !== -1) {
                      accFn = binaryAccuracy;
                    } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                      accFn = binaryCrossentropy2;
                    }
                  } else if (this.lossFunctions[i] === sparseCategoricalCrossentropy) {
                    if (["accuracy", "acc"].indexOf(metric) !== -1) {
                      accFn = sparseCategoricalAccuracy;
                    } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                      accFn = sparseCategoricalCrossentropy2;
                    }
                  } else {
                    if (["accuracy", "acc"].indexOf(metric) !== -1) {
                      accFn = categoricalAccuracy;
                    } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                      accFn = categoricalCrossentropy2;
                    }
                  }
                  let suffix;
                  if (["accuracy", "acc"].indexOf(metric) !== -1) {
                    suffix = "acc";
                  } else if (["crossentropy", "ce"].indexOf(metric) !== -1) {
                    suffix = "ce";
                  }
                  weightedMetricFn = accFn;
                  metricName = metricNamePrefix + suffix;
                } else {
                  const metricFn = get2(metric);
                  weightedMetricFn = metricFn;
                  metricName = metricNamePrefix + getLossOrMetricName(metric);
                }
                let metricResult;
                nameScope(metricName, () => {
                  metricResult = weightedMetricFn;
                });
                appendMetric(i, metricName, metricResult);
              }
            };
            handleMetrics(outputMetrics);
          }
        });
        this.collectedTrainableWeights = this.trainableWeights;
      }
      /**
       * Check trainable weights count consistency.
       *
       * This will raise a warning if `this.trainableWeights` and
       * `this.collectedTrainableWeights` are inconsistent (i.e., have different
       * numbers of parameters).
       * Inconsistency will typically arise when one modifies `model.trainable`
       * without calling `model.compile()` again.
       */
      checkTrainableWeightsConsistency() {
        if (this.collectedTrainableWeights == null) {
          return;
        }
        if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {
          console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
        }
      }
      /**
       * Returns the loss value & metrics values for the model in test mode.
       *
       * Loss and metrics are specified during `compile()`, which needs to happen
       * before calls to `evaluate()`.
       *
       * Computation is done in batches.
       *
       * ```js
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
       * const result = model.evaluate(
       *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});
       * result.print();
       * ```
       *
       * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the
       * model has multiple inputs.
       * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the
       * model has multiple outputs.
       * @param args A `ModelEvaluateArgs`, containing optional fields.
       *
       * @return `Scalar` test loss (if the model has a single output and no
       *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs
       *   and/or metrics). The attribute `model.metricsNames`
       *   will give you the display labels for the scalar outputs.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      evaluate(x, y, args = {}) {
        const batchSize = args.batchSize == null ? 32 : args.batchSize;
        checkBatchSize(batchSize);
        const checkBatchAxis = true;
        const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);
        try {
          const ins = standardizedOuts[0].concat(standardizedOuts[1]);
          this.makeTestFunction();
          const f = this.testFunction;
          const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);
          return singletonOrArray(testOuts);
        } finally {
          disposeNewTensors(standardizedOuts[0], x);
          disposeNewTensors(standardizedOuts[1], y);
        }
      }
      // TODO(cais): Add code snippet below once real dataset objects are
      //   available.
      /**
       * Evaluate model using a dataset object.
       *
       * Note: Unlike `evaluate()`, this method is asynchronous (`async`).
       *
       * @param dataset A dataset object. Its `iterator()` method is expected
       *   to generate a dataset iterator object, the `next()` method of which
       *   is expected to produce data batches for evaluation. The return value
       *   of the `next()` call ought to contain a boolean `done` field and a
       *   `value` field. The `value` field is expected to be an array of two
       *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
       *   case is for models with exactly one input and one output (e.g.
       *   a sequential model). The latter case is for models with multiple
       *   inputs and/or multiple outputs. Of the two items in the array, the
       *   first is the input feature(s) and the second is the output target(s).
       * @param args A configuration object for the dataset-based evaluation.
       * @returns Loss and metric values as an Array of `Scalar` objects.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async evaluateDataset(dataset, args) {
        this.makeTestFunction();
        return evaluateDataset(this, dataset, args);
      }
      /**
       * Get number of samples provided for training, evaluation or prediction.
       *
       * @param ins Input `tf.Tensor`.
       * @param batchSize Integer batch size, optional.
       * @param steps Total number of steps (batches of samples) before
       * declaring loop finished. Optional.
       * @param stepsName The public API's parameter name for `steps`.
       * @returns Number of samples provided.
       */
      checkNumSamples(ins, batchSize, steps, stepsName = "steps") {
        let numSamples;
        if (steps != null) {
          numSamples = null;
          if (batchSize != null) {
            throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.Got batchSize = ${batchSize}`);
          }
        } else if (ins != null) {
          if (Array.isArray(ins)) {
            numSamples = ins[0].shape[0];
          } else {
            numSamples = ins.shape[0];
          }
        } else {
          throw new ValueError(`Either the input data should have a defined shape, or ${stepsName} shoud be specified.`);
        }
        return numSamples;
      }
      /**
       * Execute internal tensors of the model with input data feed.
       * @param inputs Input data feed. Must match the inputs of the model.
       * @param outputs Names of the output tensors to be fetched. Must match
       *   names of the SymbolicTensors that belong to the graph.
       * @returns Fetched values for `outputs`.
       */
      execute(inputs, outputs) {
        if (Array.isArray(outputs) && outputs.length === 0) {
          throw new ValueError("`outputs` is an empty Array, which is not allowed.");
        }
        const outputsIsArray = Array.isArray(outputs);
        const outputNames = outputsIsArray ? outputs : [outputs];
        const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);
        const feedDict = new FeedDict();
        if (inputs instanceof Tensor) {
          inputs = [inputs];
        }
        if (Array.isArray(inputs)) {
          if (inputs.length !== this.inputs.length) {
            throw new ValueError(`The number of inputs provided (${inputs.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
          }
          for (let i = 0; i < this.inputs.length; ++i) {
            feedDict.add(this.inputs[i], inputs[i]);
          }
        } else {
          for (const input2 of this.inputs) {
            const tensorValue = inputs[input2.name];
            if (tensorValue == null) {
              throw new ValueError(`No value is provided for the model's input ${input2.name}`);
            }
            feedDict.add(input2, tensorValue);
          }
        }
        const executeOutputs = execute(outputSymbolicTensors, feedDict);
        return outputsIsArray ? executeOutputs : executeOutputs[0];
      }
      /**
       * Retrieve the model's internal symbolic tensors from symbolic-tensor names.
       */
      retrieveSymbolicTensors(symbolicTensorNames) {
        const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);
        let outputsRemaining = symbolicTensorNames.length;
        for (const layer of this.layers) {
          const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];
          const layerOutputNames = layerOutputs.map((output) => output.name);
          for (let i = 0; i < symbolicTensorNames.length; ++i) {
            const index = layerOutputNames.indexOf(symbolicTensorNames[i]);
            if (index !== -1) {
              outputSymbolicTensors[i] = layerOutputs[index];
              outputsRemaining--;
            }
            if (outputsRemaining === 0) {
              break;
            }
          }
          if (outputsRemaining === 0) {
            break;
          }
        }
        if (outputsRemaining > 0) {
          const remainingNames = [];
          outputSymbolicTensors.forEach((tensor2, i) => {
            if (tensor2 == null) {
              remainingNames.push(symbolicTensorNames[i]);
            }
          });
          throw new ValueError(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(remainingNames)}`);
        }
        return outputSymbolicTensors;
      }
      /**
       * Helper method to loop over some data in batches.
       *
       * Porting Note: Not using the functional approach in the Python equivalent
       *   due to the imperative backend.
       * Porting Note: Does not support step mode currently.
       *
       * @param ins: input data
       * @param batchSize: integer batch size.
       * @param verbose: verbosity model
       * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of
       *   `tf.Tensor` (if multipe outputs).
       */
      predictLoop(ins, batchSize = 32, verbose = false) {
        return tidy(() => {
          const numSamples = this.checkNumSamples(ins);
          if (verbose) {
            throw new NotImplementedError("Verbose predictLoop() is not implemented yet.");
          }
          const batches = makeBatches(numSamples, batchSize);
          const outsBatches = this.outputs.map((output) => []);
          for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
            const batchOuts = tidy(() => {
              const batchStart = batches[batchIndex][0];
              const batchEnd = batches[batchIndex][1];
              const insBatch = sliceArrays(ins, batchStart, batchEnd);
              const feeds = [];
              if (Array.isArray(insBatch)) {
                for (let i = 0; i < insBatch.length; ++i) {
                  feeds.push({ key: this.inputs[i], value: insBatch[i] });
                }
              } else {
                feeds.push({ key: this.inputs[0], value: insBatch });
              }
              const feedDict = new FeedDict(feeds);
              return execute(this.outputs, feedDict);
            });
            batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));
          }
          return singletonOrArray(outsBatches.map((batches2) => concat(batches2, 0)));
        });
      }
      /**
       * Generates output predictions for the input samples.
       *
       * Computation is done in batches.
       *
       * Note: the "step" mode of predict() is currently not supported.
       *   This is because the TensorFlow.js core backend is imperative only.
       *
       * ```js
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();
       * ```
       *
       * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if
       *   the model has multiple inputs.
       * @param args A `ModelPredictArgs` object containing optional fields.
       *
       * @return Prediction results as a `tf.Tensor`(s).
       *
       * @exception ValueError In case of mismatch between the provided input data
       *   and the model's expectations, or in case a stateful model receives a
       *   number of samples that is not a multiple of the batch size.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      predict(x, args = {}) {
        const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);
        checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);
        try {
          const batchSize = args.batchSize == null ? 32 : args.batchSize;
          checkBatchSize(batchSize);
          return this.predictLoop(xsRank2OrHigher, batchSize);
        } finally {
          disposeNewTensors(xsRank2OrHigher, x);
        }
      }
      /**
       * Returns predictions for a single batch of samples.
       *
       * ```js
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.predictOnBatch(tf.ones([8, 10])).print();
       * ```
       * @param x: Input samples, as a Tensor (for models with exactly one
       *   input) or an array of Tensors (for models with more than one input).
       * @return Tensor(s) of predictions
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      predictOnBatch(x) {
        checkInputData(x, this.inputNames, this.feedInputShapes, true);
        const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];
        return this.predictLoop(x, batchSize);
      }
      standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {
        if (this.optimizer_ == null) {
          throw new RuntimeError("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
        }
        const outputShapes = [];
        for (let i = 0; i < this.feedOutputShapes.length; ++i) {
          const outputShape = this.feedOutputShapes[i];
          const lossFn = this.feedLossFns[i];
          if (lossFn === sparseCategoricalCrossentropy) {
            outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));
          } else {
            outputShapes.push(outputShape);
          }
        }
        x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, "input");
        y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, "target");
        checkArrayLengths(x, y, null);
        checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);
        if (this.stateful && batchSize != null && batchSize > 0) {
          if (x[0].shape[0] % batchSize !== 0) {
            throw new ValueError(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${batchSize}. Found: ${x[0].shape[0]} sample(s).`);
          }
        }
        return [x, y];
      }
      async standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {
        const [standardXs, standardYs] = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);
        if (sampleWeight != null) {
          throw new Error("sample weight is not supported yet.");
        }
        let standardSampleWeights = null;
        if (classWeight != null) {
          const classWeights = standardizeClassWeights(classWeight, this.outputNames);
          standardSampleWeights = [];
          for (let i = 0; i < classWeights.length; ++i) {
            standardSampleWeights.push(await standardizeWeights(standardYs[i], null, classWeights[i]));
          }
        }
        return [standardXs, standardYs, standardSampleWeights];
      }
      /**
       * Loop over some test data in batches.
       * @param f A Function returning a list of tensors.
       * @param ins Array of tensors to be fed to `f`.
       * @param batchSize Integer batch size or `null` / `undefined`.
       * @param verbose verbosity mode.
       * @param steps Total number of steps (batches of samples) before
       * declaring test finished. Ignored with the default value of `null` /
       * `undefined`.
       * @returns Array of Scalars.
       */
      testLoop(f, ins, batchSize, verbose = 0, steps) {
        return tidy(() => {
          const numSamples = this.checkNumSamples(ins, batchSize, steps, "steps");
          const outs = [];
          if (verbose > 0) {
            throw new NotImplementedError("Verbose mode is not implemented yet.");
          }
          if (steps != null) {
            throw new NotImplementedError("steps mode in testLoop() is not implemented yet");
          } else {
            const batches = makeBatches(numSamples, batchSize);
            const indexArray = tensor1d(range2(0, numSamples));
            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
              const batchStart = batches[batchIndex][0];
              const batchEnd = batches[batchIndex][1];
              const batchIds = sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart);
              const insBatch = sliceArraysByIndices(ins, batchIds);
              const batchOuts = f(insBatch);
              if (batchIndex === 0) {
                for (let i = 0; i < batchOuts.length; ++i) {
                  outs.push(scalar(0));
                }
              }
              for (let i = 0; i < batchOuts.length; ++i) {
                const batchOut = batchOuts[i];
                outs[i] = add22(outs[i], mul5(batchEnd - batchStart, batchOut));
              }
            }
            for (let i = 0; i < outs.length; ++i) {
              outs[i] = div2(outs[i], numSamples);
            }
          }
          return outs;
        });
      }
      getDedupedMetricsNames() {
        const outLabels = this.metricsNames;
        const dedupedOutLabels = [];
        for (let i = 0; i < outLabels.length; ++i) {
          const label = outLabels[i];
          let newLabel = label;
          if (count(outLabels, label) > 1) {
            const dupIndex = count(outLabels.slice(0, i), label);
            newLabel += `_${dupIndex}`;
          }
          dedupedOutLabels.push(newLabel);
        }
        return dedupedOutLabels;
      }
      /**
       * Creates a function that performs the following actions:
       *
       * 1. computes the losses
       * 2. sums them to get the total loss
       * 3. call the optimizer computes the gradients of the LayersModel's
       *    trainable weights w.r.t. the total loss and update the variables
       * 4. calculates the metrics
       * 5. returns the values of the losses and metrics.
       */
      makeTrainFunction() {
        return (data) => {
          const lossValues = [];
          const inputs = data.slice(0, this.inputs.length);
          const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);
          const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);
          const metricsValues = [];
          const totalLossFunction = () => {
            const feeds = [];
            for (let i = 0; i < this.inputs.length; ++i) {
              feeds.push({ key: this.inputs[i], value: inputs[i] });
            }
            const feedDict = new FeedDict(feeds);
            const outputs = execute(this.outputs, feedDict, { "training": true });
            let totalLoss;
            for (let i = 0; i < this.lossFunctions.length; ++i) {
              const lossFunction = this.lossFunctions[i];
              let loss = lossFunction(targets[i], outputs[i]);
              if (sampleWeights[i] != null) {
                loss = computeWeightedLoss(loss, sampleWeights[i]);
              }
              const meanLoss = mean(loss);
              lossValues.push(meanLoss);
              if (i === 0) {
                totalLoss = loss;
              } else {
                totalLoss = add22(totalLoss, loss);
              }
            }
            for (let i = 0; i < this.metricsTensors.length; ++i) {
              let weightedMetric;
              if (this.outputs.length > 1 && i < this.outputs.length) {
                weightedMetric = lossValues[i];
              } else {
                const metric = this.metricsTensors[i][0];
                const outputIndex = this.metricsTensors[i][1];
                weightedMetric = mean(metric(targets[outputIndex], outputs[outputIndex]));
              }
              keep(weightedMetric);
              metricsValues.push(weightedMetric);
            }
            totalLoss = mean(totalLoss);
            this.calculateLosses().forEach((regularizerLoss) => {
              totalLoss = add22(totalLoss, regularizerLoss);
            });
            return totalLoss;
          };
          const variables = this.collectedTrainableWeights.map((param) => param.read());
          const returnCost = true;
          const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);
          return [totalLossValue].concat(metricsValues);
        };
      }
      /**
       * Create a function which, when invoked with an array of `tf.Tensor`s as a
       * batch of inputs, returns the prespecified loss and metrics of the model
       * under the batch of input data.
       */
      makeTestFunction() {
        this.testFunction = (data) => {
          return tidy(() => {
            const valOutputs = [];
            let totalLoss;
            const inputs = data.slice(0, this.inputs.length);
            const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);
            const feeds = [];
            for (let i = 0; i < this.inputs.length; ++i) {
              feeds.push({ key: this.inputs[i], value: inputs[i] });
            }
            const feedDict = new FeedDict(feeds);
            const outputs = execute(this.outputs, feedDict);
            for (let i = 0; i < this.lossFunctions.length; ++i) {
              const lossFunction = this.lossFunctions[i];
              const loss = mean(lossFunction(targets[i], outputs[i]));
              if (i === 0) {
                totalLoss = loss;
              } else {
                totalLoss = add22(totalLoss, loss);
              }
              valOutputs.push(totalLoss);
            }
            for (let i = 0; i < this.metricsTensors.length; ++i) {
              const metric = this.metricsTensors[i][0];
              const outputIndex = this.metricsTensors[i][1];
              const meanMetric = mean(metric(targets[outputIndex], outputs[outputIndex]));
              valOutputs.push(meanMetric);
            }
            return valOutputs;
          });
        };
      }
      /**
       * Trains the model for a fixed number of epochs (iterations on a
       * dataset).
       *
       * ```js
       * const model = tf.sequential({
       *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
       * for (let i = 1; i < 5 ; ++i) {
       *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {
       *       batchSize: 4,
       *       epochs: 3
       *   });
       *   console.log("Loss after Epoch " + i + " : " + h.history.loss[0]);
       * }
       * ```
       *
       * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the
       * model has multiple inputs. If all inputs in the model are named, you
       * can also pass a dictionary mapping input names to `tf.Tensor`s.
       * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if
       * the model has multiple outputs. If all outputs in the model are named,
       * you can also pass a dictionary mapping output names to `tf.Tensor`s.
       * @param args A `ModelFitArgs`, containing optional fields.
       *
       * @return A `History` instance. Its `history` attribute contains all
       *   information collected during training.
       *
       * @exception ValueError In case of mismatch between the provided input
       * data and what the model expects.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async fit(x, y, args = {}) {
        if (this.isTraining) {
          throw new Error("Cannot start training because another fit() call is ongoing.");
        }
        this.isTraining = true;
        let inputs;
        let targets;
        let originalInputs;
        let originalTargets;
        let inputValX;
        let inputValY;
        let valX;
        let valY;
        let sampleWeights;
        try {
          const batchSize = args.batchSize == null ? 32 : args.batchSize;
          checkBatchSize(batchSize);
          const checkBatchAxis = false;
          const standardizedOuts = await this.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);
          inputs = standardizedOuts[0];
          targets = standardizedOuts[1];
          sampleWeights = standardizedOuts[2];
          let doValidation = false;
          let valIns;
          if (args.validationData != null && args.validationData.length > 0) {
            doValidation = true;
            if (args.validationData.length === 2) {
              inputValX = args.validationData[0];
              inputValY = args.validationData[1];
            } else if (args.validationData.length === 3) {
              throw new NotImplementedError("validationData including sample weights is not supported yet.");
            } else {
              throw new ValueError(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${args.validationData} is invalid.`);
            }
            const checkBatchAxis2 = true;
            const valStandardized = await this.standardizeUserData(
              inputValX,
              inputValY,
              null,
              /** Unused sample weights. */
              null,
              /** Unused class weights. */
              checkBatchAxis2,
              batchSize
            );
            valX = valStandardized[0];
            valY = valStandardized[1];
            valIns = valX.concat(valY);
          } else if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {
            doValidation = true;
            const splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));
            const originalBatchSize = inputs[0].shape[0];
            valX = sliceArrays(inputs, splitAt, originalBatchSize);
            originalInputs = inputs;
            inputs = sliceArrays(inputs, 0, splitAt);
            valY = sliceArrays(targets, splitAt, originalBatchSize);
            originalTargets = targets;
            targets = sliceArrays(targets, 0, splitAt);
            valIns = valX.concat(valY);
          } else if (args.validationSteps != null) {
            doValidation = true;
          }
          const ins = inputs.concat(targets).concat(sampleWeights);
          this.checkTrainableWeightsConsistency();
          const trainFunction = this.makeTrainFunction();
          const outLabels = this.getDedupedMetricsNames();
          let valFunction;
          let callbackMetrics;
          if (doValidation) {
            this.makeTestFunction();
            valFunction = this.testFunction;
            callbackMetrics = outLabels.slice().concat(outLabels.map((n) => "val_" + n));
          } else {
            valFunction = null;
            valIns = [];
            callbackMetrics = outLabels.slice();
          }
          const callbacks2 = standardizeCallbacks(args.callbacks, args.yieldEvery);
          const out = await this.fitLoop(trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks2, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);
          return out;
        } finally {
          this.isTraining = false;
          disposeNewTensors(inputs, x);
          disposeNewTensors(targets, y);
          disposeNewTensors(originalInputs, x);
          disposeNewTensors(originalTargets, y);
          disposeNewTensors(valX, inputValX);
          disposeNewTensors(valY, inputValY);
          if (sampleWeights != null) {
            dispose(sampleWeights);
          }
        }
      }
      /**
       * Abstract fit function for `f(ins)`.
       * @param f A Function returning a list of tensors. For training, this
       *   function is expected to perform the updates to the variables.
       * @param ins List of tensors to be fed to `f`.
       * @param outLabels List of strings, display names of the outputs of `f`.
       * @param batchSize Integer batch size or `== null` if unknown. Default : 32.
       * @param epochs Number of times to iterate over the data. Default : 1.
       * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.
       * @param callbacks List of callbacks to be called during training.
       * @param valF Function to call for validation.
       * @param valIns List of tensors to be fed to `valF`.
       * @param shuffle Whether to shuffle the data at the beginning of every
       * epoch. Default : true.
       * @param callbackMetrics List of strings, the display names of the metrics
       *   passed to the callbacks. They should be the concatenation of the
       *   display names of the outputs of `f` and the list of display names
       *   of the outputs of `valF`.
       * @param initialEpoch Epoch at which to start training (useful for
       *   resuming a previous training run). Default : 0.
       * @param stepsPerEpoch Total number of steps (batches on samples) before
       *   declaring one epoch finished and starting the next epoch. Ignored with
       *   the default value of `undefined` or `null`.
       * @param validationSteps Number of steps to run validation for (only if
       *   doing validation from data tensors). Not applicable for tfjs-layers.
       * @returns A `History` object.
       */
      async fitLoop(f, ins, outLabels, batchSize, epochs, verbose, callbacks2, valF, valIns, shuffle2, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {
        if (batchSize == null) {
          batchSize = 32;
        }
        if (epochs == null) {
          epochs = 1;
        }
        if (shuffle2 == null) {
          shuffle2 = true;
        }
        if (initialEpoch == null) {
          initialEpoch = 0;
        }
        let doValidation = false;
        if (valF != null && valIns != null) {
          doValidation = true;
        }
        if (validationSteps != null) {
          doValidation = true;
          if (stepsPerEpoch == null) {
            throw new ValueError("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
          }
        }
        const numTrainSamples = this.checkNumSamples(ins, batchSize, stepsPerEpoch, "steps_per_epoch");
        let indexArray;
        if (numTrainSamples != null) {
          indexArray = range2(0, numTrainSamples);
        }
        if (verbose == null) {
          verbose = 1;
        }
        const { callbackList, history } = configureCallbacks(callbacks2, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics);
        callbackList.setModel(this);
        this.history = history;
        await callbackList.onTrainBegin();
        this.stopTraining_ = false;
        for (let epoch = initialEpoch; epoch < epochs; ++epoch) {
          await callbackList.onEpochBegin(epoch);
          const epochLogs = {};
          if (stepsPerEpoch != null) {
            throw new NotImplementedError("stepsPerEpoch mode is not implemented yet.");
          } else {
            if (shuffle2 === "batch") {
              throw new NotImplementedError("batch shuffling is not implemneted yet");
            } else if (shuffle2) {
              util_exports.shuffle(indexArray);
            }
            const epochIndexArray1D = tensor1d(indexArray);
            const batches = makeBatches(numTrainSamples, batchSize);
            for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {
              const batchLogs = {};
              await callbackList.onBatchBegin(batchIndex, batchLogs);
              tidy(() => {
                const batchStart = batches[batchIndex][0];
                const batchEnd = batches[batchIndex][1];
                const batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);
                batchLogs["batch"] = batchIndex;
                batchLogs["size"] = batchEnd - batchStart;
                const insBatch = sliceArraysByIndices(ins, batchIds);
                const outs = f(insBatch);
                for (let i = 0; i < outLabels.length; ++i) {
                  const label = outLabels[i];
                  const out = outs[i];
                  batchLogs[label] = out;
                  keep(out);
                }
                if (batchIndex === batches.length - 1) {
                  if (doValidation) {
                    const valOuts = this.testLoop(valF, valIns, batchSize);
                    for (let i = 0; i < outLabels.length; ++i) {
                      const label = outLabels[i];
                      const out = valOuts[i];
                      keep(out);
                      epochLogs["val_" + label] = out;
                    }
                  }
                }
              });
              await callbackList.onBatchEnd(batchIndex, batchLogs);
              disposeTensorsInLogs(batchLogs);
              if (this.stopTraining_) {
                break;
              }
            }
            epochIndexArray1D.dispose();
          }
          await callbackList.onEpochEnd(epoch, epochLogs);
          if (this.stopTraining_) {
            break;
          }
        }
        await callbackList.onTrainEnd();
        await this.history.syncData();
        return this.history;
      }
      // TODO(cais): Add code snippet below when it's possible to instantiate
      //   actual dataset objects.
      /**
       * Trains the model using a dataset object.
       *
       * @param dataset A dataset object. Its `iterator()` method is expected
       *   to generate a dataset iterator object, the `next()` method of which
       *   is expected to produce data batches for training. The return value
       *   of the `next()` call ought to contain a boolean `done` field and a
       *   `value` field. The `value` field is expected to be an array of two
       *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
       *   case is for models with exactly one input and one output (e.g.
       *   a sequential model). The latter case is for models with multiple
       *   inputs and/or multiple outputs.
       *   Of the two items in the array, the first is the input feature(s) and
       *   the second is the output target(s).
       * @param args A `ModelFitDatasetArgs`, containing optional fields.
       *
       * @return A `History` instance. Its `history` attribute contains all
       *   information collected during training.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async fitDataset(dataset, args) {
        return fitDataset(this, dataset, args);
      }
      /**
       * Runs a single gradient update on a single batch of data.
       *
       * This method differs from `fit()` and `fitDataset()` in the following
       * regards:
       *   - It operates on exactly one batch of data.
       *   - It returns only the loss and metric values, instead of
       *     returning the batch-by-batch loss and metric values.
       *   - It doesn't support fine-grained options such as verbosity and
       *     callbacks.
       *
       * @param x Input data. It could be one of the following:
       *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has
       *     multiple inputs).
       *   - An Object mapping input names to corresponding `tf.Tensor` (if the
       *     model has named inputs).
       * @param y Target data. It could be either a `tf.Tensor` or multiple
       *   `tf.Tensor`s. It should be consistent with `x`.
       * @returns Training loss or losses (in case the model has
       *   multiple outputs), along with metrics (if any), as numbers.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async trainOnBatch(x, y) {
        const standardizeOut = await this.standardizeUserData(x, y);
        const inputs = standardizeOut[0];
        const targets = standardizeOut[1];
        const trainFunction = this.makeTrainFunction();
        const losses = trainFunction(inputs.concat(targets));
        const lossValues = [];
        for (const loss of losses) {
          const v = await loss.data();
          lossValues.push(v[0]);
        }
        dispose(losses);
        disposeNewTensors(standardizeOut[0], x);
        disposeNewTensors(standardizeOut[1], y);
        return singletonOrArray(lossValues);
      }
      /**
       * Extract weight values of the model.
       *
       * @param config: An instance of `io.SaveConfig`, which specifies
       * model-saving options such as whether only trainable weights are to be
       * saved.
       * @returns A `NamedTensorMap` mapping original weight names (i.e.,
       *   non-uniqueified weight names) to their values.
       */
      getNamedWeights(config) {
        const namedWeights = [];
        const trainableOnly = config != null && config.trainableOnly;
        const weights = trainableOnly ? this.trainableWeights : this.weights;
        const weightValues = this.getWeights(trainableOnly);
        for (let i = 0; i < weights.length; ++i) {
          if (trainableOnly && !weights[i].trainable) {
            continue;
          }
          namedWeights.push({ name: weights[i].originalName, tensor: weightValues[i] });
        }
        return namedWeights;
      }
      /**
       * Setter used for force stopping of LayersModel.fit() (i.e., training).
       *
       * Example:
       *
       * ```js
       * const input = tf.input({shape: [10]});
       * const output = tf.layers.dense({units: 1}).apply(input);
       * const model = tf.model({inputs: [input], outputs: [output]});
       * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
       * const xs = tf.ones([8, 10]);
       * const ys = tf.zeros([8, 1]);
       *
       * const history = await model.fit(xs, ys, {
       *   epochs: 10,
       *   callbacks: {
       *     onEpochEnd: async (epoch, logs) => {
       *       if (epoch === 2) {
       *         model.stopTraining = true;
       *       }
       *     }
       *   }
       * });
       *
       * // There should be only 3 values in the loss array, instead of 10
       * values,
       * // due to the stopping after 3 epochs.
       * console.log(history.history.loss);
       * ```
       */
      set stopTraining(stop) {
        this.stopTraining_ = stop;
      }
      get stopTraining() {
        return this.stopTraining_;
      }
      get optimizer() {
        return this.optimizer_;
      }
      set optimizer(optimizer) {
        if (this.optimizer_ !== optimizer) {
          this.optimizer_ = optimizer;
          this.isOptimizerOwned = false;
        }
      }
      dispose() {
        const result = super.dispose();
        if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {
          const numTensorsBeforeOptmizerDisposal = memory().numTensors;
          this.optimizer_.dispose();
          result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - memory().numTensors;
        }
        return result;
      }
      getLossIdentifiers() {
        let lossNames;
        if (typeof this.loss === "string") {
          lossNames = toSnakeCase(this.loss);
        } else if (Array.isArray(this.loss)) {
          for (const loss of this.loss) {
            if (typeof loss !== "string") {
              throw new Error("Serialization of non-string loss is not supported.");
            }
          }
          lossNames = this.loss.map((name) => toSnakeCase(name));
        } else {
          const outputNames = Object.keys(this.loss);
          lossNames = {};
          const losses = this.loss;
          for (const outputName of outputNames) {
            if (typeof losses[outputName] === "string") {
              lossNames[outputName] = toSnakeCase(losses[outputName]);
            } else {
              throw new Error("Serialization of non-string loss is not supported.");
            }
          }
        }
        return lossNames;
      }
      getMetricIdentifiers() {
        if (typeof this.metrics === "string" || typeof this.metrics === "function") {
          return [toSnakeCase(getLossOrMetricName(this.metrics))];
        } else if (Array.isArray(this.metrics)) {
          return this.metrics.map((metric) => toSnakeCase(getLossOrMetricName(metric)));
        } else {
          const metricsIdentifiers = {};
          for (const key in this.metrics) {
            metricsIdentifiers[key] = toSnakeCase(getLossOrMetricName(this.metrics[key]));
          }
          return metricsIdentifiers;
        }
      }
      getTrainingConfig() {
        return {
          loss: this.getLossIdentifiers(),
          metrics: this.getMetricIdentifiers(),
          optimizer_config: {
            class_name: this.optimizer.getClassName(),
            config: this.optimizer.getConfig()
          }
        };
      }
      loadTrainingConfig(trainingConfig) {
        if (trainingConfig.weighted_metrics != null) {
          throw new Error("Loading weight_metrics is not supported yet.");
        }
        if (trainingConfig.loss_weights != null) {
          throw new Error("Loading loss_weights is not supported yet.");
        }
        if (trainingConfig.sample_weight_mode != null) {
          throw new Error("Loading sample_weight_mode is not supported yet.");
        }
        const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);
        const optimizer = deserialize(tsConfig);
        let loss;
        if (typeof trainingConfig.loss === "string") {
          loss = toCamelCase(trainingConfig.loss);
        } else if (Array.isArray(trainingConfig.loss)) {
          loss = trainingConfig.loss.map((lossEntry) => toCamelCase(lossEntry));
        } else if (trainingConfig.loss != null) {
          loss = {};
          for (const key in trainingConfig.loss) {
            loss[key] = toCamelCase(trainingConfig.loss[key]);
          }
        }
        let metrics;
        if (Array.isArray(trainingConfig.metrics)) {
          metrics = trainingConfig.metrics.map((metric) => toCamelCase(metric));
        } else if (trainingConfig.metrics != null) {
          metrics = {};
          for (const key in trainingConfig.metrics) {
            metrics[key] = toCamelCase(trainingConfig.metrics[key]);
          }
        }
        this.compile({ loss, metrics, optimizer });
      }
      /**
       * Save the configuration and/or weights of the LayersModel.
       *
       * An `IOHandler` is an object that has a `save` method of the proper
       * signature defined. The `save` method manages the storing or
       * transmission of serialized data ("artifacts") that represent the
       * model's topology and weights onto or via a specific medium, such as
       * file downloads, local storage, IndexedDB in the web browser and HTTP
       * requests to a server. TensorFlow.js provides `IOHandler`
       * implementations for a number of frequently used saving mediums, such as
       * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`
       * for more details.
       *
       * This method also allows you to refer to certain types of `IOHandler`s
       * as URL-like string shortcuts, such as 'localstorage://' and
       * 'indexeddb://'.
       *
       * Example 1: Save `model`'s topology and weights to browser [local
       * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);
       * then load it back.
       *
       * ```js
       * const model = tf.sequential(
       *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
       * console.log('Prediction from original model:');
       * model.predict(tf.ones([1, 3])).print();
       *
       * const saveResults = await model.save('localstorage://my-model-1');
       *
       * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');
       * console.log('Prediction from loaded model:');
       * loadedModel.predict(tf.ones([1, 3])).print();
       * ```
       *
       * Example 2. Saving `model`'s topology and weights to browser
       * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);
       * then load it back.
       *
       * ```js
       * const model = tf.sequential(
       *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
       * console.log('Prediction from original model:');
       * model.predict(tf.ones([1, 3])).print();
       *
       * const saveResults = await model.save('indexeddb://my-model-1');
       *
       * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');
       * console.log('Prediction from loaded model:');
       * loadedModel.predict(tf.ones([1, 3])).print();
       * ```
       *
       * Example 3. Saving `model`'s topology and weights as two files
       * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from
       * browser.
       *
       * ```js
       * const model = tf.sequential(
       *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
       * const saveResults = await model.save('downloads://my-model-1');
       * ```
       *
       * Example 4. Send  `model`'s topology and weights to an HTTP server.
       * See the documentation of `tf.io.http` for more details
       * including specifying request parameters and implementation of the
       * server.
       *
       * ```js
       * const model = tf.sequential(
       *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});
       * const saveResults = await model.save('http://my-server/model/upload');
       * ```
       *
       * @param handlerOrURL An instance of `IOHandler` or a URL-like,
       * scheme-based string shortcut for `IOHandler`.
       * @param config Options for saving the model.
       * @returns A `Promise` of `SaveResult`, which summarizes the result of
       * the saving, such as byte sizes of the saved artifacts for the model's
       *   topology and weight values.
       *
       * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
       */
      async save(handlerOrURL, config) {
        if (typeof handlerOrURL === "string") {
          const handlers = io_exports.getSaveHandlers(handlerOrURL);
          if (handlers.length === 0) {
            throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);
          } else if (handlers.length > 1) {
            throw new ValueError(`Found more than one (${handlers.length}) save handlers for URL '${handlerOrURL}'`);
          }
          handlerOrURL = handlers[0];
        }
        if (handlerOrURL.save == null) {
          throw new ValueError("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
        }
        const weightDataAndSpecs = await io_exports.encodeWeights(this.getNamedWeights(config));
        const returnString = false;
        const unusedArg = null;
        const modelConfig = this.toJSON(unusedArg, returnString);
        const modelArtifacts = {
          modelTopology: modelConfig,
          format: LAYERS_MODEL_FORMAT_NAME,
          generatedBy: `TensorFlow.js tfjs-layers v${version}`,
          convertedBy: null
        };
        const includeOptimizer = config == null ? false : config.includeOptimizer;
        if (includeOptimizer && this.optimizer != null) {
          modelArtifacts.trainingConfig = this.getTrainingConfig();
          const weightType = "optimizer";
          const { data: optimizerWeightData, specs: optimizerWeightSpecs } = await io_exports.encodeWeights(await this.optimizer.getWeights(), weightType);
          weightDataAndSpecs.specs.push(...optimizerWeightSpecs);
          weightDataAndSpecs.data = io_exports.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);
        }
        if (this.userDefinedMetadata != null) {
          const checkSize = true;
          checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);
          modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;
        }
        modelArtifacts.weightData = weightDataAndSpecs.data;
        modelArtifacts.weightSpecs = weightDataAndSpecs.specs;
        return handlerOrURL.save(modelArtifacts);
      }
      /**
       * Set user-defined metadata.
       *
       * The set metadata will be serialized together with the topology
       * and weights of the model during `save()` calls.
       *
       * @param setUserDefinedMetadata
       */
      setUserDefinedMetadata(userDefinedMetadata) {
        checkUserDefinedMetadata(userDefinedMetadata, this.name);
        this.userDefinedMetadata = userDefinedMetadata;
      }
      /**
       * Get user-defined metadata.
       *
       * The metadata is supplied via one of the two routes:
       *   1. By calling `setUserDefinedMetadata()`.
       *   2. Loaded during model loading (if the model is constructed
       *      via `tf.loadLayersModel()`.)
       *
       * If no user-defined metadata is available from either of the
       * two routes, this function will return `undefined`.
       */
      getUserDefinedMetadata() {
        return this.userDefinedMetadata;
      }
    };
    LayersModel.className = "Model";
    serialization_exports.registerClass(LayersModel);
    Functional = class extends LayersModel {
    };
    Functional.className = "Functional";
    serialization_exports.registerClass(Functional);
  }
});
var Sequential;
var init_models = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/models.js"() {
    init_dist();
    init_state();
    init_input_layer();
    init_topology();
    init_training();
    init_errors();
    init_serialization2();
    init_generic_utils();
    init_serialization_utils();
    init_types_utils();
    Sequential = class extends LayersModel {
      constructor(args) {
        super({ inputs: [], outputs: [] });
        args = args || {};
        this.trainable = true;
        this.built = false;
        this.name = args.name != null ? args.name : getUid("sequential_");
        if (args.layers != null) {
          for (const layer of args.layers) {
            this.add(layer);
          }
        }
      }
      // Helper function to Sequential.add  Throws if the new output shape will be
      // invalid.
      checkShape(layer) {
        const shape = layer.inboundNodes[0].outputTensors[0].shape;
        if (shape.some((x) => x < 0)) {
          throw new ValueError(`Negative dimension size caused by adding layer ${layer.name} with input shape [${layer.inboundNodes[0].inputTensors[0].shape}]`);
        }
      }
      /**
       * Adds a layer instance on top of the layer stack.
       *
       * ```js
       *  const model = tf.sequential();
       *  model.add(tf.layers.dense({units: 8, inputShape: [1]}));
       *  model.add(tf.layers.dense({units: 4, activation: 'relu6'}));
       *  model.add(tf.layers.dense({units: 1, activation: 'relu6'}));
       *  // Note that the untrained model is random at this point.
       *  model.predict(tf.randomNormal([10, 1])).print();
       * ```
       * @param layer Layer instance.
       *
       * @exception ValueError In case the `layer` argument does not know its
       * input shape.
       * @exception ValueError In case the `layer` argument has multiple output
       *   tensors, or is already connected somewhere else (forbidden in
       *   `Sequential` models).
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      add(layer) {
        const isLayerModelInstance = layer instanceof Sequential || layer instanceof LayersModel;
        let modelLayer;
        if (isLayerModelInstance) {
          modelLayer = layer;
          if (modelLayer.outputs.length !== 1) {
            throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
          }
          if (modelLayer.inputs.length !== 1) {
            throw new ValueError("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
          }
        }
        if (this.outputs.length === 0) {
          if (layer.inboundNodes.length === 0) {
            if (layer.batchInputShape == null) {
              throw new ValueError("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
            }
            const x = Input({
              batchShape: layer.batchInputShape,
              dtype: layer.dtype,
              name: layer.name + "_input"
            });
            layer.apply(x);
          }
          if (isLayerModelInstance) {
            this.outputs = modelLayer.outputs;
            this.inputs = modelLayer.inputs;
          } else {
            if (layer.inboundNodes.length !== 1) {
              throw new ValueError(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${layer.name} which has ${layer.inboundNodes.length} pre-existing inbound connections.`);
            }
            if (layer.inboundNodes[0].outputTensors.length !== 1) {
              throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
            }
            this.checkShape(layer);
            this.outputs = [layer.inboundNodes[0].outputTensors[0]];
            this.inputs = getSourceInputs(this.outputs[0]);
          }
          this.inboundNodes = [];
          new Node({
            outboundLayer: this,
            inboundLayers: [],
            nodeIndices: [],
            tensorIndices: [],
            inputTensors: this.inputs,
            outputTensors: this.outputs,
            // no model-level masking for now
            inputMasks: pyListRepeat(null, this.inputs.length),
            outputMasks: [null],
            inputShapes: this.inputs.map((x) => x.shape),
            outputShapes: this.outputs[0].shape
          });
        } else {
          const outputTensor = layer.apply(this.outputs[0]);
          if (Array.isArray(outputTensor)) {
            throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
          }
          this.checkShape(layer);
          this.outputs = [outputTensor];
          this.inboundNodes[0].outputTensors = this.outputs;
          this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
        }
        this.layers.push(layer);
        this.built = false;
      }
      /**
       * Removes the last layer in the model.
       *
       * @exception TypeError if there are no layers in the model.
       */
      pop() {
        if (this.layers.length === 0) {
          throw new TypeError("There are no layers in the model.");
        }
        this.layers.pop();
        if (this.layers.length === 0) {
          this.outputs = [];
          this.inboundNodes = [];
          this.outboundNodes = [];
        } else {
          const lastLayerIndex = this.layers.length - 1;
          this.layers[lastLayerIndex].outboundNodes = [];
          this.outputs = [this.layers[lastLayerIndex].output];
          this.inboundNodes[0].outputTensors = this.outputs;
          this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
        }
      }
      call(inputs, kwargs) {
        if (this.model == null) {
          this.build();
        }
        return this.model.call(inputs, kwargs);
      }
      build(inputShape) {
        getExactlyOneShape(inputShape);
        if (this.inputs.length === 0 || this.outputs.length === 0) {
          throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
        }
        this.model = new LayersModel({
          inputs: this.inputs,
          outputs: this.outputs[0],
          name: this.name + "_model"
        });
        this.model.trainable = this.trainable;
        this.supportsMasking = this.model.supportsMasking;
        this.inputLayers = this.model.inputLayers;
        this.inputLayersNodeIndices = this.model.inputLayersNodeIndices;
        this.inputLayersTensorIndices = this.model.inputLayersTensorIndices;
        this.outputLayers = this.model.outputLayers;
        this.outputLayersNodeIndices = this.model.outputLayersNodeIndices;
        this.outputLayersTensorIndices = this.model.outputLayersTensorIndices;
        this.nodesByDepth = this.model.nodesByDepth;
        this.containerNodes = this.model.containerNodes;
        this.outputNames = this.model.outputNames;
        this.inputNames = this.model.inputNames;
        this.built = true;
      }
      countParams() {
        if (!this.built) {
          this.build();
        }
        return super.countParams();
      }
      /**
       * Print a text summary of the Sequential model's layers.
       *
       * The summary includes
       * - Name and type of all layers that comprise the model.
       * - Output shape(s) of the layers
       * - Number of weight parameters of each layer
       * - The total number of trainable and non-trainable parameters of the
       * model.
       *
       * ```js
       * const model = tf.sequential();
       * model.add(
       *     tf.layers.dense({units: 100, inputShape: [10], activation: 'relu'}));
       * model.add(tf.layers.dense({units: 1, activation: 'sigmoid'}));
       *
       * model.summary();
       * ```
       *
       * @param lineLength Custom line length, in number of characters.
       * @param positions Custom widths of each of the columns, as either
       *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number
       *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to
       *   right-most (i.e., ending) position of a column.
       * @param printFn Custom print function. Can be used to replace the default
       *   `console.log`. For example, you can use `x => {}` to mute the printed
       *   messages in the console.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      summary(lineLength, positions, printFn = console.log) {
        if (!this.built) {
          this.build();
        }
        super.summary(lineLength, positions, printFn);
      }
      /**
       * Sets the weights of the model.
       *
       * @param weights Should be a list of Tensors with shapes and types matching
       *   the output of `model.getWeights()`.
       */
      setWeights(weights) {
        if (this.model == null) {
          this.build();
        }
        this.model.setWeights(weights);
      }
      /**
       * Returns the loss value & metrics values for the model in test mode.
       *
       * Loss and metrics are specified during `compile()`, which needs to happen
       * before calls to `evaluate()`.
       *
       * Computation is done in batches.
       *
       * ```js
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
       * const result = model.evaluate(tf.ones([8, 10]), tf.ones([8, 1]), {
       *   batchSize: 4,
       * });
       * result.print();
       * ```
       *
       * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the
       * model has multiple inputs.
       * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the
       * model has multiple outputs.
       * @param args A `ModelEvaluateConfig`, containing optional fields.
       *
       * @return `Scalar` test loss (if the model has a single output and no
       *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs
       *   and/or metrics). The attribute `model.metricsNames`
       *   will give you the display labels for the scalar outputs.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      evaluate(x, y, args = {}) {
        if (!this.built) {
          throw new RuntimeError("The model needs to be compiled before being used.");
        }
        return this.model.evaluate(x, y, args);
      }
      // TODO(cais): Add code snippet below once real dataset objects are
      //   available.
      /**
       * Evaluate model using a dataset object.
       *
       * Note: Unlike `evaluate()`, this method is asynchronous (`async`).
       *
       * @param dataset A dataset object. Its `iterator()` method is expected
       *   to generate a dataset iterator object, the `next()` method of which
       *   is expected to produce data batches for evaluation. The return value
       *   of the `next()` call ought to contain a boolean `done` field and a
       *   `value` field. The `value` field is expected to be an array of two
       *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former
       *   case is for models with exactly one input and one output (e.g.
       *   a sequential model). The latter case is for models with multiple
       *   inputs and/or multiple outputs. Of the two items in the array, the
       *   first is the input feature(s) and the second is the output target(s).
       * @param args A configuration object for the dataset-based evaluation.
       * @returns Loss and metric values as an Array of `Scalar` objects.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async evaluateDataset(dataset, args) {
        if (!this.built) {
          throw new RuntimeError("The model needs to be compiled before being used.");
        }
        return this.model.evaluateDataset(dataset, args);
      }
      /**
       * Generates output predictions for the input samples.
       *
       * Computation is done in batches.
       *
       * Note: the "step" mode of predict() is currently not supported.
       *   This is because the TensorFlow.js core backend is imperative only.
       *
       * ```js
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.predict(tf.ones([2, 10])).print();
       * ```
       *
       * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if
       *   the model has multiple inputs.
       * @param conifg A `ModelPredictConfig` object containing optional fields.
       *
       * @return `tf.Tensor`(s) of predictions.
       *
       * @exception ValueError In case of mismatch between the provided input data
       *   and the model's expectations, or in case a stateful model receives a
       *   number of samples that is not a multiple of the batch size.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      predict(x, args = {}) {
        if (this.model == null) {
          this.build();
        }
        return this.model.predict(x, args);
      }
      /**
       * Returns predictions for a single batch of samples.
       *
       * @param x: Input samples, as a Tensor, or list of Tensors (if the model
       *   has multiple inputs).
       * @return Tensor(s) of predictions
       */
      predictOnBatch(x) {
        if (this.model == null) {
          this.build();
        }
        return this.model.predictOnBatch(x);
      }
      /**
       * See `LayersModel.compile`.
       *
       * @param args
       */
      compile(args) {
        this.build();
        this.model.compile(args);
        this.optimizer_ = this.model.optimizer;
        this.isOptimizerOwned = this.model.isOptimizerOwned;
        this.loss = this.model.loss;
        this.metrics = this.model.metrics;
        this.metricsTensors = this.model.metricsTensors;
        this.metricsNames = this.model.metricsNames;
      }
      get optimizer() {
        return this.model == null ? void 0 : this.model.optimizer;
      }
      set optimizer(optimizer) {
        this.model.optimizer = optimizer;
      }
      /**
       * Trains the model for a fixed number of epochs (iterations on a dataset).
       *
       * ```js
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]
       * });
       * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
       * const history = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {
       *   batchSize: 4,
       *   epochs: 3
       * });
       * console.log(history.history.loss[0]);
       * ```
       *
       * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the
       * model has multiple inputs. If all inputs in the model are named, you can
       * also pass a dictionary mapping input names to `tf.Tensor`s.
       * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if
       * the model has multiple outputs. If all outputs in the model are named, you
       *  can also pass a dictionary mapping output names to `tf.Tensor`s.
       * @param args  A `ModelFitConfig`, containing optional fields.
       *
       * @return A `History` instance. Its `history` attribute contains all
       *   information collected during training.
       *
       * @exception ValueError In case of mismatch between the provided input data
       *   and what the model expects.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async fit(x, y, args = {}) {
        if (!this.built) {
          throw new RuntimeError("The model needs to be compiled before being used.");
        }
        return this.model.fit(x, y, args);
      }
      /**
       * Trains the model using a dataset object.
       *
       * ```js
       * const xArray = [
       *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
       *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
       *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
       *   [1, 1, 1, 1, 1, 1, 1, 1, 1],
       * ];
       * const yArray = [1, 1, 1, 1];
       * // Create a dataset from the JavaScript array.
       * const xDataset = tf.data.array(xArray);
       * const yDataset = tf.data.array(yArray);
       * // Zip combines the `x` and `y` Datasets into a single Dataset, the
       * // iterator of which will return an object containing of two tensors,
       * // corresponding to `x` and `y`.  The call to `batch(4)` will bundle
       * // four such samples into a single object, with the same keys now pointing
       * // to tensors that hold 4 examples, organized along the batch dimension.
       * // The call to `shuffle(4)` causes each iteration through the dataset to
       * // happen in a different order.  The size of the shuffle window is 4.
       * const xyDataset = tf.data.zip({xs: xDataset, ys: yDataset})
       *     .batch(4)
       *     .shuffle(4);
       * const model = tf.sequential({
       *   layers: [tf.layers.dense({units: 1, inputShape: [9]})]
       * });
       * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
       * const history = await model.fitDataset(xyDataset, {
       *   epochs: 4,
       *   callbacks: {onEpochEnd: (epoch, logs) => console.log(logs.loss)}
       * });
       * ```
       *
       * @param dataset A dataset object. Its `iterator()` method is expected to
       *   generate a dataset iterator object, the `next()` method of which is
       *   expected to produce data batches for evaluation. The return value of the
       *   `next()` call ought to contain a boolean `done` field and a `value`
       *   field.
       *
       *   The `value` field is expected to be an object of with fields
       *   `xs` and `ys`, which point to the feature tensor and the target tensor,
       *   respectively. This case is for models with exactly one input and one
       *   output (e.g. a sequential model). For example:
       *   ```js
       *   {value: {xs: xsTensor, ys: ysTensor}, done: false}
       *   ```
       *
       *   If the model has multiple inputs, the `xs` field of `value` should
       *   be an object mapping input names to their respective feature tensors.
       *   For example:
       *   ```js
       *   {
       *     value: {
       *       xs: {
       *         input_1: xsTensor1,
       *         input_2: xsTensor2
       *       },
       *       ys: ysTensor
       *     },
       *     done: false
       *   }
       *   ```
       *   If the model has multiple outputs, the `ys` field of `value` should
       *   be an object mapping output names to their respective target tensors.
       *   For example:
       *   ```js
       *   {
       *     value: {
       *       xs: xsTensor,
       *       ys: {
       *         output_1: ysTensor1,
       *         output_2: ysTensor2
       *       },
       *     },
       *     done: false
       *   }
       *   ```
       * @param args A `ModelFitDatasetArgs`, containing optional fields.
       *
       * @return A `History` instance. Its `history` attribute contains all
       *   information collected during training.
       *
       * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}
       */
      async fitDataset(dataset, args) {
        if (!this.built) {
          throw new RuntimeError("The model needs to be compiled before being used.");
        }
        return this.model.fitDataset(dataset, args);
      }
      /**
       * Runs a single gradient update on a single batch of data.
       *
       * This method differs from `fit()` and `fitDataset()` in the following
       * regards:
       *   - It operates on exactly one batch of data.
       *   - It returns only the loss and metric values, instead of
       *     returning the batch-by-batch loss and metric values.
       *   - It doesn't support fine-grained options such as verbosity and
       *     callbacks.
       *
       * @param x Input data. It could be one of the following:
       *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has
       *     multiple inputs).
       *   - An Object mapping input names to corresponding `tf.Tensor` (if the
       *     model has named inputs).
       * @param y Target data. It could be either a `tf.Tensor` or multiple
       *   `tf.Tensor`s. It should be consistent with `x`.
       * @returns Training loss or losses (in case the model has
       *   multiple outputs), along with metrics (if any), as numbers.
       *
       * @doc {heading: 'Models', subheading: 'Classes'}
       */
      async trainOnBatch(x, y) {
        return this.model.trainOnBatch(x, y);
      }
      /* See parent class for JsDoc */
      /** @nocollapse */
      static fromConfig(cls, config, customObjects = {}, fastWeightInit = false) {
        let configArray;
        let extraModelConfig = {};
        if (config instanceof Array) {
          if (!(config[0].className != null) || config[0]["className"] === "Merge") {
            throw new ValueError("Legacy serialization format not supported yet.");
          }
          configArray = config;
        } else {
          util_exports.assert(config["layers"] != null, () => `When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.`);
          configArray = config["layers"];
          delete config["layers"];
          extraModelConfig = config;
        }
        const model2 = new cls(extraModelConfig);
        if (!(model2 instanceof Sequential)) {
          throw new NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${model2}`);
        }
        for (const conf of configArray) {
          const customObjects2 = void 0;
          const layer = deserialize(conf, customObjects2, fastWeightInit);
          if (fastWeightInit) {
            layer.setFastWeightInitDuringBuild(true);
          }
          model2.add(layer);
        }
        return model2;
      }
      /**
       * Setter used for force stopping of LayersModel.fit() (i.e., training).
       *
       * Example:
       *
       * ```js
       * const model = tf.sequential();
       * model.add(tf.layers.dense({units: 1, inputShape: [10]}));
       * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});
       * const xs = tf.ones([8, 10]);
       * const ys = tf.zeros([8, 1]);
       *
       * const history = await model.fit(xs, ys, {
       *   epochs: 10,
       *   callbacks: {
       *     onEpochEnd: async (epoch, logs) => {
       *       if (epoch === 2) {
       *         model.stopTraining = true;
       *       }
       *     }
       *   }
       * });
       *
       * // There should be only 3 values in the loss array, instead of 10 values,
       * // due to the stopping after 3 epochs.
       * console.log(history.history.loss);
       * ```
       */
      set stopTraining(stop) {
        if (this.model == null) {
          throw new ValueError("Cannot set the stopTraining property of a sequential model before it is compiled.");
        }
        this.model.stopTraining = stop;
      }
      get stopTraining() {
        if (this.model == null) {
          throw new ValueError("Cannot get the stopTraining property of a sequential model before it is compiled.");
        }
        return this.model.stopTraining;
      }
      // TODO(cais): Override get trainableWeights() here
      // tslint:disable-next-line:no-any
      getConfig() {
        const layers = [];
        for (const layer of this.layers) {
          const dict = {};
          dict["className"] = layer.getClassName();
          dict["config"] = layer.getConfig();
          layers.push(dict);
        }
        return { name: this.name, layers };
      }
    };
    Sequential.className = "Sequential";
    serialization_exports.registerClass(Sequential);
  }
});
var init_exports = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports.js"() {
    init_base_callbacks();
    init_input_layer();
    init_training();
    init_models();
    init_models();
  }
});
function serializeActivation(activation) {
  return activation.getClassName();
}
function deserializeActivation(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "activation");
}
function getActivation(identifier) {
  if (identifier == null) {
    const config = {};
    config["className"] = "linear";
    config["config"] = {};
    return deserializeActivation(config);
  }
  if (typeof identifier === "string") {
    const config = {};
    config["className"] = identifier;
    config["config"] = {};
    return deserializeActivation(config);
  } else if (identifier instanceof Activation) {
    return identifier;
  } else {
    return deserializeActivation(identifier);
  }
}
var Activation;
var Elu2;
var Selu2;
var Relu2;
var Relu62;
var Linear;
var Sigmoid2;
var HardSigmoid;
var Softplus2;
var Softsign;
var Tanh2;
var Softmax2;
var LogSoftmax2;
var Swish;
var Mish;
var init_activations = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/activations.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_generic_utils();
    Activation = class extends serialization_exports.Serializable {
      getConfig() {
        return {};
      }
    };
    Elu2 = class extends Activation {
      /**
       * Calculate the activation function.
       *
       * @param x: Input.
       * @param alpha: Scaling factor the negative section.
       * @return Output of the ELU activation.
       */
      apply(x, alpha = 1) {
        return elu2(x, alpha);
      }
    };
    Elu2.className = "elu";
    serialization_exports.registerClass(Elu2);
    Selu2 = class extends Activation {
      apply(x) {
        return selu(x);
      }
    };
    Selu2.className = "selu";
    serialization_exports.registerClass(Selu2);
    Relu2 = class extends Activation {
      apply(x) {
        return relu(x);
      }
    };
    Relu2.className = "relu";
    serialization_exports.registerClass(Relu2);
    Relu62 = class extends Activation {
      apply(x) {
        return tidy(() => minimum(6, relu(x)));
      }
    };
    Relu62.className = "relu6";
    serialization_exports.registerClass(Relu62);
    Linear = class extends Activation {
      apply(x) {
        return x;
      }
    };
    Linear.className = "linear";
    serialization_exports.registerClass(Linear);
    Sigmoid2 = class extends Activation {
      apply(x) {
        return sigmoid(x);
      }
    };
    Sigmoid2.className = "sigmoid";
    serialization_exports.registerClass(Sigmoid2);
    HardSigmoid = class extends Activation {
      apply(x) {
        return hardSigmoid(x);
      }
    };
    HardSigmoid.className = "hardSigmoid";
    serialization_exports.registerClass(HardSigmoid);
    Softplus2 = class extends Activation {
      apply(x) {
        return softplus(x);
      }
    };
    Softplus2.className = "softplus";
    serialization_exports.registerClass(Softplus2);
    Softsign = class extends Activation {
      apply(x) {
        return softsign(x);
      }
    };
    Softsign.className = "softsign";
    serialization_exports.registerClass(Softsign);
    Tanh2 = class extends Activation {
      apply(x) {
        return tanh2(x);
      }
    };
    Tanh2.className = "tanh";
    serialization_exports.registerClass(Tanh2);
    Softmax2 = class extends Activation {
      /**
       * Calculate the activation function.
       *
       * @param x Tensor.
       * @param axis Integer, axis along which the softmax normalization is applied.
       * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be
       * an error.
       *
       * @returns a Tensor of the same shape as x
       *
       * @throws ValueError: In case `dim(x) < 2`.
       */
      apply(x, axis = -1) {
        return softmax(x, axis);
      }
    };
    Softmax2.className = "softmax";
    serialization_exports.registerClass(Softmax2);
    LogSoftmax2 = class extends Activation {
      /**
       * Calculate the activation function of log softmax:
       * log( exp(x_i) / sum(exp(x)) )
       *
       * @param x Tensor.
       * @param axis Integer, axis along which the softmax normalization is applied.
       * Invalid if < 2, as softmax across 1 (the batch dimension) is assumed to be
       * an error.
       *
       * @returns a Tensor of the same shape as x
       *
       * @throws ValueError: In case `dim(x) < 2`.
       */
      apply(x, axis = -1) {
        return logSoftmax(x, axis);
      }
    };
    LogSoftmax2.className = "logSoftmax";
    serialization_exports.registerClass(LogSoftmax2);
    Swish = class extends Activation {
      /**
       * Calculate the activation function.
       *
       * @param x Tensor.
       * @param alpha Scaling factor for the sigmoid function.
       * @returns a Tensor of the same shape as x
       */
      apply(x, alpha = 1) {
        return tidy(() => mul5(sigmoid(mul5(x, alpha)), x));
      }
    };
    Swish.className = "swish";
    serialization_exports.registerClass(Swish);
    Mish = class extends Activation {
      /**
       * Calculate the activation function.
       *
       * @param x Tensor.
       * @returns a Tensor of the same shape as x
       */
      apply(x) {
        return tidy(() => mul5(x, tanh2(softplus(x))));
      }
    };
    Mish.className = "mish";
    serialization_exports.registerClass(Mish);
  }
});
function assertObjectArgs(args) {
  if (args != null && typeof args !== "object") {
    throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${args}`);
  }
}
function serializeRegularizer(constraint) {
  return serializeKerasObject(constraint);
}
function deserializeRegularizer(config, customObjects = {}) {
  return deserializeKerasObject(config, serialization_exports.SerializationMap.getMap().classNameMap, customObjects, "regularizer");
}
function getRegularizer(identifier) {
  if (identifier == null) {
    return null;
  }
  if (typeof identifier === "string") {
    const className = identifier in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[identifier] : identifier;
    const config = { className, config: {} };
    return deserializeRegularizer(config);
  } else if (identifier instanceof Regularizer) {
    return identifier;
  } else {
    return deserializeRegularizer(identifier);
  }
}
var Regularizer;
var L1L2;
var REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP;
var init_regularizers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/regularizers.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_generic_utils();
    Regularizer = class extends serialization_exports.Serializable {
    };
    L1L2 = class extends Regularizer {
      constructor(args) {
        super();
        assertObjectArgs(args);
        this.l1 = args == null || args.l1 == null ? 0.01 : args.l1;
        this.l2 = args == null || args.l2 == null ? 0.01 : args.l2;
        this.hasL1 = this.l1 !== 0;
        this.hasL2 = this.l2 !== 0;
      }
      /**
       * Porting note: Renamed from __call__.
       * @param x Variable of which to calculate the regularization score.
       */
      apply(x) {
        return tidy(() => {
          let regularization = zeros([1]);
          if (this.hasL1) {
            regularization = add22(regularization, sum2(mul5(this.l1, abs(x))));
          }
          if (this.hasL2) {
            regularization = add22(regularization, sum2(mul5(this.l2, square2(x))));
          }
          return reshape(regularization, []);
        });
      }
      getConfig() {
        return { "l1": this.l1, "l2": this.l2 };
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls({ l1: config["l1"], l2: config["l2"] });
      }
    };
    L1L2.className = "L1L2";
    serialization_exports.registerClass(L1L2);
    REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
      "l1l2": "L1L2"
    };
  }
});
var ReLU;
var LeakyReLU;
var PReLU;
var ELU;
var ThresholdedReLU;
var Softmax3;
var init_advanced_activations = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/advanced_activations.js"() {
    init_dist();
    init_activations();
    init_constraints();
    init_topology();
    init_errors();
    init_initializers();
    init_regularizers();
    init_types_utils();
    ReLU = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.supportsMasking = true;
        if (args != null) {
          this.maxValue = args.maxValue;
        }
      }
      call(inputs, kwargs) {
        inputs = getExactlyOneTensor(inputs);
        let output = relu(inputs);
        if (this.maxValue != null) {
          output = clipByValue(output, 0, this.maxValue);
        }
        return output;
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const config = { maxValue: this.maxValue };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    ReLU.className = "ReLU";
    serialization_exports.registerClass(ReLU);
    LeakyReLU = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.DEFAULT_ALPHA = 0.3;
        if (args == null) {
          args = {};
        }
        this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;
      }
      call(inputs, kwargs) {
        const x = getExactlyOneTensor(inputs);
        return leakyRelu(x, this.alpha);
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const config = { alpha: this.alpha };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    LeakyReLU.className = "LeakyReLU";
    serialization_exports.registerClass(LeakyReLU);
    PReLU = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.DEFAULT_ALPHA_INITIALIZER = "zeros";
        if (args == null) {
          args = {};
        }
        this.supportsMasking = true;
        this.alphaInitializer = getInitializer(args.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER);
        this.alphaRegularizer = getRegularizer(args.alphaRegularizer);
        this.alphaConstraint = getConstraint(args.alphaConstraint);
        if (args.sharedAxes == null) {
          this.sharedAxes = null;
        } else if (Array.isArray(args.sharedAxes)) {
          this.sharedAxes = args.sharedAxes;
        } else if (typeof args.sharedAxes === "number") {
          this.sharedAxes = [args.sharedAxes];
        } else {
          throw new ValueError(`Expected sharedAxes to be a number or an array of numbers, but got ${args.sharedAxes}`);
        }
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const paramShape = inputShape.slice(1);
        if (this.sharedAxes != null) {
          for (const i of this.sharedAxes) {
            paramShape[i - 1] = 1;
          }
        }
        this.alpha = this.addWeight("alpha", paramShape, "float32", this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);
        const axes = {};
        if (this.sharedAxes != null) {
          for (let i = 1; i < inputShape.length; ++i) {
            axes[i] = inputShape[i];
          }
        }
        this.inputSpec = [new InputSpec({
          ndim: inputShape.length,
          axes
        })];
        this.built = true;
      }
      call(inputs, kwargs) {
        inputs = getExactlyOneTensor(inputs);
        return prelu(inputs, this.alpha.read());
      }
      getConfig() {
        const config = {
          alphaInitializer: serializeInitializer(this.alphaInitializer),
          alphaRegularizer: serializeRegularizer(this.alphaRegularizer),
          alphaConstraint: serializeConstraint(this.alphaConstraint),
          sharedAxes: this.sharedAxes
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    PReLU.className = "PReLU";
    serialization_exports.registerClass(PReLU);
    ELU = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.DEFAULT_ALPHA = 1;
        if (args == null) {
          args = {};
        }
        if (args.alpha != null && args.alpha !== this.DEFAULT_ALPHA) {
          throw new NotImplementedError(`Non-default alpha value (${args.alpha}) is not supported by the ELU layer yet.`);
        }
        this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;
      }
      call(inputs, kwargs) {
        const x = getExactlyOneTensor(inputs);
        return elu(x);
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const config = { alpha: this.alpha };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    ELU.className = "ELU";
    serialization_exports.registerClass(ELU);
    ThresholdedReLU = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.DEFAULT_THETA = 1;
        if (args == null) {
          args = {};
        }
        this.theta = args.theta == null ? this.DEFAULT_THETA : args.theta;
      }
      call(inputs, kwargs) {
        const x = getExactlyOneTensor(inputs);
        return mul5(x, cast(greater(x, this.theta), "float32"));
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const config = { theta: this.theta };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    ThresholdedReLU.className = "ThresholdedReLU";
    serialization_exports.registerClass(ThresholdedReLU);
    Softmax3 = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.DEFAULT_AXIS = 1;
        if (args == null) {
          args = {};
        }
        this.softmax = new Softmax2().apply;
        this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;
      }
      call(inputs, kwargs) {
        const x = getExactlyOneTensor(inputs);
        return this.softmax(x, this.axis);
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const config = { axis: this.axis };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Softmax3.className = "Softmax";
    serialization_exports.registerClass(Softmax3);
  }
});
function normalizeArray(value, n, name) {
  if (typeof value === "number") {
    return pyListRepeat(value, n);
  } else {
    if (value.length !== n) {
      throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${value.length} elements.`);
    }
    for (let i = 0; i < n; ++i) {
      const singleValue = value[i];
      if (!isInteger(singleValue)) {
        throw new ValueError(`The ${name} argument must be an integer or tuple of ${n} integers. Received: ${JSON.stringify(value)} including a non-integer number ${singleValue}`);
      }
    }
    return value;
  }
}
function convOutputLength(inputLength, filterSize, padding, stride, dilation = 1) {
  if (inputLength == null) {
    return inputLength;
  }
  const dilatedFilterSize = filterSize + (filterSize - 1) * (dilation - 1);
  let outputLength;
  if (padding === "same") {
    outputLength = inputLength;
  } else {
    outputLength = inputLength - dilatedFilterSize + 1;
  }
  return Math.floor((outputLength + stride - 1) / stride);
}
function deconvLength(dimSize, strideSize, kernelSize, padding) {
  if (dimSize == null) {
    return null;
  }
  if (padding === "valid") {
    dimSize = dimSize * strideSize + max22([kernelSize - strideSize, 0]);
  } else if (padding === "same") {
    dimSize = dimSize * strideSize;
  } else {
    throw new ValueError(`Unsupport padding mode: ${padding}.`);
  }
  return dimSize;
}
var init_conv_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/utils/conv_utils.js"() {
    init_errors();
    init_generic_utils();
    init_math_utils();
  }
});
function preprocessConv2DInput(x, dataFormat) {
  return tidy(() => {
    checkDataFormat(dataFormat);
    if (dataFormat === "channelsFirst") {
      return transpose2(x, [0, 2, 3, 1]);
    } else {
      return x;
    }
  });
}
function preprocessConv3DInput(x, dataFormat) {
  return tidy(() => {
    checkDataFormat(dataFormat);
    if (dataFormat === "channelsFirst") {
      return transpose2(x, [0, 2, 3, 4, 1]);
    } else {
      return x;
    }
  });
}
function conv1dWithBias(x, kernel, bias, strides = 1, padding = "valid", dataFormat, dilationRate = 1) {
  return tidy(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    if (x.shape.length !== 3) {
      throw new ValueError(`The input of a conv1dWithBias operation should be 3, but is ${x.shape.length} instead.`);
    }
    if (kernel.shape.length !== 3) {
      throw new ValueError(`The kernel for a conv1dWithBias operation should be 3, but is ${kernel.shape.length} instead`);
    }
    if (bias != null && bias.shape.length !== 1) {
      throw new ValueError(`The bias for a conv1dWithBias operation should be 1, but is ${kernel.shape.length} instead`);
    }
    if (dataFormat === "channelsFirst") {
      x = transpose2(x, [0, 2, 1]);
    }
    if (padding === "causal") {
      throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    }
    let y = conv1d(x, kernel, strides, padding === "same" ? "same" : "valid", "NWC", dilationRate);
    if (bias != null) {
      y = biasAdd(y, bias);
    }
    return y;
  });
}
function conv2dWithBiasActivation(x, kernel, bias, strides = [1, 1], padding = "valid", dataFormat, dilationRate, activation = null) {
  return tidy(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    if (x.rank !== 3 && x.rank !== 4) {
      throw new ValueError(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${x.rank}.`);
    }
    if (kernel.rank !== 3 && kernel.rank !== 4) {
      throw new ValueError(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${x.rank}.`);
    }
    let y = preprocessConv2DInput(x, dataFormat);
    if (padding === "causal") {
      throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    }
    y = fused_ops_exports.conv2d({
      x: y,
      filter: kernel,
      strides,
      pad: padding === "same" ? "same" : "valid",
      dilations: dilationRate,
      dataFormat: "NHWC",
      bias,
      activation
    });
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 3, 1, 2]);
    }
    return y;
  });
}
function conv3dWithBias(x, kernel, bias, strides = [1, 1, 1], padding = "valid", dataFormat, dilationRate) {
  return tidy(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    if (x.rank !== 4 && x.rank !== 5) {
      throw new ValueError(`conv3dWithBias expects input to be of rank 4 or 5, but received ${x.rank}.`);
    }
    if (kernel.rank !== 4 && kernel.rank !== 5) {
      throw new ValueError(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${x.rank}.`);
    }
    let y = preprocessConv3DInput(x, dataFormat);
    if (padding === "causal") {
      throw new NotImplementedError("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    }
    y = conv3d(y, kernel, strides, padding === "same" ? "same" : "valid", "NDHWC", dilationRate);
    if (bias != null) {
      y = biasAdd(y, bias);
    }
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 4, 1, 2, 3]);
    }
    return y;
  });
}
var BaseConv;
var Conv;
var Conv2D2;
var Conv3D2;
var Conv2DTranspose;
var Conv3DTranspose;
var SeparableConv;
var SeparableConv2D;
var Conv1D;
var Cropping2D;
var UpSampling2D;
var init_convolutional = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional.js"() {
    init_dist();
    init_dist();
    init_activations();
    init_common3();
    init_tfjs_backend();
    init_common2();
    init_constraints();
    init_topology();
    init_errors();
    init_initializers();
    init_regularizers();
    init_conv_utils();
    init_generic_utils();
    init_types_utils();
    BaseConv = class extends Layer {
      constructor(rank, args) {
        super(args);
        this.bias = null;
        this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
        this.DEFAULT_BIAS_INITIALIZER = "zeros";
        BaseConv.verifyArgs(args);
        this.rank = rank;
        assertPositiveInteger(this.rank, "rank");
        if (this.rank !== 1 && this.rank !== 2 && this.rank !== 3) {
          throw new NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
        }
        this.kernelSize = normalizeArray(args.kernelSize, rank, "kernelSize");
        this.strides = normalizeArray(args.strides == null ? 1 : args.strides, rank, "strides");
        this.padding = args.padding == null ? "valid" : args.padding;
        checkPaddingMode(this.padding);
        this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
        checkDataFormat(this.dataFormat);
        this.activation = getActivation(args.activation);
        this.useBias = args.useBias == null ? true : args.useBias;
        this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
        this.biasConstraint = getConstraint(args.biasConstraint);
        this.biasRegularizer = getRegularizer(args.biasRegularizer);
        this.activityRegularizer = getRegularizer(args.activityRegularizer);
        this.dilationRate = normalizeArray(args.dilationRate == null ? 1 : args.dilationRate, rank, "dilationRate");
        if (this.rank === 1 && (Array.isArray(this.dilationRate) && this.dilationRate.length !== 1)) {
          throw new ValueError(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
        } else if (this.rank === 2) {
          if (typeof this.dilationRate === "number") {
            this.dilationRate = [this.dilationRate, this.dilationRate];
          } else if (this.dilationRate.length !== 2) {
            throw new ValueError(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`);
          }
        } else if (this.rank === 3) {
          if (typeof this.dilationRate === "number") {
            this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
          } else if (this.dilationRate.length !== 3) {
            throw new ValueError(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`);
          }
        }
      }
      static verifyArgs(args) {
        assert2("kernelSize" in args, `required key 'kernelSize' not in config`);
        if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 3)) {
          throw new ValueError(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(args.kernelSize)}.`);
        }
      }
      getConfig() {
        const config = {
          kernelSize: this.kernelSize,
          strides: this.strides,
          padding: this.padding,
          dataFormat: this.dataFormat,
          dilationRate: this.dilationRate,
          activation: serializeActivation(this.activation),
          useBias: this.useBias,
          biasInitializer: serializeInitializer(this.biasInitializer),
          biasRegularizer: serializeRegularizer(this.biasRegularizer),
          activityRegularizer: serializeRegularizer(this.activityRegularizer),
          biasConstraint: serializeConstraint(this.biasConstraint)
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Conv = class extends BaseConv {
      constructor(rank, args) {
        super(rank, args);
        this.kernel = null;
        Conv.verifyArgs(args);
        this.filters = args.filters;
        assertPositiveInteger(this.filters, "filters");
        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
        this.kernelConstraint = getConstraint(args.kernelConstraint);
        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
        if (inputShape[channelAxis] == null) {
          throw new ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);
        }
        const inputDim = inputShape[channelAxis];
        const kernelShape = this.kernelSize.concat([inputDim, this.filters]);
        this.kernel = this.addWeight("kernel", kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        }
        this.inputSpec = [{ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } }];
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          let outputs;
          const biasValue = this.bias == null ? null : this.bias.read();
          const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());
          if (fusedActivationName != null && this.rank === 2) {
            outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate, fusedActivationName);
          } else {
            if (this.rank === 1) {
              outputs = conv1dWithBias(inputs, this.kernel.read(), biasValue, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
            } else if (this.rank === 2) {
              outputs = conv2dWithBiasActivation(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);
            } else if (this.rank === 3) {
              outputs = conv3dWithBias(inputs, this.kernel.read(), biasValue, this.strides, this.padding, this.dataFormat, this.dilationRate);
            } else {
              throw new NotImplementedError("convolutions greater than 3D are not implemented yet.");
            }
            if (this.activation != null) {
              outputs = this.activation.apply(outputs);
            }
          }
          return outputs;
        });
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const newSpace = [];
        const space = this.dataFormat === "channelsLast" ? inputShape.slice(1, inputShape.length - 1) : inputShape.slice(2);
        for (let i = 0; i < space.length; ++i) {
          const newDim = convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === "number" ? this.dilationRate : this.dilationRate[i]);
          newSpace.push(newDim);
        }
        let outputShape = [inputShape[0]];
        if (this.dataFormat === "channelsLast") {
          outputShape = outputShape.concat(newSpace);
          outputShape.push(this.filters);
        } else {
          outputShape.push(this.filters);
          outputShape = outputShape.concat(newSpace);
        }
        return outputShape;
      }
      getConfig() {
        const config = {
          filters: this.filters,
          kernelInitializer: serializeInitializer(this.kernelInitializer),
          kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
          kernelConstraint: serializeConstraint(this.kernelConstraint)
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      static verifyArgs(args) {
        if (!("filters" in args) || typeof args.filters !== "number" || args.filters < 1) {
          throw new ValueError(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(args.filters)}`);
        }
      }
    };
    Conv2D2 = class extends Conv {
      constructor(args) {
        super(2, args);
        Conv2D2.verifyArgs(args);
      }
      getConfig() {
        const config = super.getConfig();
        delete config["rank"];
        return config;
      }
      static verifyArgs(args) {
        if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 2)) {
          throw new ValueError(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(args.kernelSize)}.`);
        }
      }
    };
    Conv2D2.className = "Conv2D";
    serialization_exports.registerClass(Conv2D2);
    Conv3D2 = class extends Conv {
      constructor(args) {
        super(3, args);
        Conv3D2.verifyArgs(args);
      }
      getConfig() {
        const config = super.getConfig();
        delete config["rank"];
        return config;
      }
      static verifyArgs(args) {
        if (typeof args.kernelSize !== "number") {
          if (!(Array.isArray(args.kernelSize) && (args.kernelSize.length === 1 || args.kernelSize.length === 3))) {
            throw new ValueError(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(args.kernelSize)}.`);
          }
        }
      }
    };
    Conv3D2.className = "Conv3D";
    serialization_exports.registerClass(Conv3D2);
    Conv2DTranspose = class extends Conv2D2 {
      constructor(args) {
        super(args);
        this.inputSpec = [new InputSpec({ ndim: 4 })];
        if (this.padding !== "same" && this.padding !== "valid") {
          throw new ValueError(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
        }
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (inputShape.length !== 4) {
          throw new ValueError("Input should have rank 4; Received input shape: " + JSON.stringify(inputShape));
        }
        const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
        if (inputShape[channelAxis] == null) {
          throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
        }
        const inputDim = inputShape[channelAxis];
        const kernelShape = this.kernelSize.concat([this.filters, inputDim]);
        this.kernel = this.addWeight("kernel", kernelShape, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        }
        this.inputSpec = [new InputSpec({ ndim: 4, axes: { [channelAxis]: inputDim } })];
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          let input2 = getExactlyOneTensor(inputs);
          if (input2.shape.length !== 4) {
            throw new ValueError(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input2.shape.length}`);
          }
          const inputShape = input2.shape;
          const batchSize = inputShape[0];
          let hAxis;
          let wAxis;
          if (this.dataFormat === "channelsFirst") {
            hAxis = 2;
            wAxis = 3;
          } else {
            hAxis = 1;
            wAxis = 2;
          }
          const height = inputShape[hAxis];
          const width = inputShape[wAxis];
          const kernelH = this.kernelSize[0];
          const kernelW = this.kernelSize[1];
          const strideH = this.strides[0];
          const strideW = this.strides[1];
          const outHeight = deconvLength(height, strideH, kernelH, this.padding);
          const outWidth = deconvLength(width, strideW, kernelW, this.padding);
          const outputShape = [batchSize, outHeight, outWidth, this.filters];
          if (this.dataFormat !== "channelsLast") {
            input2 = transpose2(input2, [0, 2, 3, 1]);
          }
          let outputs = conv2dTranspose(input2, this.kernel.read(), outputShape, this.strides, this.padding);
          if (this.dataFormat !== "channelsLast") {
            outputs = transpose2(outputs, [0, 3, 1, 2]);
          }
          if (this.bias != null) {
            outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
          }
          if (this.activation != null) {
            outputs = this.activation.apply(outputs);
          }
          return outputs;
        });
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const outputShape = inputShape.slice();
        let channelAxis;
        let heightAxis;
        let widthAxis;
        if (this.dataFormat === "channelsFirst") {
          channelAxis = 1;
          heightAxis = 2;
          widthAxis = 3;
        } else {
          channelAxis = 3;
          heightAxis = 1;
          widthAxis = 2;
        }
        const kernelH = this.kernelSize[0];
        const kernelW = this.kernelSize[1];
        const strideH = this.strides[0];
        const strideW = this.strides[1];
        outputShape[channelAxis] = this.filters;
        outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);
        outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);
        return outputShape;
      }
      getConfig() {
        const config = super.getConfig();
        delete config["dilationRate"];
        return config;
      }
    };
    Conv2DTranspose.className = "Conv2DTranspose";
    serialization_exports.registerClass(Conv2DTranspose);
    Conv3DTranspose = class extends Conv3D2 {
      constructor(args) {
        super(args);
        this.inputSpec = [new InputSpec({ ndim: 5 })];
        if (this.padding !== "same" && this.padding !== "valid") {
          throw new ValueError(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
        }
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (inputShape.length !== 5) {
          throw new ValueError("Input should have rank 5; Received input shape: " + JSON.stringify(inputShape));
        }
        const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
        if (inputShape[channelAxis] == null) {
          throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
        }
        const inputDim = inputShape[channelAxis];
        const kernelShape = this.kernelSize.concat([this.filters, inputDim]);
        this.kernel = this.addWeight("kernel", kernelShape, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        }
        this.inputSpec = [new InputSpec({ ndim: 5, axes: { [channelAxis]: inputDim } })];
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          let input2 = getExactlyOneTensor(inputs);
          if (input2.shape.length !== 5) {
            throw new ValueError(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${input2.shape.length}`);
          }
          const inputShape = input2.shape;
          const batchSize = inputShape[0];
          let hAxis;
          let wAxis;
          let dAxis;
          if (this.dataFormat === "channelsFirst") {
            dAxis = 2;
            hAxis = 3;
            wAxis = 4;
          } else {
            dAxis = 1;
            hAxis = 2;
            wAxis = 3;
          }
          const depth = inputShape[dAxis];
          const height = inputShape[hAxis];
          const width = inputShape[wAxis];
          const kernelD = this.kernelSize[0];
          const kernelH = this.kernelSize[1];
          const kernelW = this.kernelSize[2];
          const strideD = this.strides[0];
          const strideH = this.strides[1];
          const strideW = this.strides[2];
          const outDepth = deconvLength(depth, strideD, kernelD, this.padding);
          const outHeight = deconvLength(height, strideH, kernelH, this.padding);
          const outWidth = deconvLength(width, strideW, kernelW, this.padding);
          const outputShape = [batchSize, outDepth, outHeight, outWidth, this.filters];
          if (this.dataFormat !== "channelsLast") {
            input2 = transpose2(input2, [0, 2, 3, 4, 1]);
          }
          let outputs = conv3dTranspose(input2, this.kernel.read(), outputShape, this.strides, this.padding);
          if (this.dataFormat !== "channelsLast") {
            outputs = transpose2(outputs, [0, 4, 1, 2, 3]);
          }
          if (this.bias !== null) {
            outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
          }
          if (this.activation !== null) {
            outputs = this.activation.apply(outputs);
          }
          return outputs;
        });
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const outputShape = inputShape.slice();
        let channelAxis;
        let depthAxis;
        let heightAxis;
        let widthAxis;
        if (this.dataFormat === "channelsFirst") {
          channelAxis = 1;
          depthAxis = 2;
          heightAxis = 3;
          widthAxis = 4;
        } else {
          channelAxis = 4;
          depthAxis = 1;
          heightAxis = 2;
          widthAxis = 3;
        }
        const kernelD = this.kernelSize[0];
        const kernelH = this.kernelSize[1];
        const kernelW = this.kernelSize[2];
        const strideD = this.strides[0];
        const strideH = this.strides[1];
        const strideW = this.strides[2];
        outputShape[channelAxis] = this.filters;
        outputShape[depthAxis] = deconvLength(outputShape[depthAxis], strideD, kernelD, this.padding);
        outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);
        outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);
        return outputShape;
      }
      getConfig() {
        const config = super.getConfig();
        delete config["dilationRate"];
        return config;
      }
    };
    Conv3DTranspose.className = "Conv3DTranspose";
    serialization_exports.registerClass(Conv3DTranspose);
    SeparableConv = class extends Conv {
      constructor(rank, config) {
        super(rank, config);
        this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform";
        this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform";
        this.depthwiseKernel = null;
        this.pointwiseKernel = null;
        if (config.filters == null) {
          throw new ValueError("The `filters` configuration field is required by SeparableConv, but is unspecified.");
        }
        if (config.kernelInitializer != null || config.kernelRegularizer != null || config.kernelConstraint != null) {
          throw new ValueError("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
        }
        if (config.padding != null && config.padding !== "same" && config.padding !== "valid") {
          throw new ValueError(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(config.padding)}`);
        }
        this.depthMultiplier = config.depthMultiplier == null ? 1 : config.depthMultiplier;
        this.depthwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER);
        this.depthwiseRegularizer = getRegularizer(config.depthwiseRegularizer);
        this.depthwiseConstraint = getConstraint(config.depthwiseConstraint);
        this.pointwiseInitializer = getInitializer(config.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER);
        this.pointwiseRegularizer = getRegularizer(config.pointwiseRegularizer);
        this.pointwiseConstraint = getConstraint(config.pointwiseConstraint);
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (inputShape.length < this.rank + 2) {
          throw new ValueError(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(inputShape)}`);
        }
        const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
        if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {
          throw new ValueError(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(inputShape[channelAxis])}`);
        }
        const inputDim = inputShape[channelAxis];
        const depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);
        const pointwiseKernelShape = [];
        for (let i = 0; i < this.rank; ++i) {
          pointwiseKernelShape.push(1);
        }
        pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);
        const trainable = true;
        this.depthwiseKernel = this.addWeight("depthwise_kernel", depthwiseKernelShape, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);
        this.pointwiseKernel = this.addWeight("pointwise_kernel", pointwiseKernelShape, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);
        } else {
          this.bias = null;
        }
        this.inputSpec = [new InputSpec({ ndim: this.rank + 2, axes: { [channelAxis]: inputDim } })];
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          let output;
          if (this.rank === 1) {
            throw new NotImplementedError("1D separable convolution is not implemented yet.");
          } else if (this.rank === 2) {
            if (this.dataFormat === "channelsFirst") {
              inputs = transpose2(inputs, [0, 2, 3, 1]);
            }
            output = separableConv2d(inputs, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC");
          }
          if (this.useBias) {
            output = biasAdd(output, this.bias.read(), this.dataFormat);
          }
          if (this.activation != null) {
            output = this.activation.apply(output);
          }
          if (this.dataFormat === "channelsFirst") {
            output = transpose2(output, [0, 3, 1, 2]);
          }
          return output;
        });
      }
      getConfig() {
        const config = super.getConfig();
        delete config["rank"];
        delete config["kernelInitializer"];
        delete config["kernelRegularizer"];
        delete config["kernelConstraint"];
        config["depthwiseInitializer"] = serializeInitializer(this.depthwiseInitializer);
        config["pointwiseInitializer"] = serializeInitializer(this.pointwiseInitializer);
        config["depthwiseRegularizer"] = serializeRegularizer(this.depthwiseRegularizer);
        config["pointwiseRegularizer"] = serializeRegularizer(this.pointwiseRegularizer);
        config["depthwiseConstraint"] = serializeConstraint(this.depthwiseConstraint);
        config["pointwiseConstraint"] = serializeConstraint(this.pointwiseConstraint);
        return config;
      }
    };
    SeparableConv.className = "SeparableConv";
    SeparableConv2D = class extends SeparableConv {
      constructor(args) {
        super(2, args);
      }
    };
    SeparableConv2D.className = "SeparableConv2D";
    serialization_exports.registerClass(SeparableConv2D);
    Conv1D = class extends Conv {
      constructor(args) {
        super(1, args);
        Conv1D.verifyArgs(args);
        this.inputSpec = [{ ndim: 3 }];
      }
      getConfig() {
        const config = super.getConfig();
        delete config["rank"];
        delete config["dataFormat"];
        return config;
      }
      static verifyArgs(args) {
        if (typeof args.kernelSize !== "number" && !checkArrayTypeAndLength(args.kernelSize, "number", 1, 1)) {
          throw new ValueError(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(args.kernelSize)}.`);
        }
      }
    };
    Conv1D.className = "Conv1D";
    serialization_exports.registerClass(Conv1D);
    Cropping2D = class extends Layer {
      constructor(args) {
        super(args);
        if (typeof args.cropping === "number") {
          this.cropping = [[args.cropping, args.cropping], [args.cropping, args.cropping]];
        } else if (typeof args.cropping[0] === "number") {
          this.cropping = [
            [args.cropping[0], args.cropping[0]],
            [args.cropping[1], args.cropping[1]]
          ];
        } else {
          this.cropping = args.cropping;
        }
        this.dataFormat = args.dataFormat === void 0 ? "channelsLast" : args.dataFormat;
        this.inputSpec = [{ ndim: 4 }];
      }
      computeOutputShape(inputShape) {
        if (this.dataFormat === "channelsFirst") {
          return [
            inputShape[0],
            inputShape[1],
            inputShape[2] - this.cropping[0][0] - this.cropping[0][1],
            inputShape[3] - this.cropping[1][0] - this.cropping[1][1]
          ];
        } else {
          return [
            inputShape[0],
            inputShape[1] - this.cropping[0][0] - this.cropping[0][1],
            inputShape[2] - this.cropping[1][0] - this.cropping[1][1],
            inputShape[3]
          ];
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          if (this.dataFormat === "channelsLast") {
            const hSliced = sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
            return sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
          } else {
            const hSliced = sliceAlongAxis(inputs, this.cropping[0][0], inputs.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
            return sliceAlongAxis(hSliced, this.cropping[1][0], inputs.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
          }
        });
      }
      getConfig() {
        const config = { cropping: this.cropping, dataFormat: this.dataFormat };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Cropping2D.className = "Cropping2D";
    serialization_exports.registerClass(Cropping2D);
    UpSampling2D = class extends Layer {
      constructor(args) {
        super(args);
        this.DEFAULT_SIZE = [2, 2];
        this.inputSpec = [{ ndim: 4 }];
        this.size = args.size == null ? this.DEFAULT_SIZE : args.size;
        this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
        checkDataFormat(this.dataFormat);
        this.interpolation = args.interpolation == null ? "nearest" : args.interpolation;
        checkInterpolationFormat(this.interpolation);
      }
      computeOutputShape(inputShape) {
        if (this.dataFormat === "channelsFirst") {
          const height = inputShape[2] == null ? null : this.size[0] * inputShape[2];
          const width = inputShape[3] == null ? null : this.size[1] * inputShape[3];
          return [inputShape[0], inputShape[1], height, width];
        } else {
          const height = inputShape[1] == null ? null : this.size[0] * inputShape[1];
          const width = inputShape[2] == null ? null : this.size[1] * inputShape[2];
          return [inputShape[0], height, width, inputShape[3]];
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          let input2 = getExactlyOneTensor(inputs);
          const inputShape = input2.shape;
          if (this.dataFormat === "channelsFirst") {
            input2 = transpose2(input2, [0, 2, 3, 1]);
            const height = this.size[0] * inputShape[2];
            const width = this.size[1] * inputShape[3];
            const resized = this.interpolation === "nearest" ? image.resizeNearestNeighbor(input2, [height, width]) : image.resizeBilinear(input2, [height, width]);
            return transpose2(resized, [0, 3, 1, 2]);
          } else {
            const height = this.size[0] * inputShape[1];
            const width = this.size[1] * inputShape[2];
            return this.interpolation === "nearest" ? image.resizeNearestNeighbor(input2, [height, width]) : image.resizeBilinear(input2, [height, width]);
          }
        });
      }
      getConfig() {
        const config = {
          size: this.size,
          dataFormat: this.dataFormat,
          interpolation: this.interpolation
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    UpSampling2D.className = "UpSampling2D";
    serialization_exports.registerClass(UpSampling2D);
  }
});
function depthwiseConv2d3(x, depthwiseKernel, strides = [1, 1], padding = "valid", dataFormat, dilationRate) {
  return tidy(() => {
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    checkDataFormat(dataFormat);
    let y = preprocessConv2DInput(x, dataFormat);
    if (x.rank !== 4) {
      throw new ValueError(`Input for depthwiseConv2d is required to be 4-D, but is instead ${x.rank}-D`);
    }
    if (depthwiseKernel.rank !== 4) {
      throw new ValueError(`depthwiseKernel is required to be 4-D, but is instead ${depthwiseKernel.rank}-D`);
    }
    y = depthwiseConv2d(y, depthwiseKernel, strides, padding === "same" ? "same" : "valid", "NHWC", dilationRate);
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 3, 1, 2]);
    }
    return y;
  });
}
var DepthwiseConv2D;
var init_convolutional_depthwise = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_depthwise.js"() {
    init_dist();
    init_dist();
    init_common3();
    init_tfjs_backend();
    init_common2();
    init_constraints();
    init_errors();
    init_initializers();
    init_regularizers();
    init_conv_utils();
    init_types_utils();
    init_convolutional();
    DepthwiseConv2D = class extends BaseConv {
      constructor(args) {
        super(2, args);
        this.depthwiseKernel = null;
        this.depthMultiplier = args.depthMultiplier == null ? 1 : args.depthMultiplier;
        this.depthwiseInitializer = getInitializer(args.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER);
        this.depthwiseConstraint = getConstraint(args.depthwiseConstraint);
        this.depthwiseRegularizer = getRegularizer(args.depthwiseRegularizer);
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (inputShape.length < 4) {
          throw new ValueError(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(inputShape)}.`);
        }
        const channelAxis = this.dataFormat === "channelsFirst" ? 1 : 3;
        if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {
          throw new ValueError(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${inputShape[channelAxis]}).`);
        }
        const inputDim = inputShape[channelAxis];
        const depthwiseKernelShape = [
          this.kernelSize[0],
          this.kernelSize[1],
          inputDim,
          this.depthMultiplier
        ];
        this.depthwiseKernel = this.addWeight("depthwise_kernel", depthwiseKernelShape, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [inputDim * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        } else {
          this.bias = null;
        }
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          let outputs = depthwiseConv2d3(inputs, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
          if (this.useBias) {
            outputs = biasAdd(outputs, this.bias.read(), this.dataFormat);
          }
          if (this.activation != null) {
            outputs = this.activation.apply(outputs);
          }
          return outputs;
        });
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const rows = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
        const cols = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
        const outFilters = this.dataFormat === "channelsFirst" ? inputShape[1] * this.depthMultiplier : inputShape[3] * this.depthMultiplier;
        const outRows = convOutputLength(rows, this.kernelSize[0], this.padding, this.strides[0]);
        const outCols = convOutputLength(cols, this.kernelSize[1], this.padding, this.strides[1]);
        if (this.dataFormat === "channelsFirst") {
          return [inputShape[0], outFilters, outRows, outCols];
        } else {
          return [inputShape[0], outRows, outCols, outFilters];
        }
      }
      getConfig() {
        const config = super.getConfig();
        config["depthMultiplier"] = this.depthMultiplier;
        config["depthwiseInitializer"] = serializeInitializer(this.depthwiseInitializer);
        config["depthwiseRegularizer"] = serializeRegularizer(this.depthwiseRegularizer);
        config["depthwiseConstraint"] = serializeConstraint(this.depthwiseRegularizer);
        return config;
      }
    };
    DepthwiseConv2D.className = "DepthwiseConv2D";
    serialization_exports.registerClass(DepthwiseConv2D);
  }
});
function standardizeArgs(inputs, initialState, constants, numConstants) {
  if (Array.isArray(inputs)) {
    if (initialState != null || constants != null) {
      throw new ValueError("When inputs is an array, neither initialState or constants should be provided");
    }
    if (numConstants != null) {
      constants = inputs.slice(inputs.length - numConstants, inputs.length);
      inputs = inputs.slice(0, inputs.length - numConstants);
    }
    if (inputs.length > 1) {
      initialState = inputs.slice(1, inputs.length);
    }
    inputs = inputs[0];
  }
  function toListOrNull(x) {
    if (x == null || Array.isArray(x)) {
      return x;
    } else {
      return [x];
    }
  }
  initialState = toListOrNull(initialState);
  constants = toListOrNull(constants);
  return { inputs, initialState, constants };
}
function rnn(stepFunction, inputs, initialStates, goBackwards = false, mask, constants, unroll = false, needPerStepOutputs = false) {
  return tidy(() => {
    const ndim = inputs.shape.length;
    if (ndim < 3) {
      throw new ValueError(`Input should be at least 3D, but is ${ndim}D.`);
    }
    const axes = [1, 0].concat(range2(2, ndim));
    inputs = transpose2(inputs, axes);
    if (constants != null) {
      throw new NotImplementedError("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    }
    if (unroll) {
      console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend.");
    }
    if (mask != null) {
      mask = cast(cast(mask, "bool"), "float32");
      if (mask.rank === ndim - 1) {
        mask = expandDims(mask, -1);
      }
      mask = transpose2(mask, axes);
    }
    if (goBackwards) {
      inputs = reverse(inputs, 0);
      if (mask != null) {
        mask = reverse(mask, 0);
      }
    }
    const perStepOutputs = [];
    let lastOutput;
    let states = initialStates;
    const timeSteps = inputs.shape[0];
    const perStepInputs = unstack(inputs);
    let perStepMasks;
    if (mask != null) {
      perStepMasks = unstack(mask);
    }
    for (let t = 0; t < timeSteps; ++t) {
      const currentInput = perStepInputs[t];
      const stepOutputs = tidy(() => stepFunction(currentInput, states));
      if (mask == null) {
        lastOutput = stepOutputs[0];
        states = stepOutputs[1];
      } else {
        const maskedOutputs = tidy(() => {
          const stepMask = perStepMasks[t];
          const negStepMask = sub3(onesLike(stepMask), stepMask);
          const output = add22(mul5(stepOutputs[0], stepMask), mul5(states[0], negStepMask));
          const newStates = states.map((state, i) => {
            return add22(mul5(stepOutputs[1][i], stepMask), mul5(state, negStepMask));
          });
          return { output, newStates };
        });
        lastOutput = maskedOutputs.output;
        states = maskedOutputs.newStates;
      }
      if (needPerStepOutputs) {
        perStepOutputs.push(lastOutput);
      }
    }
    let outputs;
    if (needPerStepOutputs) {
      const axis = 1;
      outputs = stack(perStepOutputs, axis);
    }
    return [lastOutput, outputs, states];
  });
}
function generateDropoutMask(args) {
  const { ones: ones3, rate, training = false, count: count2 = 1, dropoutFunc } = args;
  const droppedInputs = () => dropoutFunc != null ? dropoutFunc(ones3(), rate) : dropout2(ones3(), rate);
  const createMask = () => inTrainPhase(droppedInputs, ones3, training);
  if (!count2 || count2 <= 1) {
    return keep(createMask().clone());
  }
  const masks = Array(count2).fill(void 0).map(createMask);
  return masks.map((m) => keep(m.clone()));
}
var RNN;
var RNNCell;
var SimpleRNNCell;
var SimpleRNN;
var GRUCell;
var GRU;
var LSTMCell;
var LSTM;
var StackedRNNCells;
var init_recurrent = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/recurrent.js"() {
    init_dist();
    init_dist();
    init_activations();
    init_tfjs_backend();
    init_common2();
    init_constraints();
    init_topology();
    init_topology();
    init_errors();
    init_initializers();
    init_regularizers();
    init_generic_utils();
    init_math_utils();
    init_types_utils();
    init_variables();
    init_serialization2();
    RNN = class extends Layer {
      constructor(args) {
        super(args);
        let cell;
        if (args.cell == null) {
          throw new ValueError("cell property is missing for the constructor of RNN.");
        } else if (Array.isArray(args.cell)) {
          cell = new StackedRNNCells({ cells: args.cell });
        } else {
          cell = args.cell;
        }
        if (cell.stateSize == null) {
          throw new ValueError("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
        }
        this.cell = cell;
        this.returnSequences = args.returnSequences == null ? false : args.returnSequences;
        this.returnState = args.returnState == null ? false : args.returnState;
        this.goBackwards = args.goBackwards == null ? false : args.goBackwards;
        this._stateful = args.stateful == null ? false : args.stateful;
        this.unroll = args.unroll == null ? false : args.unroll;
        this.supportsMasking = true;
        this.inputSpec = [new InputSpec({ ndim: 3 })];
        this.stateSpec = null;
        this.states_ = null;
        this.numConstants = null;
        this.keptStates = [];
      }
      // Porting Note: This is the equivalent of `RNN.states` property getter in
      //   PyKeras.
      getStates() {
        if (this.states_ == null) {
          const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
          return range2(0, numStates).map((x) => null);
        } else {
          return this.states_;
        }
      }
      // Porting Note: This is the equivalent of the `RNN.states` property setter in
      //   PyKeras.
      setStates(states) {
        this.states_ = states;
      }
      computeOutputShape(inputShape) {
        if (isArrayOfShapes(inputShape)) {
          inputShape = inputShape[0];
        }
        inputShape = inputShape;
        let stateSize = this.cell.stateSize;
        if (!Array.isArray(stateSize)) {
          stateSize = [stateSize];
        }
        const outputDim = stateSize[0];
        let outputShape;
        if (this.returnSequences) {
          outputShape = [inputShape[0], inputShape[1], outputDim];
        } else {
          outputShape = [inputShape[0], outputDim];
        }
        if (this.returnState) {
          const stateShape = [];
          for (const dim of stateSize) {
            stateShape.push([inputShape[0], dim]);
          }
          return [outputShape].concat(stateShape);
        } else {
          return outputShape;
        }
      }
      computeMask(inputs, mask) {
        return tidy(() => {
          if (Array.isArray(mask)) {
            mask = mask[0];
          }
          const outputMask = this.returnSequences ? mask : null;
          if (this.returnState) {
            const stateMask = this.states.map((s) => null);
            return [outputMask].concat(stateMask);
          } else {
            return outputMask;
          }
        });
      }
      /**
       * Get the current state tensors of the RNN.
       *
       * If the state hasn't been set, return an array of `null`s of the correct
       * length.
       */
      get states() {
        if (this.states_ == null) {
          const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
          const output = [];
          for (let i = 0; i < numStates; ++i) {
            output.push(null);
          }
          return output;
        } else {
          return this.states_;
        }
      }
      set states(s) {
        this.states_ = s;
      }
      build(inputShape) {
        const constantShape = null;
        if (this.numConstants != null) {
          throw new NotImplementedError("Constants support is not implemented in RNN yet.");
        }
        if (isArrayOfShapes(inputShape)) {
          inputShape = inputShape[0];
        }
        inputShape = inputShape;
        const batchSize = this.stateful ? inputShape[0] : null;
        const inputDim = inputShape.slice(2);
        this.inputSpec[0] = new InputSpec({ shape: [batchSize, null, ...inputDim] });
        const stepInputShape = [inputShape[0]].concat(inputShape.slice(2));
        if (constantShape != null) {
          throw new NotImplementedError("Constants support is not implemented in RNN yet.");
        } else {
          this.cell.build(stepInputShape);
        }
        let stateSize;
        if (Array.isArray(this.cell.stateSize)) {
          stateSize = this.cell.stateSize;
        } else {
          stateSize = [this.cell.stateSize];
        }
        if (this.stateSpec != null) {
          if (!util_exports.arraysEqual(this.stateSpec.map((spec) => spec.shape[spec.shape.length - 1]), stateSize)) {
            throw new ValueError(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`);
          }
        } else {
          this.stateSpec = stateSize.map((dim) => new InputSpec({ shape: [null, dim] }));
        }
        if (this.stateful) {
          this.resetStates();
        }
      }
      /**
       * Reset the state tensors of the RNN.
       *
       * If the `states` argument is `undefined` or `null`, will set the
       * state tensor(s) of the RNN to all-zero tensors of the appropriate
       * shape(s).
       *
       * If `states` is provided, will set the state tensors of the RNN to its
       * value.
       *
       * @param states Optional externally-provided initial states.
       * @param training Whether this call is done during training. For stateful
       *   RNNs, this affects whether the old states are kept or discarded. In
       *   particular, if `training` is `true`, the old states will be kept so
       *   that subsequent backpropgataion through time (BPTT) may work properly.
       *   Else, the old states will be discarded.
       */
      resetStates(states, training = false) {
        tidy(() => {
          if (!this.stateful) {
            throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
          }
          const batchSize = this.inputSpec[0].shape[0];
          if (batchSize == null) {
            throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
          }
          if (this.states_ == null) {
            if (Array.isArray(this.cell.stateSize)) {
              this.states_ = this.cell.stateSize.map((dim) => zeros([batchSize, dim]));
            } else {
              this.states_ = [zeros([batchSize, this.cell.stateSize])];
            }
          } else if (states == null) {
            dispose(this.states_);
            if (this.keptStates != null) {
              dispose(this.keptStates);
              this.keptStates = [];
            }
            if (Array.isArray(this.cell.stateSize)) {
              this.states_ = this.cell.stateSize.map((dim) => zeros([batchSize, dim]));
            } else {
              this.states_[0] = zeros([batchSize, this.cell.stateSize]);
            }
          } else {
            if (!Array.isArray(states)) {
              states = [states];
            }
            if (states.length !== this.states_.length) {
              throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);
            }
            if (training === true) {
              this.keptStates.push(this.states_.slice());
            } else {
              dispose(this.states_);
            }
            for (let index = 0; index < this.states_.length; ++index) {
              const value = states[index];
              const dim = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[index] : this.cell.stateSize;
              const expectedShape = [batchSize, dim];
              if (!util_exports.arraysEqual(value.shape, expectedShape)) {
                throw new ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);
              }
              this.states_[index] = value;
            }
          }
          this.states_ = this.states_.map((state) => keep(state.clone()));
        });
      }
      apply(inputs, kwargs) {
        let initialState = kwargs == null ? null : kwargs["initialState"];
        let constants = kwargs == null ? null : kwargs["constants"];
        if (kwargs == null) {
          kwargs = {};
        }
        const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);
        inputs = standardized.inputs;
        initialState = standardized.initialState;
        constants = standardized.constants;
        let additionalInputs = [];
        let additionalSpecs = [];
        if (initialState != null) {
          kwargs["initialState"] = initialState;
          additionalInputs = additionalInputs.concat(initialState);
          this.stateSpec = [];
          for (const state of initialState) {
            this.stateSpec.push(new InputSpec({ shape: state.shape }));
          }
          additionalSpecs = additionalSpecs.concat(this.stateSpec);
        }
        if (constants != null) {
          kwargs["constants"] = constants;
          additionalInputs = additionalInputs.concat(constants);
          this.numConstants = constants.length;
        }
        const isTensor = additionalInputs[0] instanceof SymbolicTensor;
        if (isTensor) {
          const fullInput = [inputs].concat(additionalInputs);
          const fullInputSpec = this.inputSpec.concat(additionalSpecs);
          const originalInputSpec = this.inputSpec;
          this.inputSpec = fullInputSpec;
          const output = super.apply(fullInput, kwargs);
          this.inputSpec = originalInputSpec;
          return output;
        } else {
          return super.apply(inputs, kwargs);
        }
      }
      // tslint:disable-next-line:no-any
      call(inputs, kwargs) {
        return tidy(() => {
          const mask = kwargs == null ? null : kwargs["mask"];
          const training = kwargs == null ? null : kwargs["training"];
          let initialState = kwargs == null ? null : kwargs["initialState"];
          inputs = getExactlyOneTensor(inputs);
          if (initialState == null) {
            if (this.stateful) {
              initialState = this.states_;
            } else {
              initialState = this.getInitialState(inputs);
            }
          }
          const numStates = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
          if (initialState.length !== numStates) {
            throw new ValueError(`RNN Layer has ${numStates} state(s) but was passed ${initialState.length} initial state(s).`);
          }
          if (this.unroll) {
            console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
          }
          const cellCallKwargs = { training };
          const step4 = (inputs2, states2) => {
            const outputs2 = this.cell.call([inputs2].concat(states2), cellCallKwargs);
            return [outputs2[0], outputs2.slice(1)];
          };
          const rnnOutputs = rnn(step4, inputs, initialState, this.goBackwards, mask, null, this.unroll, this.returnSequences);
          const lastOutput = rnnOutputs[0];
          const outputs = rnnOutputs[1];
          const states = rnnOutputs[2];
          if (this.stateful) {
            this.resetStates(states, training);
          }
          const output = this.returnSequences ? outputs : lastOutput;
          if (this.returnState) {
            return [output].concat(states);
          } else {
            return output;
          }
        });
      }
      getInitialState(inputs) {
        return tidy(() => {
          let initialState = zeros(inputs.shape);
          initialState = sum2(initialState, [1, 2]);
          initialState = expandDims2(initialState);
          if (Array.isArray(this.cell.stateSize)) {
            return this.cell.stateSize.map((dim) => dim > 1 ? tile2(initialState, [1, dim]) : initialState);
          } else {
            return this.cell.stateSize > 1 ? [tile2(initialState, [1, this.cell.stateSize])] : [initialState];
          }
        });
      }
      get trainableWeights() {
        if (!this.trainable) {
          return [];
        }
        return this.cell.trainableWeights;
      }
      get nonTrainableWeights() {
        if (!this.trainable) {
          return this.cell.weights;
        }
        return this.cell.nonTrainableWeights;
      }
      setFastWeightInitDuringBuild(value) {
        super.setFastWeightInitDuringBuild(value);
        if (this.cell != null) {
          this.cell.setFastWeightInitDuringBuild(value);
        }
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = {
          returnSequences: this.returnSequences,
          returnState: this.returnState,
          goBackwards: this.goBackwards,
          stateful: this.stateful,
          unroll: this.unroll
        };
        if (this.numConstants != null) {
          config["numConstants"] = this.numConstants;
        }
        const cellConfig = this.cell.getConfig();
        if (this.getClassName() === RNN.className) {
          config["cell"] = {
            "className": this.cell.getClassName(),
            "config": cellConfig
          };
        }
        return Object.assign(Object.assign(Object.assign({}, cellConfig), baseConfig), config);
      }
      /** @nocollapse */
      static fromConfig(cls, config, customObjects = {}) {
        const cellConfig = config["cell"];
        const cell = deserialize(cellConfig, customObjects);
        return new cls(Object.assign(config, { cell }));
      }
    };
    RNN.className = "RNN";
    serialization_exports.registerClass(RNN);
    RNNCell = class extends Layer {
    };
    SimpleRNNCell = class extends RNNCell {
      constructor(args) {
        super(args);
        this.DEFAULT_ACTIVATION = "tanh";
        this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
        this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
        this.DEFAULT_BIAS_INITIALIZER = "zeros";
        this.units = args.units;
        assertPositiveInteger(this.units, `units`);
        this.activation = getActivation(args.activation == null ? this.DEFAULT_ACTIVATION : args.activation);
        this.useBias = args.useBias == null ? true : args.useBias;
        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
        this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
        this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
        this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
        this.biasRegularizer = getRegularizer(args.biasRegularizer);
        this.kernelConstraint = getConstraint(args.kernelConstraint);
        this.recurrentConstraint = getConstraint(args.recurrentConstraint);
        this.biasConstraint = getConstraint(args.biasConstraint);
        this.dropout = min22([1, max22([0, args.dropout == null ? 0 : args.dropout])]);
        this.recurrentDropout = min22([
          1,
          max22([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
        ]);
        this.dropoutFunc = args.dropoutFunc;
        this.stateSize = this.units;
        this.dropoutMask = null;
        this.recurrentDropoutMask = null;
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        this.kernel = this.addWeight("kernel", [inputShape[inputShape.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        } else {
          this.bias = null;
        }
        this.built = true;
      }
      // Porting Note: PyKeras' equivalent of this method takes two tensor inputs:
      //   `inputs` and `states`. Here, the two tensors are combined into an
      //   `Tensor[]` Array as the first input argument.
      //   Similarly, PyKeras' equivalent of this method returns two values:
      //    `output` and `[output]`. Here the two are combined into one length-2
      //    `Tensor[]`, consisting of `output` repeated.
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = inputs;
          if (inputs.length !== 2) {
            throw new ValueError(`SimpleRNNCell expects 2 input Tensors, got ${inputs.length}.`);
          }
          let prevOutput = inputs[1];
          inputs = inputs[0];
          const training = kwargs["training"] == null ? false : kwargs["training"];
          if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
            this.dropoutMask = generateDropoutMask({
              ones: () => onesLike(inputs),
              rate: this.dropout,
              training,
              dropoutFunc: this.dropoutFunc
            });
          }
          if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
            this.recurrentDropoutMask = generateDropoutMask({
              ones: () => onesLike(prevOutput),
              rate: this.recurrentDropout,
              training,
              dropoutFunc: this.dropoutFunc
            });
          }
          let h;
          const dpMask = this.dropoutMask;
          const recDpMask = this.recurrentDropoutMask;
          if (dpMask != null) {
            h = dot22(mul5(inputs, dpMask), this.kernel.read());
          } else {
            h = dot22(inputs, this.kernel.read());
          }
          if (this.bias != null) {
            h = biasAdd(h, this.bias.read());
          }
          if (recDpMask != null) {
            prevOutput = mul5(prevOutput, recDpMask);
          }
          let output = add22(h, dot22(prevOutput, this.recurrentKernel.read()));
          if (this.activation != null) {
            output = this.activation.apply(output);
          }
          return [output, output];
        });
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = {
          units: this.units,
          activation: serializeActivation(this.activation),
          useBias: this.useBias,
          kernelInitializer: serializeInitializer(this.kernelInitializer),
          recurrentInitializer: serializeInitializer(this.recurrentInitializer),
          biasInitializer: serializeInitializer(this.biasInitializer),
          kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
          recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
          biasRegularizer: serializeRegularizer(this.biasRegularizer),
          activityRegularizer: serializeRegularizer(this.activityRegularizer),
          kernelConstraint: serializeConstraint(this.kernelConstraint),
          recurrentConstraint: serializeConstraint(this.recurrentConstraint),
          biasConstraint: serializeConstraint(this.biasConstraint),
          dropout: this.dropout,
          recurrentDropout: this.recurrentDropout
        };
        return Object.assign(Object.assign({}, baseConfig), config);
      }
    };
    SimpleRNNCell.className = "SimpleRNNCell";
    serialization_exports.registerClass(SimpleRNNCell);
    SimpleRNN = class extends RNN {
      constructor(args) {
        args.cell = new SimpleRNNCell(args);
        super(args);
      }
      call(inputs, kwargs) {
        return tidy(() => {
          if (this.cell.dropoutMask != null) {
            dispose(this.cell.dropoutMask);
            this.cell.dropoutMask = null;
          }
          if (this.cell.recurrentDropoutMask != null) {
            dispose(this.cell.recurrentDropoutMask);
            this.cell.recurrentDropoutMask = null;
          }
          const mask = kwargs == null ? null : kwargs["mask"];
          const training = kwargs == null ? null : kwargs["training"];
          const initialState = kwargs == null ? null : kwargs["initialState"];
          return super.call(inputs, { mask, training, initialState });
        });
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config);
      }
    };
    SimpleRNN.className = "SimpleRNN";
    serialization_exports.registerClass(SimpleRNN);
    GRUCell = class extends RNNCell {
      constructor(args) {
        super(args);
        this.DEFAULT_ACTIVATION = "tanh";
        this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid";
        this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
        this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
        this.DEFAULT_BIAS_INITIALIZER = "zeros";
        if (args.resetAfter) {
          throw new ValueError(`GRUCell does not support reset_after parameter set to true.`);
        }
        this.units = args.units;
        assertPositiveInteger(this.units, "units");
        this.activation = getActivation(args.activation === void 0 ? this.DEFAULT_ACTIVATION : args.activation);
        this.recurrentActivation = getActivation(args.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);
        this.useBias = args.useBias == null ? true : args.useBias;
        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
        this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
        this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
        this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
        this.biasRegularizer = getRegularizer(args.biasRegularizer);
        this.kernelConstraint = getConstraint(args.kernelConstraint);
        this.recurrentConstraint = getConstraint(args.recurrentConstraint);
        this.biasConstraint = getConstraint(args.biasConstraint);
        this.dropout = min22([1, max22([0, args.dropout == null ? 0 : args.dropout])]);
        this.recurrentDropout = min22([
          1,
          max22([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
        ]);
        this.dropoutFunc = args.dropoutFunc;
        this.implementation = args.implementation;
        this.stateSize = this.units;
        this.dropoutMask = null;
        this.recurrentDropoutMask = null;
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const inputDim = inputShape[inputShape.length - 1];
        this.kernel = this.addWeight("kernel", [inputDim, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
        if (this.useBias) {
          this.bias = this.addWeight("bias", [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        } else {
          this.bias = null;
        }
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = inputs;
          if (inputs.length !== 2) {
            throw new ValueError(`GRUCell expects 2 input Tensors (inputs, h, c), got ${inputs.length}.`);
          }
          const training = kwargs["training"] == null ? false : kwargs["training"];
          let hTMinus1 = inputs[1];
          inputs = inputs[0];
          if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
            this.dropoutMask = generateDropoutMask({
              ones: () => onesLike(inputs),
              rate: this.dropout,
              training,
              count: 3,
              dropoutFunc: this.dropoutFunc
            });
          }
          if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
            this.recurrentDropoutMask = generateDropoutMask({
              ones: () => onesLike(hTMinus1),
              rate: this.recurrentDropout,
              training,
              count: 3,
              dropoutFunc: this.dropoutFunc
            });
          }
          const dpMask = this.dropoutMask;
          const recDpMask = this.recurrentDropoutMask;
          let z;
          let r;
          let hh;
          if (0 < this.dropout && this.dropout < 1) {
            inputs = mul5(inputs, dpMask[0]);
          }
          let matrixX = dot22(inputs, this.kernel.read());
          if (this.useBias) {
            matrixX = biasAdd(matrixX, this.bias.read());
          }
          if (0 < this.recurrentDropout && this.recurrentDropout < 1) {
            hTMinus1 = mul5(hTMinus1, recDpMask[0]);
          }
          const recurrentKernelValue = this.recurrentKernel.read();
          const [rk1, rk2] = split(recurrentKernelValue, [2 * this.units, this.units], recurrentKernelValue.rank - 1);
          const matrixInner = dot22(hTMinus1, rk1);
          const [xZ, xR, xH] = split(matrixX, 3, matrixX.rank - 1);
          const [recurrentZ, recurrentR] = split(matrixInner, 2, matrixInner.rank - 1);
          z = this.recurrentActivation.apply(add22(xZ, recurrentZ));
          r = this.recurrentActivation.apply(add22(xR, recurrentR));
          const recurrentH = dot22(mul5(r, hTMinus1), rk2);
          hh = this.activation.apply(add22(xH, recurrentH));
          const h = add22(mul5(z, hTMinus1), mul5(add22(1, neg(z)), hh));
          return [h, h];
        });
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = {
          units: this.units,
          activation: serializeActivation(this.activation),
          recurrentActivation: serializeActivation(this.recurrentActivation),
          useBias: this.useBias,
          kernelInitializer: serializeInitializer(this.kernelInitializer),
          recurrentInitializer: serializeInitializer(this.recurrentInitializer),
          biasInitializer: serializeInitializer(this.biasInitializer),
          kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
          recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
          biasRegularizer: serializeRegularizer(this.biasRegularizer),
          activityRegularizer: serializeRegularizer(this.activityRegularizer),
          kernelConstraint: serializeConstraint(this.kernelConstraint),
          recurrentConstraint: serializeConstraint(this.recurrentConstraint),
          biasConstraint: serializeConstraint(this.biasConstraint),
          dropout: this.dropout,
          recurrentDropout: this.recurrentDropout,
          implementation: this.implementation,
          resetAfter: false
        };
        return Object.assign(Object.assign({}, baseConfig), config);
      }
    };
    GRUCell.className = "GRUCell";
    serialization_exports.registerClass(GRUCell);
    GRU = class extends RNN {
      constructor(args) {
        if (args.implementation === 0) {
          console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.");
        }
        args.cell = new GRUCell(args);
        super(args);
      }
      call(inputs, kwargs) {
        return tidy(() => {
          if (this.cell.dropoutMask != null) {
            dispose(this.cell.dropoutMask);
            this.cell.dropoutMask = null;
          }
          if (this.cell.recurrentDropoutMask != null) {
            dispose(this.cell.recurrentDropoutMask);
            this.cell.recurrentDropoutMask = null;
          }
          const mask = kwargs == null ? null : kwargs["mask"];
          const training = kwargs == null ? null : kwargs["training"];
          const initialState = kwargs == null ? null : kwargs["initialState"];
          return super.call(inputs, { mask, training, initialState });
        });
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        if (config["implmentation"] === 0) {
          config["implementation"] = 1;
        }
        return new cls(config);
      }
    };
    GRU.className = "GRU";
    serialization_exports.registerClass(GRU);
    LSTMCell = class extends RNNCell {
      constructor(args) {
        super(args);
        this.DEFAULT_ACTIVATION = "tanh";
        this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid";
        this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
        this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal";
        this.DEFAULT_BIAS_INITIALIZER = "zeros";
        this.units = args.units;
        assertPositiveInteger(this.units, "units");
        this.activation = getActivation(args.activation === void 0 ? this.DEFAULT_ACTIVATION : args.activation);
        this.recurrentActivation = getActivation(args.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : args.recurrentActivation);
        this.useBias = args.useBias == null ? true : args.useBias;
        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
        this.recurrentInitializer = getInitializer(args.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER);
        this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
        this.unitForgetBias = args.unitForgetBias;
        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
        this.recurrentRegularizer = getRegularizer(args.recurrentRegularizer);
        this.biasRegularizer = getRegularizer(args.biasRegularizer);
        this.kernelConstraint = getConstraint(args.kernelConstraint);
        this.recurrentConstraint = getConstraint(args.recurrentConstraint);
        this.biasConstraint = getConstraint(args.biasConstraint);
        this.dropout = min22([1, max22([0, args.dropout == null ? 0 : args.dropout])]);
        this.recurrentDropout = min22([
          1,
          max22([0, args.recurrentDropout == null ? 0 : args.recurrentDropout])
        ]);
        this.dropoutFunc = args.dropoutFunc;
        this.implementation = args.implementation;
        this.stateSize = [this.units, this.units];
        this.dropoutMask = null;
        this.recurrentDropoutMask = null;
      }
      build(inputShape) {
        var _a2;
        inputShape = getExactlyOneShape(inputShape);
        const inputDim = inputShape[inputShape.length - 1];
        this.kernel = this.addWeight("kernel", [inputDim, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
        let biasInitializer;
        if (this.useBias) {
          if (this.unitForgetBias) {
            const capturedBiasInit = this.biasInitializer;
            const capturedUnits = this.units;
            biasInitializer = new (_a2 = class CustomInit extends Initializer {
              apply(shape, dtype) {
                const bI = capturedBiasInit.apply([capturedUnits]);
                const bF = new Ones().apply([capturedUnits]);
                const bCAndH = capturedBiasInit.apply([capturedUnits * 2]);
                return concatAlongFirstAxis(concatAlongFirstAxis(bI, bF), bCAndH);
              }
            }, /** @nocollapse */
            _a2.className = "CustomInit", _a2)();
          } else {
            biasInitializer = this.biasInitializer;
          }
          this.bias = this.addWeight("bias", [this.units * 4], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        } else {
          this.bias = null;
        }
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const training = kwargs["training"] == null ? false : kwargs["training"];
          inputs = inputs;
          if (inputs.length !== 3) {
            throw new ValueError(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);
          }
          let hTMinus1 = inputs[1];
          const cTMinus1 = inputs[2];
          inputs = inputs[0];
          if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
            this.dropoutMask = generateDropoutMask({
              ones: () => onesLike(inputs),
              rate: this.dropout,
              training,
              count: 4,
              dropoutFunc: this.dropoutFunc
            });
          }
          if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
            this.recurrentDropoutMask = generateDropoutMask({
              ones: () => onesLike(hTMinus1),
              rate: this.recurrentDropout,
              training,
              count: 4,
              dropoutFunc: this.dropoutFunc
            });
          }
          const dpMask = this.dropoutMask;
          const recDpMask = this.recurrentDropoutMask;
          let i;
          let f;
          let c;
          let o;
          if (0 < this.dropout && this.dropout < 1) {
            inputs = mul5(inputs, dpMask[0]);
          }
          let z = dot22(inputs, this.kernel.read());
          if (0 < this.recurrentDropout && this.recurrentDropout < 1) {
            hTMinus1 = mul5(hTMinus1, recDpMask[0]);
          }
          z = add22(z, dot22(hTMinus1, this.recurrentKernel.read()));
          if (this.useBias) {
            z = biasAdd(z, this.bias.read());
          }
          const [z0, z1, z2, z3] = split(z, 4, z.rank - 1);
          i = this.recurrentActivation.apply(z0);
          f = this.recurrentActivation.apply(z1);
          c = add22(mul5(f, cTMinus1), mul5(i, this.activation.apply(z2)));
          o = this.recurrentActivation.apply(z3);
          const h = mul5(o, this.activation.apply(c));
          return [h, h, c];
        });
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = {
          units: this.units,
          activation: serializeActivation(this.activation),
          recurrentActivation: serializeActivation(this.recurrentActivation),
          useBias: this.useBias,
          kernelInitializer: serializeInitializer(this.kernelInitializer),
          recurrentInitializer: serializeInitializer(this.recurrentInitializer),
          biasInitializer: serializeInitializer(this.biasInitializer),
          unitForgetBias: this.unitForgetBias,
          kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
          recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
          biasRegularizer: serializeRegularizer(this.biasRegularizer),
          activityRegularizer: serializeRegularizer(this.activityRegularizer),
          kernelConstraint: serializeConstraint(this.kernelConstraint),
          recurrentConstraint: serializeConstraint(this.recurrentConstraint),
          biasConstraint: serializeConstraint(this.biasConstraint),
          dropout: this.dropout,
          recurrentDropout: this.recurrentDropout,
          implementation: this.implementation
        };
        return Object.assign(Object.assign({}, baseConfig), config);
      }
    };
    LSTMCell.className = "LSTMCell";
    serialization_exports.registerClass(LSTMCell);
    LSTM = class extends RNN {
      constructor(args) {
        if (args.implementation === 0) {
          console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call.");
        }
        args.cell = new LSTMCell(args);
        super(args);
      }
      call(inputs, kwargs) {
        return tidy(() => {
          if (this.cell.dropoutMask != null) {
            dispose(this.cell.dropoutMask);
            this.cell.dropoutMask = null;
          }
          if (this.cell.recurrentDropoutMask != null) {
            dispose(this.cell.recurrentDropoutMask);
            this.cell.recurrentDropoutMask = null;
          }
          const mask = kwargs == null ? null : kwargs["mask"];
          const training = kwargs == null ? null : kwargs["training"];
          const initialState = kwargs == null ? null : kwargs["initialState"];
          return super.call(inputs, { mask, training, initialState });
        });
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        if (config["implmentation"] === 0) {
          config["implementation"] = 1;
        }
        return new cls(config);
      }
    };
    LSTM.className = "LSTM";
    serialization_exports.registerClass(LSTM);
    StackedRNNCells = class extends RNNCell {
      constructor(args) {
        super(args);
        this.cells = args.cells;
      }
      get stateSize() {
        const stateSize = [];
        for (const cell of this.cells.slice().reverse()) {
          if (Array.isArray(cell.stateSize)) {
            stateSize.push(...cell.stateSize);
          } else {
            stateSize.push(cell.stateSize);
          }
        }
        return stateSize;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = inputs;
          let states = inputs.slice(1);
          const nestedStates = [];
          for (const cell of this.cells.slice().reverse()) {
            if (Array.isArray(cell.stateSize)) {
              nestedStates.push(states.splice(0, cell.stateSize.length));
            } else {
              nestedStates.push(states.splice(0, 1));
            }
          }
          nestedStates.reverse();
          const newNestedStates = [];
          let callInputs;
          for (let i = 0; i < this.cells.length; ++i) {
            const cell = this.cells[i];
            states = nestedStates[i];
            if (i === 0) {
              callInputs = [inputs[0]].concat(states);
            } else {
              callInputs = [callInputs[0]].concat(states);
            }
            callInputs = cell.call(callInputs, kwargs);
            newNestedStates.push(callInputs.slice(1));
          }
          states = [];
          for (const cellStates of newNestedStates.slice().reverse()) {
            states.push(...cellStates);
          }
          return [callInputs[0]].concat(states);
        });
      }
      build(inputShape) {
        if (isArrayOfShapes(inputShape)) {
          inputShape = inputShape[0];
        }
        inputShape = inputShape;
        let outputDim;
        this.cells.forEach((cell, i) => {
          nameScope(`RNNCell_${i}`, () => {
            cell.build(inputShape);
            if (Array.isArray(cell.stateSize)) {
              outputDim = cell.stateSize[0];
            } else {
              outputDim = cell.stateSize;
            }
            inputShape = [inputShape[0], outputDim];
          });
        });
        this.built = true;
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const getCellConfig = (cell) => {
          return {
            "className": cell.getClassName(),
            "config": cell.getConfig()
          };
        };
        const cellConfigs = this.cells.map(getCellConfig);
        const config = { "cells": cellConfigs };
        return Object.assign(Object.assign({}, baseConfig), config);
      }
      /** @nocollapse */
      static fromConfig(cls, config, customObjects = {}) {
        const cells = [];
        for (const cellConfig of config["cells"]) {
          cells.push(deserialize(cellConfig, customObjects));
        }
        return new cls({ cells });
      }
      get trainableWeights() {
        if (!this.trainable) {
          return [];
        }
        const weights = [];
        for (const cell of this.cells) {
          weights.push(...cell.trainableWeights);
        }
        return weights;
      }
      get nonTrainableWeights() {
        const weights = [];
        for (const cell of this.cells) {
          weights.push(...cell.nonTrainableWeights);
        }
        if (!this.trainable) {
          const trainableWeights = [];
          for (const cell of this.cells) {
            trainableWeights.push(...cell.trainableWeights);
          }
          return trainableWeights.concat(weights);
        }
        return weights;
      }
      /**
       * Retrieve the weights of a the model.
       *
       * @returns A flat `Array` of `tf.Tensor`s.
       */
      getWeights() {
        const weights = [];
        for (const cell of this.cells) {
          weights.push(...cell.weights);
        }
        return batchGetValue(weights);
      }
      /**
       * Set the weights of the model.
       *
       * @param weights An `Array` of `tf.Tensor`s with shapes and types matching
       *     the output of `getWeights()`.
       */
      setWeights(weights) {
        const tuples = [];
        for (const cell of this.cells) {
          const numParams = cell.weights.length;
          const inputWeights = weights.splice(numParams);
          for (let i = 0; i < cell.weights.length; ++i) {
            tuples.push([cell.weights[i], inputWeights[i]]);
          }
        }
        batchSetValue(tuples);
      }
    };
    StackedRNNCells.className = "StackedRNNCells";
    serialization_exports.registerClass(StackedRNNCells);
  }
});
var __rest;
var ConvRNN2D;
var ConvLSTM2DCell;
var ConvLSTM2D;
var init_convolutional_recurrent = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_recurrent.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_common2();
    init_topology();
    init_errors();
    init_initializers();
    init_conv_utils();
    init_generic_utils();
    init_types_utils();
    init_recurrent();
    __rest = function(s, e) {
      var t = {};
      for (var p2 in s)
        if (Object.prototype.hasOwnProperty.call(s, p2) && e.indexOf(p2) < 0)
          t[p2] = s[p2];
      if (s != null && typeof Object.getOwnPropertySymbols === "function")
        for (var i = 0, p2 = Object.getOwnPropertySymbols(s); i < p2.length; i++) {
          if (e.indexOf(p2[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p2[i]))
            t[p2[i]] = s[p2[i]];
        }
      return t;
    };
    ConvRNN2D = class extends RNN {
      constructor(args) {
        if (args.unroll) {
          throw new NotImplementedError("Unrolling is not possible with convolutional RNNs.");
        }
        if (Array.isArray(args.cell)) {
          throw new NotImplementedError("It is not possible at the moment to stack convolutional cells.");
        }
        super(args);
        this.inputSpec = [new InputSpec({ ndim: 5 })];
      }
      call(inputs, kwargs) {
        return tidy(() => {
          if (this.cell.dropoutMask != null) {
            dispose(this.cell.dropoutMask);
            this.cell.dropoutMask = null;
          }
          if (this.cell.recurrentDropoutMask != null) {
            dispose(this.cell.recurrentDropoutMask);
            this.cell.recurrentDropoutMask = null;
          }
          if (kwargs && kwargs["constants"]) {
            throw new ValueError("ConvRNN2D cell does not support constants");
          }
          const mask = kwargs == null ? null : kwargs["mask"];
          const training = kwargs == null ? null : kwargs["training"];
          const initialState = kwargs == null ? null : kwargs["initialState"];
          return super.call(inputs, { mask, training, initialState });
        });
      }
      computeOutputShape(inputShape) {
        let outShape = this.computeSingleOutputShape(inputShape);
        if (!this.returnSequences) {
          outShape = [outShape[0], ...outShape.slice(2)];
        }
        if (this.returnState) {
          outShape = [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];
        }
        return outShape;
      }
      getInitialState(inputs) {
        return tidy(() => {
          const { stateSize } = this.cell;
          const inputShape = inputs.shape;
          const outputShape = this.computeSingleOutputShape(inputShape);
          const stateShape = [outputShape[0], ...outputShape.slice(2)];
          const initialState = zeros(stateShape);
          if (Array.isArray(stateSize)) {
            return Array(stateSize.length).fill(initialState);
          }
          return [initialState];
        });
      }
      resetStates(states, training = false) {
        tidy(() => {
          if (!this.stateful) {
            throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
          }
          const inputShape = this.inputSpec[0].shape;
          const outputShape = this.computeSingleOutputShape(inputShape);
          const stateShape = [outputShape[0], ...outputShape.slice(2)];
          const batchSize = inputShape[0];
          if (batchSize == null) {
            throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
          }
          if (this.getStates() == null) {
            if (Array.isArray(this.cell.stateSize)) {
              this.states_ = this.cell.stateSize.map(() => zeros(stateShape));
            } else {
              this.states_ = [zeros(stateShape)];
            }
          } else if (states == null) {
            dispose(this.states_);
            if (this.keptStates != null) {
              dispose(this.keptStates);
              this.keptStates = [];
            }
            if (Array.isArray(this.cell.stateSize)) {
              this.states_ = this.cell.stateSize.map(() => zeros(stateShape));
            } else {
              this.states_[0] = zeros(stateShape);
            }
          } else {
            if (!Array.isArray(states)) {
              states = [states];
            }
            if (states.length !== this.states_.length) {
              throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${states.length} state value(s). Input received: ${states}`);
            }
            if (training) {
              this.keptStates.push(this.states_.slice());
            } else {
              dispose(this.states_);
            }
            for (let index = 0; index < this.states_.length; ++index) {
              const value = states[index];
              const expectedShape = stateShape;
              if (!util_exports.arraysEqual(value.shape, expectedShape)) {
                throw new ValueError(`State ${index} is incompatible with layer ${this.name}: expected shape=${expectedShape}, received shape=${value.shape}`);
              }
              this.states_[index] = value;
            }
          }
          this.states_ = this.states_.map((state) => keep(state.clone()));
        });
      }
      computeSingleOutputShape(inputShape) {
        const { dataFormat, filters, kernelSize, padding, strides, dilationRate } = this.cell;
        const isChannelsFirst = dataFormat === "channelsFirst";
        const h = inputShape[isChannelsFirst ? 3 : 2];
        const w = inputShape[isChannelsFirst ? 4 : 3];
        const hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);
        const wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);
        const outShape = [
          ...inputShape.slice(0, 2),
          ...isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters]
        ];
        return outShape;
      }
    };
    ConvRNN2D.className = "ConvRNN2D";
    ConvLSTM2DCell = class extends LSTMCell {
      constructor(args) {
        const { filters, kernelSize, strides, padding, dataFormat, dilationRate } = args;
        super(Object.assign(Object.assign({}, args), { units: filters }));
        this.filters = filters;
        assertPositiveInteger(this.filters, "filters");
        this.kernelSize = normalizeArray(kernelSize, 2, "kernelSize");
        this.kernelSize.forEach((size) => assertPositiveInteger(size, "kernelSize"));
        this.strides = normalizeArray(strides || 1, 2, "strides");
        this.strides.forEach((stride) => assertPositiveInteger(stride, "strides"));
        this.padding = padding || "valid";
        checkPaddingMode(this.padding);
        this.dataFormat = dataFormat || "channelsLast";
        checkDataFormat(this.dataFormat);
        this.dilationRate = normalizeArray(dilationRate || 1, 2, "dilationRate");
        this.dilationRate.forEach((rate) => assertPositiveInteger(rate, "dilationRate"));
      }
      build(inputShape) {
        var _a2;
        inputShape = getExactlyOneShape(inputShape);
        const channelAxis = this.dataFormat === "channelsFirst" ? 1 : inputShape.length - 1;
        if (inputShape[channelAxis] == null) {
          throw new ValueError(`The channel dimension of the input should be defined. Found ${inputShape[channelAxis]}`);
        }
        const inputDim = inputShape[channelAxis];
        const numOfKernels = 4;
        const kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);
        this.kernel = this.addWeight("kernel", kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
        const recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);
        this.recurrentKernel = this.addWeight("recurrent_kernel", recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
        if (this.useBias) {
          let biasInitializer;
          if (this.unitForgetBias) {
            const init = this.biasInitializer;
            const filters = this.filters;
            biasInitializer = new (_a2 = class CustomInit extends Initializer {
              apply(shape, dtype) {
                const biasI = init.apply([filters]);
                const biasF = ones2([filters]);
                const biasCAndO = init.apply([filters * 2]);
                return concatenate([biasI, biasF, biasCAndO]);
              }
            }, /** @nocollapse */
            _a2.className = "CustomInit", _a2)();
          } else {
            biasInitializer = this.biasInitializer;
          }
          this.bias = this.addWeight("bias", [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);
        }
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          if (inputs.length !== 3) {
            throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${inputs.length}.`);
          }
          const training = kwargs["training"] || false;
          const x = inputs[0];
          const hTMinus1 = inputs[1];
          const cTMinus1 = inputs[2];
          const numOfKernels = 4;
          if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {
            this.dropoutMask = generateDropoutMask({
              ones: () => onesLike(x),
              rate: this.dropout,
              training,
              count: numOfKernels,
              dropoutFunc: this.dropoutFunc
            });
          }
          const dropoutMask = this.dropoutMask;
          const applyDropout = (x2, mask, index) => {
            if (!mask || !mask[index]) {
              return x2;
            }
            return mul5(mask[index], x2);
          };
          let xI = applyDropout(x, dropoutMask, 0);
          let xF = applyDropout(x, dropoutMask, 1);
          let xC = applyDropout(x, dropoutMask, 2);
          let xO = applyDropout(x, dropoutMask, 3);
          if (0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null) {
            this.recurrentDropoutMask = generateDropoutMask({
              ones: () => onesLike(hTMinus1),
              rate: this.recurrentDropout,
              training,
              count: numOfKernels,
              dropoutFunc: this.dropoutFunc
            });
          }
          const recDropoutMask = this.recurrentDropoutMask;
          let hI = applyDropout(hTMinus1, recDropoutMask, 0);
          let hF = applyDropout(hTMinus1, recDropoutMask, 1);
          let hC = applyDropout(hTMinus1, recDropoutMask, 2);
          let hO = applyDropout(hTMinus1, recDropoutMask, 3);
          const kernelChannelAxis = 3;
          const [kernelI, kernelF, kernelC, kernelO] = split(this.kernel.read(), numOfKernels, kernelChannelAxis);
          const [biasI, biasF, biasC, biasO] = this.useBias ? split(this.bias.read(), numOfKernels) : [null, null, null, null];
          xI = this.inputConv(xI, kernelI, biasI, this.padding);
          xF = this.inputConv(xF, kernelF, biasF, this.padding);
          xC = this.inputConv(xC, kernelC, biasC, this.padding);
          xO = this.inputConv(xO, kernelO, biasO, this.padding);
          const [recKernelI, recKernelF, recKernelC, recKernelO] = split(this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);
          hI = this.recurrentConv(hI, recKernelI);
          hF = this.recurrentConv(hF, recKernelF);
          hC = this.recurrentConv(hC, recKernelC);
          hO = this.recurrentConv(hO, recKernelO);
          const i = this.recurrentActivation.apply(add22(xI, hI));
          const f = this.recurrentActivation.apply(add22(xF, hF));
          const c = add22(mul5(f, cTMinus1), mul5(i, this.activation.apply(add22(xC, hC))));
          const h = mul5(this.recurrentActivation.apply(add22(xO, hO)), this.activation.apply(c));
          return [h, h, c];
        });
      }
      getConfig() {
        const _a2 = super.getConfig(), { "units": _ } = _a2, baseConfig = __rest(_a2, ["units"]);
        const config = {
          filters: this.filters,
          kernelSize: this.kernelSize,
          padding: this.padding,
          dataFormat: this.dataFormat,
          dilationRate: this.dilationRate,
          strides: this.strides
        };
        return Object.assign(Object.assign({}, baseConfig), config);
      }
      inputConv(x, w, b, padding) {
        const out = conv2d(x, w, this.strides, padding || "valid", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC", this.dilationRate);
        if (b) {
          return biasAdd(out, b, this.dataFormat);
        }
        return out;
      }
      recurrentConv(x, w) {
        const strides = 1;
        return conv2d(x, w, strides, "same", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC");
      }
    };
    ConvLSTM2DCell.className = "ConvLSTM2DCell";
    serialization_exports.registerClass(ConvLSTM2DCell);
    ConvLSTM2D = class extends ConvRNN2D {
      constructor(args) {
        const cell = new ConvLSTM2DCell(args);
        super(Object.assign(Object.assign({}, args), { cell }));
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        return new cls(config);
      }
    };
    ConvLSTM2D.className = "ConvLSTM2D";
    serialization_exports.registerClass(ConvLSTM2D);
  }
});
var Dropout;
var SpatialDropout1D;
var Dense;
var Flatten;
var Activation2;
var RepeatVector;
var Reshape2;
var Permute;
var Masking;
var init_core = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/core.js"() {
    init_dist();
    init_activations();
    init_tfjs_backend();
    init_constraints();
    init_topology();
    init_errors();
    init_initializers();
    init_regularizers();
    init_generic_utils();
    init_math_utils();
    init_types_utils();
    Dropout = class extends Layer {
      constructor(args) {
        super(args);
        this.rate = Math.max(Math.min(args.rate, 1), 0);
        this.noiseShape = args.noiseShape;
        this.seed = args.seed;
        this.supportsMasking = true;
      }
      getNoiseShape(input2) {
        if (this.noiseShape == null) {
          return this.noiseShape;
        }
        const inputShape = input2.shape;
        const noiseShape = [];
        for (let i = 0; i < this.noiseShape.length; ++i) {
          noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);
        }
        return noiseShape;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          if (0 < this.rate && this.rate < 1) {
            const training = kwargs["training"] == null ? false : kwargs["training"];
            const noiseShape = this.getNoiseShape(input2);
            const output = inTrainPhase(() => dropout2(input2, this.rate, noiseShape, this.seed), () => input2, training);
            return output;
          }
          return inputs;
        });
      }
      getConfig() {
        const config = {
          rate: this.rate,
          noiseShape: this.noiseShape,
          seed: this.seed
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      dispose() {
        return super.dispose();
      }
    };
    Dropout.className = "Dropout";
    serialization_exports.registerClass(Dropout);
    SpatialDropout1D = class extends Dropout {
      constructor(args) {
        super(args);
        this.inputSpec = [{ ndim: 3 }];
      }
      getNoiseShape(input2) {
        const inputShape = input2.shape;
        return [inputShape[0], 1, inputShape[2]];
      }
    };
    SpatialDropout1D.className = "SpatialDropout1D";
    serialization_exports.registerClass(SpatialDropout1D);
    Dense = class extends Layer {
      constructor(args) {
        super(args);
        this.activation = null;
        this.useBias = true;
        this.kernel = null;
        this.bias = null;
        this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal";
        this.DEFAULT_BIAS_INITIALIZER = "zeros";
        if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {
          let batchSize = null;
          if (args.batchSize != null) {
            batchSize = args.batchSize;
          }
          this.batchInputShape = [batchSize, args.inputDim];
        }
        this.units = args.units;
        assertPositiveInteger(this.units, "units");
        this.activation = getActivation(args.activation);
        if (args.useBias != null) {
          this.useBias = args.useBias;
        }
        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);
        this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);
        this.kernelConstraint = getConstraint(args.kernelConstraint);
        this.biasConstraint = getConstraint(args.biasConstraint);
        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);
        this.biasRegularizer = getRegularizer(args.biasRegularizer);
        this.activityRegularizer = getRegularizer(args.activityRegularizer);
        this.supportsMasking = true;
        this.inputSpec = [{ minNDim: 2 }];
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const inputLastDim = inputShape[inputShape.length - 1];
        if (this.kernel == null) {
          this.kernel = this.addWeight("kernel", [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
          if (this.useBias) {
            this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);
          }
        }
        this.inputSpec = [{ minNDim: 2, axes: { [-1]: inputLastDim } }];
        this.built = true;
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const outputShape = inputShape.slice();
        outputShape[outputShape.length - 1] = this.units;
        return outputShape;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());
          let output;
          if (fusedActivationName != null) {
            output = dot22(input2, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);
          } else {
            output = dot22(input2, this.kernel.read());
            if (this.bias != null) {
              output = biasAdd(output, this.bias.read());
            }
            if (this.activation != null) {
              output = this.activation.apply(output);
            }
          }
          return output;
        });
      }
      getConfig() {
        const config = {
          units: this.units,
          activation: serializeActivation(this.activation),
          useBias: this.useBias,
          kernelInitializer: serializeInitializer(this.kernelInitializer),
          biasInitializer: serializeInitializer(this.biasInitializer),
          kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
          biasRegularizer: serializeRegularizer(this.biasRegularizer),
          activityRegularizer: serializeRegularizer(this.activityRegularizer),
          kernelConstraint: serializeConstraint(this.kernelConstraint),
          biasConstraint: serializeConstraint(this.biasConstraint)
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Dense.className = "Dense";
    serialization_exports.registerClass(Dense);
    Flatten = class extends Layer {
      constructor(args) {
        args = args || {};
        super(args);
        this.inputSpec = [{ minNDim: 3 }];
        this.dataFormat = args.dataFormat;
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        for (const dim of inputShape.slice(1)) {
          if (dim == null) {
            throw new ValueError(`The shape of the input to "Flatten" is not fully defined (got ${inputShape.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
          }
        }
        return [inputShape[0], arrayProd(inputShape, 1)];
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          let input2 = getExactlyOneTensor(inputs);
          if (this.dataFormat === "channelsFirst" && input2.rank > 1) {
            const permutation = [0];
            for (let i = 2; i < input2.rank; ++i) {
              permutation.push(i);
            }
            permutation.push(1);
            input2 = transpose2(input2, permutation);
          }
          return batchFlatten(input2);
        });
      }
      getConfig() {
        const config = {};
        if (this.dataFormat != null) {
          config["dataFormat"] = this.dataFormat;
        }
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Flatten.className = "Flatten";
    serialization_exports.registerClass(Flatten);
    Activation2 = class extends Layer {
      constructor(args) {
        super(args);
        this.supportsMasking = true;
        this.activation = getActivation(args.activation);
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          return this.activation.apply(input2);
        });
      }
      getConfig() {
        const config = { activation: serializeActivation(this.activation) };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Activation2.className = "Activation";
    serialization_exports.registerClass(Activation2);
    RepeatVector = class extends Layer {
      constructor(args) {
        super(args);
        this.n = args.n;
        this.inputSpec = [{ ndim: 2 }];
      }
      computeOutputShape(inputShape) {
        return [inputShape[0], this.n, inputShape[1]];
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          return repeat(inputs, this.n);
        });
      }
      getConfig() {
        const config = {
          n: this.n
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    RepeatVector.className = "RepeatVector";
    serialization_exports.registerClass(RepeatVector);
    Reshape2 = class extends Layer {
      constructor(args) {
        super(args);
        this.targetShape = args.targetShape;
        for (let i = 0; i < this.targetShape.length; ++i) {
          if (this.isUnknown(this.targetShape[i])) {
            this.targetShape[i] = null;
          }
        }
      }
      isUnknown(dim) {
        return dim < 0 || dim == null;
      }
      /**
       * Finds and replaces a missing dimension in output shape.
       *
       * This is a near direct port of the internal Numpy function
       * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.
       *
       * @param inputShape: Original shape of array begin reshape.
       * @param outputShape: Target shape of the array, with at most a single
       * `null` or negative number, which indicates an underdetermined dimension
       * that should be derived from `inputShape` and the known dimensions of
       *   `outputShape`.
       * @returns: The output shape with `null` replaced with its computed value.
       * @throws: ValueError: If `inputShape` and `outputShape` do not match.
       */
      fixUnknownDimension(inputShape, outputShape) {
        const errorMsg = "Total size of new array must be unchanged.";
        const finalShape = outputShape.slice();
        let known = 1;
        let unknown = null;
        for (let i = 0; i < finalShape.length; ++i) {
          const dim = finalShape[i];
          if (this.isUnknown(dim)) {
            if (unknown === null) {
              unknown = i;
            } else {
              throw new ValueError("Can only specifiy one unknown dimension.");
            }
          } else {
            known *= dim;
          }
        }
        const originalSize = arrayProd(inputShape);
        if (unknown !== null) {
          if (known === 0 || originalSize % known !== 0) {
            throw new ValueError(errorMsg);
          }
          finalShape[unknown] = originalSize / known;
        } else if (originalSize !== known) {
          throw new ValueError(errorMsg);
        }
        return finalShape;
      }
      computeOutputShape(inputShape) {
        let anyUnknownDims = false;
        for (let i = 0; i < inputShape.length; ++i) {
          if (this.isUnknown(inputShape[i])) {
            anyUnknownDims = true;
            break;
          }
        }
        if (anyUnknownDims) {
          return inputShape.slice(0, 1).concat(this.targetShape);
        } else {
          return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          const inputShape = input2.shape;
          const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));
          return reshape(input2, outputShape);
        });
      }
      getConfig() {
        const config = {
          targetShape: this.targetShape
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Reshape2.className = "Reshape";
    serialization_exports.registerClass(Reshape2);
    Permute = class extends Layer {
      constructor(args) {
        super(args);
        if (args.dims == null) {
          throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
        }
        if (!Array.isArray(args.dims)) {
          throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${args.dims} instead.`);
        }
        const expectedSortedIndices = range2(1, args.dims.length + 1);
        if (!util_exports.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {
          throw new Error("Invalid permutation `dims`: " + JSON.stringify(args.dims) + " `dims` must contain consecutive integers starting from 1.");
        }
        this.dims = args.dims;
        this.dimsIncludingBatch = [0].concat(this.dims);
        this.inputSpec = [new InputSpec({ ndim: this.dims.length + 1 })];
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const outputShape = inputShape.slice();
        this.dims.forEach((dim, i) => {
          outputShape[i + 1] = inputShape[dim];
        });
        return outputShape;
      }
      call(inputs, kwargs) {
        return transpose2(getExactlyOneTensor(inputs), this.dimsIncludingBatch);
      }
      getConfig() {
        const config = {
          dims: this.dims
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Permute.className = "Permute";
    serialization_exports.registerClass(Permute);
    Masking = class extends Layer {
      constructor(args) {
        super(args == null ? {} : args);
        this.supportsMasking = true;
        if (args != null) {
          this.maskValue = args.maskValue == null ? 0 : args.maskValue;
        } else {
          this.maskValue = 0;
        }
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = { maskValue: this.maskValue };
        Object.assign(config, baseConfig);
        return config;
      }
      computeMask(inputs, mask) {
        const input2 = getExactlyOneTensor(inputs);
        const axis = -1;
        return any(notEqual(input2, this.maskValue), axis);
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          const axis = -1;
          const keepDims = true;
          const booleanMask = any(notEqual(input2, this.maskValue), axis, keepDims);
          const output = mul5(input2, cast(booleanMask, input2.dtype));
          return output;
        });
      }
    };
    Masking.className = "Masking";
    serialization_exports.registerClass(Masking);
  }
});
var Embedding;
var init_embeddings = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/embeddings.js"() {
    init_dist();
    init_tfjs_backend();
    init_constraints();
    init_topology();
    init_errors();
    init_initializers();
    init_regularizers();
    init_generic_utils();
    init_types_utils();
    Embedding = class extends Layer {
      constructor(args) {
        super(args);
        this.embeddings = null;
        this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform";
        if (args.batchInputShape == null && args.inputShape == null) {
          let batchSize = null;
          if (args.batchSize != null) {
            batchSize = args.batchSize;
          }
          if (args.inputLength == null) {
            this.batchInputShape = [batchSize, null];
          } else {
            this.batchInputShape = [batchSize].concat(toList(args.inputLength));
          }
        }
        this.inputDim = args.inputDim;
        assertPositiveInteger(this.inputDim, "inputDim");
        this.outputDim = args.outputDim;
        assertPositiveInteger(this.outputDim, "outputDim");
        this.embeddingsInitializer = getInitializer(args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);
        this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);
        this.activityRegularizer = getRegularizer(args.activityRegularizer);
        this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);
        this.maskZero = args.maskZero;
        this.supportsMasking = args.maskZero;
        this.inputLength = args.inputLength;
      }
      build(inputShape) {
        this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint);
        this.built = true;
      }
      // Override warnOnIncompatibleInputShape because an embedding layer allows
      // the input to have varying ranks.
      warnOnIncompatibleInputShape(inputShape) {
      }
      computeMask(inputs, mask) {
        return tidy(() => {
          if (!this.maskZero) {
            return null;
          } else {
            inputs = getExactlyOneTensor(inputs);
            return notEqual(inputs, zerosLike(inputs));
          }
        });
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (this.inputLength == null) {
          return [...inputShape, this.outputDim];
        }
        const inLens = toList(this.inputLength);
        if (inLens.length !== inputShape.length - 1) {
          throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);
        } else {
          let i = 0;
          for (let k = 0; k < inLens.length; ++k) {
            const s1 = inLens[k];
            const s2 = inputShape[k + 1];
            if (s1 != null && s2 != null && s1 !== s2) {
              throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${inputShape}`);
            } else if (s1 == null) {
              inLens[i] = s2;
            }
            i++;
          }
        }
        return [inputShape[0], ...inLens, this.outputDim];
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          let input2 = getExactlyOneTensor(inputs);
          if (input2.dtype !== "int32") {
            input2 = cast2(input2, "int32");
          }
          const output = gather2(this.embeddings.read(), reshape(input2, [input2.size]));
          return reshape(output, getExactlyOneShape(this.computeOutputShape(input2.shape)));
        });
      }
      getConfig() {
        const config = {
          inputDim: this.inputDim,
          outputDim: this.outputDim,
          embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),
          embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),
          activityRegularizer: serializeRegularizer(this.activityRegularizer),
          embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),
          maskZero: this.maskZero,
          inputLength: this.inputLength
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Embedding.className = "Embedding";
    serialization_exports.registerClass(Embedding);
  }
});
function interpretAxis(axis, dim) {
  while (axis < 0) {
    axis += dim;
  }
  return axis;
}
function batchDot(x, y, axes) {
  if (x.shape.length > 3 || y.shape.length > 3) {
    throw new NotImplementedError("batchDot is not implemented for tensors of 4D or higher rank yet");
  }
  util_exports.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, but got ${x.shape.length}`);
  util_exports.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, but got ${y.shape.length}`);
  if (typeof axes === "number") {
    axes = [axes, axes];
  }
  if (x.dtype === "complex64" || y.dtype === "complex64") {
    throw new NotImplementedError("batchDot is not implemented for complex64-type Tensors yet.");
  }
  const xNDim = x.shape.length;
  const yNDim = y.shape.length;
  if (axes == null) {
    axes = [xNDim - 1, yNDim - 2];
  }
  const axesArray = axes;
  return tidy(() => {
    let diff;
    if (xNDim > yNDim) {
      diff = xNDim - yNDim;
      const diffShape = [];
      for (let i = 0; i < diff; ++i) {
        diffShape.push(1);
      }
      y = reshape(y, y.shape.concat(diffShape));
    } else if (yNDim > xNDim) {
      diff = yNDim - xNDim;
      const diffShape = [];
      for (let i = 0; i < diff; ++i) {
        diffShape.push(1);
      }
      x = reshape(x, x.shape.concat(diffShape));
    } else {
      diff = 0;
    }
    let out;
    if (x.shape.length === 2 && y.shape.length === 2) {
      if (axesArray[0] === axesArray[1]) {
        out = sum2(mul5(x, y), axesArray[0]);
      } else {
        out = sum2(mul5(transpose2(x, [1, 0]), y), axesArray[1]);
      }
    } else {
      const adjX = axesArray[0] !== x.shape.length - 1;
      const adjY = axesArray[1] === y.shape.length - 1;
      out = matMul(x, y, adjX, adjY);
    }
    if (diff > 0) {
      let idx;
      if (xNDim > yNDim) {
        idx = xNDim + yNDim - 3;
      } else {
        idx = xNDim - 1;
      }
      const squeezeAxes = [];
      for (let i = idx; i < idx + diff; ++i) {
        squeezeAxes.push(i);
      }
      out = squeeze(out, squeezeAxes);
    }
    if (out.shape.length === 1) {
      out = expandDims(out, 1);
    }
    return out;
  });
}
var Merge;
var Add2;
var Multiply2;
var Average;
var Maximum2;
var Minimum2;
var Concatenate;
var Dot;
var init_merge = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_topology();
    init_errors();
    init_losses();
    init_generic_utils();
    init_math_utils();
    init_types_utils();
    Merge = class extends Layer {
      constructor(args) {
        super(args || {});
        this.supportsMasking = true;
      }
      /**
       * Logic for merging multiple tensors, to be overridden by subclasses.
       * @param inputs
       */
      mergeFunction(inputs) {
        throw new NotImplementedError();
      }
      /**
       * Computes the shape of the result of an elementwise operation.
       *
       * @param shape1: Shape of the first tensor.
       * @param shape2: Shape of the second tensor.
       * @returns Expected output shape when an elementwise operation is carried
       *   out on 2 tensors with shapes `shape1` and `shape2`.
       * @throws ValueError: If `shape1` and `shape2` are not compatible for
       *   element-wise operations.
       */
      computeElementwiseOpOutputShape(shape1, shape2) {
        if (shape1 == null || shape2 == null) {
          return null;
        } else if (shape1.length < shape2.length) {
          return this.computeElementwiseOpOutputShape(shape2, shape1);
        } else if (shape2.length === 0) {
          return shape1;
        }
        const outputShape = shape1.slice(0, shape1.length - shape2.length);
        for (let k = 0; k < shape2.length; ++k) {
          const i = shape1[shape1.length - shape2.length + k];
          const j = shape2[k];
          if (i == null || j == null || i < 0 || j < 0) {
            outputShape.push(null);
          } else if (i === 1) {
            outputShape.push(j);
          } else if (j === 1) {
            outputShape.push(i);
          } else {
            if (i !== j) {
              throw new ValueError("Operands could not be broadcast together with shapes " + JSON.stringify(shape1) + " " + JSON.stringify(shape2));
            }
            outputShape.push(i);
          }
        }
        return outputShape;
      }
      build(inputShape) {
        if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {
          inputShape = [getExactlyOneShape(inputShape)];
        }
        inputShape = inputShape;
        if (inputShape.length < 2) {
          throw new ValueError(`A merge layer should be called on an Array of at least 2 inputs. Got ${inputShape.length} input(s).`);
        }
        let batchSizes = [];
        for (const shape of inputShape) {
          if (shape != null && shape[0] !== null) {
            batchSizes.push(shape[0]);
          }
        }
        batchSizes = unique2(batchSizes);
        if (batchSizes.length > 1) {
          throw new ValueError(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(inputShape)}.`);
        }
        let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);
        for (let i = 1; i < inputShape.length; ++i) {
          const shape = inputShape[i] == null ? null : inputShape[i].slice(1);
          outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);
        }
        const allRanks = inputShape.map((shape) => shape.length);
        if (inputShape.indexOf(null) === -1 && unique2(allRanks).length === 1) {
          this.reshapeRequired = false;
        } else {
          this.reshapeRequired = true;
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = inputs;
          if (this.reshapeRequired) {
            const reshapedInputs = [];
            const inputDims = inputs.map((input2) => input2.rank);
            if (inputDims.indexOf(null) === -1) {
              const maxNDim = max22(inputDims);
              for (let x of inputs) {
                const xNDim = x.rank;
                for (let k = 0; k < maxNDim - xNDim; ++k) {
                  x = expandDims2(x, 1);
                }
                reshapedInputs.push(x);
              }
              return this.mergeFunction(reshapedInputs);
            } else {
              let transposed = false;
              for (const x of inputs) {
                const xNDim = x.rank;
                if (xNDim == null) {
                  const xShape = x.shape;
                  const batchSize = xShape[0];
                  const newShape = xShape.slice(1).concat([batchSize]);
                  let xTransposed = reshape(x, [batchSize].concat(arrayProd(xShape.slice(1))));
                  xTransposed = transpose2(xTransposed, [1, 0]);
                  xTransposed = reshape(xTransposed, newShape);
                  reshapedInputs.push(xTransposed);
                  transposed = true;
                } else if (xNDim > 1) {
                  const dims = range2(1, xNDim).concat([0]);
                  reshapedInputs.push(transpose2(x, dims));
                  transposed = true;
                } else {
                  reshapedInputs.push(x);
                }
              }
              let y = this.mergeFunction(reshapedInputs);
              const yNDim = y.rank;
              if (transposed) {
                if (yNDim == null) {
                  const yShape = y.shape;
                  const yNDim2 = yShape.length;
                  const batchSize = yShape[yNDim2 - 1];
                  const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));
                  y = reshape(transpose2(reshape(y, [-1, batchSize]), [1, 0]), newShape);
                } else if (yNDim > 1) {
                  const dims = [yNDim - 1].concat(range2(0, yNDim - 1));
                  y = transpose2(y, dims);
                }
              }
              return y;
            }
          } else {
            return this.mergeFunction(inputs);
          }
        });
      }
      computeOutputShape(inputShape) {
        inputShape = inputShape;
        let outputShape;
        if (inputShape[0] == null) {
          outputShape = null;
        } else {
          outputShape = inputShape[0].slice(1);
        }
        for (let i = 1; i < inputShape.length; ++i) {
          const shape = inputShape[i] == null ? null : inputShape[i].slice(1);
          outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);
        }
        let batchSizes = [];
        for (const shape of inputShape) {
          if (shape != null && shape[0] !== null) {
            batchSizes.push(shape[0]);
          }
        }
        batchSizes = unique2(batchSizes);
        if (batchSizes.length === 1) {
          outputShape = batchSizes.concat(outputShape);
        } else {
          outputShape = [null].concat(outputShape);
        }
        return outputShape;
      }
      computeMask(inputs, mask) {
        return tidy(() => {
          if (mask == null) {
            return null;
          }
          if (!Array.isArray(mask)) {
            throw new ValueError("`mask` should be an Array");
          }
          if (!Array.isArray(inputs)) {
            throw new ValueError("`inputs` should be an Array");
          }
          if (mask.length !== inputs.length) {
            throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${inputs.length} vs ${mask.length})`);
          }
          if (mask.every((m) => m == null)) {
            return null;
          }
          mask = mask.map((m) => m == null ? m : expandDims(m, 0));
          let output = mask[0];
          for (let i = 1; i < mask.length - 1; ++i) {
            output = logicalAnd(output, mask[i]);
          }
          return output;
        });
      }
    };
    Add2 = class extends Merge {
      constructor(args) {
        super(args);
      }
      mergeFunction(inputs) {
        return tidy(() => {
          let output = inputs[0].clone();
          for (let i = 1; i < inputs.length; ++i) {
            output = add22(output, inputs[i]);
          }
          return output;
        });
      }
    };
    Add2.className = "Add";
    serialization_exports.registerClass(Add2);
    Multiply2 = class extends Merge {
      constructor(args) {
        super(args);
      }
      mergeFunction(inputs) {
        return tidy(() => {
          let output = inputs[0].clone();
          for (let i = 1; i < inputs.length; ++i) {
            output = mul5(output, inputs[i]);
          }
          return output;
        });
      }
    };
    Multiply2.className = "Multiply";
    serialization_exports.registerClass(Multiply2);
    Average = class extends Merge {
      constructor(args) {
        super(args);
      }
      mergeFunction(inputs) {
        return tidy(() => {
          let output = inputs[0].clone();
          for (let i = 1; i < inputs.length; ++i) {
            output = add22(output, inputs[i]);
          }
          return mul5(1 / inputs.length, output);
        });
      }
    };
    Average.className = "Average";
    serialization_exports.registerClass(Average);
    Maximum2 = class extends Merge {
      constructor(args) {
        super(args);
      }
      mergeFunction(inputs) {
        return tidy(() => {
          let output = inputs[0];
          for (let i = 1; i < inputs.length; ++i) {
            output = maximum(output, inputs[i]);
          }
          return output;
        });
      }
    };
    Maximum2.className = "Maximum";
    serialization_exports.registerClass(Maximum2);
    Minimum2 = class extends Merge {
      constructor(args) {
        super(args);
      }
      mergeFunction(inputs) {
        return tidy(() => {
          let output = inputs[0];
          for (let i = 1; i < inputs.length; ++i) {
            output = minimum(output, inputs[i]);
          }
          return output;
        });
      }
    };
    Minimum2.className = "Minimum";
    serialization_exports.registerClass(Minimum2);
    Concatenate = class extends Merge {
      constructor(args) {
        super(args);
        this.DEFAULT_AXIS = -1;
        if (args == null) {
          args = {};
        }
        this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;
        this.supportsMasking = true;
        this.reshapeRequired = false;
      }
      build(inputShape) {
        if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) || inputShape.length === 1) {
          throw new ValueError("A `Concatenate` layer should be called on a list of at least 2 inputs");
        }
        inputShape = inputShape;
        let allNoneShape = true;
        for (const shape of inputShape) {
          if (shape != null) {
            allNoneShape = false;
            break;
          }
        }
        if (allNoneShape) {
          return;
        }
        const shapeSet = [];
        for (let i = 0; i < inputShape.length; ++i) {
          const shapeWithoutConcatAxis = inputShape[i].slice();
          shapeWithoutConcatAxis.splice(this.axis, 1);
          let exists = false;
          for (const shape of shapeSet) {
            if (util_exports.arraysEqual(shape, shapeWithoutConcatAxis)) {
              exists = true;
              break;
            }
          }
          if (!exists) {
            shapeSet.push(shapeWithoutConcatAxis);
          }
        }
        if (shapeSet.length > 1) {
          throw new ValueError("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(inputShape));
        }
      }
      mergeFunction(inputs) {
        return tidy(() => {
          return concatenate(inputs, this.axis);
        });
      }
      computeOutputShape(inputShape) {
        if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {
          throw new ValueError("A `Concatenate` layer should be called on a list of inputs.");
        }
        const inputShapes = inputShape;
        const outputShape = inputShapes[0].slice();
        const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;
        for (const shape of inputShapes.slice(1)) {
          if (outputShape[axis] == null || shape[axis] == null) {
            outputShape[axis] = null;
            break;
          }
          outputShape[axis] += shape[axis];
        }
        return outputShape;
      }
      computeMask(inputs, mask) {
        if (mask == null) {
          return null;
        }
        if (!Array.isArray(mask)) {
          throw new ValueError("`mask` should be an array for Concatenate");
        }
        if (!Array.isArray(inputs)) {
          throw new ValueError("`inputs` should be an array for Concatenate");
        }
        if (mask.length !== inputs.length) {
          throw new ValueError(`Mismatch in the length of mask (${mask.length}) and the legnth of inputs (${inputs.length})`);
        }
        return tidy(() => {
          let allNullMasks = true;
          mask.forEach((m) => {
            if (m != null) {
              allNullMasks = false;
              return;
            }
          });
          if (allNullMasks) {
            return null;
          }
          const outputMasks = [];
          for (let i = 0; i < inputs.length; ++i) {
            if (mask[i] == null) {
              outputMasks.push(cast(onesLike(inputs[i]), "bool"));
            } else if (mask[i].rank < inputs[i].rank) {
              outputMasks.push(expandDims(mask[i], -1));
            } else {
              outputMasks.push(mask[i]);
            }
          }
          const concatenatedMasks = concat(outputMasks, this.axis);
          return all(concatenatedMasks, -1, false);
        });
      }
      getConfig() {
        const config = {
          "axis": this.axis
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Concatenate.className = "Concatenate";
    serialization_exports.registerClass(Concatenate);
    Dot = class extends Merge {
      constructor(args) {
        super(args);
        this.axes = args.axes;
        this.normalize = args.normalize == null ? false : args.normalize;
        this.supportsMasking = true;
        this.reshapeRequired = false;
      }
      build(inputShape) {
        util_exports.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
        const shape1 = inputShape[0];
        const shape2 = inputShape[1];
        if (shape1.length > 3 || shape2.length > 3) {
          throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
        }
        const axes = this.interpretAxes(shape1, shape2);
        if (shape1[axes[0]] !== shape2[axes[1]]) {
          throw new ValueError(`Dimension incompatibility: ${shape1[axes[0]]} !== ${shape2[axes[1]]}`);
        }
      }
      mergeFunction(inputs) {
        if (inputs.length !== 2) {
          throw new ValueError(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${inputs.length} input(s).`);
        }
        let x1 = inputs[0];
        let x2 = inputs[1];
        let axes;
        if (!Array.isArray(this.axes)) {
          axes = [
            interpretAxis(this.axes, x1.shape.length),
            interpretAxis(this.axes, x2.shape.length)
          ];
        } else {
          axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));
        }
        if (this.normalize) {
          x1 = l2Normalize(x1, axes[0]);
          x2 = l2Normalize(x2, axes[1]);
        }
        return batchDot(x1, x2, axes);
      }
      interpretAxes(shape1, shape2) {
        let axes;
        if (!Array.isArray(this.axes)) {
          axes = [
            interpretAxis(this.axes, shape1.length),
            interpretAxis(this.axes, shape2.length)
          ];
        } else {
          axes = this.axes;
        }
        return axes;
      }
      computeOutputShape(inputShape) {
        util_exports.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
        const shape1 = inputShape[0].slice();
        const shape2 = inputShape[1].slice();
        if (shape1.length > 3 || shape2.length > 3) {
          throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
        }
        const axes = this.interpretAxes(shape1, shape2);
        shape1.splice(axes[0], 1);
        shape2.splice(axes[1], 1);
        shape2.splice(0, 1);
        const outputShape = shape1.concat(shape2);
        if (outputShape.length === 1) {
          outputShape.push(1);
        }
        return outputShape;
      }
      computeMask(inputs, mask) {
        return null;
      }
      getConfig() {
        const config = {
          "axes": this.axes,
          "normalize": this.normalize
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    Dot.className = "Dot";
    serialization_exports.registerClass(Dot);
  }
});
var GaussianNoise;
var GaussianDropout;
var AlphaDropout;
var init_noise = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/noise.js"() {
    init_dist();
    init_tfjs_backend();
    init_topology();
    init_types_utils();
    GaussianNoise = class extends Layer {
      constructor(args) {
        super(args);
        this.supportsMasking = true;
        this.stddev = args.stddev;
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = { stddev: this.stddev };
        Object.assign(config, baseConfig);
        return config;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          const noised = () => add22(randomNormal2(input2.shape, 0, this.stddev), input2);
          const output = inTrainPhase(noised, () => input2, kwargs["training"] || false);
          return output;
        });
      }
    };
    GaussianNoise.className = "GaussianNoise";
    serialization_exports.registerClass(GaussianNoise);
    GaussianDropout = class extends Layer {
      constructor(args) {
        super(args);
        this.supportsMasking = true;
        this.rate = args.rate;
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = { rate: this.rate };
        Object.assign(config, baseConfig);
        return config;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          const input2 = getExactlyOneTensor(inputs);
          if (this.rate > 0 && this.rate < 1) {
            const noised = () => {
              const stddev = Math.sqrt(this.rate / (1 - this.rate));
              return mul5(input2, randomNormal2(input2.shape, 1, stddev));
            };
            return inTrainPhase(noised, () => input2, kwargs["training"] || false);
          }
          return input2;
        });
      }
    };
    GaussianDropout.className = "GaussianDropout";
    serialization_exports.registerClass(GaussianDropout);
    AlphaDropout = class extends Layer {
      constructor(args) {
        super(args);
        this.supportsMasking = true;
        this.rate = args.rate;
        this.noiseShape = args.noiseShape;
      }
      _getNoiseShape(inputs) {
        return this.noiseShape || getExactlyOneTensor(inputs).shape;
      }
      computeOutputShape(inputShape) {
        return inputShape;
      }
      getConfig() {
        const baseConfig = super.getConfig();
        const config = { rate: this.rate };
        Object.assign(config, baseConfig);
        return config;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          if (this.rate < 1 && this.rate > 0) {
            const noiseShape = this._getNoiseShape(inputs);
            const droppedInputs = () => {
              const input2 = getExactlyOneTensor(inputs);
              const alpha = 1.6732632423543772;
              const scale22 = 1.0507009873554805;
              const alphaP = -alpha * scale22;
              let keptIdx = greaterEqual(randomUniform(noiseShape), this.rate);
              keptIdx = cast2(keptIdx, "float32");
              const a = ((1 - this.rate) * (1 + this.rate * alphaP ** 2)) ** -0.5;
              const b = -a * alphaP * this.rate;
              const x = add22(mul5(input2, keptIdx), mul5(add22(keptIdx, -1), alphaP));
              return add22(mul5(x, a), b);
            };
            return inTrainPhase(droppedInputs, () => getExactlyOneTensor(inputs), kwargs["training"] || false);
          }
          return inputs;
        });
      }
    };
    AlphaDropout.className = "AlphaDropout";
    serialization_exports.registerClass(AlphaDropout);
  }
});
function batchNormalization(x, mean3, variance, beta, gamma, epsilon3 = 1e-3) {
  let out;
  if (x.rank === 2) {
    out = batchNorm2d(x, mean3, variance, beta, gamma, epsilon3);
  } else if (x.rank === 3) {
    out = batchNorm3d(x, mean3, variance, beta, gamma, epsilon3);
  } else if (x.rank === 4) {
    out = batchNorm4d(x, mean3, variance, beta, gamma, epsilon3);
  } else {
    throw new NotImplementedError(`batchNormalization is not implemented for array of rank ${x.rank} yet`);
  }
  return out;
}
function regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
  return tidy(() => {
    const meanAndVariance = moments(x, reductionAxes);
    const mean3 = meanAndVariance.mean;
    const variance = meanAndVariance.variance;
    const normed = batchNormalization(x, mean3, variance, beta, gamma, epsilon3);
    return [normed, mean3, variance];
  });
}
function broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
  return tidy(() => {
    const meanAndVariance = moments(x, reductionAxes);
    const mean3 = meanAndVariance.mean;
    const variance = meanAndVariance.variance;
    const targetShape = [];
    for (const axis of range2(0, x.rank)) {
      if (reductionAxes.indexOf(axis) !== -1) {
        targetShape.push(1);
      } else {
        targetShape.push(x.shape[axis]);
      }
    }
    const broadcastMean = reshape(mean3, targetShape);
    const broadcastVariance = reshape(variance, targetShape);
    const broadcastGamma = gamma == null ? null : reshape(gamma, targetShape);
    const broadcastBeta = beta == null ? null : reshape(beta, targetShape);
    const normed = batchNormalization(x, broadcastMean, broadcastVariance, broadcastBeta, broadcastGamma, epsilon3);
    return [normed, mean3, variance];
  });
}
function normalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3 = 1e-3) {
  if (util_exports.arraysEqual(reductionAxes.slice().sort(), range2(0, x.rank - 1))) {
    return regularNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3);
  } else {
    return broadcastNormalizeBatchInTraining(x, gamma, beta, reductionAxes, epsilon3);
  }
}
var BatchNormalization;
var LayerNormalization;
var init_normalization = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/normalization.js"() {
    init_dist();
    init_dist();
    init_constraints();
    init_topology();
    init_errors();
    init_initializers();
    init_regularizers();
    init_generic_utils();
    init_math_utils();
    init_types_utils();
    BatchNormalization = class extends Layer {
      constructor(args) {
        if (args == null) {
          args = {};
        }
        super(args);
        this.supportsMasking = true;
        this.axis = args.axis == null ? -1 : args.axis;
        this.momentum = args.momentum == null ? 0.99 : args.momentum;
        this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;
        this.center = args.center == null ? true : args.center;
        this.scale = args.scale == null ? true : args.scale;
        this.betaInitializer = getInitializer(args.betaInitializer || "zeros");
        this.gammaInitializer = getInitializer(args.gammaInitializer || "ones");
        this.movingMeanInitializer = getInitializer(args.movingMeanInitializer || "zeros");
        this.movingVarianceInitializer = getInitializer(args.movingVarianceInitializer || "ones");
        this.betaConstraint = getConstraint(args.betaConstraint);
        this.gammaConstraint = getConstraint(args.gammaConstraint);
        this.betaRegularizer = getRegularizer(args.betaRegularizer);
        this.gammaRegularizer = getRegularizer(args.gammaRegularizer);
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const axis = this.axis >= 0 ? this.axis : this.axis + inputShape.length;
        const dim = inputShape[axis];
        if (dim == null) {
          throw new ValueError(`Axis ${axis} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(inputShape)}.`);
        }
        this.inputSpec = [new InputSpec({ ndim: inputShape.length, axes: { [axis]: dim } })];
        const shape = [dim];
        if (this.scale) {
          this.gamma = this.addWeight("gamma", shape, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint);
        }
        if (this.center) {
          this.beta = this.addWeight("beta", shape, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint);
        }
        this.movingMean = this.addWeight("moving_mean", shape, null, this.movingMeanInitializer, null, false);
        this.movingVariance = this.addWeight("moving_variance", shape, null, this.movingVarianceInitializer, null, false);
        this.built = true;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const training = kwargs["training"] == null ? false : kwargs["training"];
          const input2 = getExactlyOneTensor(inputs);
          const inputShape = input2.shape;
          const ndim = inputShape.length;
          const reductionAxes = range2(0, ndim);
          const axis = this.axis >= 0 ? this.axis : this.axis + ndim;
          reductionAxes.splice(axis, 1);
          const broadcastShape = pyListRepeat(1, ndim);
          broadcastShape[axis] = inputShape[axis];
          const sortedReductionAxes = reductionAxes.slice();
          sortedReductionAxes.sort();
          const needsBroadcasting = !util_exports.arraysEqual(sortedReductionAxes, range2(0, ndim).slice(0, ndim - 1));
          const normalizeInference = () => {
            if (needsBroadcasting) {
              const broadcastMovingMean = reshape(this.movingMean.read(), broadcastShape);
              const broadcastMovingVariance = reshape(this.movingVariance.read(), broadcastShape);
              const broadcastBeta = this.center ? reshape(this.beta.read(), broadcastShape) : null;
              const broadcastGamma = this.scale ? reshape(this.gamma.read(), broadcastShape) : null;
              return batchNormalization(input2, broadcastMovingMean, broadcastMovingVariance, broadcastBeta, broadcastGamma, this.epsilon);
            } else {
              return batchNormalization(input2, this.movingMean.read(), this.movingVariance.read(), this.beta == null ? null : this.beta.read(), this.gamma == null ? null : this.gamma.read(), this.epsilon);
            }
          };
          if (!training) {
            return normalizeInference();
          }
          const [normedTraining, mean3, variance] = normalizeBatchInTraining(input2, this.gamma.read(), this.beta.read(), reductionAxes, this.epsilon);
          const doMovingAverage = (variable2, value, momentum) => {
            tidy(() => {
              const decay = 1 - momentum;
              const origValue = variable2.read();
              const updateDelta = mul5(sub3(origValue, value), decay);
              variable2.write(sub3(origValue, updateDelta));
            });
          };
          const updateMovingMeanAndVariance = () => {
            doMovingAverage(this.movingMean, mean3, this.momentum);
            doMovingAverage(this.movingVariance, variance, this.momentum);
          };
          updateMovingMeanAndVariance();
          return normedTraining;
        });
      }
      getConfig() {
        const config = {
          axis: this.axis,
          momentum: this.momentum,
          epsilon: this.epsilon,
          center: this.center,
          scale: this.scale,
          betaInitializer: serializeInitializer(this.betaInitializer),
          gammaInitializer: serializeInitializer(this.gammaInitializer),
          movingMeanInitializer: serializeInitializer(this.movingMeanInitializer),
          movingVarianceInitializer: serializeInitializer(this.movingVarianceInitializer),
          betaRegularizer: serializeRegularizer(this.betaRegularizer),
          gammaRegularizer: serializeRegularizer(this.gammaRegularizer),
          betaConstraint: serializeConstraint(this.betaConstraint),
          gammaConstraint: serializeConstraint(this.gammaConstraint)
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    BatchNormalization.className = "BatchNormalization";
    serialization_exports.registerClass(BatchNormalization);
    LayerNormalization = class extends Layer {
      constructor(args) {
        if (args == null) {
          args = {};
        }
        super(args);
        this.axis = args.axis == null ? -1 : args.axis;
        if (typeof this.axis === "number") {
          if (!Number.isInteger(this.axis)) {
            throw new Error(`Expected axis to be an integer, but received ${this.axis}`);
          }
        } else if (Array.isArray(this.axis)) {
          for (const axis of this.axis) {
            if (!Number.isInteger(axis)) {
              throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`);
            }
          }
        } else {
          throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
        }
        this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;
        this.center = args.center == null ? true : args.center;
        this.scale = args.scale == null ? true : args.scale;
        this.betaInitializer = getInitializer(args.betaInitializer || "zeros");
        this.gammaInitializer = getInitializer(args.gammaInitializer || "ones");
        this.betaRegularizer = getRegularizer(args.betaRegularizer);
        this.gammaRegularizer = getRegularizer(args.gammaRegularizer);
        this.supportsMasking = true;
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const nDims = inputShape.length;
        if (typeof this.axis === "number") {
          this.axis = [this.axis];
        }
        for (let i = 0; i < this.axis.length; ++i) {
          if (this.axis[i] < 0) {
            this.axis[i] += nDims;
          }
        }
        for (const axis of this.axis) {
          if (axis < 0 || axis >= nDims) {
            throw new Error(`Invalid axis: ${axis}`);
          }
        }
        if (this.axis.length !== unique2(this.axis).length) {
          throw new Error(`Found duplicate axes in: ${this.axis}`);
        }
        const paramShape = this.axis.map((axis) => inputShape[axis]);
        const trainable = true;
        if (this.scale) {
          this.gamma = this.addWeight("gamma", paramShape, "float32", this.gammaInitializer, this.gammaRegularizer, trainable);
        } else {
          this.gamma = null;
        }
        if (this.center) {
          this.beta = this.addWeight("beta", paramShape, "float32", this.betaInitializer, this.betaRegularizer, trainable);
        } else {
          this.beta = null;
        }
        this.built = true;
      }
      call(inputs, kwargs) {
        const input2 = getExactlyOneTensor(inputs);
        const inputShape = input2.shape;
        const nDims = inputShape.length;
        return tidy(() => {
          const keepDims = true;
          let { mean: mean3, variance } = moments(input2, this.axis, keepDims);
          const broadcastShape = pyListRepeat(1, nDims);
          for (const dim of this.axis) {
            broadcastShape[dim] = inputShape[dim];
          }
          const broadcast = (v) => {
            if (v != null && v.shape.length !== nDims) {
              return reshape(v, broadcastShape);
            } else {
              return v;
            }
          };
          let scale22 = this.scale ? broadcast(this.gamma.read()) : null;
          let offset = this.center ? broadcast(this.beta.read()) : null;
          const momentsTiling = [];
          const scaleOffsetTiling = [];
          for (let i = 0; i < nDims; ++i) {
            if (this.axis.indexOf(i) !== -1) {
              momentsTiling.push(inputShape[i]);
              scaleOffsetTiling.push(1);
            } else {
              momentsTiling.push(1);
              scaleOffsetTiling.push(inputShape[i]);
            }
          }
          mean3 = tile(mean3, momentsTiling);
          variance = tile(variance, momentsTiling);
          if (scale22 != null) {
            scale22 = tile(scale22, scaleOffsetTiling);
          }
          if (offset != null) {
            offset = tile(offset, scaleOffsetTiling);
          }
          return batchNormalization(input2, mean3, variance, offset, scale22, this.epsilon);
        });
      }
      getConfig() {
        const config = {
          axis: this.axis,
          epsilon: this.epsilon,
          center: this.center,
          scale: this.scale,
          betaInitializer: serializeInitializer(this.betaInitializer),
          gammaInitializer: serializeInitializer(this.gammaInitializer),
          betaRegularizer: serializeRegularizer(this.betaRegularizer),
          gammaRegularizer: serializeRegularizer(this.gammaRegularizer)
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    LayerNormalization.className = "LayerNormalization";
    serialization_exports.registerClass(LayerNormalization);
  }
});
function spatial2dPadding(x, padding, dataFormat) {
  return tidy(() => {
    if (x.rank !== 4) {
      throw new ValueError(`temporalPadding expects input tensor to be 4-D, but received a ${x.rank}-D tensor.`);
    }
    if (padding == null) {
      padding = [[1, 1], [1, 1]];
    }
    if (padding.length !== 2 || padding[0].length !== 2 || padding[1].length !== 2) {
      throw new ValueError("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    }
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    if (dataFormat !== "channelsLast" && dataFormat !== "channelsFirst") {
      throw new ValueError(`Unknown data format: ${dataFormat}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
    }
    let pattern;
    if (dataFormat === "channelsFirst") {
      pattern = [[0, 0], [0, 0], padding[0], padding[1]];
    } else {
      pattern = [[0, 0], padding[0], padding[1], [0, 0]];
    }
    return pad(x, pattern);
  });
}
var ZeroPadding2D;
var init_padding = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/padding.js"() {
    init_dist();
    init_dist();
    init_common3();
    init_topology();
    init_errors();
    init_types_utils();
    ZeroPadding2D = class extends Layer {
      constructor(args) {
        if (args == null) {
          args = {};
        }
        super(args);
        this.dataFormat = args.dataFormat == null ? imageDataFormat() : args.dataFormat;
        if (args.padding == null) {
          this.padding = [[1, 1], [1, 1]];
        } else if (typeof args.padding === "number") {
          this.padding = [[args.padding, args.padding], [args.padding, args.padding]];
        } else {
          args.padding = args.padding;
          if (args.padding.length !== 2) {
            throw new ValueError(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${args.padding.length} array.`);
          }
          let heightPadding;
          let widthPadding;
          if (typeof args.padding[0] === "number") {
            heightPadding = [args.padding[0], args.padding[0]];
            widthPadding = [args.padding[1], args.padding[1]];
          } else {
            args.padding = args.padding;
            if (args.padding[0].length !== 2) {
              throw new ValueError(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${args.padding[0].length} array.`);
            }
            heightPadding = args.padding[0];
            if (args.padding[1].length !== 2) {
              throw new ValueError(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${args.padding[1].length} array.`);
            }
            widthPadding = args.padding[1];
          }
          this.padding = [heightPadding, widthPadding];
        }
        this.inputSpec = [new InputSpec({ ndim: 4 })];
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        let rows;
        let cols;
        if (this.dataFormat === "channelsFirst") {
          if (inputShape[2] != null && inputShape[2] >= 0) {
            rows = inputShape[2] + this.padding[0][0] + this.padding[0][1];
          } else {
            rows = null;
          }
          if (inputShape[3] != null && inputShape[3] >= 0) {
            cols = inputShape[3] + this.padding[1][0] + this.padding[1][1];
          } else {
            cols = null;
          }
          return [inputShape[0], inputShape[1], rows, cols];
        } else {
          if (inputShape[1] != null && inputShape[1] >= 0) {
            rows = inputShape[1] + this.padding[0][0] + this.padding[0][1];
          } else {
            rows = null;
          }
          if (inputShape[2] != null && inputShape[2] >= 0) {
            cols = inputShape[2] + this.padding[1][0] + this.padding[1][1];
          } else {
            cols = null;
          }
          return [inputShape[0], rows, cols, inputShape[3]];
        }
      }
      call(inputs, kwargs) {
        return tidy(() => spatial2dPadding(getExactlyOneTensor(inputs), this.padding, this.dataFormat));
      }
      getConfig() {
        const config = {
          padding: this.padding,
          dataFormat: this.dataFormat
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    ZeroPadding2D.className = "ZeroPadding2D";
    serialization_exports.registerClass(ZeroPadding2D);
  }
});
function pool2d(x, poolSize, strides, padding, dataFormat, poolMode) {
  return tidy(() => {
    checkDataFormat(dataFormat);
    checkPoolMode(poolMode);
    checkPaddingMode(padding);
    if (strides == null) {
      strides = [1, 1];
    }
    if (padding == null) {
      padding = "valid";
    }
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    if (poolMode == null) {
      poolMode = "max";
    }
    x = preprocessConv2DInput(x, dataFormat);
    let y;
    const paddingString = padding === "same" ? "same" : "valid";
    if (poolMode === "max") {
      y = maxPool(x, poolSize, strides, paddingString);
    } else {
      y = avgPool(
        // TODO(cais): Rank check?
        x,
        poolSize,
        strides,
        paddingString
      );
    }
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 3, 1, 2]);
    }
    return y;
  });
}
function pool3d(x, poolSize, strides, padding, dataFormat, poolMode) {
  return tidy(() => {
    checkDataFormat(dataFormat);
    checkPoolMode(poolMode);
    checkPaddingMode(padding);
    if (strides == null) {
      strides = [1, 1, 1];
    }
    if (padding == null) {
      padding = "valid";
    }
    if (dataFormat == null) {
      dataFormat = imageDataFormat();
    }
    if (poolMode == null) {
      poolMode = "max";
    }
    x = preprocessConv3DInput(x, dataFormat);
    let y;
    const paddingString = padding === "same" ? "same" : "valid";
    if (poolMode === "max") {
      y = maxPool3d(x, poolSize, strides, paddingString);
    } else {
      y = avgPool3d(x, poolSize, strides, paddingString);
    }
    if (dataFormat === "channelsFirst") {
      y = transpose2(y, [0, 4, 1, 2, 3]);
    }
    return y;
  });
}
var Pooling1D;
var MaxPooling1D;
var AveragePooling1D;
var Pooling2D;
var MaxPooling2D;
var AveragePooling2D;
var Pooling3D;
var MaxPooling3D;
var AveragePooling3D;
var GlobalPooling1D;
var GlobalAveragePooling1D;
var GlobalMaxPooling1D;
var GlobalPooling2D;
var GlobalAveragePooling2D;
var GlobalMaxPooling2D;
var init_pooling = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/pooling.js"() {
    init_dist();
    init_dist();
    init_common3();
    init_tfjs_backend();
    init_common2();
    init_topology();
    init_topology();
    init_errors();
    init_conv_utils();
    init_generic_utils();
    init_types_utils();
    init_convolutional();
    Pooling1D = class extends Layer {
      /**
       *
       * @param args Parameters for the Pooling layer.
       *
       * config.poolSize defaults to 2.
       */
      constructor(args) {
        if (args.poolSize == null) {
          args.poolSize = 2;
        }
        super(args);
        if (typeof args.poolSize === "number") {
          this.poolSize = [args.poolSize];
        } else if (Array.isArray(args.poolSize) && args.poolSize.length === 1 && typeof args.poolSize[0] === "number") {
          this.poolSize = args.poolSize;
        } else {
          throw new ValueError(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.poolSize)}`);
        }
        assertPositiveInteger(this.poolSize, "poolSize");
        if (args.strides == null) {
          this.strides = this.poolSize;
        } else {
          if (typeof args.strides === "number") {
            this.strides = [args.strides];
          } else if (Array.isArray(args.strides) && args.strides.length === 1 && typeof args.strides[0] === "number") {
            this.strides = args.strides;
          } else {
            throw new ValueError(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(args.strides)}`);
          }
        }
        assertPositiveInteger(this.strides, "strides");
        this.padding = args.padding == null ? "valid" : args.padding;
        checkPaddingMode(this.padding);
        this.inputSpec = [new InputSpec({ ndim: 3 })];
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const length5 = convOutputLength(inputShape[1], this.poolSize[0], this.padding, this.strides[0]);
        return [inputShape[0], length5, inputShape[2]];
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          inputs = expandDims2(getExactlyOneTensor(inputs), 2);
          const output = this.poolingFunction(getExactlyOneTensor(inputs), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
          return squeeze(output, [2]);
        });
      }
      getConfig() {
        const config = {
          poolSize: this.poolSize,
          padding: this.padding,
          strides: this.strides
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    MaxPooling1D = class extends Pooling1D {
      constructor(args) {
        super(args);
      }
      poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
        checkDataFormat(dataFormat);
        checkPaddingMode(padding);
        return pool2d(inputs, poolSize, strides, padding, dataFormat, "max");
      }
    };
    MaxPooling1D.className = "MaxPooling1D";
    serialization_exports.registerClass(MaxPooling1D);
    AveragePooling1D = class extends Pooling1D {
      constructor(args) {
        super(args);
      }
      poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
        checkDataFormat(dataFormat);
        checkPaddingMode(padding);
        return pool2d(inputs, poolSize, strides, padding, dataFormat, "avg");
      }
    };
    AveragePooling1D.className = "AveragePooling1D";
    serialization_exports.registerClass(AveragePooling1D);
    Pooling2D = class extends Layer {
      constructor(args) {
        if (args.poolSize == null) {
          args.poolSize = [2, 2];
        }
        super(args);
        this.poolSize = Array.isArray(args.poolSize) ? args.poolSize : [args.poolSize, args.poolSize];
        if (args.strides == null) {
          this.strides = this.poolSize;
        } else if (Array.isArray(args.strides)) {
          if (args.strides.length !== 2) {
            throw new ValueError(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${args.strides.length}.`);
          }
          this.strides = args.strides;
        } else {
          this.strides = [args.strides, args.strides];
        }
        assertPositiveInteger(this.poolSize, "poolSize");
        assertPositiveInteger(this.strides, "strides");
        this.padding = args.padding == null ? "valid" : args.padding;
        this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
        checkDataFormat(this.dataFormat);
        checkPaddingMode(this.padding);
        this.inputSpec = [new InputSpec({ ndim: 4 })];
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        let rows = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
        let cols = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
        rows = convOutputLength(rows, this.poolSize[0], this.padding, this.strides[0]);
        cols = convOutputLength(cols, this.poolSize[1], this.padding, this.strides[1]);
        if (this.dataFormat === "channelsFirst") {
          return [inputShape[0], inputShape[1], rows, cols];
        } else {
          return [inputShape[0], rows, cols, inputShape[3]];
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          return this.poolingFunction(getExactlyOneTensor(inputs), this.poolSize, this.strides, this.padding, this.dataFormat);
        });
      }
      getConfig() {
        const config = {
          poolSize: this.poolSize,
          padding: this.padding,
          strides: this.strides,
          dataFormat: this.dataFormat
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    MaxPooling2D = class extends Pooling2D {
      constructor(args) {
        super(args);
      }
      poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
        checkDataFormat(dataFormat);
        checkPaddingMode(padding);
        return pool2d(inputs, poolSize, strides, padding, dataFormat, "max");
      }
    };
    MaxPooling2D.className = "MaxPooling2D";
    serialization_exports.registerClass(MaxPooling2D);
    AveragePooling2D = class extends Pooling2D {
      constructor(args) {
        super(args);
      }
      poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
        checkDataFormat(dataFormat);
        checkPaddingMode(padding);
        return pool2d(inputs, poolSize, strides, padding, dataFormat, "avg");
      }
    };
    AveragePooling2D.className = "AveragePooling2D";
    serialization_exports.registerClass(AveragePooling2D);
    Pooling3D = class extends Layer {
      constructor(args) {
        if (args.poolSize == null) {
          args.poolSize = [2, 2, 2];
        }
        super(args);
        this.poolSize = Array.isArray(args.poolSize) ? args.poolSize : [args.poolSize, args.poolSize, args.poolSize];
        if (args.strides == null) {
          this.strides = this.poolSize;
        } else if (Array.isArray(args.strides)) {
          if (args.strides.length !== 3) {
            throw new ValueError(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${args.strides.length}.`);
          }
          this.strides = args.strides;
        } else {
          this.strides = [args.strides, args.strides, args.strides];
        }
        assertPositiveInteger(this.poolSize, "poolSize");
        assertPositiveInteger(this.strides, "strides");
        this.padding = args.padding == null ? "valid" : args.padding;
        this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
        checkDataFormat(this.dataFormat);
        checkPaddingMode(this.padding);
        this.inputSpec = [new InputSpec({ ndim: 5 })];
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        let depths = this.dataFormat === "channelsFirst" ? inputShape[2] : inputShape[1];
        let rows = this.dataFormat === "channelsFirst" ? inputShape[3] : inputShape[2];
        let cols = this.dataFormat === "channelsFirst" ? inputShape[4] : inputShape[3];
        depths = convOutputLength(depths, this.poolSize[0], this.padding, this.strides[0]);
        rows = convOutputLength(rows, this.poolSize[1], this.padding, this.strides[1]);
        cols = convOutputLength(cols, this.poolSize[2], this.padding, this.strides[2]);
        if (this.dataFormat === "channelsFirst") {
          return [inputShape[0], inputShape[1], depths, rows, cols];
        } else {
          return [inputShape[0], depths, rows, cols, inputShape[4]];
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          this.invokeCallHook(inputs, kwargs);
          return this.poolingFunction(getExactlyOneTensor(inputs), this.poolSize, this.strides, this.padding, this.dataFormat);
        });
      }
      getConfig() {
        const config = {
          poolSize: this.poolSize,
          padding: this.padding,
          strides: this.strides,
          dataFormat: this.dataFormat
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    MaxPooling3D = class extends Pooling3D {
      constructor(args) {
        super(args);
      }
      poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
        checkDataFormat(dataFormat);
        checkPaddingMode(padding);
        return pool3d(inputs, poolSize, strides, padding, dataFormat, "max");
      }
    };
    MaxPooling3D.className = "MaxPooling3D";
    serialization_exports.registerClass(MaxPooling3D);
    AveragePooling3D = class extends Pooling3D {
      constructor(args) {
        super(args);
      }
      poolingFunction(inputs, poolSize, strides, padding, dataFormat) {
        checkDataFormat(dataFormat);
        checkPaddingMode(padding);
        return pool3d(inputs, poolSize, strides, padding, dataFormat, "avg");
      }
    };
    AveragePooling3D.className = "AveragePooling3D";
    serialization_exports.registerClass(AveragePooling3D);
    GlobalPooling1D = class extends Layer {
      constructor(args) {
        super(args);
        this.inputSpec = [new InputSpec({ ndim: 3 })];
      }
      computeOutputShape(inputShape) {
        return [inputShape[0], inputShape[2]];
      }
      call(inputs, kwargs) {
        throw new NotImplementedError();
      }
    };
    GlobalAveragePooling1D = class extends GlobalPooling1D {
      constructor(args) {
        super(args || {});
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const input2 = getExactlyOneTensor(inputs);
          return mean(input2, 1);
        });
      }
    };
    GlobalAveragePooling1D.className = "GlobalAveragePooling1D";
    serialization_exports.registerClass(GlobalAveragePooling1D);
    GlobalMaxPooling1D = class extends GlobalPooling1D {
      constructor(args) {
        super(args || {});
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const input2 = getExactlyOneTensor(inputs);
          return max2(input2, 1);
        });
      }
    };
    GlobalMaxPooling1D.className = "GlobalMaxPooling1D";
    serialization_exports.registerClass(GlobalMaxPooling1D);
    GlobalPooling2D = class extends Layer {
      constructor(args) {
        super(args);
        this.dataFormat = args.dataFormat == null ? "channelsLast" : args.dataFormat;
        checkDataFormat(this.dataFormat);
        this.inputSpec = [new InputSpec({ ndim: 4 })];
      }
      computeOutputShape(inputShape) {
        inputShape = inputShape;
        if (this.dataFormat === "channelsLast") {
          return [inputShape[0], inputShape[3]];
        } else {
          return [inputShape[0], inputShape[1]];
        }
      }
      call(inputs, kwargs) {
        throw new NotImplementedError();
      }
      getConfig() {
        const config = { dataFormat: this.dataFormat };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
    };
    GlobalAveragePooling2D = class extends GlobalPooling2D {
      call(inputs, kwargs) {
        return tidy(() => {
          const input2 = getExactlyOneTensor(inputs);
          if (this.dataFormat === "channelsLast") {
            return mean(input2, [1, 2]);
          } else {
            return mean(input2, [2, 3]);
          }
        });
      }
    };
    GlobalAveragePooling2D.className = "GlobalAveragePooling2D";
    serialization_exports.registerClass(GlobalAveragePooling2D);
    GlobalMaxPooling2D = class extends GlobalPooling2D {
      call(inputs, kwargs) {
        return tidy(() => {
          const input2 = getExactlyOneTensor(inputs);
          if (this.dataFormat === "channelsLast") {
            return max2(input2, [1, 2]);
          } else {
            return max2(input2, [2, 3]);
          }
        });
      }
    };
    GlobalMaxPooling2D.className = "GlobalMaxPooling2D";
    serialization_exports.registerClass(GlobalMaxPooling2D);
  }
});
function checkBidirectionalMergeMode(value) {
  checkStringTypeUnionValue(VALID_BIDIRECTIONAL_MERGE_MODES, "BidirectionalMergeMode", value);
}
var Wrapper;
var TimeDistributed;
var DEFAULT_BIDIRECTIONAL_MERGE_MODE;
var Bidirectional;
var init_wrappers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/wrappers.js"() {
    init_dist();
    init_dist();
    init_tfjs_backend();
    init_common2();
    init_topology();
    init_errors();
    init_common();
    init_generic_utils();
    init_types_utils();
    init_recurrent();
    init_serialization2();
    Wrapper = class extends Layer {
      constructor(args) {
        super(args);
        this.layer = args.layer;
      }
      build(inputShape) {
        this.built = true;
      }
      // TODO(cais): Implement activityRegularizer getter.
      get trainable() {
        if (this.layer != null) {
          return this.layer.trainable;
        } else {
          return false;
        }
      }
      set trainable(value) {
        if (this.layer != null) {
          this.layer.trainable = value;
        }
      }
      get trainableWeights() {
        return this.layer.trainableWeights;
      }
      // TODO(cais): Implement setter for trainableWeights.
      get nonTrainableWeights() {
        return this.layer.nonTrainableWeights;
      }
      // TODO(cais): Implement setter for nonTrainableWeights.
      get updates() {
        return this.layer._updates;
      }
      // TODO(cais): Implement getUpdatesFor().
      get losses() {
        return this.layer.losses;
      }
      // TODO(cais): Implement getLossesFor().
      getWeights() {
        return this.layer.getWeights();
      }
      setWeights(weights) {
        this.layer.setWeights(weights);
      }
      getConfig() {
        const config = {
          "layer": {
            "className": this.layer.getClassName(),
            "config": this.layer.getConfig()
          }
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      setFastWeightInitDuringBuild(value) {
        super.setFastWeightInitDuringBuild(value);
        if (this.layer != null) {
          this.layer.setFastWeightInitDuringBuild(value);
        }
      }
      /** @nocollapse */
      static fromConfig(cls, config, customObjects = {}) {
        const layerConfig = config["layer"];
        const layer = deserialize(layerConfig, customObjects);
        delete config["layer"];
        const newConfig = { layer };
        Object.assign(newConfig, config);
        return new cls(newConfig);
      }
    };
    TimeDistributed = class extends Wrapper {
      constructor(args) {
        super(args);
        this.supportsMasking = true;
      }
      build(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (inputShape.length < 3) {
          throw new ValueError(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(inputShape)}`);
        }
        this.inputSpec = [{ shape: inputShape }];
        const childInputShape = [inputShape[0]].concat(inputShape.slice(2));
        if (!this.layer.built) {
          this.layer.build(childInputShape);
          this.layer.built = true;
        }
        super.build(inputShape);
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const childInputShape = [inputShape[0]].concat(inputShape.slice(2));
        const childOutputShape = this.layer.computeOutputShape(childInputShape);
        const timesteps = inputShape[1];
        return [childOutputShape[0], timesteps].concat(childOutputShape.slice(1));
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          const step4 = (inputs2, states) => {
            const output = getExactlyOneTensor(this.layer.call(inputs2, kwargs));
            return [output, []];
          };
          const rnnOutputs = rnn(
            step4,
            inputs,
            [],
            false,
            null,
            null,
            false,
            true
            /* needPerStepOutputs */
          );
          const y = rnnOutputs[1];
          return y;
        });
      }
    };
    TimeDistributed.className = "TimeDistributed";
    serialization_exports.registerClass(TimeDistributed);
    DEFAULT_BIDIRECTIONAL_MERGE_MODE = "concat";
    Bidirectional = class extends Wrapper {
      constructor(args) {
        super(args);
        const layerConfig = args.layer.getConfig();
        const forwDict = {};
        forwDict["className"] = args.layer.getClassName();
        forwDict["config"] = layerConfig;
        this.forwardLayer = deserialize(forwDict);
        layerConfig["goBackwards"] = layerConfig["goBackwards"] === true ? false : true;
        const backDict = {};
        backDict["className"] = args.layer.getClassName();
        backDict["config"] = layerConfig;
        this.backwardLayer = deserialize(backDict);
        this.forwardLayer.name = "forward_" + this.forwardLayer.name;
        this.backwardLayer.name = "backward_" + this.backwardLayer.name;
        this.mergeMode = args.mergeMode === void 0 ? DEFAULT_BIDIRECTIONAL_MERGE_MODE : args.mergeMode;
        checkBidirectionalMergeMode(this.mergeMode);
        if (args.weights) {
          throw new NotImplementedError("weights support is not implemented for Bidirectional layer yet.");
        }
        this._stateful = args.layer.stateful;
        this.returnSequences = args.layer.returnSequences;
        this.returnState = args.layer.returnState;
        this.supportsMasking = true;
        this._trainable = true;
        this.inputSpec = args.layer.inputSpec;
        this.numConstants = null;
      }
      get trainable() {
        return this._trainable;
      }
      set trainable(value) {
        this._trainable = value;
        if (this.forwardLayer != null) {
          this.forwardLayer.trainable = value;
        }
        if (this.backwardLayer != null) {
          this.backwardLayer.trainable = value;
        }
      }
      getWeights() {
        return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
      }
      setWeights(weights) {
        const numWeights = weights.length;
        const numeightsOver2 = Math.floor(numWeights / 2);
        this.forwardLayer.setWeights(weights.slice(0, numeightsOver2));
        this.backwardLayer.setWeights(weights.slice(numeightsOver2));
      }
      computeOutputShape(inputShape) {
        let layerShapes = this.forwardLayer.computeOutputShape(inputShape);
        if (!(Array.isArray(layerShapes) && Array.isArray(layerShapes[0]))) {
          layerShapes = [layerShapes];
        }
        layerShapes = layerShapes;
        let outputShape;
        let outputShapes;
        let stateShape;
        if (this.returnState) {
          stateShape = layerShapes.slice(1);
          outputShape = layerShapes[0];
        } else {
          outputShape = layerShapes[0];
        }
        outputShape = outputShape;
        if (this.mergeMode === "concat") {
          outputShape[outputShape.length - 1] *= 2;
          outputShapes = [outputShape];
        } else if (this.mergeMode == null) {
          outputShapes = [outputShape, outputShape.slice()];
        } else {
          outputShapes = [outputShape];
        }
        if (this.returnState) {
          if (this.mergeMode == null) {
            return outputShapes.concat(stateShape).concat(stateShape.slice());
          }
          return [outputShape].concat(stateShape).concat(stateShape.slice());
        }
        return singletonOrArray(outputShapes);
      }
      apply(inputs, kwargs) {
        let initialState = kwargs == null ? null : kwargs["initialState"];
        let constants = kwargs == null ? null : kwargs["constants"];
        if (kwargs == null) {
          kwargs = {};
        }
        const standardized = standardizeArgs(inputs, initialState, constants, this.numConstants);
        inputs = standardized.inputs;
        initialState = standardized.initialState;
        constants = standardized.constants;
        if (Array.isArray(inputs)) {
          initialState = inputs.slice(1);
          inputs = inputs[0];
        }
        if ((initialState == null || initialState.length === 0) && constants == null) {
          return super.apply(inputs, kwargs);
        }
        const additionalInputs = [];
        const additionalSpecs = [];
        if (initialState != null) {
          const numStates = initialState.length;
          if (numStates % 2 > 0) {
            throw new ValueError("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
          }
          kwargs["initialState"] = initialState;
          additionalInputs.push(...initialState);
          const stateSpecs = initialState.map((state) => new InputSpec({ shape: state.shape }));
          this.forwardLayer.stateSpec = stateSpecs.slice(0, numStates / 2);
          this.backwardLayer.stateSpec = stateSpecs.slice(numStates / 2);
          additionalSpecs.push(...stateSpecs);
        }
        if (constants != null) {
          throw new NotImplementedError("Support for constants in Bidirectional layers is not implemented yet.");
        }
        const isSymbolicTensor = additionalInputs[0] instanceof SymbolicTensor;
        for (const tensor2 of additionalInputs) {
          if (tensor2 instanceof SymbolicTensor !== isSymbolicTensor) {
            throw new ValueError("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
          }
        }
        if (isSymbolicTensor) {
          const fullInput = [inputs].concat(additionalInputs);
          const fullInputSpec = this.inputSpec.concat(additionalSpecs);
          const originalInputSpec = this.inputSpec;
          this.inputSpec = fullInputSpec;
          const output = super.apply(fullInput, kwargs);
          this.inputSpec = originalInputSpec;
          return output;
        } else {
          return super.apply(inputs, kwargs);
        }
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const initialState = kwargs["initialState"];
          let y;
          let yRev;
          if (initialState == null) {
            y = this.forwardLayer.call(inputs, kwargs);
            yRev = this.backwardLayer.call(inputs, kwargs);
          } else {
            const forwardState = initialState.slice(0, initialState.length / 2);
            const backwardState = initialState.slice(initialState.length / 2);
            y = this.forwardLayer.call(inputs, Object.assign(kwargs, { initialState: forwardState }));
            yRev = this.backwardLayer.call(inputs, Object.assign(kwargs, { initialState: backwardState }));
          }
          let states;
          if (this.returnState) {
            if (Array.isArray(y)) {
              states = y.slice(1).concat(yRev.slice(1));
            } else {
            }
            y = y[0];
            yRev = yRev[0];
          }
          if (this.returnSequences) {
            yRev = reverse(yRev, 1);
          }
          let output;
          if (this.mergeMode === "concat") {
            output = concatenate([y, yRev]);
          } else if (this.mergeMode === "sum") {
            output = add22(y, yRev);
          } else if (this.mergeMode === "ave") {
            output = mul5(0.5, add22(y, yRev));
          } else if (this.mergeMode === "mul") {
            output = mul5(y, yRev);
          } else if (this.mergeMode == null) {
            output = [y, yRev];
          }
          if (this.returnState) {
            if (this.mergeMode == null) {
              return output.concat(states);
            }
            return [output].concat(states);
          }
          return output;
        });
      }
      resetStates(states) {
        this.forwardLayer.resetStates();
        this.backwardLayer.resetStates();
      }
      build(inputShape) {
        nameScope(this.forwardLayer.name, () => {
          this.forwardLayer.build(inputShape);
        });
        nameScope(this.backwardLayer.name, () => {
          this.backwardLayer.build(inputShape);
        });
        this.built = true;
      }
      computeMask(inputs, mask) {
        if (Array.isArray(mask)) {
          mask = mask[0];
        }
        let outputMask;
        if (this.returnSequences) {
          if (this.mergeMode == null) {
            outputMask = [mask, mask];
          } else {
            outputMask = mask;
          }
        } else {
          if (this.mergeMode == null) {
            outputMask = [null, null];
          } else {
            outputMask = null;
          }
        }
        if (this.returnState) {
          const states = this.forwardLayer.states;
          const stateMask = states.map((state) => null);
          if (Array.isArray(outputMask)) {
            return outputMask.concat(stateMask).concat(stateMask);
          } else {
            return [outputMask].concat(stateMask).concat(stateMask);
          }
        } else {
          return outputMask;
        }
      }
      get trainableWeights() {
        return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
      }
      get nonTrainableWeights() {
        return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
      }
      // TODO(cais): Implement constraints().
      setFastWeightInitDuringBuild(value) {
        super.setFastWeightInitDuringBuild(value);
        if (this.forwardLayer != null) {
          this.forwardLayer.setFastWeightInitDuringBuild(value);
        }
        if (this.backwardLayer != null) {
          this.backwardLayer.setFastWeightInitDuringBuild(value);
        }
      }
      getConfig() {
        const config = {
          "mergeMode": this.mergeMode
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      /** @nocollapse */
      static fromConfig(cls, config) {
        const rnnLayer = deserialize(config["layer"]);
        delete config["layer"];
        if (config["numConstants"] != null) {
          throw new NotImplementedError(`Deserialization of a Bidirectional layer with numConstants present is not supported yet.`);
        }
        const newConfig = config;
        newConfig["layer"] = rnnLayer;
        return new cls(newConfig);
      }
    };
    Bidirectional.className = "Bidirectional";
    serialization_exports.registerClass(Bidirectional);
  }
});
var Rescaling;
var init_image_preprocessing = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/image_preprocessing.js"() {
    init_topology();
    init_dist();
    init_types_utils();
    init_tfjs_backend();
    Rescaling = class extends Layer {
      constructor(args) {
        super(args);
        this.scale = args.scale;
        if (args.offset) {
          this.offset = args.offset;
        } else {
          this.offset = 0;
        }
      }
      getConfig() {
        const config = {
          "scale": this.scale,
          "offset": this.offset
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          if (inputs.dtype !== "float32") {
            inputs = cast2(inputs, "float32");
          }
          return add22(mul5(inputs, this.scale), this.offset);
        });
      }
    };
    Rescaling.className = "Rescaling";
    serialization_exports.registerClass(Rescaling);
  }
});
var resizeBilinear2;
var cropAndResize2;
var CenterCrop;
var init_center_crop = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/center_crop.js"() {
    init_dist();
    init_types_utils();
    init_topology();
    init_tfjs_backend();
    ({ resizeBilinear: resizeBilinear2, cropAndResize: cropAndResize2 } = image);
    CenterCrop = class extends Layer {
      constructor(args) {
        super(args);
        this.height = args.height;
        this.width = args.width;
      }
      centerCrop(inputs, hBuffer, wBuffer, height, width, inputHeight, inputWidth, dtype) {
        return tidy(() => {
          let input2;
          let isRank3 = false;
          const top = hBuffer / inputHeight;
          const left = wBuffer / inputWidth;
          const bottom = (height + hBuffer) / inputHeight;
          const right = (width + wBuffer) / inputWidth;
          const bound = [top, left, bottom, right];
          const boxesArr = [];
          if (inputs.rank === 3) {
            isRank3 = true;
            input2 = stack([inputs]);
          } else {
            input2 = inputs;
          }
          for (let i = 0; i < input2.shape[0]; i++) {
            boxesArr.push(bound);
          }
          const boxes = tensor(boxesArr, [boxesArr.length, 4]);
          const boxInd = range(0, boxesArr.length, 1, "int32");
          const cropSize = [height, width];
          const cropped = cropAndResize2(input2, boxes, boxInd, cropSize, "nearest");
          if (isRank3) {
            return cast2(getExactlyOneTensor(unstack(cropped)), dtype);
          }
          return cast2(cropped, dtype);
        });
      }
      upsize(inputs, height, width, dtype) {
        return tidy(() => {
          const outputs = resizeBilinear2(inputs, [height, width]);
          return cast2(outputs, dtype);
        });
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const rankedInputs = getExactlyOneTensor(inputs);
          const dtype = rankedInputs.dtype;
          const inputShape = rankedInputs.shape;
          const inputHeight = inputShape[inputShape.length - 3];
          const inputWidth = inputShape[inputShape.length - 2];
          let hBuffer = 0;
          if (inputHeight !== this.height) {
            hBuffer = Math.floor((inputHeight - this.height) / 2);
          }
          let wBuffer = 0;
          if (inputWidth !== this.width) {
            wBuffer = Math.floor((inputWidth - this.width) / 2);
            if (wBuffer === 0) {
              wBuffer = 1;
            }
          }
          if (hBuffer >= 0 && wBuffer >= 0) {
            return this.centerCrop(rankedInputs, hBuffer, wBuffer, this.height, this.width, inputHeight, inputWidth, dtype);
          } else {
            return this.upsize(inputs, this.height, this.width, dtype);
          }
        });
      }
      getConfig() {
        const config = {
          "height": this.height,
          "width": this.width
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const hAxis = inputShape.length - 3;
        const wAxis = inputShape.length - 2;
        inputShape[hAxis] = this.height;
        inputShape[wAxis] = this.width;
        return inputShape;
      }
    };
    CenterCrop.className = "CenterCrop";
    serialization_exports.registerClass(CenterCrop);
  }
});
function encodeCategoricalInputs(inputs, outputMode, depth, weights) {
  let input2 = getExactlyOneTensor(inputs);
  if (input2.dtype !== "int32") {
    input2 = cast2(input2, "int32");
  }
  if (outputMode === "int") {
    return input2;
  }
  const originalShape = input2.shape;
  if (input2.rank === 0) {
    input2 = expandDims(input2, -1);
  }
  if (outputMode === "oneHot") {
    if (input2.shape[input2.shape.length - 1] !== 1) {
      input2 = expandDims(input2, -1);
    }
  }
  if (input2.rank > 2) {
    throw new ValueError(`When outputMode is not int, maximum output rank is 2 Received outputMode ${outputMode} and input shape ${originalShape} which would result in output rank ${input2.rank}.`);
  }
  const binaryOutput = ["multiHot", "oneHot"].includes(outputMode);
  const denseBincountInput = input2;
  let binCounts;
  if (typeof weights !== "undefined" && outputMode === "count") {
    binCounts = denseBincount(denseBincountInput, weights, depth, binaryOutput);
  } else {
    binCounts = denseBincount(denseBincountInput, [], depth, binaryOutput);
  }
  if (outputMode !== "tfIdf") {
    return binCounts;
  }
  if (weights) {
    return mul5(binCounts, weights);
  } else {
    throw new ValueError(`When outputMode is 'tfIdf', weights must be provided.`);
  }
}
var init_preprocessing_utils = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/preprocessing_utils.js"() {
    init_dist();
    init_types_utils();
    init_dist();
    init_errors();
    init_tfjs_backend();
  }
});
var CategoryEncoding;
var init_category_encoding = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/category_encoding.js"() {
    init_topology();
    init_dist();
    init_dist();
    init_types_utils();
    init_errors();
    init_tfjs_backend();
    init_preprocessing_utils();
    CategoryEncoding = class extends Layer {
      constructor(args) {
        super(args);
        this.numTokens = args.numTokens;
        if (args.outputMode) {
          this.outputMode = args.outputMode;
        } else {
          this.outputMode = "multiHot";
        }
      }
      getConfig() {
        const config = {
          "numTokens": this.numTokens,
          "outputMode": this.outputMode
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        if (inputShape == null) {
          return [this.numTokens];
        }
        if (this.outputMode === "oneHot" && inputShape[inputShape.length - 1] !== 1) {
          inputShape.push(this.numTokens);
          return inputShape;
        }
        inputShape[inputShape.length - 1] = this.numTokens;
        return inputShape;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          inputs = getExactlyOneTensor(inputs);
          if (inputs.dtype !== "int32") {
            inputs = cast2(inputs, "int32");
          }
          let countWeights;
          if (typeof kwargs["countWeights"] !== "undefined") {
            if (this.outputMode !== "count") {
              throw new ValueError(`countWeights is not used when outputMode !== count.
              Received countWeights=${kwargs["countWeights"]}`);
            }
            countWeights = getExactlyOneTensor(kwargs["countWeights"]);
          }
          const maxValue = max2(inputs);
          const minValue = min2(inputs);
          const greaterEqualMax = greater(this.numTokens, maxValue).bufferSync().get(0);
          const greaterMin = greaterEqual(minValue, 0).bufferSync().get(0);
          if (!(greaterEqualMax && greaterMin)) {
            throw new ValueError(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);
          }
          return encodeCategoricalInputs(inputs, this.outputMode, this.numTokens, countWeights);
        });
      }
    };
    CategoryEncoding.className = "CategoryEncoding";
    serialization_exports.registerClass(CategoryEncoding);
  }
});
var INTERPOLATION_KEYS;
var INTERPOLATION_METHODS;
var Resizing;
var init_image_resizing = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/image_resizing.js"() {
    init_dist();
    init_topology();
    init_errors();
    init_types_utils();
    INTERPOLATION_KEYS = ["bilinear", "nearest"];
    INTERPOLATION_METHODS = new Set(INTERPOLATION_KEYS);
    Resizing = class extends Layer {
      constructor(args) {
        super(args);
        this.height = args.height;
        this.width = args.width;
        if (args.interpolation) {
          if (INTERPOLATION_METHODS.has(args.interpolation)) {
            this.interpolation = args.interpolation;
          } else {
            throw new ValueError(`Invalid interpolation parameter: ${args.interpolation} is not implemented`);
          }
        } else {
          this.interpolation = "bilinear";
        }
        this.cropToAspectRatio = Boolean(args.cropToAspectRatio);
      }
      computeOutputShape(inputShape) {
        inputShape = getExactlyOneShape(inputShape);
        const numChannels = inputShape[2];
        return [this.height, this.width, numChannels];
      }
      getConfig() {
        const config = {
          "height": this.height,
          "width": this.width,
          "interpolation": this.interpolation,
          "cropToAspectRatio": this.cropToAspectRatio
        };
        const baseConfig = super.getConfig();
        Object.assign(config, baseConfig);
        return config;
      }
      call(inputs, kwargs) {
        return tidy(() => {
          const size = [this.height, this.width];
          if (this.interpolation === "bilinear") {
            return image.resizeBilinear(inputs, size, !this.cropToAspectRatio);
          } else if (this.interpolation === "nearest") {
            return image.resizeNearestNeighbor(inputs, size, !this.cropToAspectRatio);
          } else {
            throw new Error(`Interpolation is ${this.interpolation} but only ${[...INTERPOLATION_METHODS]} are supported`);
          }
        });
      }
    };
    Resizing.className = "Resizing";
    serialization_exports.registerClass(Resizing);
  }
});
var init_exports_layers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports_layers.js"() {
    init_input_layer();
    init_topology();
    init_exports();
    init_advanced_activations();
    init_convolutional();
    init_convolutional_depthwise();
    init_convolutional_recurrent();
    init_core();
    init_embeddings();
    init_merge();
    init_noise();
    init_normalization();
    init_padding();
    init_pooling();
    init_recurrent();
    init_wrappers();
    init_image_preprocessing();
    init_center_crop();
    init_category_encoding();
    init_image_resizing();
  }
});
var init_exports_metrics = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports_metrics.js"() {
    init_losses();
    init_metrics();
  }
});
var init_exports_models = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports_models.js"() {
    init_models();
  }
});
var init_exports_regularizers = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/exports_regularizers.js"() {
    init_regularizers();
    init_regularizers();
  }
});
var init_callbacks = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/callbacks.js"() {
    init_base_callbacks();
    init_training();
    init_errors();
    init_logs();
  }
});
var init_dist2 = __esm({
  "node_modules/@tensorflow/tfjs-layers/dist/index.js"() {
    init_flags_layers();
    init_dist();
    init_register_all_gradients();
    init_exports_constraints();
    init_exports_initializers();
    init_exports_layers();
    init_exports_metrics();
    init_exports_models();
    init_exports_regularizers();
    init_base_callbacks();
    init_callbacks();
    init_topology();
    init_training();
    init_exports();
    init_recurrent();
    init_models();
    init_variables();
    init_version();
  }
});
var ENV4;
var init_flags2 = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/flags.js"() {
    init_dist();
    ENV4 = env();
    ENV4.registerFlag("KEEP_INTERMEDIATE_TENSORS", () => false, (debugValue) => {
      if (debugValue) {
        console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
      }
    });
  }
});
var DataType;
var SaverDef;
var init_compiled_api = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/data/compiled_api.js"() {
    (function(DataType2) {
      DataType2[DataType2["DT_INVALID"] = 0] = "DT_INVALID";
      DataType2[DataType2["DT_FLOAT"] = 1] = "DT_FLOAT";
      DataType2[DataType2["DT_DOUBLE"] = 2] = "DT_DOUBLE";
      DataType2[DataType2["DT_INT32"] = 3] = "DT_INT32";
      DataType2[DataType2["DT_UINT8"] = 4] = "DT_UINT8";
      DataType2[DataType2["DT_INT16"] = 5] = "DT_INT16";
      DataType2[DataType2["DT_INT8"] = 6] = "DT_INT8";
      DataType2[DataType2["DT_STRING"] = 7] = "DT_STRING";
      DataType2[DataType2["DT_COMPLEX64"] = 8] = "DT_COMPLEX64";
      DataType2[DataType2["DT_INT64"] = 9] = "DT_INT64";
      DataType2[DataType2["DT_BOOL"] = 10] = "DT_BOOL";
      DataType2[DataType2["DT_QINT8"] = 11] = "DT_QINT8";
      DataType2[DataType2["DT_QUINT8"] = 12] = "DT_QUINT8";
      DataType2[DataType2["DT_QINT32"] = 13] = "DT_QINT32";
      DataType2[DataType2["DT_BFLOAT16"] = 14] = "DT_BFLOAT16";
      DataType2[DataType2["DT_QINT16"] = 15] = "DT_QINT16";
      DataType2[DataType2["DT_QUINT16"] = 16] = "DT_QUINT16";
      DataType2[DataType2["DT_UINT16"] = 17] = "DT_UINT16";
      DataType2[DataType2["DT_COMPLEX128"] = 18] = "DT_COMPLEX128";
      DataType2[DataType2["DT_HALF"] = 19] = "DT_HALF";
      DataType2[DataType2["DT_RESOURCE"] = 20] = "DT_RESOURCE";
      DataType2[DataType2["DT_VARIANT"] = 21] = "DT_VARIANT";
      DataType2[DataType2["DT_UINT32"] = 22] = "DT_UINT32";
      DataType2[DataType2["DT_UINT64"] = 23] = "DT_UINT64";
      DataType2[DataType2["DT_FLOAT_REF"] = 101] = "DT_FLOAT_REF";
      DataType2[DataType2["DT_DOUBLE_REF"] = 102] = "DT_DOUBLE_REF";
      DataType2[DataType2["DT_INT32_REF"] = 103] = "DT_INT32_REF";
      DataType2[DataType2["DT_UINT8_REF"] = 104] = "DT_UINT8_REF";
      DataType2[DataType2["DT_INT16_REF"] = 105] = "DT_INT16_REF";
      DataType2[DataType2["DT_INT8_REF"] = 106] = "DT_INT8_REF";
      DataType2[DataType2["DT_STRING_REF"] = 107] = "DT_STRING_REF";
      DataType2[DataType2["DT_COMPLEX64_REF"] = 108] = "DT_COMPLEX64_REF";
      DataType2[DataType2["DT_INT64_REF"] = 109] = "DT_INT64_REF";
      DataType2[DataType2["DT_BOOL_REF"] = 110] = "DT_BOOL_REF";
      DataType2[DataType2["DT_QINT8_REF"] = 111] = "DT_QINT8_REF";
      DataType2[DataType2["DT_QUINT8_REF"] = 112] = "DT_QUINT8_REF";
      DataType2[DataType2["DT_QINT32_REF"] = 113] = "DT_QINT32_REF";
      DataType2[DataType2["DT_BFLOAT16_REF"] = 114] = "DT_BFLOAT16_REF";
      DataType2[DataType2["DT_QINT16_REF"] = 115] = "DT_QINT16_REF";
      DataType2[DataType2["DT_QUINT16_REF"] = 116] = "DT_QUINT16_REF";
      DataType2[DataType2["DT_UINT16_REF"] = 117] = "DT_UINT16_REF";
      DataType2[DataType2["DT_COMPLEX128_REF"] = 118] = "DT_COMPLEX128_REF";
      DataType2[DataType2["DT_HALF_REF"] = 119] = "DT_HALF_REF";
      DataType2[DataType2["DT_RESOURCE_REF"] = 120] = "DT_RESOURCE_REF";
      DataType2[DataType2["DT_VARIANT_REF"] = 121] = "DT_VARIANT_REF";
      DataType2[DataType2["DT_UINT32_REF"] = 122] = "DT_UINT32_REF";
      DataType2[DataType2["DT_UINT64_REF"] = 123] = "DT_UINT64_REF";
    })(DataType || (DataType = {}));
    (function(SaverDef2) {
      let CheckpointFormatVersion;
      (function(CheckpointFormatVersion2) {
        CheckpointFormatVersion2[CheckpointFormatVersion2["LEGACY"] = 0] = "LEGACY";
        CheckpointFormatVersion2[CheckpointFormatVersion2["V1"] = 1] = "V1";
        CheckpointFormatVersion2[CheckpointFormatVersion2["V2"] = 2] = "V2";
      })(CheckpointFormatVersion = SaverDef2.CheckpointFormatVersion || (SaverDef2.CheckpointFormatVersion = {}));
    })(SaverDef || (SaverDef = {}));
  }
});
var init_register = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/register.js"() {
  }
});
var init_utils = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/utils.js"() {
    init_dist();
  }
});
var init_arithmetic = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js"() {
  }
});
var init_basic_math = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js"() {
  }
});
var init_control = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/control.js"() {
  }
});
var init_convolution = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js"() {
  }
});
var init_creation = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/creation.js"() {
  }
});
var init_dynamic = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js"() {
  }
});
var init_evaluation = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js"() {
  }
});
var init_graph = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/graph.js"() {
  }
});
var init_hash_table = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js"() {
  }
});
var init_image = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/image.js"() {
  }
});
var init_logical = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/logical.js"() {
  }
});
var init_matrices = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js"() {
  }
});
var init_normalization2 = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js"() {
  }
});
var init_reduction = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js"() {
  }
});
var init_slice_join = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js"() {
  }
});
var init_sparse = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js"() {
  }
});
var init_spectral = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js"() {
  }
});
var init_string = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/string.js"() {
  }
});
var init_transformation = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js"() {
  }
});
var init_operation_mapper = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/operation_mapper.js"() {
    init_dist();
    init_compiled_api();
    init_register();
    init_utils();
    init_arithmetic();
    init_basic_math();
    init_control();
    init_convolution();
    init_creation();
    init_dynamic();
    init_evaluation();
    init_graph();
    init_hash_table();
    init_image();
    init_logical();
    init_matrices();
    init_normalization2();
    init_reduction();
    init_slice_join();
    init_sparse();
    init_spectral();
    init_string();
    init_transformation();
  }
});
var init_node_value_impl = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js"() {
    init_utils();
    init_operation_mapper();
  }
});
var init_arithmetic_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js"() {
    init_utils();
  }
});
var init_basic_math_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js"() {
    init_utils();
  }
});
var init_tensor_utils = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_utils.js"() {
    init_dist();
  }
});
var init_tensor_array = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js"() {
    init_dist();
    init_tensor_utils();
  }
});
var init_tensor_list = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_list.js"() {
    init_dist();
    init_tensor_utils();
  }
});
var init_control_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js"() {
    init_dist();
    init_tensor_array();
    init_tensor_list();
    init_utils();
  }
});
var init_convolution_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js"() {
    init_utils();
  }
});
var init_creation_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js"() {
    init_utils();
  }
});
var init_dynamic_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js"() {
    init_utils();
  }
});
var init_evaluation_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js"() {
    init_utils();
  }
});
var init_graph_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js"() {
    init_utils();
  }
});
var init_hash_table2 = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/hash_table.js"() {
    init_dist();
  }
});
var init_hash_table_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js"() {
    init_hash_table2();
    init_utils();
  }
});
var init_image_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js"() {
    init_utils();
  }
});
var init_logical_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js"() {
    init_utils();
  }
});
var init_matrices_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js"() {
    init_utils();
  }
});
var init_normalization_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js"() {
    init_utils();
  }
});
var init_ragged_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js"() {
    init_utils();
  }
});
var init_reduction_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js"() {
    init_utils();
  }
});
var init_slice_join_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js"() {
    init_dist();
    init_utils();
  }
});
var init_sparse_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js"() {
    init_utils();
  }
});
var init_spectral_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js"() {
    init_utils();
  }
});
var init_string_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js"() {
    init_utils();
  }
});
var init_transformation_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js"() {
    init_utils();
  }
});
var init_operation_executor = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/operations/operation_executor.js"() {
    init_dist();
    init_node_value_impl();
    init_register();
    init_arithmetic_executor();
    init_basic_math_executor();
    init_control_executor();
    init_convolution_executor();
    init_creation_executor();
    init_dynamic_executor();
    init_evaluation_executor();
    init_graph_executor();
    init_hash_table_executor();
    init_image_executor();
    init_logical_executor();
    init_matrices_executor();
    init_normalization_executor();
    init_ragged_executor();
    init_reduction_executor();
    init_slice_join_executor();
    init_sparse_executor();
    init_spectral_executor();
    init_string_executor();
    init_transformation_executor();
  }
});
var init_execution_context = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/execution_context.js"() {
  }
});
var init_model_analysis = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/model_analysis.js"() {
    init_utils();
  }
});
var init_graph_executor2 = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js"() {
    init_dist();
    init_utils();
    init_operation_executor();
    init_execution_context();
    init_model_analysis();
  }
});
var init_resource_manager = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/resource_manager.js"() {
  }
});
var init_graph_model = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/executor/graph_model.js"() {
    init_dist();
    init_operation_mapper();
    init_graph_executor2();
    init_resource_manager();
  }
});
var init_version2 = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/version.js"() {
  }
});
var init_dist3 = __esm({
  "node_modules/@tensorflow/tfjs-converter/dist/index.js"() {
    init_flags2();
    init_graph_model();
    init_register();
    init_version2();
  }
});
var require_string_decoder = __commonJS({
  "(disabled):node_modules/string_decoder/lib/string_decoder.js"() {
  }
});
function deepMap(input2, mapFn) {
  return deepMapInternal(input2, mapFn);
}
function deepMapInternal(input2, mapFn, seen = /* @__PURE__ */ new Map(), containedIn = /* @__PURE__ */ new Set()) {
  if (input2 == null) {
    return null;
  }
  if (typeof Blob === "function" && input2 instanceof Blob) {
    return input2.slice();
  }
  if (containedIn.has(input2)) {
    throw new Error("Circular references are not supported.");
  }
  if (seen.has(input2)) {
    return seen.get(input2);
  }
  const result = mapFn(input2);
  if (result.recurse && result.value !== null) {
    throw new Error("A deep map function may not return both a value and recurse=true.");
  }
  if (!result.recurse) {
    seen.set(input2, result.value);
    return result.value;
  } else if (isIterable2(input2)) {
    const mappedIterable = Array.isArray(input2) ? [] : {};
    containedIn.add(input2);
    for (const k in input2) {
      const child = input2[k];
      const childResult = deepMapInternal(child, mapFn, seen, containedIn);
      mappedIterable[k] = childResult;
    }
    containedIn.delete(input2);
    if (input2.__proto__) {
      mappedIterable.__proto__ = input2.__proto__;
    }
    return mappedIterable;
  } else {
    throw new Error(`Can't recurse into non-iterable type: ${input2}`);
  }
}
function deepZip(inputs, zipFn = zipToList) {
  return deepZipInternal(inputs, zipFn);
}
function deepZipInternal(inputs, zipFn, containedIn = /* @__PURE__ */ new Set()) {
  const input2 = inputs[0];
  if (containedIn.has(input2)) {
    throw new Error("Circular references are not supported.");
  }
  const result = zipFn(inputs);
  if (result.recurse && result.value !== null) {
    throw new Error("A deep zip function may not return both a value and recurse=true.");
  }
  if (!result.recurse) {
    return result.value;
  } else if (isIterable2(input2)) {
    const mappedIterable = Array.isArray(input2) ? [] : {};
    containedIn.add(input2);
    for (const k in input2) {
      const children = inputs.map((x) => x[k]);
      const childResult = deepZipInternal(children, zipFn, containedIn);
      mappedIterable[k] = childResult;
    }
    containedIn.delete(input2);
    return mappedIterable;
  } else {
    throw new Error(`Can't recurse into non-iterable type: ${input2}`);
  }
}
function zipToList(x) {
  if (x === null) {
    return null;
  }
  if (isIterable2(x[0])) {
    return { value: null, recurse: true };
  } else {
    return { value: x, recurse: false };
  }
}
function isIterable2(obj) {
  let isTextDecoder = false;
  if (env().get("IS_BROWSER")) {
    isTextDecoder = obj instanceof TextDecoder;
  } else {
    const { StringDecoder } = require_string_decoder();
    isTextDecoder = obj instanceof StringDecoder;
  }
  return obj != null && !ArrayBuffer.isView(obj) && (Array.isArray(obj) || typeof obj === "object" && !(obj instanceof Tensor) && !(obj instanceof Promise) && !isTextDecoder);
}
function canTensorify(obj) {
  return obj == null || isPrimitive(obj) || Array.isArray(obj) || typeof obj === "object" && obj instanceof Tensor || util_exports.isTypedArray(obj);
}
function isPrimitive(value) {
  return value === null || typeof value !== "object" && typeof value !== "function";
}
var init_deep_map = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/util/deep_map.js"() {
    init_dist();
  }
});
function deepClone(container) {
  return deepMap(container, cloneIfTensor);
}
function cloneIfTensor(item) {
  if (item instanceof Tensor) {
    return { value: item.clone(), recurse: false };
  } else if (isIterable2(item)) {
    return { value: null, recurse: true };
  } else {
    return { value: item, recurse: false };
  }
}
var init_deep_clone = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/util/deep_clone.js"() {
    init_dist();
    init_deep_map();
  }
});
var RingBuffer;
var init_ring_buffer = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/util/ring_buffer.js"() {
    RingBuffer = class {
      /**
       * Constructs a `RingBuffer`.
       * @param capacity The number of items that the buffer can accomodate.
       */
      constructor(capacity) {
        this.capacity = capacity;
        this.begin = 0;
        this.end = 0;
        if (capacity == null) {
          throw new RangeError("Can't create a ring buffer of unknown capacity.");
        }
        if (capacity < 1) {
          throw new RangeError("Can't create ring buffer of capacity < 1.");
        }
        this.data = new Array(capacity);
        this.doubledCapacity = 2 * capacity;
      }
      /**
       * Map any index into the range 0 <= index < 2*capacity.
       */
      wrap(index) {
        while (index < 0) {
          index += this.doubledCapacity;
        }
        return index % this.doubledCapacity;
      }
      get(index) {
        if (index < 0) {
          throw new RangeError("Can't get item at a negative index.");
        }
        return this.data[index % this.capacity];
      }
      set(index, value) {
        if (index < 0) {
          throw new RangeError("Can't set item at a negative index.");
        }
        this.data[index % this.capacity] = value;
      }
      /**
       * Returns the current number of items in the buffer.
       */
      length() {
        let length5 = this.end - this.begin;
        if (length5 < 0) {
          length5 = this.doubledCapacity + length5;
        }
        return length5;
      }
      /**
       * Reports whether the buffer is full.
       * @returns true if the number of items in the buffer equals its capacity, and
       *   false otherwise.
       */
      isFull() {
        return this.length() === this.capacity;
      }
      /**
       * Reports whether the buffer is empty.
       * @returns true if the number of items in the buffer equals zero, and
       *   false otherwise.
       */
      isEmpty() {
        return this.length() === 0;
      }
      /**
       * Adds an item to the end of the buffer.
       */
      push(value) {
        if (this.isFull()) {
          throw new RangeError("Ring buffer is full.");
        }
        this.set(this.end, value);
        this.end = this.wrap(this.end + 1);
      }
      /**
       * Adds many items to the end of the buffer, in order.
       */
      pushAll(values) {
        for (const value of values) {
          this.push(value);
        }
      }
      /**
       * Removes and returns the last item in the buffer.
       */
      pop() {
        if (this.isEmpty()) {
          throw new RangeError("Ring buffer is empty.");
        }
        this.end = this.wrap(this.end - 1);
        const result = this.get(this.end);
        this.set(this.end, void 0);
        return result;
      }
      /**
       * Adds an item to the beginning of the buffer.
       */
      unshift(value) {
        if (this.isFull()) {
          throw new RangeError("Ring buffer is full.");
        }
        this.begin = this.wrap(this.begin - 1);
        this.set(this.begin, value);
      }
      /**
       * Removes and returns the first item in the buffer.
       */
      shift() {
        if (this.isEmpty()) {
          throw new RangeError("Ring buffer is empty.");
        }
        const result = this.get(this.begin);
        this.set(this.begin, void 0);
        this.begin = this.wrap(this.begin + 1);
        return result;
      }
      /**
       * Removes and returns a specific item in the buffer, and moves the last item
       * to the vacated slot.  This is useful for implementing a shuffling stream.
       * Note that this operation necessarily scrambles the original order.
       *
       * @param relativeIndex: the index of the item to remove, relative to the
       *   first item in the buffer (e.g., hiding the ring nature of the underlying
       *   storage).
       */
      shuffleExcise(relativeIndex) {
        if (this.isEmpty()) {
          throw new RangeError("Ring buffer is empty.");
        }
        const index = this.wrap(this.begin + relativeIndex);
        const result = this.get(index);
        this.set(index, this.pop());
        return result;
      }
    };
  }
});
var GrowingRingBuffer;
var init_growing_ring_buffer = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/util/growing_ring_buffer.js"() {
    init_ring_buffer();
    GrowingRingBuffer = class extends RingBuffer {
      /**
       * Constructs a `GrowingRingBuffer`.
       */
      constructor() {
        super(GrowingRingBuffer.INITIAL_CAPACITY);
      }
      isFull() {
        return false;
      }
      push(value) {
        if (super.isFull()) {
          this.expand();
        }
        super.push(value);
      }
      unshift(value) {
        if (super.isFull()) {
          this.expand();
        }
        super.unshift(value);
      }
      /**
       * Doubles the capacity of the buffer.
       */
      expand() {
        const newCapacity = this.capacity * 2;
        const newData = new Array(newCapacity);
        const len4 = this.length();
        for (let i = 0; i < len4; i++) {
          newData[i] = this.get(this.wrap(this.begin + i));
        }
        this.data = newData;
        this.capacity = newCapacity;
        this.doubledCapacity = 2 * this.capacity;
        this.begin = 0;
        this.end = len4;
      }
    };
    GrowingRingBuffer.INITIAL_CAPACITY = 32;
  }
});
function iteratorFromItems(items) {
  return new ArrayIterator(items);
}
function iteratorFromFunction(func2) {
  return new FunctionCallIterator(func2);
}
function iteratorFromConcatenated(baseIterators, baseErrorHandler) {
  return new ChainedIterator(baseIterators, baseErrorHandler);
}
var seedrandom2;
var LazyIterator;
var ArrayIterator;
var FunctionCallIterator;
var SerialIterator;
var SkipIterator;
var TakeIterator;
var RowMajorBatchIterator;
var FilterIterator;
var MapIterator;
var ErrorHandlingLazyIterator;
var AsyncMapIterator;
var OneToManyIterator;
var FlatmapIterator;
var ChainedIterator;
var ZipMismatchMode;
var PrefetchIterator;
var ShuffleIterator;
var init_lazy_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/lazy_iterator.js"() {
    init_dist();
    seedrandom2 = __toESM(require_seedrandom2());
    init_deep_clone();
    init_deep_map();
    init_growing_ring_buffer();
    init_ring_buffer();
    LazyIterator = class {
      /**
       * Collect all remaining elements of a bounded stream into an array.
       * Obviously this will succeed only for small streams that fit in memory.
       * Useful for testing.
       *
       * @returns A Promise for an array of stream elements, which will resolve
       *   when the stream is exhausted.
       */
      async toArray() {
        const result = [];
        let x = await this.next();
        while (!x.done) {
          result.push(x.value);
          x = await this.next();
        }
        return result;
      }
      /**
       * Collect all elements of this dataset into an array with prefetching 100
       * elements. This is useful for testing, because the prefetch changes the
       * order in which the Promises are resolved along the processing pipeline.
       * This may help expose bugs where results are dependent on the order of
       * Promise resolution rather than on the logical order of the stream (i.e.,
       * due to hidden mutable state).
       *
       * @returns A Promise for an array of stream elements, which will resolve
       *   when the stream is exhausted.
       */
      async toArrayForTest() {
        const stream = this.prefetch(100);
        const result = [];
        let x = await stream.next();
        while (!x.done) {
          result.push(x.value);
          x = await stream.next();
        }
        return result;
      }
      /**
       * Draw items from the stream until it is exhausted.
       *
       * This can be useful when the stream has side effects but no output.  In
       * that case, calling this function guarantees that the stream will be
       * fully processed.
       */
      async resolveFully() {
        let x = await this.next();
        while (!x.done) {
          x = await this.next();
        }
      }
      /**
       * Draw items from the stream until it is exhausted, or a predicate fails.
       *
       * This can be useful when the stream has side effects but no output.  In
       * that case, calling this function guarantees that the stream will be
       * fully processed.
       */
      async resolveWhile(predicate) {
        let x = await this.next();
        let shouldContinue = predicate(x.value);
        while (!x.done && shouldContinue) {
          x = await this.next();
          shouldContinue = predicate(x.value);
        }
      }
      /**
       * Handles errors thrown on this stream using a provided handler function.
       *
       * @param handler A function that handles any `Error` thrown during a `next()`
       *   call and returns true if the stream should continue (dropping the failed
       *   call) or false if the stream should quietly terminate.  If the handler
       *   itself throws (or rethrows) an `Error`, that will be propagated.
       *
       * @returns A `LazyIterator` of elements passed through from upstream,
       *   possibly filtering or terminating on upstream `next()` calls that
       *   throw an `Error`.
       */
      handleErrors(handler) {
        return new ErrorHandlingLazyIterator(this, handler);
      }
      // TODO(soergel): Implement reduce() etc.
      /**
       * Filters this stream according to `predicate`.
       *
       * @param predicate A function mapping a stream element to a boolean or a
       * `Promise` for one.
       *
       * @returns A `LazyIterator` of elements for which the predicate was true.
       */
      filter(predicate) {
        return new FilterIterator(this, predicate);
      }
      /**
       * Maps this stream through a 1-to-1 transform.
       *
       * @param transform A function mapping a stream element to a transformed
       *   element.
       *
       * @returns A `LazyIterator` of transformed elements.
       */
      map(transform4) {
        return new MapIterator(this, transform4);
      }
      /**
       * Maps this stream through an async 1-to-1 transform.
       *
       * @param transform A function mapping a stream element to a `Promise` for a
       *   transformed stream element.
       *
       * @returns A `LazyIterator` of transformed elements.
       */
      mapAsync(transform4) {
        return new AsyncMapIterator(this, transform4);
      }
      /**
       * Maps this stream through a 1-to-1 transform, forcing serial execution.
       *
       * @param transform A function mapping a stream element to a transformed
       *   element.
       *
       * @returns A `LazyIterator` of transformed elements.
       */
      serialMapAsync(transform4) {
        return new AsyncMapIterator(this, transform4).serial();
      }
      /**
       * Maps this stream through a 1-to-many transform.
       *
       * @param transform A function mapping a stream element to an array of
       *   transformed elements.
       *
       * @returns A `DataStream` of transformed elements.
       */
      flatmap(transform4) {
        return new FlatmapIterator(this, transform4);
      }
      /**
       * Apply a function to every element of the stream.
       *
       * @param f A function to apply to each stream element.
       */
      async forEachAsync(f) {
        return this.map(f).resolveFully();
      }
      /**
       * Apply a function to every element of the stream, forcing serial execution.
       *
       * @param f A function to apply to each stream element.  Should return 'true'
       *   to indicate that the stream should continue, or 'false' to cause it to
       *   terminate.
       */
      async serialForEach(f) {
        return this.serialMapAsync(f).resolveWhile((x) => x === true);
      }
      /**
       * Groups elements into batches, represented as arrays of elements.
       *
       * We can think of the elements of this iterator as 'rows' (even if they are
       * nested structures).  By the same token, consecutive values for a given
       * key within the elements form a 'column'.  This matches the usual sense of
       * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
       *
       * Thus, "Row-major" means that the resulting batch is simply a collection of
       * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major
       * form, which is needed for vectorized computation.
       *
       * @param batchSize The number of elements desired per batch.
       * @param smallLastBatch Whether to emit the final batch when it has fewer
       *   than batchSize elements. Default true.
       * @returns A `LazyIterator` of batches of elements, represented as arrays
       *   of the original element type.
       */
      rowMajorBatch(batchSize, smallLastBatch = true) {
        return new RowMajorBatchIterator(this, batchSize, smallLastBatch);
      }
      /**
       * Groups elements into batches, represented in column-major form.
       *
       * We can think of the elements of this iterator as 'rows' (even if they are
       * nested structures).  By the same token, consecutive values for a given
       * key within the elements form a 'column'.  This matches the usual sense of
       * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).
       *
       * Thus, "column-major" means that the resulting batch is a (potentially
       * nested) structure representing the columns.  Each column entry, then,
       * contains a collection of the values found in that column for a range of
       * input elements.  This representation allows for vectorized computation, in
       * contrast to the row-major form.
       *
       * The inputs should all have the same nested structure (i.e., of arrays and
       * dicts).  The result is a single object with the same nested structure,
       * where the leaves are arrays collecting the values of the inputs at that
       * location (or, optionally, the result of a custom function applied to those
       * arrays).
       *
       * @param batchSize The number of elements desired per batch.
       * @param smallLastBatch Whether to emit the final batch when it has fewer
       *   than batchSize elements. Default true.
       * @param zipFn: (optional) A function that expects an array of elements at a
       *   single node of the object tree, and returns a `DeepMapResult`.  The
       *   `DeepMapResult` either provides a result value for that node (i.e.,
       *   representing the subtree), or indicates that the node should be processed
       *   recursively.  The default zipFn recurses as far as possible and places
       *   arrays at the leaves.
       * @returns A `LazyIterator` of batches of elements, represented as an object
       *   with collections at the leaves.
       */
      columnMajorBatch(batchSize, smallLastBatch = true, zipFn = zipToList) {
        const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);
        return rowBatches.map((x) => deepZip(x, zipFn));
      }
      /**
       * Concatenate this `LazyIterator` with another.
       *
       * @param iterator A `LazyIterator` to be concatenated onto this one.
       * @param baseErrorHandler An optional function that can intercept `Error`s
       *   raised during a `next()` call on the base stream.  This function can
       *   decide whether the error should be propagated, whether the error should
       *   be ignored, or whether the base stream should be terminated.
       * @returns A `LazyIterator`.
       */
      concatenate(iterator, baseErrorHandler) {
        return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);
      }
      /**
       * Limits this stream to return at most `count` items.
       *
       * @param count The maximum number of items to provide from the stream. If
       * a negative or undefined value is given, the entire stream is returned
       *   unaltered.
       */
      take(count2) {
        if (count2 < 0 || count2 == null) {
          return this;
        }
        return new TakeIterator(this, count2);
      }
      /**
       * Skips the first `count` items in this stream.
       *
       * @param count The number of items to skip.  If a negative or undefined
       * value is given, the entire stream is returned unaltered.
       */
      skip(count2) {
        if (count2 < 0 || count2 == null) {
          return this;
        }
        return new SkipIterator(this, count2);
      }
      /**
       * Prefetch the first `bufferSize` items in this stream.
       *
       * Note this prefetches Promises, but makes no guarantees about when those
       * Promises resolve.
       *
       * @param bufferSize: An integer specifying the number of elements to be
       *   prefetched.
       */
      prefetch(bufferSize) {
        return new PrefetchIterator(this, bufferSize);
      }
      // TODO(soergel): deep sharded shuffle, where supported
      /**
       * Randomly shuffles the elements of this stream.
       *
       * @param bufferSize: An integer specifying the number of elements from
       * this stream from which the new stream will sample.
       * @param seed: (Optional.) An integer specifying the random seed that
       * will be used to create the distribution.
       */
      shuffle(windowSize, seed) {
        return new ShuffleIterator(this, windowSize, seed);
      }
      /**
       * Force an iterator to execute serially: each next() call will await the
       * prior one, so that they cannot execute concurrently.
       */
      serial() {
        return new SerialIterator(this);
      }
    };
    ArrayIterator = class extends LazyIterator {
      constructor(items) {
        super();
        this.items = items;
        this.trav = 0;
      }
      summary() {
        return `Array of ${this.items.length} items`;
      }
      async next() {
        if (this.trav >= this.items.length) {
          return { value: null, done: true };
        }
        const item = this.items[this.trav];
        this.trav++;
        return { value: deepClone(item), done: false };
      }
    };
    FunctionCallIterator = class extends LazyIterator {
      constructor(nextFn) {
        super();
        this.nextFn = nextFn;
      }
      summary() {
        return `Function call`;
      }
      async next() {
        try {
          return this.nextFn();
        } catch (e) {
          e.message = `Error thrown while iterating through a dataset: ${e.message}`;
          throw e;
        }
      }
    };
    SerialIterator = class extends LazyIterator {
      constructor(upstream) {
        super();
        this.upstream = upstream;
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      summary() {
        return `${this.upstream.summary()} -> Serial`;
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      async serialNext() {
        return this.upstream.next();
      }
    };
    SkipIterator = class extends LazyIterator {
      constructor(upstream, maxCount) {
        super();
        this.upstream = upstream;
        this.maxCount = maxCount;
        this.count = 0;
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      summary() {
        return `${this.upstream.summary()} -> Skip`;
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      async serialNext() {
        while (this.count++ < this.maxCount) {
          const skipped = await this.upstream.next();
          if (skipped.done) {
            return skipped;
          }
          dispose(skipped.value);
        }
        return this.upstream.next();
      }
    };
    TakeIterator = class extends LazyIterator {
      constructor(upstream, maxCount) {
        super();
        this.upstream = upstream;
        this.maxCount = maxCount;
        this.count = 0;
      }
      summary() {
        return `${this.upstream.summary()} -> Take`;
      }
      async next() {
        if (this.count++ >= this.maxCount) {
          return { value: null, done: true };
        }
        return this.upstream.next();
      }
    };
    RowMajorBatchIterator = class extends LazyIterator {
      constructor(upstream, batchSize, enableSmallLastBatch = true) {
        super();
        this.upstream = upstream;
        this.batchSize = batchSize;
        this.enableSmallLastBatch = enableSmallLastBatch;
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      summary() {
        return `${this.upstream.summary()} -> RowMajorBatch`;
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      async serialNext() {
        const batch = [];
        while (batch.length < this.batchSize) {
          const item = await this.upstream.next();
          if (item.done) {
            if (this.enableSmallLastBatch && batch.length > 0) {
              return { value: batch, done: false };
            }
            return { value: null, done: true };
          }
          batch.push(item.value);
        }
        return { value: batch, done: false };
      }
    };
    FilterIterator = class extends LazyIterator {
      constructor(upstream, predicate) {
        super();
        this.upstream = upstream;
        this.predicate = predicate;
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      summary() {
        return `${this.upstream.summary()} -> Filter`;
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      async serialNext() {
        while (true) {
          const item = await this.upstream.next();
          if (item.done || this.predicate(item.value)) {
            return item;
          }
          dispose(item.value);
        }
      }
    };
    MapIterator = class extends LazyIterator {
      constructor(upstream, transform4) {
        super();
        this.upstream = upstream;
        this.transform = transform4;
      }
      summary() {
        return `${this.upstream.summary()} -> Map`;
      }
      async next() {
        const item = await this.upstream.next();
        if (item.done) {
          return { value: null, done: true };
        }
        const inputTensors = tensor_util_exports.getTensorsInContainer(item.value);
        const mapped = this.transform(item.value);
        const outputTensors = tensor_util_exports.getTensorsInContainer(mapped);
        for (const t of inputTensors) {
          if (!tensor_util_exports.isTensorInList(t, outputTensors)) {
            t.dispose();
          }
        }
        return { value: mapped, done: false };
      }
    };
    ErrorHandlingLazyIterator = class extends LazyIterator {
      constructor(upstream, handler) {
        super();
        this.upstream = upstream;
        this.handler = handler;
        this.count = 0;
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      summary() {
        return `${this.upstream.summary()} -> handleErrors`;
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      async serialNext() {
        while (true) {
          try {
            return await this.upstream.next();
          } catch (e) {
            if (!this.handler(e)) {
              return { value: null, done: true };
            }
          }
        }
      }
    };
    AsyncMapIterator = class extends LazyIterator {
      constructor(upstream, transform4) {
        super();
        this.upstream = upstream;
        this.transform = transform4;
      }
      summary() {
        return `${this.upstream.summary()} -> AsyncMap`;
      }
      async next() {
        const item = await this.upstream.next();
        if (item.done) {
          return { value: null, done: true };
        }
        const inputTensors = tensor_util_exports.getTensorsInContainer(item.value);
        const mapped = await this.transform(item.value);
        const outputTensors = tensor_util_exports.getTensorsInContainer(mapped);
        for (const t of inputTensors) {
          if (!tensor_util_exports.isTensorInList(t, outputTensors)) {
            t.dispose();
          }
        }
        return { value: mapped, done: false };
      }
    };
    OneToManyIterator = class extends LazyIterator {
      constructor() {
        super();
        this.outputQueue = new GrowingRingBuffer();
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      async serialNext() {
        while (this.outputQueue.length() === 0) {
          if (!await this.pump()) {
            return { value: null, done: true };
          }
        }
        return { value: this.outputQueue.shift(), done: false };
      }
    };
    FlatmapIterator = class extends OneToManyIterator {
      constructor(upstream, transform4) {
        super();
        this.upstream = upstream;
        this.transform = transform4;
      }
      summary() {
        return `${this.upstream.summary()} -> Flatmap`;
      }
      async pump() {
        const item = await this.upstream.next();
        if (item.done) {
          return false;
        }
        const inputTensors = tensor_util_exports.getTensorsInContainer(item.value);
        const mappedArray = this.transform(item.value);
        const outputTensors = tensor_util_exports.getTensorsInContainer(mappedArray);
        this.outputQueue.pushAll(mappedArray);
        for (const t of inputTensors) {
          if (!tensor_util_exports.isTensorInList(t, outputTensors)) {
            t.dispose();
          }
        }
        return true;
      }
    };
    ChainedIterator = class extends LazyIterator {
      constructor(iterators, baseErrorHandler) {
        super();
        this.baseErrorHandler = baseErrorHandler;
        this.lastRead = null;
        this.iterator = null;
        this.moreIterators = iterators;
      }
      summary() {
        const upstreamSummaries = "TODO: fill in upstream of chained summaries";
        return `${upstreamSummaries} -> Chained`;
      }
      async next() {
        this.lastRead = this.readFromChain(this.lastRead);
        return this.lastRead;
      }
      async readFromChain(lastRead) {
        await lastRead;
        if (this.iterator == null) {
          const iteratorResult = await this.moreIterators.next();
          if (iteratorResult.done) {
            return { value: null, done: true };
          }
          this.iterator = iteratorResult.value;
          if (this.baseErrorHandler != null) {
            this.iterator = this.iterator.handleErrors(this.baseErrorHandler);
          }
        }
        const itemResult = await this.iterator.next();
        if (itemResult.done) {
          this.iterator = null;
          return this.readFromChain(lastRead);
        }
        return itemResult;
      }
    };
    (function(ZipMismatchMode2) {
      ZipMismatchMode2[ZipMismatchMode2["FAIL"] = 0] = "FAIL";
      ZipMismatchMode2[ZipMismatchMode2["SHORTEST"] = 1] = "SHORTEST";
      ZipMismatchMode2[ZipMismatchMode2["LONGEST"] = 2] = "LONGEST";
    })(ZipMismatchMode || (ZipMismatchMode = {}));
    PrefetchIterator = class extends LazyIterator {
      constructor(upstream, bufferSize) {
        super();
        this.upstream = upstream;
        this.bufferSize = bufferSize;
        this.buffer = new RingBuffer(bufferSize);
      }
      summary() {
        return `${this.upstream.summary()} -> Prefetch`;
      }
      /**
       * Refill the prefetch buffer.  Returns only after the buffer is full, or
       * the upstream source is exhausted.
       */
      refill() {
        while (!this.buffer.isFull()) {
          const v = this.upstream.next();
          this.buffer.push(v);
        }
      }
      next() {
        this.refill();
        return this.buffer.shift();
      }
    };
    ShuffleIterator = class extends PrefetchIterator {
      constructor(upstream, windowSize, seed) {
        super(upstream, windowSize);
        this.upstream = upstream;
        this.windowSize = windowSize;
        this.upstreamExhausted = false;
        this.random = seedrandom2.alea(seed || util_exports.now().toString());
        this.lastRead = Promise.resolve({ value: null, done: false });
      }
      async next() {
        this.lastRead = this.lastRead.then(() => this.serialNext());
        return this.lastRead;
      }
      randomInt(max5) {
        return Math.floor(this.random() * max5);
      }
      chooseIndex() {
        return this.randomInt(this.buffer.length());
      }
      async serialNext() {
        if (!this.upstreamExhausted) {
          this.refill();
        }
        while (!this.buffer.isEmpty()) {
          const chosenIndex = this.chooseIndex();
          const result = await this.buffer.shuffleExcise(chosenIndex);
          if (result.done) {
            this.upstreamExhausted = true;
          } else {
            this.refill();
            return result;
          }
        }
        return { value: null, done: true };
      }
    };
  }
});
function datasetFromIteratorFn(iteratorFn, size = null) {
  return new class extends Dataset {
    constructor() {
      super(...arguments);
      this.size = size;
    }
    /*
     * Provide a new stream of elements.  Note this will also start new streams
     * from any underlying `Dataset`s.
     */
    async iterator() {
      return iteratorFn();
    }
  }();
}
function deepBatchConcat(rows) {
  if (rows === null) {
    return null;
  }
  const exampleRow = rows[0];
  if (canTensorify(exampleRow)) {
    const value = batchConcat(rows);
    return { value, recurse: false };
  }
  return { value: null, recurse: true };
}
function batchConcat(arrays) {
  if (arrays.length === 0) {
    throw new Error("Can't make a batch of zero elements.");
  }
  if (arrays[0] instanceof Tensor) {
    return stack(arrays);
  } else {
    return tensor(arrays);
  }
}
var seedrandom3;
var Dataset;
var init_dataset = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/dataset.js"() {
    init_dist();
    seedrandom3 = __toESM(require_seedrandom2());
    init_lazy_iterator();
    init_deep_map();
    Dataset = class {
      constructor() {
        this.size = null;
      }
      // TODO(soergel): Make Datasets report whether repeated iterator() calls
      // produce the same result (e.g., reading from a file) or different results
      // (e.g., from the webcam).  Currently we don't make this distinction but it
      // could be important for the user to know.
      // abstract isDeterministic(): boolean;
      /**
       * Groups elements into batches.
       *
       * It is assumed that each of the incoming dataset elements has the same
       * structure -- i.e. the same set of keys at each location in an object
       * hierarchy.  For each key, the resulting `Dataset` provides a batched
       * element collecting all of the incoming values for that key.
       *
       *  * Incoming primitives are grouped into a 1-D Tensor.
       *  * Incoming Tensors are grouped into a new Tensor where the 0th axis is
       *    the batch dimension.
       *  * Incoming arrays are converted to Tensor and then batched.
       *  * A nested array is interpreted as an n-D Tensor, so the batched result
       *    has n+1 dimensions.
       *  * An array that cannot be converted to Tensor produces an error.
       *
       * If an array should not be batched as a unit, it should first be converted
       * to an object with integer keys.
       *
       * Here are a few examples:
       *
       * Batch a dataset of numbers:
       * ```js
       * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8]).batch(4);
       * await a.forEachAsync(e => e.print());
       * ```
       *
       * Batch a dataset of arrays:
       * ```js
       * const b = tf.data.array([[1], [2], [3], [4], [5], [6], [7], [8]]).batch(4);
       * await b.forEachAsync(e => e.print());
       * ```
       *
       * Batch a dataset of objects:
       * ```js
       * const c = tf.data.array([{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13},
       *   {a: 4, b: 14}, {a: 5, b: 15}, {a: 6, b: 16}, {a: 7, b: 17},
       *   {a: 8, b: 18}]).batch(4);
       * await c.forEachAsync(e => {
       *   console.log('{');
       *   for(var key in e) {
       *     console.log(key+':');
       *     e[key].print();
       *   }
       *   console.log('}');
       * })
       * ```
       *
       * @param batchSize The number of elements desired per batch.
       * @param smallLastBatch Whether to emit the final batch when it has fewer
       *   than batchSize elements. Default true.
       * @returns A `Dataset`, from which a stream of batches can be obtained.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      batch(batchSize, smallLastBatch = true) {
        const base = this;
        util_exports.assert(batchSize > 0, () => `batchSize needs to be positive, but it is
      ${batchSize}`);
        let size;
        if (this.size === Infinity || this.size == null) {
          size = this.size;
        } else if (smallLastBatch) {
          size = Math.ceil(this.size / batchSize);
        } else {
          size = Math.floor(this.size / batchSize);
        }
        return datasetFromIteratorFn(async () => {
          return (await base.iterator()).columnMajorBatch(batchSize, smallLastBatch, deepBatchConcat);
        }, size);
      }
      /**
       * Concatenates this `Dataset` with another.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3]);
       * const b = tf.data.array([4, 5, 6]);
       * const c = a.concatenate(b);
       * await c.forEachAsync(e => console.log(e));
       * ```
       *
       * @param dataset A `Dataset` to be concatenated onto this one.
       * @returns A `Dataset`.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      concatenate(dataset) {
        const base = this;
        let size;
        if (this.size === Infinity || dataset.size === Infinity) {
          size = Infinity;
        } else if (this.size != null && dataset.size != null) {
          size = this.size + dataset.size;
        } else {
          size = null;
        }
        return datasetFromIteratorFn(async () => (await base.iterator()).concatenate(await dataset.iterator()), size);
      }
      /**
       * Filters this dataset according to `predicate`.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
       *   .filter(x => x%2 === 0);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param predicate A function mapping a dataset element to a boolean or a
       * `Promise` for one.
       *
       * @returns A `Dataset` of elements for which the predicate was true.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      filter(predicate) {
        const base = this;
        let size;
        if (this.size === Infinity) {
          size = Infinity;
        } else {
          size = null;
        }
        return datasetFromIteratorFn(async () => {
          return (await base.iterator()).filter((x) => tidy(() => predicate(x)));
        }, size);
      }
      /**
       * Apply a function to every element of the dataset.
       *
       * After the function is applied to a dataset element, any Tensors contained
       * within that element are disposed.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3]);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param f A function to apply to each dataset element.
       * @returns A `Promise` that resolves after all elements have been processed.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      async forEachAsync(f) {
        return (await this.iterator()).forEachAsync(f);
      }
      /**
       * Maps this dataset through a 1-to-1 transform.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3]).map(x => x*x);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param transform A function mapping a dataset element to a transformed
       *   dataset element.
       *
       * @returns A `Dataset` of transformed elements.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      map(transform4) {
        const base = this;
        return datasetFromIteratorFn(async () => {
          return (await base.iterator()).map((x) => tidy(() => transform4(x)));
        }, this.size);
      }
      /**
       * Maps this dataset through an async 1-to-1 transform.
       *
       * ```js
       * const a =
       *  tf.data.array([1, 2, 3]).mapAsync(x => new Promise(function(resolve){
       *    setTimeout(() => {
       *      resolve(x * x);
       *    }, Math.random()*1000 + 500);
       *  }));
       * console.log(await a.toArray());
       * ```
       *
       * @param transform A function mapping a dataset element to a `Promise` for a
       *   transformed dataset element.  This transform is responsible for disposing
       *   any intermediate `Tensor`s, i.e. by wrapping its computation in
       *   `tf.tidy()`; that cannot be automated here (as it is in the synchronous
       *   `map()` case).
       *
       * @returns A `Dataset` of transformed elements.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      mapAsync(transform4) {
        const base = this;
        return datasetFromIteratorFn(async () => {
          return (await base.iterator()).mapAsync(transform4);
        }, this.size);
      }
      /**
       *  Creates a `Dataset` that prefetches elements from this dataset.
       *
       * @param bufferSize: An integer specifying the number of elements to be
       *   prefetched.
       * @returns A `Dataset`.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      prefetch(bufferSize) {
        if (bufferSize == null) {
          throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
        }
        const base = this;
        return datasetFromIteratorFn(async () => (await base.iterator()).prefetch(bufferSize), this.size);
      }
      /**
       * Repeats this dataset `count` times.
       *
       * NOTE: If this dataset is a function of global state (e.g. a random number
       * generator), then different repetitions may produce different elements.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3]).repeat(3);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param count: (Optional) An integer, representing the number of times
       *   the dataset should be repeated. The default behavior (if `count` is
       *   `undefined` or negative) is for the dataset be repeated indefinitely.
       * @returns A `Dataset`.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      repeat(count2) {
        const base = this;
        let size;
        if (this.size != null && count2 > 0) {
          size = this.size * count2;
        } else if (count2 === 0) {
          size = 0;
        } else if (this.size != null && (count2 === void 0 || count2 < 0)) {
          size = Infinity;
        } else {
          size = null;
        }
        return datasetFromIteratorFn(async () => {
          const iteratorIterator = iteratorFromFunction(async () => ({ value: await base.iterator(), done: false }));
          return iteratorFromConcatenated(iteratorIterator.take(count2));
        }, size);
      }
      /**
       * Creates a `Dataset` that skips `count` initial elements from this dataset.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3, 4, 5, 6]).skip(3);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param count: The number of elements of this dataset that should be skipped
       *   to form the new dataset.  If `count` is greater than the size of this
       *   dataset, the new dataset will contain no elements.  If `count`
       *   is `undefined` or negative, skips the entire dataset.
       *
       * @returns A `Dataset`.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      skip(count2) {
        const base = this;
        let size;
        if (this.size != null && count2 >= 0 && this.size >= count2) {
          size = this.size - count2;
        } else if (this.size != null && (this.size < count2 || count2 === void 0 || count2 < 0)) {
          size = 0;
        } else {
          size = null;
        }
        return datasetFromIteratorFn(async () => (await base.iterator()).skip(count2), size);
      }
      /**
       * Pseudorandomly shuffles the elements of this dataset. This is done in a
       * streaming manner, by sampling from a given number of prefetched elements.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3, 4, 5, 6]).shuffle(3);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param bufferSize: An integer specifying the number of elements from this
       *   dataset from which the new dataset will sample.
       * @param seed: (Optional) An integer specifying the random seed that will
       *   be used to create the distribution.
       * @param reshuffleEachIteration: (Optional) A boolean, which if true
       *   indicates that the dataset should be pseudorandomly reshuffled each time
       *   it is iterated over. If false, elements will be returned in the same
       *   shuffled order on each iteration. (Defaults to `true`.)
       * @returns A `Dataset`.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      shuffle(bufferSize, seed, reshuffleEachIteration = true) {
        if (bufferSize == null || bufferSize < 0) {
          if (this.size == null) {
            throw new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.");
          } else {
            throw new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
          }
        }
        const base = this;
        const random3 = seedrandom3.alea(seed || util_exports.now().toString());
        return datasetFromIteratorFn(async () => {
          let seed2 = random3.int32();
          if (reshuffleEachIteration) {
            seed2 += random3.int32();
          }
          return (await base.iterator()).shuffle(bufferSize, seed2.toString());
        }, this.size);
      }
      /**
       * Creates a `Dataset` with at most `count` initial elements from this
       * dataset.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3, 4, 5, 6]).take(3);
       * await a.forEachAsync(e => console.log(e));
       * ```
       *
       * @param count: The number of elements of this dataset that should be taken
       *   to form the new dataset.  If `count` is `undefined` or negative, or if
       *   `count` is greater than the size of this dataset, the new dataset will
       *   contain all elements of this dataset.
       * @returns A `Dataset`.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      take(count2) {
        const base = this;
        let size;
        if (this.size != null && this.size > count2) {
          size = count2;
        } else if (this.size != null && this.size <= count2) {
          size = this.size;
        } else {
          size = null;
        }
        return datasetFromIteratorFn(async () => (await base.iterator()).take(count2), size);
      }
      /**
       * Collect all elements of this dataset into an array.
       *
       * Obviously this will succeed only for small datasets that fit in memory.
       * Useful for testing and generally should be avoided if possible.
       *
       * ```js
       * const a = tf.data.array([1, 2, 3, 4, 5, 6]);
       * console.log(await a.toArray());
       * ```
       *
       * @returns A Promise for an array of elements, which will resolve
       *   when a new stream has been obtained and fully consumed.
       *
       * @doc {heading: 'Data', subheading: 'Classes'}
       */
      async toArray() {
        if (this.size === Infinity) {
          throw new Error("Can not convert infinite data stream to array.");
        }
        return (await this.iterator()).toArray();
      }
      /**
       * Collect all elements of this dataset into an array with prefetching 100
       * elements. This is useful for testing, because the prefetch changes the
       * order in which the Promises are resolved along the processing pipeline.
       * This may help expose bugs where results are dependent on the order of
       * Promise resolution rather than on the logical order of the stream (i.e.,
       * due to hidden mutable state).
       *
       * @returns A Promise for an array of elements, which will resolve
       *   when a new stream has been obtained and fully consumed.
       */
      async toArrayForTest() {
        if (this.size === Infinity) {
          throw new Error("Can not convert infinite data stream to array.");
        }
        return (await this.iterator()).toArrayForTest();
      }
    };
    Dataset.MAX_BUFFER_SIZE = 1e4;
  }
});
var init_text_line_dataset = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/datasets/text_line_dataset.js"() {
    init_dataset();
  }
});
var STATE_OUT;
var STATE_FIELD;
var STATE_QUOTE;
var STATE_QUOTE_AFTER_QUOTE;
var STATE_WITHIN_QUOTE_IN_QUOTE;
var init_csv_dataset = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/datasets/csv_dataset.js"() {
    init_dist();
    init_dataset();
    init_text_line_dataset();
    STATE_OUT = Symbol("out");
    STATE_FIELD = Symbol("field");
    STATE_QUOTE = Symbol("quote");
    STATE_QUOTE_AFTER_QUOTE = Symbol("quoteafterquote");
    STATE_WITHIN_QUOTE_IN_QUOTE = Symbol("quoteinquote");
  }
});
var init_microphone_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/microphone_iterator.js"() {
    init_dist();
    init_lazy_iterator();
  }
});
var init_webcam_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/webcam_iterator.js"() {
    init_dist();
    init_lazy_iterator();
  }
});
var init_datasource = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/datasource.js"() {
  }
});
var init_string_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/string_iterator.js"() {
    init_lazy_iterator();
  }
});
var init_byte_chunk_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/byte_chunk_iterator.js"() {
    init_dist();
    init_lazy_iterator();
    init_string_iterator();
  }
});
var init_file_chunk_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/file_chunk_iterator.js"() {
    init_dist();
    init_byte_chunk_iterator();
  }
});
var init_url_chunk_iterator = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/iterators/url_chunk_iterator.js"() {
    init_dist();
    init_file_chunk_iterator();
  }
});
var init_source_util = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/util/source_util.js"() {
  }
});
var init_file_data_source = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/sources/file_data_source.js"() {
    init_dist();
    init_datasource();
    init_file_chunk_iterator();
    init_source_util();
  }
});
var init_url_data_source = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/sources/url_data_source.js"() {
    init_datasource();
    init_url_chunk_iterator();
    init_source_util();
    init_file_data_source();
  }
});
var init_readers = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/readers.js"() {
    init_dataset();
    init_csv_dataset();
    init_lazy_iterator();
    init_microphone_iterator();
    init_webcam_iterator();
    init_url_data_source();
  }
});
var init_version3 = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/version.js"() {
  }
});
var init_dist4 = __esm({
  "node_modules/@tensorflow/tfjs-data/dist/index.js"() {
    init_dataset();
    init_csv_dataset();
    init_text_line_dataset();
    init_readers();
    init_file_data_source();
    init_url_data_source();
    init_version3();
  }
});
function assertNotComplex(tensor2, opName) {
  if (!Array.isArray(tensor2)) {
    tensor2 = [tensor2];
  }
  tensor2.forEach((t) => {
    if (t != null) {
      util_exports.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the CPU backend.`);
    }
  });
}
var init_cpu_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/cpu_util.js"() {
    init_dist();
  }
});
var whereImpl2;
var MathBackendCPU;
var init_backend_cpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/backend_cpu.js"() {
    init_dist();
    init_cpu_util();
    whereImpl2 = kernel_impls_exports.whereImpl;
    MathBackendCPU = class extends KernelBackend {
      constructor() {
        super();
        this.blockSize = 48;
        this.firstUse = true;
        this.data = new DataStorage(this, engine());
      }
      nextDataId() {
        return MathBackendCPU.nextDataId++;
      }
      write(values, shape, dtype) {
        if (this.firstUse) {
          this.firstUse = false;
          if (env().get("IS_NODE")) {
            backend_util_exports.warn("\n============================\nHi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. \n============================");
          }
        }
        const dataId = { id: this.nextDataId() };
        this.data.set(dataId, { values, dtype, refCount: 1 });
        return dataId;
      }
      /**
       * Create a data bucket in cpu backend.
       * @param shape Shape of the `TensorInfo`.
       * @param dtype DType of the `TensorInfo`.
       * @param values The value of the `TensorInfo` stored as a flattened array.
       */
      makeTensorInfo(shape, dtype, values) {
        let outId;
        if (dtype === "string" && values != null && values.length > 0 && util_exports.isString(values[0])) {
          const encodedValues = values.map((d) => util_exports.encodeString(d));
          outId = this.write(encodedValues, shape, dtype);
        } else {
          outId = this.write(values, shape, dtype);
        }
        return { dataId: outId, shape, dtype };
      }
      /** Return refCount of a `TensorData`. */
      refCount(dataId) {
        if (this.data.has(dataId)) {
          const tensorData = this.data.get(dataId);
          return tensorData.refCount;
        }
        return 0;
      }
      /** Increase refCount of a `TensorData`. */
      incRef(dataId) {
        const tensorData = this.data.get(dataId);
        tensorData.refCount++;
      }
      /** Decrease refCount of a `TensorData`. */
      decRef(dataId) {
        if (this.data.has(dataId)) {
          const tensorData = this.data.get(dataId);
          tensorData.refCount--;
        }
      }
      move(dataId, values, shape, dtype, refCount) {
        this.data.set(dataId, { values, dtype, refCount });
      }
      numDataIds() {
        return this.data.numDataIds();
      }
      async read(dataId) {
        return this.readSync(dataId);
      }
      readSync(dataId) {
        const { dtype, complexTensorInfos } = this.data.get(dataId);
        if (dtype === "complex64") {
          const realValues = this.readSync(complexTensorInfos.real.dataId);
          const imagValues = this.readSync(complexTensorInfos.imag.dataId);
          return backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
        }
        return util_exports.convertBackendValuesAndArrayBuffer(this.data.get(dataId).values, dtype);
      }
      bufferSync(t) {
        const data = this.readSync(t.dataId);
        if (t.dtype === "string") {
          try {
            const strings = data.map((d) => util_exports.decodeString(d));
            return buffer(t.shape, t.dtype, strings);
          } catch (_a2) {
            throw new Error("Failed to decode encoded string bytes into utf-8");
          }
        }
        return buffer(t.shape, t.dtype, data);
      }
      makeOutput(values, shape, dtype) {
        return engine().makeTensorFromTensorInfo(this.makeTensorInfo(shape, dtype, values), this);
      }
      /**
       * Dispose the memory if the dataId has 0 refCount. Return true if the memory
       * is released or memory is not managed in this backend, false if memory is
       * not cleared.
       * @param dataId
       * @oaram force Optional, remove the data regardless of refCount
       */
      disposeData(dataId, force = false) {
        if (this.data.has(dataId)) {
          this.data.get(dataId).refCount--;
          if (!force && this.data.get(dataId).refCount > 0) {
            return false;
          }
          const { complexTensorInfos } = this.data.get(dataId);
          if (complexTensorInfos != null) {
            this.disposeData(complexTensorInfos.real.dataId, true);
            this.disposeData(complexTensorInfos.imag.dataId, true);
          }
          this.data.delete(dataId);
        }
        return true;
      }
      disposeIntermediateTensorInfo(tensorInfo) {
        this.disposeData(tensorInfo.dataId);
      }
      async time(f) {
        const start = util_exports.now();
        f();
        const kernelMs = util_exports.now() - start;
        return { kernelMs };
      }
      memory() {
        return {
          // Unreliable due to automatic gc. The numbers above are cumulative.
          unreliable: true,
          reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
        };
      }
      where(condition) {
        assertNotComplex([condition], "where");
        const condVals = this.readSync(condition.dataId);
        return whereImpl2(condition.shape, condVals);
      }
      dispose() {
      }
      floatPrecision() {
        return 32;
      }
      /** Returns the smallest representable number.  */
      epsilon() {
        return super.epsilon();
      }
    };
    MathBackendCPU.nextDataId = 0;
  }
});
function simpleAbsImpl(vals) {
  const resultValues = new Float32Array(vals.length);
  for (let i = 0; i < vals.length; ++i) {
    resultValues[i] = Math.abs(vals[i]);
  }
  return resultValues;
}
var abs2;
var absConfig;
var init_Abs = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js"() {
    init_dist();
    init_cpu_util();
    abs2 = (args) => {
      const { x } = args.inputs;
      const cpuBackend = args.backend;
      assertNotComplex(x, "abs");
      let resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
      const values = cpuBackend.data.get(x.dataId).values;
      resultValues = simpleAbsImpl(values);
      return cpuBackend.makeOutput(resultValues, x.shape, x.dtype);
    };
    absConfig = {
      kernelName: Abs,
      backendName: "cpu",
      kernelFunc: abs2
    };
  }
});
function createSimpleBinaryKernelImpl(op2) {
  return (aShape, bShape, aVals, bVals, dtype) => {
    const newShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
    const resultRank = newShape.length;
    const resultStrides = util_exports.computeStrides(newShape);
    const resultSize = util_exports.sizeFromShape(newShape);
    const result = util_exports.getTypedArrayFromDType(dtype, resultSize);
    const aRank = aShape.length;
    const bRank = bShape.length;
    const aStrides = util_exports.computeStrides(aShape);
    const bStrides = util_exports.computeStrides(bShape);
    const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, newShape);
    const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, newShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < result.length; ++i) {
        result[i] = op2(aVals[i % aVals.length], bVals[i % bVals.length]);
      }
    } else {
      for (let i = 0; i < result.length; ++i) {
        const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
        result[i] = op2(aVals[aIndex], bVals[bIndex]);
      }
    }
    return [result, newShape];
  };
}
var init_binary_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js"() {
    init_dist();
  }
});
function complex2(args) {
  const { inputs, backend: backend2 } = args;
  const { real: real4, imag: imag4 } = inputs;
  const realVals = backend2.data.get(real4.dataId).values;
  const imagVals = backend2.data.get(imag4.dataId).values;
  const complexInfo = backend2.makeTensorInfo(real4.shape, "complex64");
  const complex4 = backend2.data.get(complexInfo.dataId);
  complex4.complexTensorInfos = {
    real: backend2.makeTensorInfo(real4.shape, "float32", realVals),
    imag: backend2.makeTensorInfo(imag4.shape, "float32", imagVals)
  };
  return complexInfo;
}
var complexConfig;
var init_Complex = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js"() {
    init_dist();
    complexConfig = {
      kernelName: Complex,
      backendName: "cpu",
      kernelFunc: complex2
    };
  }
});
function zeros2(backend2, shape, dtype = "float32") {
  if (dtype === "complex64") {
    const real4 = zeros2(backend2, shape, "float32");
    const imag4 = zeros2(backend2, shape, "float32");
    return complex2({ inputs: { real: real4, imag: imag4 }, backend: backend2 });
  }
  const values = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(shape), dtype);
  return backend2.makeTensorInfo(shape, dtype, values);
}
var init_zeros_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js"() {
    init_dist();
    init_Complex();
  }
});
function identity4(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  backend2.incRef(x.dataId);
  return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
}
var identityConfig;
var init_Identity = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js"() {
    init_dist();
    identityConfig = {
      kernelName: Identity,
      backendName: "cpu",
      kernelFunc: identity4
    };
  }
});
function real2(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  const real4 = backend2.data.get(input2.dataId).complexTensorInfos.real;
  const realVal = backend2.data.get(real4.dataId).values;
  return backend2.makeTensorInfo(real4.shape, real4.dtype, realVal);
}
var realConfig;
var init_Real = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js"() {
    init_dist();
    realConfig = {
      kernelName: Real,
      backendName: "cpu",
      kernelFunc: real2
    };
  }
});
function castImpl(values, shape, inputType, dtype) {
  if (dtype === "int32") {
    const resultValues = Int32Array.from(values);
    return [shape, "int32", resultValues];
  }
  if (dtype === "bool") {
    const zero2 = util_exports.toTypedArray([0], inputType);
    const [resultData, resultShape] = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0)(shape, [], values, zero2, "bool");
    return [resultShape, "bool", resultData];
  }
  throw new Error(`Error in Cast: failed to cast ${inputType} to ${dtype}`);
}
function cast3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { dtype } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity4({ inputs: { x }, backend: backend2 });
    }
    const zerosTensorInfo = zeros2(backend2, x.shape, x.dtype);
    const floatX = cast3({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
    const result = complex2({ inputs: { real: floatX, imag: zerosTensorInfo }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(zerosTensorInfo);
    backend2.disposeIntermediateTensorInfo(floatX);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real2({ inputs: { input: x }, backend: backend2 });
    const result = cast3({ inputs: { x: realPart }, backend: backend2, attrs: { dtype } });
    backend2.disposeIntermediateTensorInfo(realPart);
    return result;
  }
  if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity4({ inputs: { x }, backend: backend2 });
    return { dataId: result.dataId, shape: result.shape, dtype };
  }
  const values = backend2.data.get(x.dataId).values;
  const [resultShape, resultType, resultData] = castImpl(values, x.shape, x.dtype, dtype);
  return backend2.makeTensorInfo(resultShape, resultType, resultData);
}
var castConfig;
var init_Cast = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js"() {
    init_dist();
    init_binary_impl();
    init_zeros_impl();
    init_Complex();
    init_Identity();
    init_Real();
    castConfig = {
      kernelName: Cast,
      backendName: "cpu",
      kernelFunc: cast3
    };
  }
});
function binaryKernelFunc(name, simpleImpl, complexImpl, dtype) {
  if (complexImpl == null) {
    return ({ inputs, backend: backend2 }) => {
      const { a, b } = inputs;
      const cpuBackend = backend2;
      assertNotComplex([a, b], name);
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(aVals)
      ) : aVals;
      const decodedBVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(bVals)
      ) : bVals;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    };
  }
  return ({ inputs, backend: backend2 }) => {
    const { a, b } = inputs;
    const cpuBackend = backend2;
    if (a.dtype === "complex64" || b.dtype === "complex64") {
      const $aComplex = cast3({ inputs: { x: a }, backend: cpuBackend, attrs: { dtype: "complex64" } });
      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);
      const aReal = $aComplexVals.complexTensorInfos.real;
      const aImag = $aComplexVals.complexTensorInfos.imag;
      const aRealVals = cpuBackend.data.get(aReal.dataId).values;
      const aImagVals = cpuBackend.data.get(aImag.dataId).values;
      const $bComplex = cast3({ inputs: { x: b }, backend: cpuBackend, attrs: { dtype: "complex64" } });
      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);
      const bReal = $bComplexVals.complexTensorInfos.real;
      const bImag = $bComplexVals.complexTensorInfos.imag;
      const bRealVals = cpuBackend.data.get(bReal.dataId).values;
      const bImagVals = cpuBackend.data.get(bImag.dataId).values;
      const [resultRealData, resultImagData, resultShape] = complexImpl(a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);
      const resultReal = cpuBackend.makeTensorInfo(resultShape, "float32", resultRealData);
      const resultImag = cpuBackend.makeTensorInfo(resultShape, "float32", resultImagData);
      const result = complex2({ inputs: { real: resultReal, imag: resultImag }, backend: cpuBackend });
      cpuBackend.disposeIntermediateTensorInfo($aComplex);
      cpuBackend.disposeIntermediateTensorInfo($bComplex);
      cpuBackend.disposeIntermediateTensorInfo(resultReal);
      cpuBackend.disposeIntermediateTensorInfo(resultImag);
      return result;
    } else {
      const aVals = cpuBackend.data.get(a.dataId).values;
      const bVals = cpuBackend.data.get(b.dataId).values;
      const $dtype = dtype || a.dtype;
      const [resultData, resultShape] = simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);
      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);
    }
  };
}
function createComplexBinaryKernelImpl(op2) {
  return (aShape, bShape, aRealVals, aImagVals, bRealVals, bImagVals) => {
    const resultShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
    const resultSize = util_exports.sizeFromShape(resultShape);
    const resultRank = resultShape.length;
    const resultStrides = util_exports.computeStrides(resultShape);
    const resultRealVals = util_exports.getTypedArrayFromDType("float32", resultSize);
    const resultImagVals = util_exports.getTypedArrayFromDType("float32", resultSize);
    const aBroadcastDims = backend_util_exports.getBroadcastDims(aShape, resultShape);
    const bBroadcastDims = backend_util_exports.getBroadcastDims(bShape, resultShape);
    const aVals = backend_util_exports.mergeRealAndImagArrays(aRealVals, aImagVals);
    const bVals = backend_util_exports.mergeRealAndImagArrays(bRealVals, bImagVals);
    const aRank = aShape.length;
    const aStrides = util_exports.computeStrides(aShape);
    const bRank = bShape.length;
    const bStrides = util_exports.computeStrides(bShape);
    if (aBroadcastDims.length + bBroadcastDims.length === 0) {
      for (let i = 0; i < resultRealVals.length; i++) {
        const aIdx = i % aVals.length;
        const bIdx = i % bVals.length;
        const result = op2(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2], bVals[bIdx * 2 + 1]);
        resultRealVals[i] = result.real;
        resultImagVals[i] = result.imag;
      }
    } else {
      for (let i = 0; i < resultRealVals.length; i++) {
        const loc = util_exports.indexToLoc(i, resultRank, resultStrides);
        const aLoc = loc.slice(-aRank);
        aBroadcastDims.forEach((d) => aLoc[d] = 0);
        const aIndex = util_exports.locToIndex(aLoc, aRank, aStrides);
        const bLoc = loc.slice(-bRank);
        bBroadcastDims.forEach((d) => bLoc[d] = 0);
        const bIndex = util_exports.locToIndex(bLoc, bRank, bStrides);
        const opResult = op2(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2], bVals[bIndex * 2 + 1]);
        resultRealVals[i] = opResult.real;
        resultImagVals[i] = opResult.imag;
      }
    }
    return [resultRealVals, resultImagVals, resultShape];
  };
}
var init_binary_utils = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js"() {
    init_dist();
    init_cpu_util();
    init_Cast();
    init_Complex();
  }
});
var addImpl;
var addComplexImpl;
var add32;
var addConfig;
var init_Add = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    addImpl = createSimpleBinaryKernelImpl((a, b) => a + b);
    addComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
      return { real: aReal + bReal, imag: aImag + bImag };
    });
    add32 = binaryKernelFunc(Add, addImpl, addComplexImpl);
    addConfig = {
      kernelName: Add,
      backendName: "cpu",
      kernelFunc: add32
    };
  }
});
function bincountImpl(xVals, weightsVals, weightsDtype, weightsShape, size) {
  const weightsSize = util_exports.sizeFromShape(weightsShape);
  const outVals = util_exports.makeZerosTypedArray(size, weightsDtype);
  for (let i = 0; i < xVals.length; i++) {
    const value = xVals[i];
    if (value < 0) {
      throw new Error("Input x must be non-negative!");
    }
    if (value >= size) {
      continue;
    }
    if (weightsSize > 0) {
      outVals[value] += weightsVals[i];
    } else {
      outVals[value] += 1;
    }
  }
  return outVals;
}
function bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput = false) {
  const numRows = xBuf.shape[0];
  const numCols = xBuf.shape[1];
  const outBuf = buffer([numRows, size], weightsBuf.dtype);
  for (let i = 0; i < numRows; i++) {
    for (let j = 0; j < numCols; j++) {
      const value = xBuf.get(i, j);
      if (value < 0) {
        throw new Error("Input x must be non-negative!");
      }
      if (value >= size) {
        continue;
      }
      if (binaryOutput) {
        outBuf.set(1, i, value);
      } else {
        if (weightsBuf.size > 0) {
          outBuf.set(outBuf.get(i, value) + weightsBuf.get(i, j), i, value);
        } else {
          outBuf.set(outBuf.get(i, value) + 1, i, value);
        }
      }
    }
  }
  return outBuf;
}
var init_Bincount_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js"() {
    init_dist();
  }
});
function createSimpleUnaryImpl(op2) {
  return (values, dtype, attrs) => {
    const newValues = util_exports.getTypedArrayFromDType(dtype, values.length);
    for (let i = 0; i < values.length; ++i) {
      newValues[i] = op2(values[i], attrs);
    }
    return newValues;
  };
}
var init_unary_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js"() {
    init_dist();
  }
});
function unaryKernelFunc(name, op2, dtype) {
  return ({ inputs, attrs, backend: backend2 }) => {
    const { x } = inputs;
    assertNotComplex(x, name);
    if (x.dtype === "string" || dtype === "string") {
      throw new Error("unaryKernelFunc does not support string input/output");
    }
    const cpuBackend = backend2;
    const values = cpuBackend.data.get(x.dataId).values;
    const xSize = util_exports.sizeFromShape(x.shape);
    const $dtype = dtype || x.dtype;
    const newValues = util_exports.getArrayFromDType($dtype, xSize);
    for (let i = 0; i < xSize; ++i) {
      newValues[i] = op2(values[i], attrs);
    }
    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
  };
}
function unaryKernelFuncFromImpl(name, unaryImpl, dtype) {
  return ({ inputs, attrs, backend: backend2 }) => {
    const { x } = inputs;
    assertNotComplex(x, name);
    if (x.dtype === "string" || dtype === "string") {
      throw new Error("unaryKernelFunc does not support string input/output");
    }
    const cpuBackend = backend2;
    const values = cpuBackend.data.get(x.dataId).values;
    const $dtype = dtype || x.dtype;
    const newValues = unaryImpl(values, $dtype, attrs);
    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);
  };
}
var init_unary_utils = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js"() {
    init_dist();
    init_cpu_util();
  }
});
var ceilImpl;
var ceil22;
var ceilConfig;
var init_Ceil = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));
    ceil22 = unaryKernelFuncFromImpl(Ceil, ceilImpl);
    ceilConfig = {
      kernelName: Ceil,
      backendName: "cpu",
      kernelFunc: ceil22
    };
  }
});
function concatImpl(inputs, outShape, dtype, simplyConcat) {
  const outVals = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
  if (simplyConcat && dtype !== "string") {
    let offset = 0;
    inputs.forEach((input2) => {
      const size = util_exports.sizeFromShape(input2.shape);
      outVals.set(input2.vals, offset);
      offset += size;
    });
  } else {
    let colOffset = 0;
    inputs.forEach((input2) => {
      const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(input2.vals) : input2.vals;
      let tIdx = 0;
      for (let row = 0; row < input2.shape[0]; ++row) {
        const resIdx = row * outShape[1] + colOffset;
        for (let col = 0; col < input2.shape[1]; ++col) {
          outVals[resIdx + col] = decodedData[tIdx++];
        }
      }
      colOffset += input2.shape[1];
    });
  }
  return outVals;
}
var init_Concat_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js"() {
    init_dist();
  }
});
var equalImpl;
var equal2;
var equalConfig;
var init_Equal = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    equalImpl = createSimpleBinaryKernelImpl((a, b) => a === b ? 1 : 0);
    equal2 = binaryKernelFunc(Equal, equalImpl, null, "bool");
    equalConfig = {
      kernelName: Equal,
      backendName: "cpu",
      kernelFunc: equal2
    };
  }
});
var expImpl;
var exp22;
var expConfig;
var init_Exp = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));
    exp22 = unaryKernelFuncFromImpl(Exp, expImpl, "float32");
    expConfig = {
      kernelName: Exp,
      backendName: "cpu",
      kernelFunc: exp22
    };
  }
});
var expm1Impl;
var expm12;
var expm1Config;
var init_Expm1 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));
    expm12 = unaryKernelFuncFromImpl(Expm1, expm1Impl);
    expm1Config = {
      kernelName: Expm1,
      backendName: "cpu",
      kernelFunc: expm12
    };
  }
});
var floorImpl;
var floor22;
var floorConfig;
var init_Floor = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));
    floor22 = unaryKernelFuncFromImpl(Floor, floorImpl);
    floorConfig = {
      kernelName: Floor,
      backendName: "cpu",
      kernelFunc: floor22
    };
  }
});
function gatherNdImpl(indicesData, paramsBuf, dtype, numSlices, sliceRank, sliceSize, strides, paramsShape, paramsSize) {
  const outBuf = buffer([numSlices, sliceSize], dtype);
  for (let i = 0; i < numSlices; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      flattenIndex += dim * strides[j];
      index.push(dim);
    }
    if (flattenIndex < 0 || flattenIndex >= paramsSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${paramsShape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      outBuf.values[i * sliceSize + k] = paramsBuf.get(...paramsBuf.indexToLoc(flattenIndex * sliceSize + k));
    }
  }
  return outBuf;
}
var init_GatherNd_Impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js"() {
    init_dist();
  }
});
function gatherV2Impl(xBuf, indicesBuf, flattenOutputShape) {
  const outBuf = buffer(flattenOutputShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const newLoc = outBuf.indexToLoc(i);
    const originalLoc = newLoc.slice();
    const batchIdx = originalLoc[0];
    const indicesIdx = originalLoc[2];
    const indicesIndex = indicesBuf.locToIndex([batchIdx, indicesIdx]);
    originalLoc[2] = indicesBuf.values[indicesIndex];
    const originalIndex = xBuf.locToIndex(originalLoc);
    if (0 <= originalIndex && originalIndex < xBuf.values.length) {
      outBuf.values[i] = xBuf.values[originalIndex];
    }
  }
  return outBuf;
}
var init_GatherV2_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js"() {
    init_dist();
  }
});
var greaterImpl;
var greater2;
var greaterConfig;
var init_Greater = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    greaterImpl = createSimpleBinaryKernelImpl((a, b) => a > b ? 1 : 0);
    greater2 = binaryKernelFunc(Greater, greaterImpl, null, "bool");
    greaterConfig = {
      kernelName: Greater,
      backendName: "cpu",
      kernelFunc: greater2
    };
  }
});
var greaterEqualImpl;
var greaterEqual2;
var greaterEqualConfig;
var init_GreaterEqual = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    greaterEqualImpl = createSimpleBinaryKernelImpl((a, b) => a >= b ? 1 : 0);
    greaterEqual2 = binaryKernelFunc(GreaterEqual, greaterEqualImpl, null, "bool");
    greaterEqualConfig = {
      kernelName: GreaterEqual,
      backendName: "cpu",
      kernelFunc: greaterEqual2
    };
  }
});
var lessImpl;
var less2;
var lessConfig;
var init_Less = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    lessImpl = createSimpleBinaryKernelImpl((a, b) => a < b ? 1 : 0);
    less2 = binaryKernelFunc(Less, lessImpl, null, "bool");
    lessConfig = {
      kernelName: Less,
      backendName: "cpu",
      kernelFunc: less2
    };
  }
});
var lessEqualImpl;
var lessEqual2;
var lessEqualConfig;
var init_LessEqual = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    lessEqualImpl = createSimpleBinaryKernelImpl((a, b) => a <= b ? 1 : 0);
    lessEqual2 = binaryKernelFunc(LessEqual, lessEqualImpl, null, "bool");
    lessEqualConfig = {
      kernelName: LessEqual,
      backendName: "cpu",
      kernelFunc: lessEqual2
    };
  }
});
function linSpaceImpl(start, stop, num) {
  const step4 = (stop - start) / (num - 1);
  const values = util_exports.makeZerosTypedArray(num, "float32");
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step4;
  }
  return values;
}
var init_LinSpace_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js"() {
    init_dist();
  }
});
var logImpl;
var log3;
var logConfig;
var init_Log = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));
    log3 = unaryKernelFuncFromImpl(Log, logImpl);
    logConfig = {
      kernelName: Log,
      backendName: "cpu",
      kernelFunc: log3
    };
  }
});
function maxImpl(aVals, reduceSize, outShape, dtype) {
  const vals = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(outShape));
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let max5 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (Number.isNaN(value) || value > max5) {
        max5 = value;
      }
    }
    vals[i] = max5;
  }
  return vals;
}
var init_Max_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js"() {
    init_dist();
  }
});
var maximumImpl;
var maximum2;
var maximumConfig;
var init_Maximum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    maximumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.max(aValue, bValue));
    maximum2 = binaryKernelFunc(Maximum, maximumImpl);
    maximumConfig = {
      kernelName: Maximum,
      backendName: "cpu",
      kernelFunc: maximum2
    };
  }
});
var minimumImpl;
var minimum2;
var minimumConfig;
var init_Minimum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    minimumImpl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.min(aValue, bValue));
    minimum2 = binaryKernelFunc(Minimum, minimumImpl);
    minimumConfig = {
      kernelName: Minimum,
      backendName: "cpu",
      kernelFunc: minimum2
    };
  }
});
var multiplyImpl;
var multiplyComplexImpl;
var multiply5;
var multiplyConfig;
var init_Multiply = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    multiplyImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue * bValue);
    multiplyComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
      return {
        real: aReal * bReal - aImag * bImag,
        imag: aReal * bImag + aImag * bReal
      };
    });
    multiply5 = binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);
    multiplyConfig = {
      kernelName: Multiply,
      backendName: "cpu",
      kernelFunc: multiply5
    };
  }
});
function negImpl(xVals, xShape, xDtype) {
  const minusOne = util_exports.createScalarValue(-1, xDtype);
  return multiplyImpl([], xShape, minusOne, xVals, xDtype);
}
function neg2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  assertNotComplex(x, "neg");
  const xVals = backend2.data.get(x.dataId).values;
  const [res, newShape] = negImpl(xVals, x.shape, x.dtype);
  return backend2.makeTensorInfo(newShape, x.dtype, res);
}
var negConfig;
var init_Neg = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js"() {
    init_dist();
    init_cpu_util();
    init_Multiply();
    negConfig = {
      kernelName: Neg,
      backendName: "cpu",
      kernelFunc: neg2
    };
  }
});
var notEqualImpl;
var notEqual2;
var notEqualConfig;
var init_NotEqual = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    notEqualImpl = createSimpleBinaryKernelImpl((a, b) => a !== b ? 1 : 0);
    notEqual2 = binaryKernelFunc(NotEqual, notEqualImpl, null, "bool");
    notEqualConfig = {
      kernelName: NotEqual,
      backendName: "cpu",
      kernelFunc: notEqual2
    };
  }
});
function transposeImpl(xVals, xShape, dtype, perm, newShape) {
  const xRank = xShape.length;
  const xSize = util_exports.sizeFromShape(xShape);
  const xStrides = util_exports.computeStrides(xShape);
  const newStrides = util_exports.computeStrides(newShape);
  const result = util_exports.getTypedArrayFromDType(dtype, util_exports.sizeFromShape(newShape));
  for (let i = 0; i < xSize; ++i) {
    const loc = util_exports.indexToLoc(i, xRank, xStrides);
    const newLoc = new Array(loc.length);
    for (let i2 = 0; i2 < newLoc.length; i2++) {
      newLoc[i2] = loc[perm[i2]];
    }
    const newIndex = util_exports.locToIndex(newLoc, xRank, newStrides);
    result[newIndex] = xVals[i];
  }
  return result;
}
var init_Transpose_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js"() {
    init_dist();
  }
});
function transpose22(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { x } = inputs;
  const { perm } = attrs;
  assertNotComplex(x, "transpose");
  const xRank = x.shape.length;
  const newShape = new Array(xRank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[perm[i]];
  }
  const values = backend2.data.get(x.dataId).values;
  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);
  const dataId = backend2.write(result, newShape, x.dtype);
  return { dataId, shape: newShape, dtype: x.dtype };
}
var transposeConfig;
var init_Transpose = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js"() {
    init_dist();
    init_cpu_util();
    init_Transpose_impl();
    transposeConfig = {
      kernelName: Transpose,
      backendName: "cpu",
      kernelFunc: transpose22
    };
  }
});
function prodImpl(xShape, xDtype, xVals, reductionAxes) {
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, reductionAxes);
  const outDtype = upcastType(xDtype, "int32");
  const outVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), outDtype);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  for (let i = 0; i < outVals.length; ++i) {
    const offset = i * reduceSize;
    let prod4 = 1;
    for (let j = 0; j < reduceSize; ++j) {
      prod4 *= xVals[offset + j];
    }
    outVals[i] = prod4;
  }
  return { outVals, outShape, outDtype };
}
function prod2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "prod");
  const xRank = x.shape.length;
  const axes = util_exports.parseAxisParam(axis, x.shape);
  const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
  let reductionAxes = axes;
  let permutedX = x;
  const intermediateTensorInfos = [];
  if (permutation != null) {
    permutedX = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
    intermediateTensorInfos.push(permutedX);
    reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
  }
  const xVals = backend2.data.get(permutedX.dataId).values;
  const { outVals, outShape, outDtype } = prodImpl(permutedX.shape, permutedX.dtype, xVals, reductionAxes);
  let resultShape = outShape;
  if (keepDims) {
    resultShape = backend_util_exports.expandShapeToKeepDim(outShape, axes);
  }
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return backend2.makeTensorInfo(resultShape, outDtype, outVals);
}
var prodConfig;
var init_Prod = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js"() {
    init_dist();
    init_cpu_util();
    init_Transpose();
    prodConfig = {
      kernelName: Prod,
      backendName: "cpu",
      kernelFunc: prod2
    };
  }
});
function validateIndices(indices, indicesShape, numParams) {
  indices.forEach((index, i) => {
    if (index < 0 || index >= numParams) {
      const locString = util_exports.indexToLoc(i, indicesShape.length, util_exports.computeStrides(indicesShape)).join(",");
      throw new Error(`indices[${locString}] = ${index} is not in [0, ${numParams})`);
    }
  });
}
function validateSplits(paramsNestedSplits, numParamsDenseValues) {
  for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
    const splits = paramsNestedSplits[dim];
    const lastSplit = dim === paramsNestedSplits.length - 1 ? numParamsDenseValues : paramsNestedSplits[dim + 1].length;
    if (splits.length === 0) {
      throw new Error("Ragged splits may not be empty");
    }
    if (splits[0] < 0) {
      throw new Error("Ragged splits must be non-negative");
    }
    if (splits[splits.length - 1] > lastSplit) {
      throw new Error("Ragged splits must not point past values");
    }
    for (let i = 1; i < splits.length; ++i) {
      if (splits[i - 1] > splits[i]) {
        throw new Error("Ragged splits must be sorted in ascending order");
      }
    }
  }
}
function makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues) {
  const valueSlices = [];
  let numValues = 0;
  const numSplits = indicesShape.length - 1 + paramsNestedSplits.length;
  const outSplits = new Array(numSplits).fill(null).map(() => [0]);
  validateSplits(paramsNestedSplits, numParamsDenseValues);
  let nrows = 1;
  for (let dim = 0; dim < indicesShape.length - 1; ++dim) {
    nrows *= indicesShape[dim];
    const rowLength = indicesShape[dim + 1];
    for (let i = 1; i < nrows + 1; ++i) {
      outSplits[dim].push(i * rowLength);
    }
  }
  for (let i = 0; i < indices.length; ++i) {
    let start = indices[i];
    let limit = indices[i] + 1;
    for (let dim = 0; dim < paramsNestedSplits.length; ++dim) {
      const splits = paramsNestedSplits[dim];
      const outDim = dim + indicesShape.length - 1;
      if (outDim >= 0) {
        const outSplitsOutDim = outSplits[outDim];
        const delta = outSplitsOutDim[outSplitsOutDim.length - 1] - splits[start];
        for (let j = start; j < limit; ++j) {
          outSplits[outDim].push(splits[j + 1] + delta);
        }
      }
      start = splits[start];
      limit = splits[limit];
    }
    if (limit !== start) {
      valueSlices.push([start, limit]);
      numValues += limit - start;
    }
  }
  return { outSplits, valueSlices, numValues };
}
function getSplits(outSplits) {
  const splitsOut = [];
  for (let i = 0; i < outSplits.length; ++i) {
    const numSplits = outSplits[i].length;
    const splits = util_exports.getArrayFromDType("int32", numSplits);
    splitsOut.push(splits);
    outSplits[i].forEach((value, j) => splits[j] = value);
  }
  return splitsOut;
}
function computeFlatOuterDims(orig, numOutDims) {
  const outDims = orig.slice(0, numOutDims);
  while (outDims.length < numOutDims) {
    outDims.push(1);
  }
  for (let inDim = numOutDims; inDim < orig.length; inDim++) {
    outDims[numOutDims - 1] *= orig[inDim];
  }
  return outDims;
}
function writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, values, valuesShape) {
  const denseM = computeFlatOuterDims(paramsDenseValuesShape, 2)[1];
  const valuesM = computeFlatOuterDims(valuesShape, 2)[1];
  let outPos = 0;
  for (const slice4 of valueSlices) {
    for (let i = slice4[0]; i < slice4[1]; ++i) {
      for (let j = 0; j < valueSize; ++j) {
        values[outPos * valuesM + j] = paramsDenseValues[i * denseM + j];
      }
      ++outPos;
    }
  }
}
function getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues) {
  const valuesShape = paramsDenseValuesShape.slice();
  valuesShape[0] = numValues;
  const valuesOut = util_exports.getArrayFromDType(paramsDenseValuesDType, util_exports.sizeFromShape(valuesShape));
  const numElements = paramsDenseValues.length;
  const valueSize = numElements === 0 ? 0 : numElements / paramsDenseValuesShape[0];
  writeValueSlices(paramsDenseValues, paramsDenseValuesShape, valueSlices, valueSize, valuesOut, valuesShape);
  return [valuesOut, valuesShape];
}
function raggedGatherImpl(paramsNestedSplits, paramsNestedSplitsShapes, paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, indices, indicesShape, outputRaggedRank) {
  if (paramsNestedSplits.length === 0) {
    throw new Error("paramsNestedSplits must be non empty");
  }
  if (paramsNestedSplitsShapes[0].length === 0) {
    throw new Error("Split tensors must not be scalars");
  }
  const numParams = paramsNestedSplitsShapes[0][0] - 1;
  validateIndices(indices, indicesShape, numParams);
  if (paramsDenseValuesShape.length === 0) {
    throw new Error("params.rank must be nonzero");
  }
  const numParamsDenseValues = paramsDenseValuesShape[0];
  const { outSplits, valueSlices, numValues } = makeSplits(indices, indicesShape, paramsNestedSplits, numParamsDenseValues);
  const outputNestedSplits = getSplits(outSplits);
  const outputDenseValues = getValues(paramsDenseValues, paramsDenseValuesShape, paramsDenseValuesDType, valueSlices, numValues);
  return [outputNestedSplits, outputDenseValues[0], outputDenseValues[1]];
}
var init_RaggedGather_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js"() {
    init_dist();
  }
});
function raggedRangeImpl(starts, startsShape, startsDType, limits, limitsShape, deltas, deltasShape) {
  if (startsShape.length > 1) {
    throw new Error("starts must be a scalar or vector");
  }
  if (limitsShape.length > 1) {
    throw new Error("limits must be a scalar or vector");
  }
  if (deltasShape.length > 1) {
    throw new Error("deltas must be a scalar or vector");
  }
  const broadcastStarts = startsShape.length === 0;
  const broadcastLimits = limitsShape.length === 0;
  const broadcastDeltas = deltasShape.length === 0;
  const inSizes = [];
  if (!broadcastStarts) {
    inSizes.push(startsShape[0]);
  }
  if (!broadcastLimits) {
    inSizes.push(limitsShape[0]);
  }
  if (!broadcastDeltas) {
    inSizes.push(deltasShape[0]);
  }
  for (let i = 1; i < inSizes.length; ++i) {
    if (inSizes[i] !== inSizes[i - 1]) {
      throw new Error("starts, limits, and deltas must have the same shape");
    }
  }
  const nRows = inSizes.length === 0 ? 1 : inSizes[0];
  const rtNestedSplits = util_exports.getArrayFromDType("int32", nRows + 1);
  rtNestedSplits[0] = 0;
  for (let row = 0; row < nRows; ++row) {
    const start = broadcastStarts ? starts[0] : starts[row];
    const limit = broadcastLimits ? limits[0] : limits[row];
    const delta = broadcastDeltas ? deltas[0] : deltas[row];
    if (delta === 0) {
      throw new Error("Requires delta != 0");
    }
    let size;
    if (delta > 0 && limit < start || delta < 0 && limit > start) {
      size = 0;
    } else {
      size = Math.ceil(Math.abs((limit - start) / delta));
      if (size > INT32_MAX) {
        throw new Error(`Requires ((limit - start) / delta) <= ${INT32_MAX}`);
      }
    }
    rtNestedSplits[row + 1] = rtNestedSplits[row] + size;
  }
  const nVals = rtNestedSplits[nRows];
  const rtDenseValues = util_exports.getArrayFromDType(startsDType, nVals);
  let valueIndex = 0;
  for (let row = 0; row < nRows; ++row) {
    const rowSize = rtNestedSplits[row + 1] - rtNestedSplits[row];
    let value = broadcastStarts ? starts[0] : starts[row];
    const delta = broadcastDeltas ? deltas[0] : deltas[row];
    for (let i = 0; i < rowSize; ++i) {
      rtDenseValues[valueIndex++] = value;
      value += delta;
    }
  }
  return [rtNestedSplits, rtDenseValues];
}
var INT32_MAX;
var init_RaggedRange_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js"() {
    init_dist();
    INT32_MAX = 2147483647;
  }
});
function copyArray(dst, src, size) {
  for (let i = 0; i < size; i++) {
    dst[i] = src[i];
  }
}
function makeShape(shape, isPartial) {
  const out = [];
  for (let dim of shape) {
    if (dim < 0) {
      if (!isPartial) {
        throw new Error(`Dimension ${dim} must be >= 0`);
      }
      if (dim < -1) {
        throw new Error(`Dimension ${dim} must be >= -1`);
      }
      dim = -1;
    }
    out.push(dim);
  }
  return out;
}
function raggedTensorToTensorImpl(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes) {
  return new RaggedTensorToTensorOp(shape, shapesShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes).compute();
}
var RowPartitionType2;
var RaggedTensorToTensorOp;
var init_RaggedTensorToTensor_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js"() {
    init_dist();
    RowPartitionType2 = backend_util_exports.RowPartitionType;
    RaggedTensorToTensorOp = class {
      constructor(shape, shapeShape, values, valuesShape, valuesDType, defaultValue, defaultValueShape, rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypeStrings) {
        this.shape = shape;
        this.shapeShape = shapeShape;
        this.values = values;
        this.valuesShape = valuesShape;
        this.valuesDType = valuesDType;
        this.defaultValue = defaultValue;
        this.defaultValueShape = defaultValueShape;
        this.rowPartitionValues = rowPartitionValues;
        this.rowPartitionValuesShapes = rowPartitionValuesShapes;
        this.rowPartitionTypes = backend_util_exports.getRowPartitionTypesHelper(rowPartitionTypeStrings);
        this.raggedRank = backend_util_exports.getRaggedRank(this.rowPartitionTypes);
      }
      getRowPartitionTypeByDimension(dimension) {
        if (this.rowPartitionTypes[0] === RowPartitionType2.FIRST_DIM_SIZE) {
          return this.rowPartitionTypes[dimension + 1];
        } else {
          return this.rowPartitionTypes[dimension];
        }
      }
      // Returns the relationship between dimension and dimension + 1.
      getRowPartitionTensor(dimension) {
        if (this.rowPartitionTypes[0] === RowPartitionType2.FIRST_DIM_SIZE) {
          return this.rowPartitionValues[dimension + 1];
        } else {
          return this.rowPartitionValues[dimension];
        }
      }
      getMaxWidth(dimension) {
        const rowPartitionTensor = this.getRowPartitionTensor(dimension - 1);
        switch (this.getRowPartitionTypeByDimension(dimension - 1)) {
          case RowPartitionType2.VALUE_ROWIDS:
            return RaggedTensorToTensorOp.getMaxWidthValueRowID(rowPartitionTensor);
          case RowPartitionType2.ROW_SPLITS:
            return RaggedTensorToTensorOp.getMaxWidthRowSplit(rowPartitionTensor);
          default:
            throw new Error(`Cannot handle partition type ${RowPartitionType2[this.getRowPartitionTypeByDimension(dimension - 1)]}`);
        }
      }
      static getMaxWidthRowSplit(rowSplit) {
        const tensorLength = rowSplit.length;
        if (tensorLength === 0 || tensorLength === 1) {
          return 0;
        }
        let maxWidth = 0;
        for (let i = 0; i < tensorLength - 1; ++i) {
          const currentWidth = rowSplit[i + 1] - rowSplit[i];
          if (currentWidth > maxWidth) {
            maxWidth = currentWidth;
          }
        }
        return maxWidth;
      }
      static getMaxWidthValueRowID(valueRowIds) {
        const indexLength = valueRowIds.length;
        if (indexLength === 0) {
          return 0;
        }
        let firstEqualIndex = 0;
        let firstEqualIndexValue = valueRowIds[0];
        let maxWidth = 0;
        for (let i = 1; i < indexLength; ++i) {
          const value = valueRowIds[i];
          if (value !== firstEqualIndexValue) {
            firstEqualIndexValue = value;
            maxWidth = Math.max(i - firstEqualIndex, maxWidth);
            firstEqualIndex = i;
          }
        }
        return Math.max(indexLength - firstEqualIndex, maxWidth);
      }
      tensorShapeFromTensor(t, tShape, isPartial = true) {
        if (tShape.length === 0) {
          if (t[0] === -1) {
            return [];
          }
          throw new Error(`The only valid scalar shape tensor is the fully unknown shape specified as -1.`);
        }
        return makeShape(t, isPartial);
      }
      calculateOutputSize(firstDim) {
        const valueShape = this.valuesShape;
        const defaultValueShape = this.defaultValueShape;
        backend_util_exports.validateDefaultValueShape(defaultValueShape, valueShape);
        const shape = this.tensorShapeFromTensor(this.shape, this.shapeShape);
        const outputShape = backend_util_exports.combineRaggedTensorToTensorShapes(this.raggedRank, shape, valueShape);
        const result = outputShape;
        if (result[0] < 0) {
          result[0] = firstDim;
        }
        for (let i = 1; i <= this.raggedRank; ++i) {
          if (result[i] < 0) {
            result[i] = this.getMaxWidth(i);
          }
        }
        return result;
      }
      /**
       * The outputIndex represents the index in the output tensor
       * where the first element of a particular dimension would be written.
       * If it is -1, it indicates that the index is out of scope.
       * Example, given firstDimension = 10, firstDimensionOutput = 6,
       * and outputIndexMultiplier = 100:
       * result = [0 100 200 300 400 500 -1 -1 -1 -1]
       * If firstDimensionOutput = 11 instead, then:
       * result = [0 100 200 300 400 500 600 700 800 900]
       */
      calculateFirstParentOutputIndex(firstDimension, outputIndexMultiplier, firstDimensionOutput) {
        const minDimension = Math.min(firstDimension, firstDimensionOutput);
        const result = [];
        let currentOutputIndex = 0;
        for (let i = 0; i < minDimension; ++i, currentOutputIndex += outputIndexMultiplier) {
          result.push(currentOutputIndex);
        }
        for (let i = minDimension; i < firstDimension; ++i) {
          result.push(-1);
        }
        util_exports.assert(result.length === firstDimension, () => "Final length of result must be equal to firstDimension.");
        return result;
      }
      calculateOutputIndexRowSplit(rowSplit, parentOutputIndex, outputIndexMultiplier, outputSize) {
        const rowSplitSize = rowSplit.length;
        const result = [];
        for (let i = 0; i < rowSplitSize - 1; ++i) {
          const rowLength = rowSplit[i + 1] - rowSplit[i];
          let realLength = Math.min(outputSize, rowLength);
          let parentOutputIndexCurrent = parentOutputIndex[i];
          if (parentOutputIndexCurrent === -1) {
            realLength = 0;
          }
          for (let j = 0; j < realLength; ++j) {
            result.push(parentOutputIndexCurrent);
            parentOutputIndexCurrent += outputIndexMultiplier;
          }
          for (let j = 0; j < rowLength - realLength; ++j) {
            result.push(-1);
          }
        }
        if (rowSplitSize > 0 && result.length !== rowSplit[rowSplitSize - 1]) {
          throw new Error("Invalid row split size.");
        }
        return result;
      }
      // Calculate the output index of the first element of a list.
      // The parentOutputIndex is the same computation for the previous list.
      // -1 indicates an element or list that is out of range.
      // The outputIndexMultiplier is the number of output indices one moves
      // forward for each column.
      // E.g., given:
      // valueRowIds:[0 1 2 2 2 3 5 5 6]
      // parentOutputIndex:[1000 1100 2000 2100 -1 3000 4000]
      // outputIndexMultiplier: 10
      // outputSize: 2
      // You get:
      // result = [1000 1100 2000 2010 -1 2100 -1 -1 3000]
      // result[0] = parentOutputIndex[valueRowIds[0]]
      // result[1] = parentOutputIndex[valueRowIds[1]]
      // result[2] = parentOutputIndex[valueRowIds[2]]
      // result[3] = parentOutputIndex[valueRowIds[2] + 10]
      // result[4] = -1 because it is the third element the size is 2.
      // result[5] = parentOutputIndex[valueRowIds[3]]
      // result[6] = -1 because parentOutputIndex[valueRowIds[6]] == -1
      // result[7] = -1 because parentOutputIndex[valueRowIds[6]] == -1
      // result[8] = parentOutputIndex[valueRowIds[7]]
      calculateOutputIndexValueRowID(valueRowIds, parentOutputIndex, outputIndexMultiplier, outputSize) {
        const indexSize = valueRowIds.length;
        const result = [];
        if (indexSize === 0) {
          return [];
        }
        let currentOutputColumn = 0;
        let currentValueRowId = valueRowIds[0];
        if (currentValueRowId >= parentOutputIndex.length) {
          throw new Error(`Got currentValueRowId=${currentValueRowId}, which is not less than ${parentOutputIndex.length}`);
        }
        let currentOutputIndex = parentOutputIndex[currentValueRowId];
        result.push(currentOutputIndex);
        for (let i = 1; i < indexSize; ++i) {
          const nextValueRowId = valueRowIds[i];
          if (nextValueRowId === currentValueRowId) {
            if (currentOutputIndex >= 0) {
              ++currentOutputColumn;
              if (currentOutputColumn < outputSize) {
                currentOutputIndex += outputIndexMultiplier;
              } else {
                currentOutputIndex = -1;
              }
            }
          } else {
            currentOutputColumn = 0;
            currentValueRowId = nextValueRowId;
            if (nextValueRowId >= parentOutputIndex.length) {
              throw new Error(`Got nextValueRowId=${nextValueRowId} which is not less than ${parentOutputIndex.length}`);
            }
            currentOutputIndex = parentOutputIndex[nextValueRowId];
          }
          result.push(currentOutputIndex);
        }
        if (result.length !== valueRowIds.length) {
          throw new Error("Invalid row ids.");
        }
        return result;
      }
      calculateOutputIndex(dimension, parentOutputIndex, outputIndexMultiplier, outputSize) {
        const rowPartitionTensor = this.getRowPartitionTensor(dimension);
        const partitionType = this.getRowPartitionTypeByDimension(dimension);
        switch (partitionType) {
          case RowPartitionType2.VALUE_ROWIDS:
            return this.calculateOutputIndexValueRowID(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
          case RowPartitionType2.ROW_SPLITS:
            if (rowPartitionTensor.length - 1 > parentOutputIndex.length) {
              throw new Error(`Row partition size is greater than output size: ${rowPartitionTensor.length - 1} > ${parentOutputIndex.length}`);
            }
            return this.calculateOutputIndexRowSplit(rowPartitionTensor, parentOutputIndex, outputIndexMultiplier, outputSize);
          default:
            throw new Error(`Unsupported partition type: ${RowPartitionType2[partitionType]}`);
        }
      }
      getFirstDimensionSize() {
        const firstPartitionTensor = this.rowPartitionValues[0];
        if (this.rowPartitionTypes.length === 0) {
          throw new Error("No row_partition_types given.");
        }
        const firstPartitionType = this.rowPartitionTypes[0];
        switch (firstPartitionType) {
          case RowPartitionType2.FIRST_DIM_SIZE:
            return firstPartitionTensor[0];
          case RowPartitionType2.VALUE_ROWIDS:
            throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
          case RowPartitionType2.ROW_SPLITS:
            return this.rowPartitionValuesShapes[0][0] - 1;
          default:
            throw new Error(`Cannot handle type ${RowPartitionType2[firstPartitionType]}`);
        }
      }
      compute() {
        const firstPartitionTensor = this.rowPartitionValues[0];
        if (firstPartitionTensor.length <= 0) {
          throw new Error("Invalid first partition input. Tensor requires at least one element.");
        }
        const firstDimension = this.getFirstDimensionSize();
        const outputSize = this.calculateOutputSize(firstDimension);
        const multiplier = new Array(this.raggedRank + 1);
        multiplier[multiplier.length - 1] = 1;
        for (let i = multiplier.length - 2; i >= 0; --i) {
          multiplier[i] = multiplier[i + 1] * outputSize[i + 1];
        }
        const outputShape = makeShape(outputSize, false);
        const outputTensor = util_exports.getArrayFromDType(this.valuesDType, util_exports.sizeFromShape(outputShape));
        const fullSize = multiplier[0] * outputSize[0];
        if (fullSize > 0) {
          let outputIndex = this.calculateFirstParentOutputIndex(firstDimension, multiplier[0], outputSize[0]);
          for (let i = 1; i <= this.raggedRank; ++i) {
            const newOutputIndex = this.calculateOutputIndex(i - 1, outputIndex, multiplier[i], outputSize[i]);
            outputIndex = newOutputIndex;
          }
          this.setOutput(this.raggedRank, outputIndex, outputTensor, outputShape);
        }
        return [outputShape, outputTensor];
      }
      setOutput(raggedRank, outputIndex, outputTensor, outputShape) {
        if (outputTensor.length === 0) {
          return;
        }
        const valuesBase = this.values;
        const outputBase = outputTensor;
        let elementShape = outputShape.slice();
        elementShape = elementShape.slice(raggedRank + 1);
        const valueElementSize = util_exports.sizeFromShape(elementShape);
        const outputIndexSize = outputIndex.length;
        let defaultValue = this.defaultValue;
        if (defaultValue.length !== valueElementSize && defaultValue.length !== 1) {
          const srcShape = this.defaultValueShape;
          tidy(() => {
            const defaultValueTensor = reshape(defaultValue, srcShape);
            const bCastDefault = broadcastTo(defaultValueTensor, elementShape);
            defaultValue = bCastDefault.dataSync();
          });
        }
        let srcStart = 0;
        let dstStart = 0;
        let dstEnd = 0;
        for (let srcI = 0; srcI <= outputIndexSize; ++srcI) {
          let dstI = srcI < outputIndexSize ? outputIndex[srcI] : -1;
          if (dstI === dstEnd) {
            ++dstEnd;
            continue;
          }
          if (dstStart < dstEnd) {
            const src = valuesBase.subarray(srcStart * valueElementSize);
            const dst = outputBase.subarray(dstStart * valueElementSize);
            const nVals = (dstEnd - dstStart) * valueElementSize;
            copyArray(dst, src, nVals);
          }
          if (srcI >= outputIndexSize) {
            const outputSize = outputTensor.length;
            dstI = Math.floor(outputSize / valueElementSize);
          }
          if (dstI > dstEnd) {
            if (this.defaultValue.length === 1) {
              outputBase.subarray(dstEnd * valueElementSize, dstI * valueElementSize).fill(this.defaultValue[0]);
              dstEnd = dstI;
            } else {
              while (dstI > dstEnd) {
                const dst = outputBase.slice(dstEnd * valueElementSize);
                copyArray(dst, defaultValue, valueElementSize);
                ++dstEnd;
              }
            }
          }
          if (dstI < 0) {
            srcStart = srcI + 1;
            dstStart = dstEnd;
          } else {
            srcStart = srcI;
            dstStart = dstEnd;
            dstEnd = dstStart + 1;
          }
        }
      }
    };
  }
});
function rangeImpl(start, stop, step4, dtype) {
  const sameStartStop = start === stop;
  const increasingRangeNegativeStep = start < stop && step4 < 0;
  const decreasingRangePositiveStep = stop < start && step4 > 1;
  if (sameStartStop || increasingRangeNegativeStep || decreasingRangePositiveStep) {
    return util_exports.makeZerosTypedArray(0, dtype);
  }
  const numElements = Math.abs(Math.ceil((stop - start) / step4));
  const values = util_exports.makeZerosTypedArray(numElements, dtype);
  if (stop < start && step4 === 1) {
    step4 = -1;
  }
  values[0] = start;
  for (let i = 1; i < values.length; i++) {
    values[i] = values[i - 1] + step4;
  }
  return values;
}
var init_Range_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js"() {
    init_dist();
  }
});
var rsqrtImpl;
var rsqrt2;
var rsqrtConfig;
var init_Rsqrt = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));
    rsqrt2 = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);
    rsqrtConfig = {
      kernelName: Rsqrt,
      backendName: "cpu",
      kernelFunc: rsqrt2
    };
  }
});
function scatterImpl(indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, defaultValue, sumDupeIndices) {
  const flattenShape = [outputSize / sliceSize, sliceSize];
  const indicesData = indices.values;
  const updatesData = updates.values;
  if (outputSize === 0) {
    return buffer(shape, updates.dtype);
  }
  const outBuf = buffer(flattenShape, updates.dtype);
  if (typeof defaultValue === "string") {
    outBuf.values.fill(defaultValue);
  } else if (typeof defaultValue === "number") {
    outBuf.values.fill(defaultValue);
  } else if (typeof defaultValue === "boolean") {
    outBuf.values.fill(+defaultValue);
  }
  for (let i = 0; i < numUpdates; i++) {
    const index = [];
    let flattenIndex = 0;
    for (let j = 0; j < sliceRank; j++) {
      const dim = indicesData[i * sliceRank + j];
      index.push(dim);
      flattenIndex += dim * strides[j];
    }
    if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {
      throw new Error(`Invalid indices: ${index} does not index into ${shape}`);
    }
    for (let k = 0; k < sliceSize; k++) {
      if (sumDupeIndices) {
        outBuf.values[flattenIndex * sliceSize + k] += updatesData[i * sliceSize + k];
      } else {
        outBuf.values[flattenIndex * sliceSize + k] = updates.rank === 0 ? updatesData[0] : updatesData[i * sliceSize + k];
      }
    }
  }
  return outBuf;
}
var init_Scatter_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js"() {
    init_dist();
  }
});
var sigmoidImpl;
var sigmoid2;
var sigmoidConfig;
var init_Sigmoid = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    sigmoidImpl = createSimpleUnaryImpl((xi) => 1 / (1 + Math.exp(-xi)));
    sigmoid2 = unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));
    sigmoidConfig = {
      kernelName: Sigmoid,
      backendName: "cpu",
      kernelFunc: sigmoid2
    };
  }
});
function sliceImpl(vals, begin, size, shape, dtype) {
  const isContinous = slice_util_exports.isSliceContinous(shape, begin, size);
  const length5 = util_exports.sizeFromShape(size);
  const xStrides = util_exports.computeStrides(shape);
  if (isContinous) {
    const flatOffset = slice_util_exports.computeFlatOffset(begin, xStrides);
    if (dtype === "string") {
      return vals.slice(flatOffset, flatOffset + length5);
    }
    return vals.subarray(flatOffset, flatOffset + length5);
  }
  const decodedData = dtype === "string" ? backend_util_exports.fromUint8ToStringArray(vals) : vals;
  const inBuf = buffer(shape, dtype, decodedData);
  const outBuf = buffer(size, dtype);
  for (let i = 0; i < outBuf.size; ++i) {
    const outLoc = outBuf.indexToLoc(i);
    const inLoc = outLoc.map((idx, j) => idx + begin[j]);
    outBuf.set(inBuf.get(...inLoc), ...outLoc);
  }
  if (dtype === "string") {
    return backend_util_exports.fromStringArrayToUint8(outBuf.values);
  }
  return outBuf.values;
}
function slice2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { begin, size } = attrs;
  assertNotComplex(x, "slice");
  const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size);
  slice_util_exports.assertParamsValid(x, $begin, $size);
  const vals = backend2.data.get(x.dataId).values;
  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);
  return backend2.makeTensorInfo($size, x.dtype, outVals);
}
var sliceConfig;
var init_Slice = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js"() {
    init_dist();
    init_cpu_util();
    sliceConfig = {
      kernelName: Slice,
      backendName: "cpu",
      kernelFunc: slice2
    };
  }
});
function sparseFillEmptyRowsImpl(indices, indicesShape, indicesDType, values, valuesDType, denseShape, defaultValue) {
  const indicesCount = indicesShape[0];
  const denseRows = denseShape[0];
  const emptyRowIndicator = new Array(denseRows);
  const reverseIndexMap = new Array(indicesCount);
  const rank = indicesShape[1];
  if (denseRows === 0) {
    if (indicesCount !== 0) {
      throw new Error(backend_util_exports.getSparseFillEmptyRowsIndicesDenseShapeMismatch(indicesCount));
    }
    const outputIndices = util_exports.getArrayFromDType(indicesDType, 0);
    const outputValues = util_exports.getArrayFromDType(valuesDType, 0);
    return [
      outputIndices,
      [0, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  }
  let rowsAreOrdered = true;
  let lastIndicesRow = 0;
  const csrOffset = new Array(denseRows).fill(0);
  for (let i = 0; i < indicesCount; ++i) {
    const row = indices[i * rank];
    if (row < 0) {
      throw new Error(backend_util_exports.getSparseFillEmptyRowsNegativeIndexErrorMessage(i, row));
    }
    if (row >= denseRows) {
      throw new Error(backend_util_exports.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(i, row, denseRows));
    }
    ++csrOffset[row];
    rowsAreOrdered = rowsAreOrdered && row >= lastIndicesRow;
    lastIndicesRow = row;
  }
  let allRowsFull = true;
  for (let row = 0; row < denseRows; ++row) {
    const rowEmpty = csrOffset[row] === 0;
    emptyRowIndicator[row] = rowEmpty;
    allRowsFull = allRowsFull && !rowEmpty;
    csrOffset[row] = Math.max(csrOffset[row], 1);
    if (row > 0) {
      csrOffset[row] += csrOffset[row - 1];
    }
  }
  if (allRowsFull && rowsAreOrdered) {
    const outputIndices = indices;
    const outputValues = values;
    for (let i = 0; i < indicesCount; ++i) {
      reverseIndexMap[i] = i;
    }
    return [
      outputIndices,
      [indicesCount, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  } else {
    const fullIndicesCount = csrOffset[denseRows - 1];
    const outputIndices = util_exports.getArrayFromDType(indicesDType, fullIndicesCount * rank);
    const outputValues = util_exports.getArrayFromDType(valuesDType, fullIndicesCount);
    const filledCount = new Array(denseRows).fill(0);
    for (let i = 0; i < indicesCount; ++i) {
      const row = indices[i * rank];
      const offset = filledCount[row];
      const outputI = (row === 0 ? 0 : csrOffset[row - 1]) + offset;
      filledCount[row]++;
      for (let j = 0; j < rank; ++j) {
        outputIndices[outputI * rank + j] = indices[i * rank + j];
      }
      outputValues[outputI] = values[i];
      reverseIndexMap[i] = outputI;
    }
    for (let row = 0; row < denseRows; ++row) {
      const rowCount = filledCount[row];
      if (rowCount === 0) {
        const startingIndex = row === 0 ? 0 : csrOffset[row - 1];
        outputIndices[startingIndex * rank + 0] = row;
        for (let col = 1; col < rank; ++col) {
          outputIndices[startingIndex * rank + col] = 0;
        }
        outputValues[startingIndex] = defaultValue;
      }
    }
    return [
      outputIndices,
      [fullIndicesCount, rank],
      outputValues,
      emptyRowIndicator,
      reverseIndexMap
    ];
  }
}
var init_SparseFillEmptyRows_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js"() {
    init_dist();
  }
});
function sparseReshapeImpl(inputIndices, inputIndicesShape, inputDType, inputShape, targetShape) {
  const denseSize = util_exports.sizeFromShape(inputShape);
  const nnz = inputIndicesShape[0];
  const outputRank = targetShape.length;
  const outputShape = [];
  let product = 1;
  let unknownIndex = -1;
  for (let d = 0; d < outputRank; ++d) {
    const size = targetShape[d];
    if (size === -1) {
      if (unknownIndex !== -1) {
        throw new Error(backend_util_exports.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(unknownIndex, d));
      }
      unknownIndex = d;
      outputShape.push(1);
    } else {
      if (size < 0) {
        throw new Error(backend_util_exports.getSparseReshapeNegativeOutputDimErrorMessage(d, size));
      }
      product *= size;
      outputShape.push(size);
    }
  }
  if (unknownIndex !== -1) {
    if (product <= 0) {
      throw new Error(backend_util_exports.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
    }
    const missing = Math.trunc(denseSize / product);
    if (product * missing !== denseSize) {
      throw new Error(backend_util_exports.getSparseReshapeInputOutputMultipleErrorMessage(inputShape, outputShape));
    }
    outputShape[unknownIndex] = missing;
  }
  const outputSize = util_exports.sizeFromShape(outputShape);
  if (outputSize !== denseSize) {
    throw new Error(backend_util_exports.getSparseReshapeInputOutputMismatchErrorMessage(inputShape, outputShape));
  }
  const inputRank = inputShape.length;
  const inputStrides = [];
  if (inputRank > 0) {
    inputStrides[inputRank - 1] = 1;
    for (let d = inputRank - 2; d >= 0; --d) {
      inputStrides[d] = inputStrides[d + 1] * inputShape[d + 1];
    }
  }
  const outputStrides = [];
  if (outputRank > 0) {
    outputStrides[outputRank - 1] = 1;
    for (let d = outputRank - 2; d >= 0; --d) {
      outputStrides[d] = outputStrides[d + 1] * outputShape[d + 1];
    }
  }
  const newIndices = util_exports.getArrayFromDType(inputDType, nnz * outputRank);
  for (let i = 0; i < nnz; ++i) {
    let id = 0;
    for (let j = 0; j < inputRank; ++j) {
      id += inputIndices[i * inputRank + j] * inputStrides[j];
    }
    for (let j = 0; j < outputRank; ++j) {
      newIndices[i * outputRank + j] = Math.trunc(id / outputStrides[j]);
      id %= outputStrides[j];
    }
  }
  return [newIndices, [nnz, outputRank], outputShape];
}
var init_SparseReshape_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js"() {
    init_dist();
  }
});
function sparseSegmentReductionImpl(input2, inputShape, inputDType, indices, segmentIds, isMean = false, defaultValue = 0) {
  const numIndices = indices.length;
  const inputFlat = [inputShape[0], input2.length / inputShape[0]];
  const numCol = inputFlat[1];
  const lastSegmentIdPlusOne = numIndices > 0 ? segmentIds[numIndices - 1] + 1 : 0;
  const outputRows = lastSegmentIdPlusOne;
  if (outputRows < 0) {
    throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
  }
  const outputShape = inputShape.slice();
  outputShape[0] = outputRows;
  const outputLength = outputShape.reduce((product, value) => product * value, 1);
  const output = util_exports.getArrayFromDType(inputDType, outputLength);
  if (numIndices === 0) {
    if (outputRows > 0) {
      output.fill(defaultValue);
    }
    return [output, outputShape];
  }
  if (outputRows <= 0) {
    throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
  }
  let start = 0, end = 1;
  let uninitializedIndex = 0;
  let outIndex = segmentIds[start];
  while (true) {
    let nextIndex = 0;
    if (end < numIndices) {
      nextIndex = segmentIds[end];
      if (outIndex === nextIndex) {
        ++end;
        continue;
      }
      if (outIndex >= nextIndex) {
        throw new Error(backend_util_exports.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
      }
    }
    if (outIndex < 0 || outIndex >= outputRows) {
      throw new Error(backend_util_exports.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(outIndex, outputRows));
    }
    if (outIndex > uninitializedIndex) {
      output.fill(defaultValue, uninitializedIndex * numCol, outIndex * numCol);
    }
    for (let i = start; i < end; ++i) {
      const index = indices[i];
      if (index < 0 || index >= inputFlat[0]) {
        throw new Error(backend_util_exports.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(i, indices[i], inputFlat[0]));
      }
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] += input2[index * numCol + j];
      }
    }
    if (isMean) {
      for (let j = 0; j < numCol; j++) {
        output[outIndex * numCol + j] /= end - start;
      }
    }
    start = end;
    ++end;
    uninitializedIndex = outIndex + 1;
    outIndex = nextIndex;
    if (end > numIndices) {
      break;
    }
  }
  if (uninitializedIndex < outputRows) {
    output.fill(defaultValue, uninitializedIndex * numCol, outputRows * numCol);
  }
  return [output, outputShape];
}
var init_SparseSegmentReduction_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js"() {
    init_dist();
  }
});
var sqrtImpl;
var sqrt2;
var sqrtConfig;
var init_Sqrt = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js"() {
    init_dist();
    init_unary_impl();
    init_unary_utils();
    sqrtImpl = createSimpleUnaryImpl((xi) => Math.sqrt(xi));
    sqrt2 = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));
    sqrtConfig = {
      kernelName: Sqrt,
      backendName: "cpu",
      kernelFunc: sqrt2
    };
  }
});
var squaredDifferenceImpl;
var squaredDifference2;
var squaredDifferenceConfig;
var init_SquaredDifference = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    squaredDifferenceImpl = createSimpleBinaryKernelImpl((a, b) => {
      const diff = a - b;
      return diff * diff;
    });
    squaredDifference2 = binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);
    squaredDifferenceConfig = {
      kernelName: SquaredDifference,
      backendName: "cpu",
      kernelFunc: squaredDifference2
    };
  }
});
function stridedSliceImpl(outShape, xBuf, strides, begin) {
  const outBuf = buffer(outShape, xBuf.dtype);
  for (let i = 0; i < outBuf.size; i++) {
    const loc = outBuf.indexToLoc(i);
    const newLoc = new Array(loc.length);
    for (let j = 0; j < newLoc.length; j++) {
      newLoc[j] = loc[j] * strides[j] + begin[j];
    }
    outBuf.set(xBuf.get(...newLoc), ...loc);
  }
  return outBuf;
}
var init_StridedSlice_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js"() {
    init_dist();
  }
});
function stringNGramsImpl(data, dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
  return new StringNGramsOp(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences).compute(data, dataSplits);
}
var StringNGramsOp;
var init_StringNGrams_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js"() {
    init_dist();
    StringNGramsOp = class {
      constructor(separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences) {
        this.separator = util_exports.encodeString(separator);
        this.nGramWidths = nGramWidths;
        this.leftPad = util_exports.encodeString(leftPad);
        this.rightPad = util_exports.encodeString(rightPad2);
        this.padWidth = padWidth;
        this.preserveShort = preserveShortSequences;
      }
      getPadWidth(nGramWidth) {
        return Math.min(this.padWidth < 0 ? nGramWidth - 1 : this.padWidth, nGramWidth - 1);
      }
      getNumNGrams(length5, nGramWidth) {
        const padWidth = this.getPadWidth(nGramWidth);
        return Math.max(0, length5 + 2 * padWidth - nGramWidth + 1);
      }
      createNGrams(data, splitIndex, output, outputStartIndex, numNGrams, nGramWidth) {
        for (let nGramIndex = 0; nGramIndex < numNGrams; ++nGramIndex) {
          const padWidth = this.getPadWidth(nGramWidth);
          const leftPadding = Math.max(0, padWidth - nGramIndex);
          const rightPadding = Math.max(0, padWidth - (numNGrams - (nGramIndex + 1)));
          const numTokens = nGramWidth - (leftPadding + rightPadding);
          const dataStartIndex = splitIndex + (leftPadding > 0 ? 0 : nGramIndex - padWidth);
          let nGramSize = 0;
          nGramSize += leftPadding * this.leftPad.length;
          for (let n = 0; n < numTokens; ++n) {
            nGramSize += data[dataStartIndex + n].length;
          }
          nGramSize += rightPadding * this.rightPad.length;
          const numSeparators = leftPadding + rightPadding + numTokens - 1;
          nGramSize += numSeparators * this.separator.length;
          output[outputStartIndex + nGramIndex] = new Uint8Array(nGramSize);
          const nGram = output[outputStartIndex + nGramIndex];
          let nextNGramIndex = 0;
          const appendToNGram = (str5) => str5.forEach((value) => nGram[nextNGramIndex++] = value);
          for (let n = 0; n < leftPadding; ++n) {
            appendToNGram(this.leftPad);
            appendToNGram(this.separator);
          }
          for (let n = 0; n < numTokens - 1; ++n) {
            appendToNGram(data[dataStartIndex + n]);
            appendToNGram(this.separator);
          }
          if (numTokens > 0) {
            appendToNGram(data[dataStartIndex + numTokens - 1]);
            for (let n = 0; n < rightPadding; ++n) {
              appendToNGram(this.separator);
              appendToNGram(this.rightPad);
            }
          } else {
            for (let n = 0; n < rightPadding - 1; ++n) {
              appendToNGram(this.rightPad);
              appendToNGram(this.separator);
            }
            appendToNGram(this.rightPad);
          }
        }
      }
      // Data and splits together form the definition of the ragged tensor,
      // where data is 1 dimensional and contains the values of the tensor
      // and splits denotes the indices at which each row starts.
      compute(data, splits) {
        const inputDataSize = data.length;
        const splitsSize = splits.length;
        if (splitsSize > 0) {
          let prevSplit = splits[0];
          if (prevSplit !== 0) {
            throw new Error(`First split value must be 0, got ${prevSplit}`);
          }
          for (let i = 1; i < splitsSize; ++i) {
            let validSplits = splits[i] >= prevSplit;
            validSplits = validSplits && splits[i] <= inputDataSize;
            if (!validSplits) {
              throw new Error(`Invalid split value ${splits[i]}, must be in [${prevSplit}, ${inputDataSize}]`);
            }
            prevSplit = splits[i];
          }
          if (prevSplit !== inputDataSize) {
            throw new Error(`Last split value must be data size. Expected ${inputDataSize}, got ${prevSplit}`);
          }
        }
        const numBatchItems = splitsSize - 1;
        const nGramsSplits = util_exports.getArrayFromDType("int32", splitsSize);
        if (inputDataSize === 0 || splitsSize === 0) {
          const empty = new Array(inputDataSize);
          for (let i = 0; i <= numBatchItems; ++i) {
            nGramsSplits[i] = 0;
          }
          return [empty, nGramsSplits];
        }
        nGramsSplits[0] = 0;
        for (let i = 1; i <= numBatchItems; ++i) {
          const length5 = splits[i] - splits[i - 1];
          let numNGrams = 0;
          this.nGramWidths.forEach((nGramWidth) => {
            numNGrams += this.getNumNGrams(length5, nGramWidth);
          });
          if (this.preserveShort && length5 > 0 && numNGrams === 0) {
            numNGrams = 1;
          }
          nGramsSplits[i] = nGramsSplits[i - 1] + numNGrams;
        }
        const nGrams = new Array(nGramsSplits[numBatchItems]);
        for (let i = 0; i < numBatchItems; ++i) {
          const splitIndex = splits[i];
          let outputStartIdx = nGramsSplits[i];
          this.nGramWidths.forEach((nGramWidth) => {
            const length5 = splits[i + 1] - splits[i];
            const numNGrams = this.getNumNGrams(length5, nGramWidth);
            this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
            outputStartIdx += numNGrams;
          });
          if (this.preserveShort && outputStartIdx === nGramsSplits[i]) {
            const dataLength = splits[i + 1] - splits[i];
            if (dataLength === 0) {
              continue;
            }
            const nGramWidth = dataLength + 2 * this.padWidth;
            const numNGrams = 1;
            this.createNGrams(data, splitIndex, nGrams, outputStartIdx, numNGrams, nGramWidth);
          }
        }
        return [nGrams, nGramsSplits];
      }
    };
  }
});
function split3(str5, delimiters, skipEmpty, result) {
  if (!str5.length) {
    return;
  }
  if (delimiters.length === 0) {
    for (let i = 0; i < str5.length; ++i) {
      result.push(str5.subarray(i, i + 1));
    }
    return;
  }
  if (delimiters.length === 1) {
    const delimiter = delimiters[0];
    let f = str5.indexOf(delimiter);
    while (f !== -1) {
      const token = str5.subarray(0, f);
      if (!skipEmpty || token.length !== 0) {
        result.push(token);
      }
      str5 = str5.subarray(f + 1);
      f = str5.indexOf(delimiter);
    }
    if (!skipEmpty || str5.length !== 0) {
      result.push(str5);
    }
    return;
  }
  let tokenStart = 0;
  for (let i = 0; i < str5.length + 1; i++) {
    if (i === str5.length || delimiters.indexOf(str5[i]) !== -1) {
      const token = str5.subarray(tokenStart, i);
      if (!skipEmpty || token.length !== 0) {
        result.push(token);
      }
      tokenStart = i + 1;
    }
  }
}
function stringSplitImpl(input2, delimiter, skipEmpty) {
  const batchSize = input2.length;
  const tokens = [];
  let outputSize = 0;
  let maxNumEntries = 0;
  const numIndices = new Array(batchSize);
  for (let i = 0; i < batchSize; ++i) {
    const prevTokensLength = tokens.length;
    split3(input2[i], delimiter, skipEmpty, tokens);
    const nEntries = tokens.length - prevTokensLength;
    numIndices[i] = nEntries;
    outputSize += nEntries;
    maxNumEntries = Math.max(maxNumEntries, nEntries);
  }
  const indices = util_exports.getArrayFromDType("int32", outputSize * 2);
  const values = new Array(outputSize);
  const shape = [batchSize, maxNumEntries];
  let c = 0;
  for (let i = 0; i < batchSize; ++i) {
    for (let j = 0; j < numIndices[i]; ++j) {
      indices[c * 2] = i;
      indices[c * 2 + 1] = j;
      values[c] = tokens[c];
      ++c;
    }
  }
  return [indices, values, shape];
}
var init_StringSplit_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js"() {
    init_dist();
  }
});
function stringToHashBucketFastImpl(input2, numBuckets) {
  const output = util_exports.getArrayFromDType("int32", input2.length);
  for (let i = 0; i < input2.length; ++i) {
    output[i] = util_exports.fingerPrint64(input2[i]).modulo(numBuckets).getLowBitsUnsigned();
  }
  return output;
}
var init_StringToHashBucketFast_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js"() {
    init_dist();
  }
});
var subImpl;
var subComplexImpl;
var sub22;
var subConfig;
var init_Sub = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    subImpl = createSimpleBinaryKernelImpl((aValue, bValue) => aValue - bValue);
    subComplexImpl = createComplexBinaryKernelImpl((aReal, aImag, bReal, bImag) => {
      return { real: aReal - bReal, imag: aImag - bImag };
    });
    sub22 = binaryKernelFunc(Sub, subImpl, subComplexImpl);
    subConfig = {
      kernelName: Sub,
      backendName: "cpu",
      kernelFunc: sub22
    };
  }
});
function tileImpl(xBuf, reps) {
  const newShape = new Array(xBuf.rank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = xBuf.shape[i] * reps[i];
  }
  const result = buffer(newShape, xBuf.dtype);
  for (let i = 0; i < result.values.length; ++i) {
    const newLoc = result.indexToLoc(i);
    const originalLoc = new Array(xBuf.rank);
    for (let j = 0; j < originalLoc.length; j++) {
      originalLoc[j] = newLoc[j] % xBuf.shape[j];
    }
    const originalIndex = xBuf.locToIndex(originalLoc);
    result.values[i] = xBuf.values[originalIndex];
  }
  return result;
}
var init_Tile_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js"() {
    init_dist();
  }
});
function select(array2, k, left = 0, right = array2.length - 1) {
  while (right > left) {
    if (right - left > 600) {
      const n = right - left + 1;
      const i2 = k - left + 1;
      const z = Math.log(n);
      const s = 0.5 * Math.exp(2 * z / 3);
      const sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * Math.sign(i2 - n / 2);
      const newLeft = Math.max(left, Math.floor(k - i2 * s / n + sd));
      const newRight = Math.min(right, Math.floor(k + (n - i2) * s / n + sd));
      select(array2, k, newLeft, newRight);
    }
    const t = array2[k];
    let i = left;
    let j = right;
    util_exports.swap(array2, left, k);
    if (comparePair(array2[right], t) > 0) {
      util_exports.swap(array2, left, right);
    }
    while (i < j) {
      util_exports.swap(array2, i, j);
      i++;
      j--;
      while (comparePair(array2[i], t) < 0) {
        i = i + 1;
      }
      while (comparePair(array2[j], t) > 0) {
        j = j - 1;
      }
    }
    if (comparePair(array2[left], t) === 0) {
      util_exports.swap(array2, left, j);
    } else {
      j = j + 1;
      util_exports.swap(array2, j, right);
    }
    if (j <= k) {
      left = j + 1;
    }
    if (k <= j) {
      right = j - 1;
    }
  }
}
function topKImpl(x, xShape, xDtype, k, sorted) {
  const lastDim = xShape[xShape.length - 1];
  const [batch, size] = [x.length / lastDim, lastDim];
  const allTopKVals = util_exports.getTypedArrayFromDType(xDtype, batch * k);
  const allTopKIndices = util_exports.getTypedArrayFromDType("int32", batch * k);
  for (let b = 0; b < batch; b++) {
    const offset = b * size;
    const vals = x.subarray(offset, offset + size);
    let valAndInd = new Array(vals.length);
    vals.forEach((value, index) => valAndInd[index] = { value, index });
    if (k < valAndInd.length) {
      select(valAndInd, k);
      valAndInd = valAndInd.slice(0, k);
    }
    if (sorted) {
      valAndInd.sort(comparePair);
    }
    const outOffset = b * k;
    const topKVals = allTopKVals.subarray(outOffset, outOffset + k);
    const topKIndices = allTopKIndices.subarray(outOffset, outOffset + k);
    for (let i = 0; i < k; i++) {
      topKVals[i] = valAndInd[i].value;
      topKIndices[i] = valAndInd[i].index;
    }
  }
  const outputShape = xShape.slice();
  outputShape[outputShape.length - 1] = k;
  return [
    buffer(outputShape, xDtype, allTopKVals),
    buffer(outputShape, "int32", allTopKIndices)
  ];
}
var comparePair;
var init_TopK_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js"() {
    init_dist();
    comparePair = (a, b) => {
      const valueDiff = b.value - a.value;
      return valueDiff === 0 ? a.index - b.index : valueDiff;
    };
  }
});
function uniqueImpl(values, axis, shape, dtype) {
  const $axis = util_exports.parseAxisParam(axis, shape)[0];
  const newShape = [1, shape[0], 1];
  for (let i = 0; i < $axis; i++) {
    newShape[0] *= shape[i];
  }
  newShape[1] = shape[$axis];
  for (let i = $axis + 1; i < shape.length; i++) {
    newShape[2] *= shape[i];
  }
  const uniqueElements = {};
  const indices = new Int32Array(shape[$axis]);
  const inputBuffer = new TensorBuffer(newShape, dtype, values);
  const uniqueIndices = [];
  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;
  for (let i = 0; i < shape[$axis]; i++) {
    let element;
    if (is1DTensor) {
      element = values[i].toString();
    } else {
      const axisValues = [];
      for (let m = 0; m < newShape[0]; m++) {
        for (let n = 0; n < newShape[2]; n++) {
          axisValues.push(inputBuffer.get(m, i, n));
        }
      }
      element = axisValues.join(",");
    }
    if (uniqueElements[element] !== void 0) {
      indices[i] = uniqueElements[element];
    } else {
      const uniqueIndex = Object.keys(uniqueElements).length;
      uniqueElements[element] = uniqueIndex;
      indices[i] = uniqueIndex;
      uniqueIndices.push(i);
    }
  }
  const outputTmpShape = newShape.slice();
  outputTmpShape[1] = Object.keys(uniqueElements).length;
  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);
  uniqueIndices.forEach((uniqueElementIndex, i) => {
    for (let m = 0; m < newShape[0]; m++) {
      for (let n = 0; n < newShape[2]; n++) {
        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);
      }
    }
  });
  const outputShape = shape.slice();
  outputShape[$axis] = outputTmpShape[1];
  return {
    outputValues: outputBuffer.values,
    outputShape,
    indices
  };
}
var init_Unique_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js"() {
    init_dist();
  }
});
var shared_exports = {};
__export2(shared_exports, {
  addImpl: () => addImpl,
  bincountImpl: () => bincountImpl,
  bincountReduceImpl: () => bincountReduceImpl,
  castImpl: () => castImpl,
  ceilImpl: () => ceilImpl,
  concatImpl: () => concatImpl,
  equalImpl: () => equalImpl,
  expImpl: () => expImpl,
  expm1Impl: () => expm1Impl,
  floorImpl: () => floorImpl,
  gatherNdImpl: () => gatherNdImpl,
  gatherV2Impl: () => gatherV2Impl,
  greaterEqualImpl: () => greaterEqualImpl,
  greaterImpl: () => greaterImpl,
  lessEqualImpl: () => lessEqualImpl,
  lessImpl: () => lessImpl,
  linSpaceImpl: () => linSpaceImpl,
  logImpl: () => logImpl,
  maxImpl: () => maxImpl,
  maximumImpl: () => maximumImpl,
  minimumImpl: () => minimumImpl,
  multiplyImpl: () => multiplyImpl,
  negImpl: () => negImpl,
  notEqualImpl: () => notEqualImpl,
  prodImpl: () => prodImpl,
  raggedGatherImpl: () => raggedGatherImpl,
  raggedRangeImpl: () => raggedRangeImpl,
  raggedTensorToTensorImpl: () => raggedTensorToTensorImpl,
  rangeImpl: () => rangeImpl,
  rsqrtImpl: () => rsqrtImpl,
  scatterImpl: () => scatterImpl,
  sigmoidImpl: () => sigmoidImpl,
  simpleAbsImpl: () => simpleAbsImpl,
  sliceImpl: () => sliceImpl,
  sparseFillEmptyRowsImpl: () => sparseFillEmptyRowsImpl,
  sparseReshapeImpl: () => sparseReshapeImpl,
  sparseSegmentReductionImpl: () => sparseSegmentReductionImpl,
  sqrtImpl: () => sqrtImpl,
  squaredDifferenceImpl: () => squaredDifferenceImpl,
  stridedSliceImpl: () => stridedSliceImpl,
  stringNGramsImpl: () => stringNGramsImpl,
  stringSplitImpl: () => stringSplitImpl,
  stringToHashBucketFastImpl: () => stringToHashBucketFastImpl,
  subImpl: () => subImpl,
  tileImpl: () => tileImpl,
  topKImpl: () => topKImpl,
  transposeImpl: () => transposeImpl,
  uniqueImpl: () => uniqueImpl
});
var init_shared = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/shared.js"() {
    init_Abs();
    init_Add();
    init_Bincount_impl();
    init_Cast();
    init_Ceil();
    init_Concat_impl();
    init_Equal();
    init_Exp();
    init_Expm1();
    init_Floor();
    init_GatherNd_Impl();
    init_GatherV2_impl();
    init_Greater();
    init_GreaterEqual();
    init_Less();
    init_LessEqual();
    init_LinSpace_impl();
    init_Log();
    init_Max_impl();
    init_Maximum();
    init_Minimum();
    init_Multiply();
    init_Neg();
    init_NotEqual();
    init_Prod();
    init_RaggedGather_impl();
    init_RaggedRange_impl();
    init_RaggedTensorToTensor_impl();
    init_Range_impl();
    init_Rsqrt();
    init_Scatter_impl();
    init_Sigmoid();
    init_Slice();
    init_SparseFillEmptyRows_impl();
    init_SparseReshape_impl();
    init_SparseSegmentReduction_impl();
    init_Sqrt();
    init_SquaredDifference();
    init_StridedSlice_impl();
    init_StringNGrams_impl();
    init_StringSplit_impl();
    init_StringToHashBucketFast_impl();
    init_Sub();
    init_Tile_impl();
    init_TopK_impl();
    init_Transpose_impl();
    init_Unique_impl();
  }
});
var init_base2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/base.js"() {
    init_dist();
    init_backend_cpu();
    registerBackend(
      "cpu",
      () => new MathBackendCPU(),
      1
      /* priority */
    );
  }
});
var elu3;
var eluConfig;
var init_Elu = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js"() {
    init_dist();
    init_unary_utils();
    elu3 = unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : Math.exp(xi) - 1);
    eluConfig = {
      kernelName: Elu,
      backendName: "cpu",
      kernelFunc: elu3
    };
  }
});
function leakyRelu2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { alpha } = attrs;
  assertNotComplex([x], "leakyRelu");
  const xSize = util_exports.sizeFromShape(x.shape);
  const xVals = backend2.data.get(x.dataId).values;
  const outVals = util_exports.getTypedArrayFromDType("float32", xSize);
  for (let i = 0; i < xVals.length; i++) {
    outVals[i] = xVals[i] < 0 ? alpha * xVals[i] : xVals[i];
  }
  return backend2.makeTensorInfo(x.shape, "float32", outVals);
}
var leakyReluConfig;
var init_LeakyRelu = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js"() {
    init_dist();
    init_cpu_util();
    leakyReluConfig = {
      kernelName: LeakyRelu,
      backendName: "cpu",
      kernelFunc: leakyRelu2
    };
  }
});
function prelu2(args) {
  const { inputs, backend: backend2 } = args;
  const { x, alpha } = inputs;
  assertNotComplex([x, alpha], "prelu");
  const aVals = backend2.data.get(x.dataId).values;
  const bVals = backend2.data.get(alpha.dataId).values;
  const [resultData, resultShape] = preluImpl(x.shape, alpha.shape, aVals, bVals, "float32");
  return backend2.makeTensorInfo(resultShape, "float32", resultData);
}
var preluImpl;
var preluConfig;
var init_Prelu = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js"() {
    init_dist();
    init_cpu_util();
    init_binary_impl();
    preluImpl = createSimpleBinaryKernelImpl((xValue, aValue) => xValue < 0 ? aValue * xValue : xValue);
    preluConfig = {
      kernelName: Prelu,
      backendName: "cpu",
      kernelFunc: prelu2
    };
  }
});
var relu2;
var reluConfig;
var init_Relu = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js"() {
    init_dist();
    init_unary_utils();
    relu2 = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));
    reluConfig = {
      kernelName: Relu,
      backendName: "cpu",
      kernelFunc: relu2
    };
  }
});
var relu62;
var relu6Config;
var init_Relu6 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js"() {
    init_dist();
    init_unary_utils();
    relu62 = unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));
    relu6Config = {
      kernelName: Relu6,
      backendName: "cpu",
      kernelFunc: relu62
    };
  }
});
function applyActivation2(backend2, x, activation, preluActivationWeights, leakyreluAlpha) {
  if (activation === "linear") {
    return identity4({ inputs: { x }, backend: backend2 });
  } else if (activation === "relu") {
    return relu2({ inputs: { x }, backend: backend2 });
  } else if (activation === "elu") {
    return elu3({ inputs: { x }, backend: backend2 });
  } else if (activation === "relu6") {
    return relu62({ inputs: { x }, backend: backend2 });
  } else if (activation === "prelu") {
    return prelu2({ inputs: { x, alpha: preluActivationWeights }, backend: backend2 });
  } else if (activation === "leakyrelu") {
    return leakyRelu2({ inputs: { x }, backend: backend2, attrs: { alpha: leakyreluAlpha } });
  } else if (activation === "sigmoid") {
    return sigmoid2({ inputs: { x }, backend: backend2 });
  }
  throw new Error(`Activation ${activation} has not been implemented for the CPU backend.`);
}
var init_fused_utils = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js"() {
    init_Elu();
    init_Identity();
    init_LeakyRelu();
    init_Prelu();
    init_Relu();
    init_Relu6();
    init_Sigmoid();
  }
});
function reshape2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { shape } = attrs;
  const xSize = util_exports.sizeFromShape(x.shape);
  const $shape = util_exports.inferFromImplicitShape(shape, xSize);
  const $xSize = util_exports.sizeFromShape($shape);
  util_exports.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
  backend2.incRef(x.dataId);
  const xData = backend2.data.get(x.dataId);
  if (xData.complexTensorInfos != null) {
    const real4 = xData.complexTensorInfos.real;
    const imag4 = xData.complexTensorInfos.imag;
    real4.shape = $shape;
    imag4.shape = $shape;
  }
  return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
}
var reshapeConfig;
var init_Reshape = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js"() {
    init_dist();
    reshapeConfig = {
      kernelName: Reshape,
      backendName: "cpu",
      kernelFunc: reshape2
    };
  }
});
function batchMatMul(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { a, b } = inputs;
  const { transposeA, transposeB } = attrs;
  assertNotComplex([a, b], "matMul");
  const aRank = a.shape.length;
  const bRank = b.shape.length;
  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
  const outerDimsA = a.shape.slice(0, -2);
  const outerDimsB = b.shape.slice(0, -2);
  const batchDimA = util_exports.sizeFromShape(outerDimsA);
  const batchDimB = util_exports.sizeFromShape(outerDimsB);
  const outShapeOuterDims = broadcast_util_exports.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  util_exports.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
  const a3d = reshape2({ inputs: { x: a }, backend: backend2, attrs: { shape: a3dShape } });
  const b3d = reshape2({ inputs: { x: b }, backend: backend2, attrs: { shape: b3dShape } });
  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];
  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];
  const batchDim = Math.max(batchDimA, batchDimB);
  const a3dValues = backend2.data.get(a3d.dataId).values;
  const b3dValues = backend2.data.get(b3d.dataId).values;
  const a3dStrides = util_exports.computeStrides(a3d.shape);
  const b3dStrides = util_exports.computeStrides(b3d.shape);
  const [aBatch, aOuterStep, aInnerStep] = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1];
  const [bInnerStep, bOuterStep, bBatch] = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]];
  const size = leftDim * rightDim;
  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);
  const resVals = result.values;
  const blockSize = backend2.blockSize;
  for (let bi = 0; bi < batchDim; bi++) {
    const batchIndexA = bi % batchDimA;
    const batchIndexB = bi % batchDimB;
    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {
      const iBlock = Math.min(i0 + blockSize, leftDim);
      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {
        const jBlock = Math.min(j0 + blockSize, rightDim);
        for (let k02 = 0; k02 < sharedDim; k02 += blockSize) {
          const kBlock = Math.min(k02 + blockSize, sharedDim);
          for (let i = i0; i < iBlock; i++) {
            for (let j = j0; j < jBlock; j++) {
              let sum5 = 0;
              for (let k = k02; k < kBlock; k++) {
                const aVal = (
                  // tslint:disable-next-line: max-line-length
                  a3dValues[batchIndexA * aBatch + i * aOuterStep + k * aInnerStep]
                );
                const bVal = (
                  // tslint:disable-next-line: max-line-length
                  b3dValues[k * bInnerStep + j * bOuterStep + batchIndexB * bBatch]
                );
                sum5 += aVal * bVal;
              }
              resVals[bi * size + (i * rightDim + j)] += sum5;
            }
          }
        }
      }
    }
  }
  backend2.disposeIntermediateTensorInfo(a3d);
  backend2.disposeIntermediateTensorInfo(b3d);
  return backend2.makeTensorInfo(outShape, result.dtype, result.values);
}
var batchMatMulConfig;
var init_BatchMatMul = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js"() {
    init_dist();
    init_cpu_util();
    init_Reshape();
    batchMatMulConfig = {
      kernelName: BatchMatMul,
      backendName: "cpu",
      kernelFunc: batchMatMul
    };
  }
});
function _fusedMatMul(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { a, b, bias, preluActivationWeights } = inputs;
  const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
  let current;
  let addRes;
  let activationRes;
  const intermediates = [];
  const matMulRes = batchMatMul({ inputs: { a, b }, attrs: { transposeA, transposeB }, backend: backend2 });
  current = matMulRes;
  if (bias) {
    addRes = add32({ inputs: { a: current, b: bias }, backend: backend2 });
    intermediates.push(current);
    current = addRes;
  }
  if (activation) {
    activationRes = applyActivation2(backend2, current, activation, preluActivationWeights, leakyreluAlpha);
    intermediates.push(current);
    current = activationRes;
  }
  for (const i of intermediates) {
    backend2.disposeIntermediateTensorInfo(i);
  }
  return current;
}
var _fusedMatMulConfig;
var init_FusedMatMul = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js"() {
    init_dist();
    init_fused_utils();
    init_Add();
    init_BatchMatMul();
    _fusedMatMulConfig = {
      kernelName: _FusedMatMul,
      backendName: "cpu",
      kernelFunc: _fusedMatMul
    };
  }
});
var acos2;
var acosConfig;
var init_Acos = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js"() {
    init_dist();
    init_unary_utils();
    acos2 = unaryKernelFunc(Acos, (xi) => Math.acos(xi));
    acosConfig = {
      kernelName: Acos,
      backendName: "cpu",
      kernelFunc: acos2
    };
  }
});
var acosh2;
var acoshConfig;
var init_Acosh = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js"() {
    init_dist();
    init_unary_utils();
    acosh2 = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));
    acoshConfig = {
      kernelName: Acosh,
      backendName: "cpu",
      kernelFunc: acosh2
    };
  }
});
function addN(args) {
  const { inputs, backend: backend2 } = args;
  const tensors = inputs;
  assertNotComplex(inputs, "addN");
  const vals = tensors.map((t) => backend2.data.get(t.dataId).values);
  const outBuf = buffer(tensors[0].shape, tensors[0].dtype);
  const outVals = outBuf.values;
  for (let i = 0; i < tensors.length; i++) {
    const currVals = vals[i];
    for (let j = 0; j < outVals.length; j++) {
      outVals[j] += currVals[j];
    }
  }
  return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
}
var addNConfig;
var init_AddN = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js"() {
    init_dist();
    init_cpu_util();
    addNConfig = {
      kernelName: AddN,
      backendName: "cpu",
      kernelFunc: addN
    };
  }
});
function all2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "all");
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  if (permutedAxes != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("all", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
  const aVals = backend2.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let all4 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      all4 = all4 && value;
    }
    vals[i] = all4;
  }
  if (permutedAxes != null) {
    backend2.disposeIntermediateTensorInfo($x);
  }
  const result = backend2.makeTensorInfo(outShape, $x.dtype, vals);
  if (keepDims) {
    const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
    const reshapedResult = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: expandedShape } });
    backend2.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  return result;
}
var allConfig;
var init_All = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/All.js"() {
    init_dist();
    init_cpu_util();
    init_Reshape();
    init_Transpose();
    allConfig = {
      kernelName: All,
      backendName: "cpu",
      kernelFunc: all2
    };
  }
});
function any2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "any");
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  if (permutedAxes != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("any", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
  const aVals = backend2.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let anyVal = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      anyVal = anyVal || value;
    }
    vals[i] = anyVal;
  }
  if (permutedAxes != null) {
    backend2.disposeIntermediateTensorInfo($x);
  }
  const result = backend2.makeTensorInfo(outShape, $x.dtype, vals);
  if (keepDims) {
    const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
    const reshapedResult = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: expandedShape } });
    backend2.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  return result;
}
var anyConfig;
var init_Any = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Any.js"() {
    init_dist();
    init_cpu_util();
    init_Reshape();
    init_Transpose();
    anyConfig = {
      kernelName: Any,
      backendName: "cpu",
      kernelFunc: any2
    };
  }
});
function argMax2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  assertNotComplex(x, "argMax");
  let axes = util_exports.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
  }
  axes = [axes[0]];
  backend_util_exports.assertAxesAreInnerMostDims("argMax", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
  const outSize = util_exports.sizeFromShape(outShape);
  const vals = util_exports.makeZerosTypedArray(outSize, "int32");
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const aVals = backend2.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let max5 = aVals[offset];
    let maxIndex = 0;
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (value > max5) {
        max5 = value;
        maxIndex = j;
      }
    }
    vals[i] = maxIndex;
  }
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return backend2.makeTensorInfo(outShape, "int32", vals);
}
var argMaxConfig;
var init_ArgMax = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js"() {
    init_dist();
    init_cpu_util();
    init_Transpose();
    argMaxConfig = {
      kernelName: ArgMax,
      backendName: "cpu",
      kernelFunc: argMax2
    };
  }
});
function argMin2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  assertNotComplex(x, "argMin");
  let axes = util_exports.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
  }
  axes = [axes[0]];
  backend_util_exports.assertAxesAreInnerMostDims("argMin", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
  const outSize = util_exports.sizeFromShape(outShape);
  const vals = util_exports.makeZerosTypedArray(outSize, "int32");
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const aVals = backend2.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let min5 = aVals[offset];
    let minIndex = 0;
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (value < min5) {
        min5 = value;
        minIndex = j;
      }
    }
    vals[i] = minIndex;
  }
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return backend2.makeTensorInfo(outShape, "int32", vals);
}
var argMinConfig;
var init_ArgMin = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js"() {
    init_dist();
    init_cpu_util();
    init_Transpose();
    argMinConfig = {
      kernelName: ArgMin,
      backendName: "cpu",
      kernelFunc: argMin2
    };
  }
});
var asin2;
var asinConfig;
var init_Asin = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js"() {
    init_dist();
    init_unary_utils();
    asin2 = unaryKernelFunc(Asin, (xi) => Math.asin(xi));
    asinConfig = {
      kernelName: Asin,
      backendName: "cpu",
      kernelFunc: asin2
    };
  }
});
var asinh2;
var asinhConfig;
var init_Asinh = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js"() {
    init_dist();
    init_unary_utils();
    asinh2 = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));
    asinhConfig = {
      kernelName: Asinh,
      backendName: "cpu",
      kernelFunc: asinh2
    };
  }
});
var atan3;
var atanConfig;
var init_Atan = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js"() {
    init_dist();
    init_unary_utils();
    atan3 = unaryKernelFunc(Atan, (xi) => Math.atan(xi));
    atanConfig = {
      kernelName: Atan,
      backendName: "cpu",
      kernelFunc: atan3
    };
  }
});
var atan2Impl;
var atan22;
var atan2Config;
var init_Atan2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    atan2Impl = createSimpleBinaryKernelImpl((aValue, bValue) => Math.atan2(aValue, bValue));
    atan22 = binaryKernelFunc(Atan2, atan2Impl);
    atan2Config = {
      kernelName: Atan2,
      backendName: "cpu",
      kernelFunc: atan22
    };
  }
});
var atanh2;
var atanhConfig;
var init_Atanh = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js"() {
    init_dist();
    init_unary_utils();
    atanh2 = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));
    atanhConfig = {
      kernelName: Atanh,
      backendName: "cpu",
      kernelFunc: atanh2
    };
  }
});
function pool2(xValues, xShape, dtype, strides, convInfo, poolType) {
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
  const output = buffer(convInfo.outShape, dtype);
  const outputVals = output.values;
  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];
  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];
  const outputColStrides = convInfo.outShape[3];
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const outputBatchOffset = b * outputBatchStrides;
    const inputBatchOffset = b * strides[0];
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const xRCorner = yR * strideHeight - padTop;
        const xRMin = Math.max(0, xRCorner);
        const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const xCCorner = yC * strideWidth - padLeft;
          const xCMin = Math.max(0, xCCorner);
          const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
          let minMaxValue = initialValue;
          let avgValue = 0;
          let count2 = 0;
          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
            const xROffset = inputBatchOffset + xR * strides[1];
            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
              const xCOffset = xROffset + xC * strides[2];
              const pixel = xValues[xCOffset + d];
              if (poolType === "max" && pixel > minMaxValue) {
                minMaxValue = pixel;
              } else if (poolType === "avg") {
                avgValue += pixel;
                count2++;
              }
            }
            if (isNaN(minMaxValue)) {
              break;
            }
          }
          const outputOffset = outputRowOffset + yC * outputColStrides + d;
          outputVals[outputOffset] = poolType === "avg" ? avgValue / count2 : minMaxValue;
        }
      }
    }
  }
  return output;
}
function maxPoolPositions(xValues, xShape, dtype, convInfo, flattenPositions = false, includeBatchInIndex = false) {
  const maxPositions = buffer(convInfo.outShape, "int32");
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  const xBuf = buffer(xShape, dtype, xValues);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let yR = 0; yR < convInfo.outHeight; ++yR) {
        const xRCorner = yR * strideHeight - padTop;
        let xRMin = xRCorner;
        while (xRMin < 0) {
          xRMin += dilationHeight;
        }
        const xRMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const xCCorner = yC * strideWidth - padLeft;
          let xCMin = xCCorner;
          while (xCMin < 0) {
            xCMin += dilationWidth;
          }
          const xCMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);
          let maxValue = Number.NEGATIVE_INFINITY;
          let maxPosition = -1;
          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {
            const wR = xR - xRCorner;
            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {
              const wC = xC - xCCorner;
              const pixel = xBuf.get(b, xR, xC, d);
              if (pixel > maxValue) {
                maxValue = pixel;
                if (flattenPositions) {
                  maxPosition = includeBatchInIndex ? ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) * convInfo.inChannels + d : (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;
                } else {
                  maxPosition = wR * effectiveFilterWidth + wC;
                }
              }
            }
          }
          maxPositions.set(maxPosition, b, yR, yC, d);
        }
      }
    }
  }
  return maxPositions;
}
function pool3d2(xValues, xShape, dtype, strides, convInfo, poolType) {
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = convInfo.padInfo.front;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  const initialValue = poolType === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY;
  const output = buffer(convInfo.outShape, dtype);
  const outputVals = output.values;
  const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
  const outputDepthStrides = convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];
  const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];
  const outputColStrides = convInfo.outShape[4];
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    const outputBatchOffset = batch * outputBatchStrides;
    const inputBatchOffset = batch * strides[0];
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
        const xDepthCorner = yDepth * strideDepth - padFront;
        let xDepthMin = xDepthCorner;
        while (xDepthMin < 0) {
          xDepthMin += dilationDepth;
        }
        const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
        const outputDepthOffset = outputBatchOffset + yDepth * outputDepthStrides;
        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
          const xRowCorner = yRow * strideHeight - padTop;
          let xRowMin = xRowCorner;
          while (xRowMin < 0) {
            xRowMin += dilationHeight;
          }
          const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
          const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;
          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
            const xColCorner = yCol * strideWidth - padLeft;
            let xColMin = xColCorner;
            while (xColMin < 0) {
              xColMin += dilationWidth;
            }
            const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
            const outputColOffset = outputRowOffset + yCol * outputColStrides;
            let minMaxValue = initialValue;
            let avgValue = 0;
            let count2 = 0;
            for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
              const xDepthOffset = inputBatchOffset + xDepth * strides[1];
              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                const xRowOffset = xDepthOffset + xRow * strides[2];
                for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                  const xColOffset = xRowOffset + xCol * strides[3];
                  const pixel = xValues[xColOffset + channel];
                  if (poolType === "max" && pixel > minMaxValue) {
                    minMaxValue = pixel;
                  } else if (poolType === "avg") {
                    avgValue += pixel;
                    count2++;
                  }
                  if (isNaN(minMaxValue)) {
                    break;
                  }
                }
                if (isNaN(minMaxValue)) {
                  break;
                }
              }
              if (isNaN(minMaxValue)) {
                break;
              }
            }
            const outputOffset = outputColOffset + channel;
            outputVals[outputOffset] = poolType === "avg" ? avgValue / Math.max(count2, 1) : minMaxValue;
          }
        }
      }
    }
  }
  return output;
}
function maxPool3dPositions(xBuf, convInfo) {
  const maxPositions = buffer(convInfo.outShape, "int32");
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = convInfo.padInfo.front;
  const padTop = convInfo.padInfo.top;
  const padLeft = convInfo.padInfo.left;
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {
        const xDepthCorner = yDepth * strideDepth - padFront;
        let xDepthMin = xDepthCorner;
        while (xDepthMin < 0) {
          xDepthMin += dilationDepth;
        }
        const xDepthMax = Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);
        for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {
          const xRowCorner = yRow * strideHeight - padTop;
          let xRowMin = xRowCorner;
          while (xRowMin < 0) {
            xRowMin += dilationHeight;
          }
          const xRowMax = Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);
          for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {
            const xColCorner = yCol * strideWidth - padLeft;
            let xColMin = xColCorner;
            while (xColMin < 0) {
              xColMin += dilationWidth;
            }
            const xColMax = Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);
            let maxValue = Number.NEGATIVE_INFINITY;
            let maxPosition = -1;
            for (let xDepth = xDepthMin; xDepth < xDepthMax; xDepth += dilationDepth) {
              const wDepth = xDepth - xDepthCorner;
              for (let xRow = xRowMin; xRow < xRowMax; xRow += dilationHeight) {
                const wRow = xRow - xRowCorner;
                for (let xCol = xColMin; xCol < xColMax; xCol += dilationWidth) {
                  const wCol = xCol - xColCorner;
                  const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);
                  if (pixel >= maxValue) {
                    maxValue = pixel;
                    maxPosition = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterHeight + wCol;
                  }
                }
              }
            }
            maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);
          }
        }
      }
    }
  }
  return maxPositions;
}
var init_pool_utils = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js"() {
    init_dist();
  }
});
function avgPool2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  assertNotComplex(x, "avgPool");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  let res;
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    res = identity4({ inputs: { x }, backend: backend2 });
  } else {
    const xValues = backend2.data.get(x.dataId).values;
    const strides2 = util_exports.computeStrides(x.shape);
    const buffer2 = pool2(xValues, x.shape, x.dtype, strides2, convInfo, "avg");
    res = backend2.makeTensorInfo(convInfo.outShape, x.dtype, buffer2.values);
  }
  return res;
}
var avgPoolConfig;
var init_AvgPool = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js"() {
    init_dist();
    init_cpu_util();
    init_pool_utils();
    init_Identity();
    avgPoolConfig = {
      kernelName: AvgPool,
      backendName: "cpu",
      kernelFunc: avgPool2
    };
  }
});
function avgPool3D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
  assertNotComplex(x, "avgPool3d");
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode, dataFormat);
  const xValues = backend2.data.get(x.dataId).values;
  const outBuf = pool3d2(xValues, x.shape, x.dtype, util_exports.computeStrides(x.shape), convInfo, "avg");
  return backend2.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
}
var avgPool3DConfig;
var init_AvgPool3D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js"() {
    init_dist();
    init_cpu_util();
    init_pool_utils();
    avgPool3DConfig = {
      kernelName: AvgPool3D,
      backendName: "cpu",
      kernelFunc: avgPool3D
    };
  }
});
function avgPool3DGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2 } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  assertNotComplex([dy, input2], "avgPool3DGrad");
  const convInfo = backend_util_exports.computePool3DInfo(input2.shape, filterSize, strides, 1, pad2, dimRoundingMode);
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const filterDepth = convInfo.filterDepth;
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer(input2.shape, "float32");
  const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
  const dyBuf = backend2.bufferSync(dy);
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
            const dyDepthCorner = dxDepth - padFront;
            const dyRowCorner = dxRow - padTop;
            const dyColCorner = dxCol - padLeft;
            let dotProd = 0;
            for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
              if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                continue;
              }
              for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                const dyRow = (dyRowCorner + wRow) / strideHeight;
                if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                  continue;
                }
                for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                  const dyCol = (dyColCorner + wCol) / strideWidth;
                  if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                    continue;
                  }
                  const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                  dotProd += pixel;
                }
              }
            }
            dx.set(dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol, channel);
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var avgPool3DGradConfig2;
var init_AvgPool3DGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js"() {
    init_dist();
    init_cpu_util();
    avgPool3DGradConfig2 = {
      kernelName: AvgPool3DGrad,
      backendName: "cpu",
      kernelFunc: avgPool3DGrad
    };
  }
});
function avgPoolGrad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  assertNotComplex([dy, input2], "avgPoolGrad");
  const { filterSize, strides, pad: pad2 } = attrs;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2);
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer(x.shape, "float32");
  const avgMultiplier = 1 / (filterHeight * filterWidth);
  const dyData = backend2.data.get(dy.dataId).values;
  const dyBuf = buffer(dy.shape, "float32", dyData);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
          const dyRCorner = dxR - padTop;
          const dyCCorner = dxC - padLeft;
          let dotProd = 0;
          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
            const dyR = (dyRCorner + wR) / strideHeight;
            if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
              continue;
            }
            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
              const dyC = (dyCCorner + wC) / strideWidth;
              if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                continue;
              }
              const pixel = dyBuf.get(b, dyR, dyC, d);
              dotProd += pixel;
            }
          }
          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var avgPoolGradConfig2;
var init_AvgPoolGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js"() {
    init_dist();
    init_cpu_util();
    avgPoolGradConfig2 = {
      kernelName: AvgPoolGrad,
      backendName: "cpu",
      kernelFunc: avgPoolGrad2
    };
  }
});
function batchNorm2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, scale: scale22, offset, mean: mean3, variance } = inputs;
  util_exports.assert(mean3.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
  util_exports.assert(offset == null || mean3.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
  util_exports.assert(scale22 == null || mean3.shape.length === scale22.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  assertNotComplex([x, mean3, variance, scale22, offset], "batchNorm");
  let { varianceEpsilon } = attrs;
  if (varianceEpsilon == null) {
    varianceEpsilon = 1e-3;
  }
  const xVals = backend2.data.get(x.dataId).values;
  const mVals = backend2.data.get(mean3.dataId).values;
  const varVals = backend2.data.get(variance.dataId).values;
  const sVals = scale22 ? backend2.data.get(scale22.dataId).values : new Float32Array([1]);
  const offVals = offset ? backend2.data.get(offset.dataId).values : new Float32Array([0]);
  const outVals = new Float32Array(xVals.length);
  const offValsLength = offVals.length;
  const sValsLength = sVals.length;
  const varValsLength = varVals.length;
  const mValsLength = mVals.length;
  let offi = 0;
  let mi = 0;
  let si = 0;
  let vi = 0;
  for (let i = 0; i < xVals.length; ++i) {
    outVals[i] = offVals[offi++] + (xVals[i] - mVals[mi++]) * sVals[si++] / Math.sqrt(varVals[vi++] + varianceEpsilon);
    if (offi >= offValsLength) {
      offi = 0;
    }
    if (mi >= mValsLength) {
      mi = 0;
    }
    if (si >= sValsLength) {
      si = 0;
    }
    if (vi >= varValsLength) {
      vi = 0;
    }
  }
  return backend2.makeTensorInfo(x.shape, x.dtype, outVals);
}
var batchNormConfig;
var init_BatchNorm = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js"() {
    init_dist();
    init_cpu_util();
    batchNormConfig = {
      kernelName: FusedBatchNorm,
      backendName: "cpu",
      kernelFunc: batchNorm2
    };
  }
});
function batchToSpaceND2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockShape, crops } = attrs;
  assertNotComplex([x], "batchToSpaceND");
  const prod4 = blockShape.reduce((a, b) => a * b);
  const reshaped = backend_util_exports.getReshaped(x.shape, blockShape, prod4);
  const permuted = backend_util_exports.getPermuted(reshaped.length, blockShape.length);
  const reshapedPermuted = backend_util_exports.getReshapedPermuted(x.shape, blockShape, prod4);
  const sliceBeginCoords = backend_util_exports.getSliceBeginCoords(crops, blockShape.length);
  const sliceSize = backend_util_exports.getSliceSize(reshapedPermuted, crops, blockShape.length);
  const xReshaped = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: reshaped } });
  const xTransposed = transpose22({ inputs: { x: xReshaped }, backend: backend2, attrs: { perm: permuted } });
  const xTransposedReshaped = reshape2({ inputs: { x: xTransposed }, backend: backend2, attrs: { shape: reshapedPermuted } });
  const result = slice2({
    inputs: { x: xTransposedReshaped },
    backend: backend2,
    attrs: { begin: sliceBeginCoords, size: sliceSize }
  });
  backend2.disposeIntermediateTensorInfo(xReshaped);
  backend2.disposeIntermediateTensorInfo(xTransposed);
  backend2.disposeIntermediateTensorInfo(xTransposedReshaped);
  return result;
}
var batchToSpaceNDConfig;
var init_BatchToSpaceND = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js"() {
    init_dist();
    init_cpu_util();
    init_Reshape();
    init_Slice();
    init_Transpose();
    batchToSpaceNDConfig = {
      kernelName: BatchToSpaceND,
      backendName: "cpu",
      kernelFunc: batchToSpaceND2
    };
  }
});
function bincount2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, weights } = inputs;
  const { size } = attrs;
  const xVals = backend2.data.get(x.dataId).values;
  const weightsVals = backend2.data.get(weights.dataId).values;
  const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
  return backend2.makeTensorInfo([size], weights.dtype, outVals);
}
var bincountConfig;
var init_Bincount = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js"() {
    init_dist();
    init_Bincount_impl();
    bincountConfig = {
      kernelName: Bincount,
      backendName: "cpu",
      kernelFunc: bincount2
    };
  }
});
function broadcastArgs(args) {
  const { inputs, backend: backend2 } = args;
  const { s0, s1 } = inputs;
  const s0Vals = backend2.data.get(s0.dataId).values;
  const s1Vals = backend2.data.get(s1.dataId).values;
  const broadcastShape = backend_util_exports.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
  return backend2.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
}
var broadcastArgsConfig;
var init_BroadcastArgs = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js"() {
    init_dist();
    broadcastArgsConfig = {
      kernelName: BroadcastArgs,
      backendName: "cpu",
      kernelFunc: broadcastArgs
    };
  }
});
var clipByValue2;
var clipByValueConfig;
var init_ClipByValue = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ClipByValue.js"() {
    init_dist();
    init_unary_utils();
    clipByValue2 = unaryKernelFunc(ClipByValue, (xi, attrs) => {
      const clipAttrs = attrs;
      if (xi > clipAttrs.clipValueMax) {
        return clipAttrs.clipValueMax;
      }
      return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;
    });
    clipByValueConfig = {
      kernelName: ClipByValue,
      backendName: "cpu",
      kernelFunc: clipByValue2
    };
  }
});
var complexAbs;
var complexAbsConfig;
var init_ComplexAbs = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js"() {
    init_dist();
    complexAbs = (args) => {
      const { x } = args.inputs;
      const cpuBackend = args.backend;
      const resultValues = new Float32Array(util_exports.sizeFromShape(x.shape));
      const complexVals = cpuBackend.data.get(x.dataId);
      const real4 = complexVals.complexTensorInfos.real;
      const imag4 = complexVals.complexTensorInfos.imag;
      const realVals = cpuBackend.data.get(real4.dataId).values;
      const imagVals = cpuBackend.data.get(imag4.dataId).values;
      for (let i = 0; i < realVals.length; i++) {
        const real5 = realVals[i];
        const imag5 = imagVals[i];
        resultValues[i] = Math.hypot(real5, imag5);
      }
      return cpuBackend.makeOutput(resultValues, x.shape, "float32");
    };
    complexAbsConfig = {
      kernelName: ComplexAbs,
      backendName: "cpu",
      kernelFunc: complexAbs
    };
  }
});
function imag2(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  const imag4 = backend2.data.get(input2.dataId).complexTensorInfos.imag;
  const imagVal = backend2.data.get(imag4.dataId).values;
  return backend2.makeTensorInfo(imag4.shape, imag4.dtype, imagVal);
}
var imagConfig;
var init_Imag = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js"() {
    init_dist();
    imagConfig = {
      kernelName: Imag,
      backendName: "cpu",
      kernelFunc: imag2
    };
  }
});
function concat2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { axis } = attrs;
  const $axis = util_exports.parseAxisParam(axis, inputs[0].shape)[0];
  const shapes = inputs.map((t) => t.shape);
  backend_util_exports.assertParamsConsistent(shapes, $axis);
  let outShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), $axis);
  if (util_exports.sizeFromShape(outShape) === 0) {
    return backend2.makeTensorInfo(outShape, inputs[0].dtype, []);
  }
  const $inputs = inputs.filter((t) => util_exports.sizeFromShape(t.shape) > 0);
  if ($inputs.length === 1) {
    return identity4({ inputs: { x: $inputs[0] }, backend: backend2 });
  }
  if ($inputs[0].dtype === "complex64") {
    const reals = $inputs.map((t) => real2({ inputs: { input: t }, backend: backend2 }));
    const imags = $inputs.map((t) => imag2({ inputs: { input: t }, backend: backend2 }));
    const realConcated = concat2({ inputs: reals, backend: backend2, attrs: { axis: $axis } });
    const imagConcated = concat2({ inputs: imags, backend: backend2, attrs: { axis: $axis } });
    const result = complex2({ inputs: { real: realConcated, imag: imagConcated }, backend: backend2 });
    reals.forEach((r) => backend2.disposeIntermediateTensorInfo(r));
    imags.forEach((i) => backend2.disposeIntermediateTensorInfo(i));
    backend2.disposeIntermediateTensorInfo(realConcated);
    backend2.disposeIntermediateTensorInfo(imagConcated);
    return result;
  }
  const inputs2D = $inputs.map((t) => {
    const innerSize = util_exports.sizeFromShape(t.shape.slice($axis));
    const shape = [-1, innerSize];
    return reshape2({ inputs: { x: t }, backend: backend2, attrs: { shape } });
  });
  const inputsValShapes = inputs2D.map((t) => {
    return { vals: backend2.data.get(t.dataId).values, shape: t.shape };
  });
  outShape = backend_util_exports.computeOutShape(
    inputs2D.map((t) => t.shape),
    1
    /* axis */
  );
  const simplyConcat = inputs2D[0].shape[0] === 1;
  const outVals = concatImpl(inputsValShapes, outShape, inputs[0].dtype, simplyConcat);
  const finalOutShape = backend_util_exports.computeOutShape($inputs.map((t) => t.shape), $axis);
  const outInfo = backend2.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);
  inputs2D.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return outInfo;
}
var concatConfig;
var init_Concat = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js"() {
    init_dist();
    init_Complex();
    init_Concat_impl();
    init_Identity();
    init_Imag();
    init_Real();
    init_Reshape();
    concatConfig = {
      kernelName: Concat,
      backendName: "cpu",
      kernelFunc: concat2
    };
  }
});
function conv2D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
  assertNotComplex([x, filter], "conv2d");
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const padLeft = convInfo.padInfo.left;
  const padTop = convInfo.padInfo.top;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const y = new TensorBuffer(convInfo.outShape, x.dtype);
  const xStrides = util_exports.computeStrides(x.shape);
  const filterStrides = util_exports.computeStrides(filter.shape);
  const xBatchStride = xStrides[0];
  const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];
  const xColStride = isChannelsLast ? xStrides[2] : 1;
  const xChannelStride = isChannelsLast ? 1 : xStrides[1];
  const yBatchStride = y.strides[0];
  const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];
  const yColStride = isChannelsLast ? y.strides[2] : 1;
  const yChannelStride = isChannelsLast ? 1 : y.strides[1];
  const xVals = backend2.data.get(x.dataId).values;
  const wVals = backend2.data.get(filter.dataId).values;
  const yVals = y.values;
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const xOffset1 = b * xBatchStride;
    const yOffset1 = b * yBatchStride;
    for (let yR = 0; yR < convInfo.outHeight; ++yR) {
      const yOffset2 = yOffset1 + yR * yRowStride;
      const xRCorner = yR * convInfo.strideHeight - padTop;
      for (let wR = 0; wR < filterHeight; ++wR) {
        const xR = xRCorner + wR * dilationHeight;
        if (xR < 0 || xR >= convInfo.inHeight) {
          continue;
        }
        const wOffset1 = wR * filterStrides[0];
        const xOffset2 = xOffset1 + xR * xRowStride;
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const yOffset3 = yOffset2 + yC * yColStride;
          const xCCorner = yC * convInfo.strideWidth - padLeft;
          for (let wC = 0; wC < filterWidth; ++wC) {
            const xC = xCCorner + wC * dilationWidth;
            if (xC < 0 || xC >= convInfo.inWidth) {
              continue;
            }
            const wOffset2 = wOffset1 + wC * filterStrides[1];
            const xOffset3 = xOffset2 + xC * xColStride;
            let wOffset3 = wOffset2;
            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
              const xVal = xVals[xOffset3 + d1 * xChannelStride];
              for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                yVals[yOffset3 + d2 * yChannelStride] += xVal * wVals[wOffset3 + d2];
              }
              wOffset3 += convInfo.outChannels;
            }
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(y.shape, y.dtype, yVals);
}
var conv2DConfig;
var init_Conv2D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js"() {
    init_dist();
    init_cpu_util();
    conv2DConfig = {
      kernelName: Conv2D,
      backendName: "cpu",
      kernelFunc: conv2D
    };
  }
});
function conv2DBackpropFilter2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape } = attrs;
  assertNotComplex([x, dy], "conv2dBackpropFilter");
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
  const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const dW = new TensorBuffer(convInfo.filterShape, "float32");
  const leftPad = convInfo.padInfo.left;
  const topPad = convInfo.padInfo.top;
  const xVals = backend2.data.get(x.dataId).values;
  const dyVals = backend2.data.get(dy.dataId).values;
  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);
  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);
  for (let wR = 0; wR < filterHeight; ++wR) {
    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
    const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
    for (let wC = 0; wC < filterWidth; ++wC) {
      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
      const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
          let dotProd = 0;
          for (let b = 0; b < convInfo.batchSize; ++b) {
            for (let yR = yRMin; yR < yRMax; ++yR) {
              const xR = wR + yR * strideHeight - topPad;
              for (let yC = yCMin; yC < yCMax; ++yC) {
                const xC = wC + yC * strideWidth - leftPad;
                if (isChannelsLast) {
                  dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
                } else {
                  dotProd += xBuf.get(b, d1, xR, xC) * dyBuf.get(b, d2, yR, yC);
                }
              }
            }
          }
          dW.set(dotProd, wR, wC, d1, d2);
        }
      }
    }
  }
  return backend2.makeTensorInfo(dW.shape, dW.dtype, dW.values);
}
var conv2DBackpropFilterConfig;
var init_Conv2DBackpropFilter = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js"() {
    init_dist();
    init_cpu_util();
    conv2DBackpropFilterConfig = {
      kernelName: Conv2DBackpropFilter,
      backendName: "cpu",
      kernelFunc: conv2DBackpropFilter2
    };
  }
});
function conv2DBackpropInput2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { inputShape, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
  assertNotComplex([dy, filter], "conv2dBackpropInput");
  const filterStrides = util_exports.computeStrides(filter.shape);
  const dyStrides = util_exports.computeStrides(dy.shape);
  let $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
  const dx = new TensorBuffer(convInfo.inShape, "float32");
  const dxValues = dx.values;
  const dyValues = backend2.data.get(dy.dataId).values;
  const fltValues = backend2.data.get(filter.dataId).values;
  const [fltS0, fltS1, fltS2] = filterStrides;
  const { batchSize, filterHeight, filterWidth, inChannels, inHeight, inWidth, outChannels, outHeight, outWidth, strideHeight, strideWidth } = convInfo;
  $dataFormat = convInfo.dataFormat;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  const isChannelsLast = $dataFormat === "channelsLast";
  const xBatchStride = dx.strides[0];
  const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];
  const xColStride = isChannelsLast ? dx.strides[2] : 1;
  const xChannelStride = isChannelsLast ? 1 : dx.strides[1];
  const yBatchStride = dyStrides[0];
  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];
  const yColStride = isChannelsLast ? dyStrides[2] : 1;
  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];
  for (let b = 0; b < batchSize; ++b) {
    for (let d1 = 0; d1 < inChannels; ++d1) {
      for (let xR = 0; xR < inHeight; ++xR) {
        const xRCorner = xR - topPad;
        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
        const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
        for (let xC = 0; xC < inWidth; ++xC) {
          const xCCorner = xC - leftPad;
          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
          const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
          let dotProd = 0;
          for (let yR = xRMin; yR < yRMax; ++yR) {
            const wR = yR * strideHeight - xRCorner;
            for (let yC = xCMin; yC < yCMax; ++yC) {
              const wC = yC * strideWidth - xCCorner;
              const dyOffset = yBatchStride * b + yRowStride * yR + yColStride * yC;
              const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
              for (let d2 = 0; d2 < outChannels; ++d2) {
                const pixel = dyValues[dyOffset + yChannelStride * d2];
                const weight = fltValues[fltOffset + d2];
                dotProd += pixel * weight;
              }
            }
          }
          const dxOffset = xBatchStride * b + xRowStride * xR + xColStride * xC + xChannelStride * d1;
          dxValues[dxOffset] = dotProd;
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var conv2DBackpropInputConfig;
var init_Conv2DBackpropInput = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js"() {
    init_dist();
    init_cpu_util();
    conv2DBackpropInputConfig = {
      kernelName: Conv2DBackpropInput,
      backendName: "cpu",
      kernelFunc: conv2DBackpropInput2
    };
  }
});
function conv3D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  assertNotComplex([x, filter], "conv3d");
  const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
  const { filterDepth, filterHeight, filterWidth, dilationDepth, dilationHeight, dilationWidth, padInfo } = convInfo;
  const padFront = padInfo.front;
  const padLeft = padInfo.left;
  const padTop = padInfo.top;
  const y = new TensorBuffer(convInfo.outShape, x.dtype);
  const xVals = backend2.data.get(x.dataId).values;
  const wVals = backend2.data.get(filter.dataId).values;
  const yVals = y.values;
  const xStrides = util_exports.computeStrides(x.shape);
  const filterStrides = util_exports.computeStrides(filter.shape);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const xOffset1 = b * xStrides[0];
    const yOffset1 = b * y.strides[0];
    for (let yF = 0; yF < convInfo.outDepth; ++yF) {
      const yOffset2 = yOffset1 + yF * y.strides[1];
      const xFCorner = yF * convInfo.strideDepth - padFront;
      for (let wF = 0; wF < filterDepth; ++wF) {
        const xF = xFCorner + wF * dilationDepth;
        if (xF < 0 || xF >= convInfo.inDepth) {
          continue;
        }
        const wOffset1 = wF * filterStrides[0];
        const xOffset2 = xOffset1 + xF * xStrides[1];
        for (let yR = 0; yR < convInfo.outHeight; ++yR) {
          const yOffset3 = yOffset2 + yR * y.strides[2];
          const xRCorner = yR * convInfo.strideHeight - padTop;
          for (let wR = 0; wR < filterHeight; ++wR) {
            const xR = xRCorner + wR * dilationHeight;
            if (xR < 0 || xR >= convInfo.inHeight) {
              continue;
            }
            const wOffset2 = wOffset1 + wR * filterStrides[1];
            const xOffset3 = xOffset2 + xR * xStrides[2];
            for (let yC = 0; yC < convInfo.outWidth; ++yC) {
              const yOffset4 = yOffset3 + yC * convInfo.outChannels;
              const xCCorner = yC * convInfo.strideWidth - padLeft;
              for (let wC = 0; wC < filterWidth; ++wC) {
                const xC = xCCorner + wC * dilationWidth;
                if (xC < 0 || xC >= convInfo.inWidth) {
                  continue;
                }
                const wOffset3 = wOffset2 + wC * filterStrides[2];
                const xOffset4 = xOffset3 + xC * convInfo.inChannels;
                let wOffset4 = wOffset3;
                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
                  const xVal = xVals[xOffset4 + d1];
                  for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
                    yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];
                  }
                  wOffset4 += convInfo.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(y.shape, y.dtype, y.values);
}
var conv3DConfig;
var init_Conv3D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js"() {
    init_dist();
    init_cpu_util();
    conv3DConfig = {
      kernelName: Conv3D,
      backendName: "cpu",
      kernelFunc: conv3D
    };
  }
});
function conv3DBackpropFilterV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad2, filterShape } = attrs;
  assertNotComplex([x, dy], "conv3dBackpropFilterV2");
  const xStrides = util_exports.computeStrides(x.shape);
  const dyStrides = util_exports.computeStrides(dy.shape);
  const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filterShape, strides, 1, pad2);
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const filterDepth = convInfo.filterDepth;
  const filterHeight = convInfo.filterHeight;
  const filterWidth = convInfo.filterWidth;
  const dw = new TensorBuffer(convInfo.filterShape, "float32");
  const dwValues = dw.values;
  const [dwS0, dwS1, dwS2, dwS3] = dw.strides;
  const dyValues = backend2.data.get(dy.dataId).values;
  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
  const xValues = backend2.data.get(x.dataId).values;
  const [xS0, xS1, xS2, xS3] = xStrides;
  const frontPad = convInfo.padInfo.front;
  const leftPad = convInfo.padInfo.left;
  const topPad = convInfo.padInfo.top;
  for (let wF = 0; wF < filterDepth; ++wF) {
    const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));
    const yFMax = Math.min(convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);
    const wOffset1 = wF * dwS0;
    for (let wR = 0; wR < filterHeight; ++wR) {
      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
      const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
      const wOffset2 = wR * dwS1 + wOffset1;
      for (let wC = 0; wC < filterWidth; ++wC) {
        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
        const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
        const wOffset3 = wC * dwS2 + wOffset2;
        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
          const wOffset4 = d1 * dwS3 + wOffset3;
          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
            let dotProd = 0;
            for (let b = 0; b < convInfo.batchSize; ++b) {
              const xOffset1 = b * xS0;
              const yOffset1 = b * dyS0;
              for (let yF = yFMin; yF < yFMax; ++yF) {
                const xF = wF + yF * strideDepth - frontPad;
                const xOffset2 = xF * xS1 + xOffset1;
                const yOffset2 = yF * dyS1 + yOffset1;
                for (let yR = yRMin; yR < yRMax; ++yR) {
                  const xR = wR + yR * strideHeight - topPad;
                  const xOffset3 = xR * xS2 + xOffset2;
                  const yOffset3 = yR * dyS2 + yOffset2;
                  for (let yC = yCMin; yC < yCMax; ++yC) {
                    const xC = wC + yC * strideWidth - leftPad;
                    const xOffset4 = xC * xS3 + xOffset3;
                    const yOffset4 = yC * dyS3 + yOffset3;
                    dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];
                  }
                }
              }
            }
            dwValues[wOffset4 + d2] = dotProd;
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(dw.shape, dw.dtype, dw.values);
}
var conv3DBackpropFilterV2Config;
var init_Conv3DBackpropFilterV2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js"() {
    init_dist();
    init_cpu_util();
    conv3DBackpropFilterV2Config = {
      kernelName: Conv3DBackpropFilterV2,
      backendName: "cpu",
      kernelFunc: conv3DBackpropFilterV2
    };
  }
});
function conv3DBackpropInputV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { pad: pad2, strides, inputShape } = attrs;
  assertNotComplex([dy], "conv3dBackpropInputV2");
  const dyStrides = util_exports.computeStrides(dy.shape);
  const filterStrides = util_exports.computeStrides(filter.shape);
  const convInfo = backend_util_exports.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad2);
  const dx = new TensorBuffer(convInfo.inShape, "float32");
  const dxValues = dx.values;
  const [dxS0, dxS1, dxS2, dxS3] = dx.strides;
  const dyValues = backend2.data.get(dy.dataId).values;
  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;
  const fltValues = backend2.data.get(filter.dataId).values;
  const [fltS0, fltS1, fltS2, fltS3] = filterStrides;
  const { batchSize, filterDepth, filterHeight, filterWidth, inChannels, inDepth, inHeight, inWidth, outChannels, outDepth, outHeight, outWidth, strideDepth, strideHeight, strideWidth } = convInfo;
  const frontPad = filterDepth - 1 - convInfo.padInfo.front;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  for (let b = 0; b < batchSize; ++b) {
    for (let d1 = 0; d1 < inChannels; ++d1) {
      for (let xF = 0; xF < inDepth; ++xF) {
        const xFCorner = xF - frontPad;
        const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));
        const yFMax = Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);
        for (let xR = 0; xR < inHeight; ++xR) {
          const xRCorner = xR - topPad;
          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
          const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
          for (let xC = 0; xC < inWidth; ++xC) {
            const xCCorner = xC - leftPad;
            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
            const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
            let dotProd = 0;
            for (let yF = xFMin; yF < yFMax; ++yF) {
              const wF = yF * strideDepth - xFCorner;
              for (let yR = xRMin; yR < yRMax; ++yR) {
                const wR = yR * strideHeight - xRCorner;
                for (let yC = xCMin; yC < yCMax; ++yC) {
                  const wC = yC * strideWidth - xCCorner;
                  const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;
                  const fltOffset = fltS0 * (filterDepth - 1 - wF) + fltS1 * (filterHeight - 1 - wR) + fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;
                  for (let d2 = 0; d2 < outChannels; ++d2) {
                    const pixel = dyValues[dyOffset + d2];
                    const weight = fltValues[fltOffset + d2];
                    dotProd += pixel * weight;
                  }
                }
              }
            }
            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] = dotProd;
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var conv3DBackpropInputV2Config;
var init_Conv3DBackpropInputV2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js"() {
    init_dist();
    init_cpu_util();
    conv3DBackpropInputV2Config = {
      kernelName: Conv3DBackpropInputV2,
      backendName: "cpu",
      kernelFunc: conv3DBackpropInputV2
    };
  }
});
var cos2;
var cosConfig;
var init_Cos = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js"() {
    init_dist();
    init_unary_utils();
    cos2 = unaryKernelFunc(Cos, (xi) => Math.cos(xi));
    cosConfig = {
      kernelName: Cos,
      backendName: "cpu",
      kernelFunc: cos2
    };
  }
});
var cosh2;
var coshConfig;
var init_Cosh = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js"() {
    init_dist();
    init_unary_utils();
    cosh2 = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));
    coshConfig = {
      kernelName: Cosh,
      backendName: "cpu",
      kernelFunc: cosh2
    };
  }
});
function cropAndResize3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { image: image2, boxes, boxInd } = inputs;
  const { cropSize, method, extrapolationValue } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
  const numBoxes = boxes.shape[0];
  const [cropHeight, cropWidth] = cropSize;
  const output = buffer([numBoxes, cropHeight, cropWidth, numChannels], "float32");
  const boxVals = backend2.data.get(boxes.dataId).values;
  const boxIndVals = backend2.data.get(boxInd.dataId).values;
  const imageVals = backend2.data.get(image2.dataId).values;
  const inStride = util_exports.computeStrides(image2.shape);
  const outStride = util_exports.computeStrides(output.shape);
  for (let b = 0; b < numBoxes; b++) {
    const startInd = b * 4;
    const y1 = boxVals[startInd];
    const x1 = boxVals[startInd + 1];
    const y2 = boxVals[startInd + 2];
    const x2 = boxVals[startInd + 3];
    const bInd = boxIndVals[b];
    if (bInd >= batch) {
      continue;
    }
    const heightScale = cropHeight > 1 ? (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) : 0;
    const widthScale = cropWidth > 1 ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;
    for (let y = 0; y < cropHeight; y++) {
      const yInd = cropHeight > 1 ? y1 * (imageHeight - 1) + y * heightScale : 0.5 * (y1 + y2) * (imageHeight - 1);
      if (yInd < 0 || yInd > imageHeight - 1) {
        for (let x = 0; x < cropWidth; x++) {
          for (let c = 0; c < numChannels; c++) {
            const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
            output.values[ind] = extrapolationValue;
          }
        }
        continue;
      }
      if (method === "bilinear") {
        const topInd = Math.floor(yInd);
        const bottomInd = Math.ceil(yInd);
        const yLerp = yInd - topInd;
        for (let x = 0; x < cropWidth; x++) {
          const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
          if (xInd < 0 || xInd > imageWidth - 1) {
            for (let c = 0; c < numChannels; c++) {
              const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = extrapolationValue;
            }
            continue;
          }
          const leftInd = Math.floor(xInd);
          const rightInd = Math.ceil(xInd);
          const xLerp = xInd - leftInd;
          for (let c = 0; c < numChannels; c++) {
            let ind = c + leftInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
            const topLeft = imageVals[ind];
            ind = c + rightInd * inStride[2] + topInd * inStride[1] + bInd * inStride[0];
            const topRight = imageVals[ind];
            ind = c + leftInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
            const bottomLeft = imageVals[ind];
            ind = c + rightInd * inStride[2] + bottomInd * inStride[1] + bInd * inStride[0];
            const bottomRight = imageVals[ind];
            const top = topLeft + (topRight - topLeft) * xLerp;
            const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;
            ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
            output.values[ind] = top + (bottom - top) * yLerp;
          }
        }
      } else {
        for (let x = 0; x < cropWidth; ++x) {
          const xInd = cropWidth > 1 ? x1 * (imageWidth - 1) + x * widthScale : 0.5 * (x1 + x2) * (imageWidth - 1);
          if (xInd < 0 || xInd > imageWidth - 1) {
            for (let c = 0; c < numChannels; c++) {
              const ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
              output.values[ind] = extrapolationValue;
            }
            continue;
          }
          const closestX = Math.round(xInd);
          const closestY = Math.round(yInd);
          for (let c = 0; c < numChannels; c++) {
            const inInd = c + closestX * inStride[2] + closestY * inStride[1] + bInd * inStride[0];
            const outInd = c + x * outStride[2] + y * outStride[1] + b * outStride[0];
            output.values[outInd] = imageVals[inInd];
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(output.shape, output.dtype, output.values);
}
var cropAndResizeConfig;
var init_CropAndResize = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js"() {
    init_dist();
    cropAndResizeConfig = {
      kernelName: CropAndResize,
      backendName: "cpu",
      kernelFunc: cropAndResize3
    };
  }
});
function cumprod2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse4 } = attrs;
  assertNotComplex(x, "cumprod");
  const permutation = backend_util_exports.getAxesPermutation([axis], x.shape.length);
  let $x = x;
  if (permutation != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
  }
  const permutedAxis = backend_util_exports.getInnerMostAxes(1, x.shape.length)[0];
  if (permutedAxis !== $x.shape.length - 1) {
    throw new Error(`backend.cumprod in CPU expects an inner-most axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);
  }
  const resultDtype = upcastType($x.dtype, "int32");
  const vals = util_exports.makeOnesTypedArray(util_exports.sizeFromShape($x.shape), resultDtype);
  const aVals = backend2.data.get($x.dataId).values;
  const finalDim = $x.shape[$x.shape.length - 1];
  const indexAdjuster = reverse4 ? (i, j) => i + finalDim - j - 1 : (i, j) => i + j;
  for (let i = 0; i < aVals.length; i += finalDim) {
    for (let j = 0; j < finalDim; j++) {
      const idx = indexAdjuster(i, j);
      if (j === 0) {
        vals[idx] = exclusive ? 1 : aVals[idx];
      } else {
        const prevIdx = indexAdjuster(i, j - 1);
        vals[idx] = exclusive ? aVals[prevIdx] * vals[prevIdx] : aVals[idx] * vals[prevIdx];
      }
    }
  }
  const result = backend2.makeTensorInfo($x.shape, resultDtype, vals);
  if (permutation != null) {
    const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
    const reverseTransposedResult = transpose22({ inputs: { x: result }, backend: backend2, attrs: { perm: reversePermutation } });
    backend2.disposeIntermediateTensorInfo(result);
    backend2.disposeIntermediateTensorInfo($x);
    return reverseTransposedResult;
  }
  return result;
}
var cumprodConfig;
var init_Cumprod = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumprod.js"() {
    init_dist();
    init_cpu_util();
    init_Transpose();
    cumprodConfig = {
      kernelName: Cumprod,
      backendName: "cpu",
      kernelFunc: cumprod2
    };
  }
});
function cumsum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse4 } = attrs;
  assertNotComplex(x, "cumsum");
  const permutation = backend_util_exports.getAxesPermutation([axis], x.shape.length);
  let $x = x;
  if (permutation != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
  }
  const permutedAxis = backend_util_exports.getInnerMostAxes(1, x.shape.length)[0];
  if (permutedAxis !== $x.shape.length - 1) {
    throw new Error(`backend.cumsum in CPU expects an inner-most axis=${$x.shape.length - 1} but got axis=${permutedAxis}`);
  }
  const resultDtype = upcastType($x.dtype, "int32");
  const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape($x.shape), resultDtype);
  const aVals = backend2.data.get($x.dataId).values;
  const finalDim = $x.shape[$x.shape.length - 1];
  const indexAdjuster = reverse4 ? (i, j) => i + finalDim - j - 1 : (i, j) => i + j;
  for (let i = 0; i < aVals.length; i += finalDim) {
    for (let j = 0; j < finalDim; j++) {
      const idx = indexAdjuster(i, j);
      if (j === 0) {
        vals[idx] = exclusive ? 0 : aVals[idx];
      } else {
        const prevIdx = indexAdjuster(i, j - 1);
        vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] : aVals[idx] + vals[prevIdx];
      }
    }
  }
  const result = backend2.makeTensorInfo($x.shape, resultDtype, vals);
  if (permutation != null) {
    const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
    const reverseTransposedResult = transpose22({ inputs: { x: result }, backend: backend2, attrs: { perm: reversePermutation } });
    backend2.disposeIntermediateTensorInfo(result);
    backend2.disposeIntermediateTensorInfo($x);
    return reverseTransposedResult;
  }
  return result;
}
var cumsumConfig;
var init_Cumsum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js"() {
    init_dist();
    init_cpu_util();
    init_Transpose();
    cumsumConfig = {
      kernelName: Cumsum,
      backendName: "cpu",
      kernelFunc: cumsum2
    };
  }
});
function denseBincount2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, weights } = inputs;
  const { size, binaryOutput } = attrs;
  if (x.shape.length === 1) {
    const xVals = backend2.data.get(x.dataId).values;
    const weightsVals = backend2.data.get(weights.dataId).values;
    const outVals = bincountImpl(xVals, weightsVals, weights.dtype, weights.shape, size);
    return backend2.makeTensorInfo([size], weights.dtype, outVals);
  } else if (x.shape.length === 2) {
    const xBuf = backend2.bufferSync(x);
    const weightsBuf = backend2.bufferSync(weights);
    const outBuf = bincountReduceImpl(xBuf, weightsBuf, size, binaryOutput);
    return backend2.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
}
var denseBincountConfig;
var init_DenseBincount = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js"() {
    init_dist();
    init_Bincount_impl();
    denseBincountConfig = {
      kernelName: DenseBincount,
      backendName: "cpu",
      kernelFunc: denseBincount2
    };
  }
});
function depthToSpace2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockSize, dataFormat } = attrs;
  util_exports.assert(dataFormat === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${dataFormat}`);
  const batchSize = x.shape[0];
  const inputHeight = x.shape[1];
  const inputWidth = x.shape[2];
  const inputDepth = x.shape[3];
  const outputHeight = inputHeight * blockSize;
  const outputWidth = inputWidth * blockSize;
  const outputDepth = inputDepth / (blockSize * blockSize);
  const xValues = backend2.data.get(x.dataId).values;
  const result = new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);
  let outputIdx = 0;
  for (let b = 0; b < batchSize; ++b) {
    for (let h = 0; h < outputHeight; ++h) {
      const inH = Math.floor(h / blockSize);
      const offsetH = h % blockSize;
      for (let w = 0; w < outputWidth; ++w) {
        const inW = Math.floor(w / blockSize);
        const offsetW = w % blockSize;
        const offsetD = (offsetH * blockSize + offsetW) * outputDepth;
        for (let d = 0; d < outputDepth; ++d) {
          const inD = d + offsetD;
          const inputIdx = inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));
          result[outputIdx++] = xValues[inputIdx];
        }
      }
    }
  }
  return backend2.makeTensorInfo([batchSize, outputHeight, outputWidth, outputDepth], x.dtype, result);
}
var depthToSpaceConfig;
var init_DepthToSpace = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js"() {
    init_dist();
    depthToSpaceConfig = {
      kernelName: DepthToSpace,
      backendName: "cpu",
      kernelFunc: depthToSpace2
    };
  }
});
function depthwiseConv2dNative(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations, dimRoundingMode } = attrs;
  assertNotComplex([x, filter], "depthwiseConv2DNative");
  const xStrides = util_exports.computeStrides(x.shape);
  const filterStrides = util_exports.computeStrides(filter.shape);
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filter.shape,
    strides,
    $dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const { filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo } = convInfo;
  const padLeft = padInfo.left;
  const padTop = padInfo.top;
  const chMul = convInfo.outChannels / convInfo.inChannels;
  const y = new TensorBuffer(convInfo.outShape, x.dtype);
  const xVals = backend2.data.get(x.dataId).values;
  const wVals = backend2.data.get(filter.dataId).values;
  const yVals = y.values;
  for (let b = 0; b < convInfo.batchSize; ++b) {
    const xOffset1 = b * xStrides[0];
    const yOffset1 = b * y.strides[0];
    for (let yR = 0; yR < convInfo.outHeight; ++yR) {
      const yOffset2 = yOffset1 + yR * y.strides[1];
      const xRCorner = yR * convInfo.strideHeight - padTop;
      for (let wR = 0; wR < filterHeight; ++wR) {
        const xR = xRCorner + wR * dilationHeight;
        if (xR < 0 || xR >= convInfo.inHeight) {
          continue;
        }
        const wOffset1 = wR * filterStrides[0];
        const xOffset2 = xOffset1 + xR * xStrides[1];
        for (let yC = 0; yC < convInfo.outWidth; ++yC) {
          const yOffset3 = yOffset2 + yC * y.strides[2];
          const xCCorner = yC * convInfo.strideWidth - padLeft;
          for (let wC = 0; wC < filterWidth; ++wC) {
            const xC = xCCorner + wC * dilationWidth;
            if (xC < 0 || xC >= convInfo.inWidth) {
              continue;
            }
            const wOffset2 = wOffset1 + wC * filterStrides[1];
            const xOffset3 = xOffset2 + xC * convInfo.inChannels;
            let yOffset4 = yOffset3;
            let wOffset3 = wOffset2;
            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {
              const xVal = xVals[xOffset3 + d1];
              for (let q = 0; q < chMul; ++q) {
                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];
              }
              yOffset4 += chMul;
              wOffset3 += chMul;
            }
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(y.shape, y.dtype, y.values);
}
var depthwiseConv2dNativeConfig;
var init_DepthwiseConv2dNative = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js"() {
    init_dist();
    init_cpu_util();
    depthwiseConv2dNativeConfig = {
      kernelName: DepthwiseConv2dNative,
      backendName: "cpu",
      kernelFunc: depthwiseConv2dNative
    };
  }
});
function depthwiseConv2dNativeBackpropFilter2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, dilations, pad: pad2, dimRoundingMode, filterShape } = attrs;
  assertNotComplex([x, dy], "depthwiseConv2dNativeBackpropFilter");
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filterShape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const { strideHeight, strideWidth, filterHeight, filterWidth } = convInfo;
  const dW = new TensorBuffer(convInfo.filterShape, "float32");
  const leftPad = convInfo.padInfo.left;
  const topPad = convInfo.padInfo.top;
  const chMul = convInfo.outChannels / convInfo.inChannels;
  const xVals = backend2.data.get(x.dataId).values;
  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);
  const dyVals = backend2.data.get(dy.dataId).values;
  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);
  for (let wR = 0; wR < filterHeight; ++wR) {
    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));
    const yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);
    for (let wC = 0; wC < filterWidth; ++wC) {
      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));
      const yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);
      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {
        const d1 = Math.trunc(d2 / chMul);
        const dm = d2 % chMul;
        let dotProd = 0;
        for (let b = 0; b < convInfo.batchSize; ++b) {
          for (let yR = yRMin; yR < yRMax; ++yR) {
            const xR = wR + yR * strideHeight - topPad;
            for (let yC = yCMin; yC < yCMax; ++yC) {
              const xC = wC + yC * strideWidth - leftPad;
              dotProd += xBuf.get(b, xR, xC, d1) * dyBuf.get(b, yR, yC, d2);
            }
          }
        }
        dW.set(dotProd, wR, wC, d1, dm);
      }
    }
  }
  return backend2.makeTensorInfo(dW.shape, dW.dtype, dW.values);
}
var depthwiseConv2dNativeBackpropFilterConfig;
var init_DepthwiseConv2dNativeBackpropFilter = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js"() {
    init_dist();
    init_cpu_util();
    depthwiseConv2dNativeBackpropFilterConfig = {
      kernelName: DepthwiseConv2dNativeBackpropFilter,
      backendName: "cpu",
      kernelFunc: depthwiseConv2dNativeBackpropFilter2
    };
  }
});
function depthwiseConv2dNativeBackpropInput2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, dilations, pad: pad2, dimRoundingMode, inputShape } = attrs;
  assertNotComplex([dy, filter], "depthwiseConv2DNativeBackpropInput");
  const dyStrides = util_exports.computeStrides(dy.shape);
  const filterStrides = util_exports.computeStrides(filter.shape);
  const convInfo = backend_util_exports.computeConv2DInfo(
    inputShape,
    filter.shape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const dx = new TensorBuffer(convInfo.inShape, "float32");
  const dxValues = dx.values;
  const [dxS0, dxS1, dxS2] = dx.strides;
  const dyValues = backend2.data.get(dy.dataId).values;
  const [dyS0, dyS1, dyS2] = dyStrides;
  const fltValues = backend2.data.get(filter.dataId).values;
  const [fltS0, fltS1, fltS2] = filterStrides;
  const { batchSize, filterHeight, filterWidth, inChannels, inHeight, inWidth, outChannels, outHeight, outWidth, strideHeight, strideWidth } = convInfo;
  const topPad = filterHeight - 1 - convInfo.padInfo.top;
  const leftPad = filterWidth - 1 - convInfo.padInfo.left;
  const chMul = outChannels / inChannels;
  for (let b = 0; b < batchSize; ++b) {
    for (let d1 = 0; d1 < inChannels; ++d1) {
      for (let xR = 0; xR < inHeight; ++xR) {
        const xRCorner = xR - topPad;
        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));
        const yRMax = Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);
        for (let xC = 0; xC < inWidth; ++xC) {
          const xCCorner = xC - leftPad;
          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));
          const yCMax = Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);
          let dotProd = 0;
          for (let yR = xRMin; yR < yRMax; ++yR) {
            const wR = yR * strideHeight - xRCorner;
            for (let yC = xCMin; yC < yCMax; ++yC) {
              const wC = yC * strideWidth - xCCorner;
              const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;
              const fltOffset = fltS0 * (filterHeight - 1 - wR) + fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;
              for (let dm = 0; dm < chMul; ++dm) {
                const d2 = d1 * chMul + dm;
                const pixel = dyValues[dyOffset + d2];
                const weight = fltValues[fltOffset + dm];
                dotProd += pixel * weight;
              }
            }
          }
          dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var depthwiseConv2dNativeBackpropInputConfig;
var init_DepthwiseConv2dNativeBackpropInput = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js"() {
    init_dist();
    init_cpu_util();
    depthwiseConv2dNativeBackpropInputConfig = {
      kernelName: DepthwiseConv2dNativeBackpropInput,
      backendName: "cpu",
      kernelFunc: depthwiseConv2dNativeBackpropInput2
    };
  }
});
function diag(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  const xSize = util_exports.sizeFromShape(x.shape);
  const xVals = backend2.data.get(x.dataId).values;
  const outBuf = buffer([xSize, xSize], x.dtype);
  const vals = outBuf.values;
  for (let i = 0; i < xVals.length; i++) {
    vals[i * xSize + i] = xVals[i];
  }
  const outShape = [...x.shape, ...x.shape];
  return backend2.makeTensorInfo(outShape, outBuf.dtype, outBuf.values);
}
var diagConfig;
var init_Diag = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js"() {
    init_dist();
    diagConfig = {
      kernelName: Diag,
      backendName: "cpu",
      kernelFunc: diag
    };
  }
});
var dilation2DConfig;
var init_Dilation2D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js"() {
    init_dist();
    dilation2DConfig = {
      kernelName: Dilation2D,
      backendName: "cpu",
      kernelFunc: ({ inputs, backend: backend2, attrs }) => {
        const { x, filter } = inputs;
        const { strides, pad: pad2, dilations } = attrs;
        const cpuBackend = backend2;
        const xVals = cpuBackend.data.get(x.dataId).values;
        const xRank = x.shape.length;
        const filterVals = cpuBackend.data.get(filter.dataId).values;
        const filterRank = filter.shape.length;
        const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
        const outSize = util_exports.sizeFromShape(outShape);
        const outRank = outShape.length;
        const outputVals = util_exports.getArrayFromDType(x.dtype, outSize);
        for (let b = 0; b < batchSize; ++b) {
          for (let hOut = 0; hOut < outHeight; ++hOut) {
            const hBeg = hOut * strideHeight - padInfo.top;
            for (let wOut = 0; wOut < outWidth; ++wOut) {
              const wBeg = wOut * strideWidth - padInfo.left;
              for (let d = 0; d < inChannels; ++d) {
                let curVal = Number.MIN_SAFE_INTEGER;
                for (let h = 0; h < filterHeight; ++h) {
                  const hIn = hBeg + h * dilationHeight;
                  if (hIn >= 0 && hIn < inHeight) {
                    for (let w = 0; w < filterWidth; ++w) {
                      const wIn = wBeg + w * dilationWidth;
                      if (wIn >= 0 && wIn < inWidth) {
                        const xIndex = util_exports.locToIndex([b, hIn, wIn, d], xRank, util_exports.computeStrides(x.shape));
                        const filterIndex = util_exports.locToIndex([h, w, d], filterRank, util_exports.computeStrides(filter.shape));
                        const val = xVals[xIndex] + filterVals[filterIndex];
                        if (val > curVal) {
                          curVal = val;
                        }
                      }
                    }
                  }
                }
                const outputIndex = util_exports.locToIndex([b, hOut, wOut, d], outRank, util_exports.computeStrides(outShape));
                outputVals[outputIndex] = curVal;
              }
            }
          }
        }
        const dataId = cpuBackend.write(util_exports.toTypedArray(outputVals, x.dtype), outShape, x.dtype);
        return { dataId, shape: outShape, dtype: x.dtype };
      }
    };
  }
});
var dilation2DBackpropFilterConfig;
var init_Dilation2DBackpropFilter = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js"() {
    init_dist();
    dilation2DBackpropFilterConfig = {
      kernelName: Dilation2DBackpropFilter,
      backendName: "cpu",
      kernelFunc: ({ inputs, backend: backend2, attrs }) => {
        const { x, filter, dy } = inputs;
        const { strides, pad: pad2, dilations } = attrs;
        const cpuBackend = backend2;
        const $x = util_exports.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
        const $filter = util_exports.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
        const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
        util_exports.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropFilter}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
        const $dy = util_exports.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
        const gradients = util_exports.makeZerosNestedTypedArray(filter.shape, filter.dtype);
        for (let b = 0; b < batchSize; ++b) {
          for (let hOut = 0; hOut < outHeight; ++hOut) {
            const hBeg = hOut * strideHeight - padInfo.top;
            for (let wOut = 0; wOut < outWidth; ++wOut) {
              const wBeg = wOut * strideWidth - padInfo.left;
              for (let d = 0; d < inChannels; ++d) {
                let curVal = Number.MIN_SAFE_INTEGER;
                let hMax = 0;
                let wMax = 0;
                for (let h = 0; h < filterHeight; ++h) {
                  const hIn = hBeg + h * dilationHeight;
                  if (hIn >= 0 && hIn < inHeight) {
                    for (let w = 0; w < filterWidth; ++w) {
                      const wIn = wBeg + w * dilationWidth;
                      if (wIn >= 0 && wIn < inWidth) {
                        const val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                        if (val > curVal) {
                          curVal = val;
                          hMax = h;
                          wMax = w;
                        }
                      }
                    }
                  }
                }
                gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];
              }
            }
          }
        }
        const dataId = cpuBackend.write(util_exports.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);
        return { dataId, shape: filter.shape, dtype: filter.dtype };
      }
    };
  }
});
var dilation2DBackpropInputConfig;
var init_Dilation2DBackpropInput = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js"() {
    init_dist();
    dilation2DBackpropInputConfig = {
      kernelName: Dilation2DBackpropInput,
      backendName: "cpu",
      kernelFunc: ({ inputs, backend: backend2, attrs }) => {
        const { x, filter, dy } = inputs;
        const { strides, pad: pad2, dilations } = attrs;
        const cpuBackend = backend2;
        const $x = util_exports.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);
        const $filter = util_exports.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);
        const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
        util_exports.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput}, dy must have the same rank as output ${outShape.length}, but got ${dy.rank}`);
        const $dy = util_exports.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);
        const gradients = util_exports.makeZerosNestedTypedArray(x.shape, x.dtype);
        for (let b = 0; b < batchSize; ++b) {
          for (let hOut = 0; hOut < outHeight; ++hOut) {
            const hBeg = hOut * strideHeight - padInfo.top;
            for (let wOut = 0; wOut < outWidth; ++wOut) {
              const wBeg = wOut * strideWidth - padInfo.left;
              for (let d = 0; d < inChannels; ++d) {
                let curVal = Number.MIN_SAFE_INTEGER;
                let hInMax = hBeg < 0 ? 0 : hBeg;
                let wInMax = wBeg < 0 ? 0 : wBeg;
                for (let h = 0; h < filterHeight; ++h) {
                  const hIn = hBeg + h * dilationHeight;
                  if (hIn >= 0 && hIn < inHeight) {
                    for (let w = 0; w < filterWidth; ++w) {
                      const wIn = wBeg + w * dilationWidth;
                      if (wIn >= 0 && wIn < inWidth) {
                        const val = $x[b][hIn][wIn][d] + $filter[h][w][d];
                        if (val > curVal) {
                          curVal = val;
                          hInMax = hIn;
                          wInMax = wIn;
                        }
                      }
                    }
                  }
                }
                gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];
              }
            }
          }
        }
        const dataId = cpuBackend.write(util_exports.toTypedArray(gradients, x.dtype), x.shape, x.dtype);
        return { dataId, shape: x.shape, dtype: x.dtype };
      }
    };
  }
});
function sum3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "sum");
  let $x;
  if (x.dtype === "bool") {
    $x = cast3({ inputs: { x }, backend: backend2, attrs: { dtype: "int32" } });
  } else {
    $x = identity4({ inputs: { x }, backend: backend2 });
  }
  const xRank = $x.shape.length;
  const axes = util_exports.parseAxisParam(axis, $x.shape);
  const permutation = backend_util_exports.getAxesPermutation(axes, xRank);
  let reductionAxes = axes;
  let permutedX = $x;
  if (permutation != null) {
    permutedX = transpose22({ inputs: { x: $x }, backend: backend2, attrs: { perm: permutation } });
    reductionAxes = backend_util_exports.getInnerMostAxes(reductionAxes.length, xRank);
  }
  backend_util_exports.assertAxesAreInnerMostDims("sum", reductionAxes, permutedX.shape.length);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, reductionAxes);
  const resultDtype = backend_util_exports.upcastType(permutedX.dtype, "int32");
  let result = zeros2(backend2, outShape, resultDtype);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const vals = backend2.data.get(result.dataId).values;
  const aVals = backend2.data.get(permutedX.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let sum5 = 0;
    for (let j = 0; j < reduceSize; ++j) {
      sum5 += aVals[offset + j];
    }
    vals[i] = sum5;
  }
  if (keepDims) {
    const newShape = backend_util_exports.expandShapeToKeepDim(result.shape, axes);
    const oldResult = result;
    result = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: newShape } });
    backend2.disposeIntermediateTensorInfo(oldResult);
  }
  backend2.disposeIntermediateTensorInfo($x);
  if (permutation != null) {
    backend2.disposeIntermediateTensorInfo(permutedX);
  }
  return result;
}
var sumConfig;
var init_Sum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js"() {
    init_dist();
    init_cpu_util();
    init_zeros_impl();
    init_Cast();
    init_Identity();
    init_Reshape();
    init_Transpose();
    sumConfig = {
      kernelName: Sum,
      backendName: "cpu",
      kernelFunc: sum3
    };
  }
});
function einsum(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { equation } = attrs;
  const tensors = inputs;
  const { allDims, summedDims, idDims } = backend_util_exports.decodeEinsumEquation(equation, tensors.length);
  backend_util_exports.checkEinsumDimSizes(allDims.length, idDims, tensors);
  const { path, steps } = backend_util_exports.getEinsumComputePath(summedDims, idDims);
  const nSteps = steps.length;
  let out = null;
  let numDimsRemaining = allDims.length;
  const tensorsToDispose = [];
  for (let i = 0; i < nSteps; ++i) {
    for (const idTerm of steps[i]) {
      const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
      let x;
      if (backend_util_exports.isIdentityPermutation(perm)) {
        x = tensors[idTerm];
      } else {
        x = transpose22({ inputs: { x: tensors[idTerm] }, backend: backend2, attrs: { perm } });
        tensorsToDispose.push(x);
      }
      const targetShape = x.shape.slice();
      for (let k = 0; k < dimsToExpand.length; ++k) {
        targetShape.splice(dimsToExpand[k], 0, 1);
      }
      if (!util_exports.arraysEqual(x.shape, targetShape)) {
        x = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: targetShape } });
        tensorsToDispose.push(x);
      }
      if (out === null) {
        out = x;
      } else {
        out = multiply5({ inputs: { a: x, b: out }, backend: backend2 });
        tensorsToDispose.push(out);
      }
    }
    if (i < nSteps - 1) {
      if (path[i] >= 0) {
        out = sum3({
          inputs: { x: out },
          backend: backend2,
          attrs: {
            axis: path[i] - (allDims.length - numDimsRemaining),
            keepDims: false
          }
        });
        tensorsToDispose.push(out);
      }
      numDimsRemaining--;
    }
  }
  for (const tensorInfo of tensorsToDispose) {
    if (tensorInfo === out) {
      continue;
    }
    backend2.disposeIntermediateTensorInfo(tensorInfo);
  }
  return out;
}
var einsumConfig;
var init_Einsum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js"() {
    init_dist();
    init_Multiply();
    init_Reshape();
    init_Sum();
    init_Transpose();
    einsumConfig = {
      kernelName: Einsum,
      backendName: "cpu",
      kernelFunc: einsum
    };
  }
});
function eluGrad(args) {
  const { inputs, backend: backend2 } = args;
  const { dy, y } = inputs;
  assertNotComplex([dy, y], "eluGrad");
  const resultValues = new Float32Array(util_exports.sizeFromShape(y.shape));
  const values = backend2.data.get(y.dataId).values;
  const dyValues = backend2.data.get(dy.dataId).values;
  for (let i = 0; i < values.length; ++i) {
    const v = values[i];
    if (v >= 1) {
      resultValues[i] = dyValues[i];
    } else {
      resultValues[i] = dyValues[i] * (v + 1);
    }
  }
  return backend2.makeTensorInfo(y.shape, "float32", resultValues);
}
var eluGradConfig2;
var init_EluGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js"() {
    init_dist();
    init_cpu_util();
    eluGradConfig2 = {
      kernelName: EluGrad,
      backendName: "cpu",
      kernelFunc: eluGrad
    };
  }
});
var p;
var a1;
var a2;
var a3;
var a4;
var a5;
var erf2;
var erfConfig;
var init_Erf = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js"() {
    init_dist();
    init_unary_utils();
    p = backend_util_exports.ERF_P;
    a1 = backend_util_exports.ERF_A1;
    a2 = backend_util_exports.ERF_A2;
    a3 = backend_util_exports.ERF_A3;
    a4 = backend_util_exports.ERF_A4;
    a5 = backend_util_exports.ERF_A5;
    erf2 = unaryKernelFunc(Erf, (xi) => {
      const sign4 = Math.sign(xi);
      const v = Math.abs(xi);
      const t = 1 / (1 + p * v);
      return sign4 * (1 - ((((a5 * t + a4) * t + a3) * t + a2) * t + a1) * t * Math.exp(-v * v));
    });
    erfConfig = {
      kernelName: Erf,
      backendName: "cpu",
      kernelFunc: erf2
    };
  }
});
function expandDims3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { input: input2 } = inputs;
  const { dim } = attrs;
  const inputRank = input2.shape.length;
  const newShape = input2.shape.slice();
  let $dim = dim;
  if (dim < 0) {
    util_exports.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
    $dim = inputRank + dim + 1;
  }
  newShape.splice($dim, 0, 1);
  return reshape2({ inputs: { x: input2 }, backend: backend2, attrs: { shape: newShape } });
}
var expandDimsConfig;
var init_ExpandDims = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js"() {
    init_dist();
    init_Reshape();
    expandDimsConfig = {
      kernelName: ExpandDims,
      backendName: "cpu",
      kernelFunc: expandDims3
    };
  }
});
var realDivImpl;
var div22;
var realDivConfig;
var init_RealDiv = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    realDivImpl = createSimpleBinaryKernelImpl((a, b) => a / b);
    div22 = binaryKernelFunc(RealDiv, realDivImpl);
    realDivConfig = {
      kernelName: RealDiv,
      backendName: "cpu",
      kernelFunc: div22
    };
  }
});
function fftBatch(input2, inverse2, cpuBackend) {
  const inputShape = input2.shape;
  const batch = inputShape[0];
  const innerDim = inputShape[1];
  const inputVals = cpuBackend.data.get(input2.dataId);
  const real2D = inputVals.complexTensorInfos.real;
  const imag2D = inputVals.complexTensorInfos.imag;
  const resultShape = [batch, innerDim];
  const resultSize = util_exports.sizeFromShape(resultShape);
  const resultReal = util_exports.getTypedArrayFromDType("float32", resultSize);
  const resultImag = util_exports.getTypedArrayFromDType("float32", resultSize);
  for (let b = 0; b < batch; b++) {
    const r = slice2({
      inputs: { x: real2D },
      backend: cpuBackend,
      attrs: { begin: [b, 0], size: [1, innerDim] }
    });
    const i = slice2({
      inputs: { x: imag2D },
      backend: cpuBackend,
      attrs: { begin: [b, 0], size: [1, innerDim] }
    });
    const input3 = complex2({ inputs: { real: r, imag: i }, backend: cpuBackend });
    const { real: real4, imag: imag4 } = fftImpl(input3, inverse2, cpuBackend);
    const res = backend_util_exports.mergeRealAndImagArrays(real4, imag4);
    for (let d = 0; d < innerDim; d++) {
      const c = backend_util_exports.getComplexWithIndex(res, d);
      resultReal[b * innerDim + d] = c.real;
      resultImag[b * innerDim + d] = c.imag;
    }
    cpuBackend.disposeIntermediateTensorInfo(r);
    cpuBackend.disposeIntermediateTensorInfo(i);
    cpuBackend.disposeIntermediateTensorInfo(input3);
  }
  const $realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultReal);
  const $imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", resultImag);
  const result = complex2({ inputs: { real: $realInfo, imag: $imagInfo }, backend: cpuBackend });
  cpuBackend.disposeIntermediateTensorInfo($realInfo);
  cpuBackend.disposeIntermediateTensorInfo($imagInfo);
  return result;
}
function fftImpl(input2, inverse2, cpuBackend) {
  const inputSize = util_exports.sizeFromShape(input2.shape);
  const inputVals = cpuBackend.data.get(input2.dataId);
  const realVals = cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values;
  const imagVals = cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values;
  if (isExponentOf2(inputSize)) {
    const result = fftRadix2(realVals, imagVals, inputSize, inverse2, cpuBackend);
    const resultShape = [input2.shape[0], input2.shape[1]];
    if (inverse2) {
      const realInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.real);
      const imagInfo = cpuBackend.makeTensorInfo(resultShape, "float32", result.imag);
      const sizeInfo = cpuBackend.makeTensorInfo([], "float32", util_exports.createScalarValue(inputSize, "float32"));
      const sizeInfoCopy = identity4({ inputs: { x: sizeInfo }, backend: cpuBackend });
      const divRealInfo = realDivConfig.kernelFunc({ inputs: { a: realInfo, b: sizeInfo }, backend: cpuBackend });
      const divImagInfo = realDivConfig.kernelFunc({ inputs: { a: imagInfo, b: sizeInfoCopy }, backend: cpuBackend });
      const divRealVals = cpuBackend.data.get(divRealInfo.dataId).values;
      const divImagVals = cpuBackend.data.get(divImagInfo.dataId).values;
      cpuBackend.disposeIntermediateTensorInfo(realInfo);
      cpuBackend.disposeIntermediateTensorInfo(imagInfo);
      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);
      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);
      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);
      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);
      return { real: divRealVals, imag: divImagVals };
    }
    return result;
  } else {
    const data = backend_util_exports.mergeRealAndImagArrays(realVals, imagVals);
    const rawOutput = fourierTransformByMatmul(data, inputSize, inverse2);
    return backend_util_exports.splitRealAndImagArrays(rawOutput);
  }
}
function isExponentOf2(size) {
  return (size & size - 1) === 0;
}
function fftRadix2(realVals, imagVals, size, inverse2, cpuBackend) {
  if (size === 1) {
    return { real: realVals, imag: imagVals };
  }
  const data = backend_util_exports.mergeRealAndImagArrays(realVals, imagVals);
  const half = size / 2;
  const evenComplex = backend_util_exports.complexWithEvenIndex(data);
  const evenRealVals = evenComplex.real;
  const evenImagVals = evenComplex.imag;
  const evenShape = [evenRealVals.length];
  const evenRealInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenRealVals);
  const evenImagInfo = cpuBackend.makeTensorInfo(evenShape, "float32", evenImagVals);
  const evenTensorInfo = complex2({ inputs: { real: evenRealInfo, imag: evenImagInfo }, backend: cpuBackend });
  const oddComplex = backend_util_exports.complexWithOddIndex(data);
  const oddRealVals = oddComplex.real;
  const oddImagVals = oddComplex.imag;
  const oddShape = [oddRealVals.length];
  const oddRealInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddRealVals);
  const oddImagInfo = cpuBackend.makeTensorInfo(oddShape, "float32", oddImagVals);
  const oddTensorInfo = complex2({ inputs: { real: oddRealInfo, imag: oddImagInfo }, backend: cpuBackend });
  const $evenComplex = fftRadix2(evenRealVals, evenImagVals, half, inverse2, cpuBackend);
  const $evenRealVals = $evenComplex.real;
  const $evenImagVals = $evenComplex.imag;
  const $evenShape = [$evenRealVals.length];
  const $evenRealInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenRealVals);
  const $evenImagInfo = cpuBackend.makeTensorInfo($evenShape, "float32", $evenImagVals);
  const $evenTensorInfo = complex2({
    inputs: { real: $evenRealInfo, imag: $evenImagInfo },
    backend: cpuBackend
  });
  const $oddComplex = fftRadix2(oddRealVals, oddImagVals, half, inverse2, cpuBackend);
  const $oddRealVals = $oddComplex.real;
  const $oddImagVals = $oddComplex.imag;
  const $oddShape = [$oddRealVals.length];
  const $oddRealInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddRealVals);
  const $oddImagInfo = cpuBackend.makeTensorInfo($oddShape, "float32", $oddImagVals);
  const $oddTensorInfo = complex2({ inputs: { real: $oddRealInfo, imag: $oddImagInfo }, backend: cpuBackend });
  const e = backend_util_exports.exponents(size, inverse2);
  const eShape = [e.real.length];
  const eRealInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.real);
  const eImagInfo = cpuBackend.makeTensorInfo(eShape, "float32", e.imag);
  const complexInfo = complex2({ inputs: { real: eRealInfo, imag: eImagInfo }, backend: cpuBackend });
  const exponentInfo = multiply5({ inputs: { a: complexInfo, b: $oddTensorInfo }, backend: cpuBackend });
  const addPart = add32({
    inputs: { a: $evenTensorInfo, b: exponentInfo },
    backend: cpuBackend
  });
  const subPart = sub22({
    inputs: { a: $evenTensorInfo, b: exponentInfo },
    backend: cpuBackend
  });
  const addPartReal = real2({ inputs: { input: addPart }, backend: cpuBackend });
  const subPartReal = real2({ inputs: { input: subPart }, backend: cpuBackend });
  const addPartImag = imag2({ inputs: { input: addPart }, backend: cpuBackend });
  const subPartImag = imag2({ inputs: { input: subPart }, backend: cpuBackend });
  const $real = concat2({
    inputs: [addPartReal, subPartReal],
    backend: cpuBackend,
    attrs: { axis: 0 }
  });
  const $imag = concat2({
    inputs: [addPartImag, subPartImag],
    backend: cpuBackend,
    attrs: { axis: 0 }
  });
  const $realVals = cpuBackend.data.get($real.dataId).values;
  const $imagVals = cpuBackend.data.get($imag.dataId).values;
  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);
  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);
  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);
  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);
  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);
  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);
  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);
  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);
  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);
  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);
  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);
  cpuBackend.disposeIntermediateTensorInfo(complexInfo);
  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);
  cpuBackend.disposeIntermediateTensorInfo(addPart);
  cpuBackend.disposeIntermediateTensorInfo(subPart);
  cpuBackend.disposeIntermediateTensorInfo(addPartReal);
  cpuBackend.disposeIntermediateTensorInfo(addPartImag);
  cpuBackend.disposeIntermediateTensorInfo(subPartReal);
  cpuBackend.disposeIntermediateTensorInfo(subPartImag);
  cpuBackend.disposeIntermediateTensorInfo($real);
  cpuBackend.disposeIntermediateTensorInfo($imag);
  return { real: $realVals, imag: $imagVals };
}
function fourierTransformByMatmul(data, size, inverse2) {
  const ret = new Float32Array(size * 2);
  for (let r = 0; r < size; r++) {
    let real4 = 0;
    let imag4 = 0;
    for (let c = 0; c < size; c++) {
      const e = backend_util_exports.exponent(r * c, size, inverse2);
      const term = backend_util_exports.getComplexWithIndex(data, c);
      real4 += term.real * e.real - term.imag * e.imag;
      imag4 += term.real * e.imag + term.imag * e.real;
    }
    if (inverse2) {
      real4 /= size;
      imag4 /= size;
    }
    backend_util_exports.assignToTypedArray(ret, real4, imag4, r);
  }
  return ret;
}
var init_fft_utils = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js"() {
    init_dist();
    init_Add();
    init_Complex();
    init_Concat();
    init_Identity();
    init_Imag();
    init_Multiply();
    init_Real();
    init_RealDiv();
    init_Slice();
    init_Sub();
  }
});
function fft2(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  const inputSize = util_exports.sizeFromShape(input2.shape);
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const input2D = reshape2({
    inputs: { x: input2 },
    backend: backend2,
    attrs: { shape: [batch, innerDimensionSize] }
  });
  const result = fftBatch(input2D, false, backend2);
  const resultReshaped = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: input2.shape } });
  backend2.disposeIntermediateTensorInfo(input2D);
  backend2.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var fftConfig;
var init_FFT = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js"() {
    init_dist();
    init_fft_utils();
    init_Reshape();
    fftConfig = {
      kernelName: FFT,
      backendName: "cpu",
      kernelFunc: fft2
    };
  }
});
function fill2(args) {
  const { backend: backend2, attrs } = args;
  const { shape, value, dtype } = attrs;
  const $dtype = dtype || util_exports.inferDtype(value);
  const values = util_exports.getArrayFromDType($dtype, util_exports.sizeFromShape(shape));
  fillValues(values, value, $dtype);
  return backend2.makeTensorInfo(shape, $dtype, values);
}
function fillValues(values, value, dtype) {
  if (dtype === "string") {
    values.fill(value);
  } else {
    values.fill(value);
  }
}
var fillConfig;
var init_Fill = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js"() {
    init_dist();
    fillConfig = {
      kernelName: Fill,
      backendName: "cpu",
      kernelFunc: fill2
    };
  }
});
var flipLeftRightConfig;
var init_FlipLeftRight = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js"() {
    init_dist();
    flipLeftRightConfig = {
      kernelName: FlipLeftRight,
      backendName: "cpu",
      kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
        const { image: image2 } = inputs;
        const cpuBackend = backend2;
        const output = util_exports.getTypedArrayFromDType(image2.dtype, util_exports.sizeFromShape(image2.shape));
        const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
        const imageVals = cpuBackend.data.get(image2.dataId).values;
        for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
          const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
          for (let row = 0; row < imageHeight; row++) {
            const rowOffset = row * (imageWidth * numChannels);
            for (let col = 0; col < imageWidth; col++) {
              const colOffset = col * numChannels;
              for (let channel = 0; channel < numChannels; channel++) {
                const coordX = Math.round(imageWidth - col - 1);
                const outIdx = batchOffset + rowOffset + colOffset + channel;
                let outputValue = imageVals[outIdx];
                if (coordX >= 0 && coordX < imageWidth) {
                  const rotatedColOffset = coordX * numChannels;
                  const imageIdx = batchOffset + rowOffset + rotatedColOffset + channel;
                  outputValue = imageVals[imageIdx];
                }
                output[outIdx] = outputValue;
              }
            }
          }
        }
        const dataId = cpuBackend.write(output, image2.shape, image2.dtype);
        return { dataId, shape: image2.shape, dtype: image2.dtype };
      }
    };
  }
});
var floorDivImpl;
var floorDiv2;
var floorDivConfig;
var init_FloorDiv = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    floorDivImpl = createSimpleBinaryKernelImpl((a, b) => Math.floor(a / b));
    floorDiv2 = binaryKernelFunc(FloorDiv, floorDivImpl, null, "int32");
    floorDivConfig = {
      kernelName: FloorDiv,
      backendName: "cpu",
      kernelFunc: floorDiv2
    };
  }
});
function fusedConv2D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
  let result = conv2D({
    inputs: { x, filter },
    backend: backend2,
    attrs: { strides, pad: pad2, dataFormat, dilations, dimRoundingMode }
  });
  if (bias) {
    const resultOld = result;
    if (dataFormat === "NCHW" && bias.shape.length === 1 && bias.shape[0] !== 1) {
      const reshapedBias = reshape2({ inputs: { x: bias }, backend: backend2, attrs: { shape: [bias.shape[0], 1, 1] } });
      result = add32({ inputs: { a: result, b: reshapedBias }, backend: backend2 });
      backend2.disposeIntermediateTensorInfo(reshapedBias);
    } else {
      result = add32({ inputs: { a: result, b: bias }, backend: backend2 });
    }
    backend2.disposeIntermediateTensorInfo(resultOld);
  }
  if (activation) {
    const resultOld = result;
    if (dataFormat === "NCHW" && activation === "prelu" && preluActivationWeights.shape.length === 1 && preluActivationWeights.shape[0] !== 1) {
      const reshapedAlpha = reshape2({
        inputs: { x: preluActivationWeights },
        backend: backend2,
        attrs: { shape: [preluActivationWeights.shape[0], 1, 1] }
      });
      result = applyActivation2(backend2, result, activation, reshapedAlpha, leakyreluAlpha);
      backend2.disposeIntermediateTensorInfo(reshapedAlpha);
    } else {
      result = applyActivation2(backend2, result, activation, preluActivationWeights, leakyreluAlpha);
    }
    backend2.disposeIntermediateTensorInfo(resultOld);
  }
  return result;
}
var fusedConv2DConfig;
var init_FusedConv2D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js"() {
    init_dist();
    init_fused_utils();
    init_Add();
    init_Conv2D();
    init_Reshape();
    fusedConv2DConfig = {
      kernelName: FusedConv2D,
      backendName: "cpu",
      kernelFunc: fusedConv2D
    };
  }
});
function fusedDepthwiseConv2D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
  let result = depthwiseConv2dNative({
    inputs: { x, filter },
    backend: backend2,
    attrs: { strides, pad: pad2, dataFormat, dilations, dimRoundingMode }
  });
  if (bias) {
    const oldResult = result;
    result = add32({ inputs: { a: result, b: bias }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(oldResult);
  }
  if (activation) {
    const oldResult = result;
    result = applyActivation2(backend2, result, activation, preluActivationWeights, leakyreluAlpha);
    backend2.disposeIntermediateTensorInfo(oldResult);
  }
  return result;
}
var fusedDepthwiseConv2DConfig;
var init_FusedDepthwiseConv2D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js"() {
    init_dist();
    init_fused_utils();
    init_Add();
    init_DepthwiseConv2dNative();
    fusedDepthwiseConv2DConfig = {
      kernelName: FusedDepthwiseConv2D,
      backendName: "cpu",
      kernelFunc: fusedDepthwiseConv2D
    };
  }
});
function gatherNd(args) {
  const { inputs, backend: backend2 } = args;
  const { params, indices } = inputs;
  const paramsSize = util_exports.sizeFromShape(params.shape);
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  const [resultShape, numSlices, sliceSize, strides] = backend_util_exports.prepareAndValidate(params, indices);
  if (numSlices === 0) {
    return backend2.makeTensorInfo(resultShape, params.dtype, []);
  }
  const indicesData = backend2.data.get(indices.dataId).values;
  const paramsBuf = backend2.bufferSync(params);
  const outBuf = gatherNdImpl(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
  return backend2.makeTensorInfo(resultShape, params.dtype, outBuf.values);
}
var gatherNdConfig;
var init_GatherNd = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js"() {
    init_dist();
    init_GatherNd_Impl();
    gatherNdConfig = {
      kernelName: GatherNd,
      backendName: "cpu",
      kernelFunc: gatherNd
    };
  }
});
function gatherV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, indices } = inputs;
  const { axis, batchDims } = attrs;
  assertNotComplex([x, indices], "gatherV2");
  const parsedAxis = util_exports.parseAxisParam(axis, x.shape)[0];
  const indicesVals = backend2.data.get(indices.dataId).values;
  const axisDim = x.shape[parsedAxis];
  for (let i = 0; i < indicesVals.length; ++i) {
    const index = indicesVals[i];
    util_exports.assert(index <= axisDim - 1 && index >= 0, () => `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);
  }
  let $batchDims = batchDims;
  if (batchDims == null) {
    $batchDims = 0;
  }
  const indicesSize = util_exports.sizeFromShape(indices.shape);
  const shapeInfo = backend_util_exports.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, $batchDims);
  const flattenX = reshape2({
    inputs: { x },
    backend: backend2,
    attrs: {
      shape: [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        shapeInfo.dimSize,
        shapeInfo.sliceSize
      ]
    }
  });
  const flattenIndex = reshape2({
    inputs: { x: indices },
    backend: backend2,
    attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
  });
  const flattenOutputShape = [
    shapeInfo.batchSize,
    shapeInfo.outerSize,
    indicesSize / shapeInfo.batchSize,
    shapeInfo.sliceSize
  ];
  const indicesBuf = backend2.bufferSync(flattenIndex);
  const xBuf = backend2.bufferSync(flattenX);
  const outBuf = gatherV2Impl(xBuf, indicesBuf, flattenOutputShape);
  backend2.disposeIntermediateTensorInfo(flattenX);
  backend2.disposeIntermediateTensorInfo(flattenIndex);
  return backend2.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
}
var gatherV2Config;
var init_GatherV2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js"() {
    init_dist();
    init_cpu_util();
    init_GatherV2_impl();
    init_Reshape();
    gatherV2Config = {
      kernelName: GatherV2,
      backendName: "cpu",
      kernelFunc: gatherV2
    };
  }
});
function ifft2(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  const inputSize = util_exports.sizeFromShape(input2.shape);
  const innerDimensionSize = input2.shape[input2.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const input2D = reshape2({
    inputs: { x: input2 },
    backend: backend2,
    attrs: { shape: [batch, innerDimensionSize] }
  });
  const result = fftBatch(input2D, true, backend2);
  const resultReshaped = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: input2.shape } });
  backend2.disposeIntermediateTensorInfo(input2D);
  backend2.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var ifftConfig;
var init_IFFT = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js"() {
    init_dist();
    init_fft_utils();
    init_Reshape();
    ifftConfig = {
      kernelName: IFFT,
      backendName: "cpu",
      kernelFunc: ifft2
    };
  }
});
var isFinite3;
var isFiniteConfig;
var init_IsFinite = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js"() {
    init_dist();
    init_unary_utils();
    isFinite3 = unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, "bool");
    isFiniteConfig = {
      kernelName: IsFinite,
      backendName: "cpu",
      kernelFunc: isFinite3
    };
  }
});
var isInf2;
var isInfConfig;
var init_IsInf = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js"() {
    init_dist();
    init_unary_utils();
    isInf2 = unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, "bool");
    isInfConfig = {
      kernelName: IsInf,
      backendName: "cpu",
      kernelFunc: isInf2
    };
  }
});
var isNaN3;
var isNaNConfig;
var init_IsNaN = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js"() {
    init_dist();
    init_unary_utils();
    isNaN3 = unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, "bool");
    isNaNConfig = {
      kernelName: IsNan,
      backendName: "cpu",
      kernelFunc: isNaN3
    };
  }
});
function linSpace(args) {
  const { backend: backend2, attrs } = args;
  const { start, stop, num } = attrs;
  const outVals = linSpaceImpl(start, stop, num);
  return backend2.makeTensorInfo([outVals.length], "float32", outVals);
}
var linSpaceConfig;
var init_LinSpace = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js"() {
    init_dist();
    init_LinSpace_impl();
    linSpaceConfig = {
      kernelName: LinSpace,
      backendName: "cpu",
      kernelFunc: linSpace
    };
  }
});
var log1p2;
var log1pConfig;
var init_Log1p = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js"() {
    init_dist();
    init_unary_utils();
    log1p2 = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));
    log1pConfig = {
      kernelName: Log1p,
      backendName: "cpu",
      kernelFunc: log1p2
    };
  }
});
var logicalAndImpl;
var logicalAnd2;
var logicalAndConfig;
var init_LogicalAnd = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    logicalAndImpl = createSimpleBinaryKernelImpl((a, b) => a && b);
    logicalAnd2 = binaryKernelFunc(LogicalAnd, logicalAndImpl, null, "bool");
    logicalAndConfig = {
      kernelName: LogicalAnd,
      backendName: "cpu",
      kernelFunc: logicalAnd2
    };
  }
});
var logicalNot2;
var logicalNotConfig;
var init_LogicalNot = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js"() {
    init_dist();
    init_unary_utils();
    logicalNot2 = unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, "bool");
    logicalNotConfig = {
      kernelName: LogicalNot,
      backendName: "cpu",
      kernelFunc: logicalNot2
    };
  }
});
var logicalOrImpl;
var logicalOr2;
var logicalOrConfig;
var init_LogicalOr = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    logicalOrImpl = createSimpleBinaryKernelImpl((a, b) => a || b);
    logicalOr2 = binaryKernelFunc(LogicalOr, logicalOrImpl, null, "bool");
    logicalOrConfig = {
      kernelName: LogicalOr,
      backendName: "cpu",
      kernelFunc: logicalOr2
    };
  }
});
function lRN(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  assertNotComplex(x, "LRN");
  const channels = x.shape[3];
  const maxD = channels - 1;
  const xValues = backend2.data.get(x.dataId).values;
  const size = util_exports.sizeFromShape(x.shape);
  const result = new Float32Array(size);
  function sumAcrossChannels(offset) {
    const currentChannel = offset % channels;
    let beginSumOffset = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
    const endSumOffset = offset - currentChannel + Math.min(currentChannel + depthRadius, maxD);
    let sum5 = 0;
    for (; beginSumOffset <= endSumOffset; beginSumOffset++) {
      const z = xValues[beginSumOffset];
      sum5 += z * z;
    }
    return sum5;
  }
  for (let offset = 0; offset < size; offset++) {
    const sum5 = sumAcrossChannels(offset);
    const val = xValues[offset] * Math.pow(bias + alpha * sum5, -beta);
    result[offset] = val;
  }
  return backend2.makeTensorInfo(x.shape, x.dtype, result);
}
var LRNConfig;
var init_LRN = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js"() {
    init_dist();
    init_cpu_util();
    LRNConfig = {
      kernelName: LRN,
      backendName: "cpu",
      kernelFunc: lRN
    };
  }
});
function lRNGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, y, dy } = inputs;
  const { depthRadius, bias, alpha, beta } = attrs;
  assertNotComplex(dy, "LRNGrad");
  const dySize = util_exports.sizeFromShape(dy.shape);
  const channels = dy.shape[3];
  const dyValues = backend2.data.get(dy.dataId).values;
  const xValues = backend2.data.get(x.dataId).values;
  const yValues = backend2.data.get(y.dataId).values;
  const result = new Float32Array(dySize);
  const size = dySize;
  for (let offset = 0; offset < size; offset++) {
    const currentChannel = offset % channels;
    const depthBegin = offset - currentChannel + Math.max(0, currentChannel - depthRadius);
    const depthEnd = offset - currentChannel + Math.min(channels, currentChannel + depthRadius + 1);
    let norm2 = 0;
    for (let k = depthBegin; k < depthEnd; k++) {
      norm2 += Math.pow(xValues[k], 2);
    }
    norm2 = alpha * norm2 + bias;
    for (let k = depthBegin; k < depthEnd; k++) {
      let dyi = -2 * alpha * beta * xValues[k] * yValues[offset] / norm2;
      if (offset === k) {
        dyi += Math.pow(norm2, -beta);
      }
      dyi *= dyValues[offset];
      result[k] += dyi;
    }
  }
  return backend2.makeTensorInfo(dy.shape, x.dtype, result);
}
var LRNGradConfig;
var init_LRNGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js"() {
    init_dist();
    init_cpu_util();
    LRNGradConfig = {
      kernelName: LRNGrad,
      backendName: "cpu",
      kernelFunc: lRNGrad
    };
  }
});
function max3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { reductionIndices, keepDims } = attrs;
  const cpuBackend = backend2;
  let xShape = x.shape;
  const xRank = xShape.length;
  const origAxes = util_exports.parseAxisParam(reductionIndices, xShape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  let xVals = cpuBackend.data.get(x.dataId).values;
  if (permutedAxes != null) {
    const newShape = new Array(xRank);
    for (let i = 0; i < newShape.length; i++) {
      newShape[i] = xShape[permutedAxes[i]];
    }
    xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    xShape = newShape;
  }
  assertNotComplex(x, "max");
  backend_util_exports.assertAxesAreInnerMostDims("max", axes, xRank);
  const [maxOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xShape, axes);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);
  const dataId = cpuBackend.write(result, maxOutShape, x.dtype);
  let outShape = maxOutShape;
  if (keepDims) {
    const newShape = backend_util_exports.expandShapeToKeepDim(maxOutShape, origAxes);
    outShape = newShape;
  }
  return { dataId, shape: outShape, dtype: x.dtype };
}
var maxConfig;
var init_Max = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Max.js"() {
    init_dist();
    init_dist();
    init_dist();
    init_cpu_util();
    init_Max_impl();
    init_Transpose_impl();
    maxConfig = {
      kernelName: Max,
      backendName: "cpu",
      kernelFunc: max3
    };
  }
});
function maxPool2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  assertNotComplex(x, "maxPool");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  let res;
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    res = identity4({ inputs: { x }, backend: backend2 });
  } else {
    const xValues = backend2.data.get(x.dataId).values;
    const strides2 = util_exports.computeStrides(x.shape);
    const buffer2 = pool2(xValues, x.shape, x.dtype, strides2, convInfo, "max");
    res = backend2.makeTensorInfo(convInfo.outShape, x.dtype, buffer2.values);
  }
  return res;
}
var maxPoolConfig;
var init_MaxPool = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js"() {
    init_dist();
    init_cpu_util();
    init_pool_utils();
    init_Identity();
    maxPoolConfig = {
      kernelName: MaxPool,
      backendName: "cpu",
      kernelFunc: maxPool2
    };
  }
});
function maxPool3D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
  assertNotComplex(x, "maxPool3d");
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode, dataFormat);
  const xValues = backend2.data.get(x.dataId).values;
  const outBuf = pool3d2(xValues, x.shape, x.dtype, util_exports.computeStrides(x.shape), convInfo, "max");
  return backend2.makeTensorInfo(outBuf.shape, "float32", outBuf.values);
}
var maxPool3DConfig;
var init_MaxPool3D = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js"() {
    init_dist();
    init_cpu_util();
    init_pool_utils();
    maxPool3DConfig = {
      kernelName: MaxPool3D,
      backendName: "cpu",
      kernelFunc: maxPool3D
    };
  }
});
function maxPool3DGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2 } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  assertNotComplex([dy, input2], "maxPool3DGrad");
  const convInfo = backend_util_exports.computePool3DInfo(input2.shape, filterSize, strides, 1, pad2, dimRoundingMode);
  const inputBuf = backend2.bufferSync(input2);
  const maxPosBuf = maxPool3dPositions(inputBuf, convInfo);
  const strideDepth = convInfo.strideDepth;
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationDepth = convInfo.dilationDepth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterDepth = convInfo.effectiveFilterDepth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer(input2.shape, "float32");
  const dyBuf = backend2.bufferSync(dy);
  for (let batch = 0; batch < convInfo.batchSize; ++batch) {
    for (let channel = 0; channel < convInfo.inChannels; ++channel) {
      for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {
        for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {
          for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {
            const dyDepthCorner = dxDepth - padFront;
            const dyRowCorner = dxRow - padTop;
            const dyColCorner = dxCol - padLeft;
            let dotProd = 0;
            for (let wDepth = 0; wDepth < effectiveFilterDepth; wDepth += dilationDepth) {
              const dyDepth = (dyDepthCorner + wDepth) / strideDepth;
              if (dyDepth < 0 || dyDepth >= convInfo.outDepth || Math.floor(dyDepth) !== dyDepth) {
                continue;
              }
              for (let wRow = 0; wRow < effectiveFilterHeight; wRow += dilationHeight) {
                const dyRow = (dyRowCorner + wRow) / strideHeight;
                if (dyRow < 0 || dyRow >= convInfo.outHeight || Math.floor(dyRow) !== dyRow) {
                  continue;
                }
                for (let wCol = 0; wCol < effectiveFilterWidth; wCol += dilationWidth) {
                  const dyCol = (dyColCorner + wCol) / strideWidth;
                  if (dyCol < 0 || dyCol >= convInfo.outWidth || Math.floor(dyCol) !== dyCol) {
                    continue;
                  }
                  const maxPos = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                  const curPos = wDepth * effectiveFilterHeight * effectiveFilterWidth + wRow * effectiveFilterWidth + wCol;
                  const mask = maxPos === curPos ? 1 : 0;
                  if (mask === 0) {
                    continue;
                  }
                  const pixel = dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);
                  dotProd += pixel * mask;
                }
              }
            }
            dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);
          }
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var maxPool3DGradConfig2;
var init_MaxPool3DGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js"() {
    init_dist();
    init_cpu_util();
    init_pool_utils();
    maxPool3DGradConfig2 = {
      kernelName: MaxPool3DGrad,
      backendName: "cpu",
      kernelFunc: maxPool3DGrad
    };
  }
});
function maxPoolGrad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2, output } = inputs;
  const x = input2;
  assertNotComplex([input2, output], "maxPoolGrad");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
  const xValues = backend2.data.get(x.dataId).values;
  const maxPosBuf = buffer(convInfo.outShape, x.dtype, maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);
  const strideHeight = convInfo.strideHeight;
  const strideWidth = convInfo.strideWidth;
  const dilationHeight = convInfo.dilationHeight;
  const dilationWidth = convInfo.dilationWidth;
  const effectiveFilterHeight = convInfo.effectiveFilterHeight;
  const effectiveFilterWidth = convInfo.effectiveFilterWidth;
  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
  const dx = buffer(x.shape, "float32");
  const dyData = backend2.data.get(dy.dataId).values;
  const dyBuf = buffer(dy.shape, "float32", dyData);
  for (let b = 0; b < convInfo.batchSize; ++b) {
    for (let d = 0; d < convInfo.inChannels; ++d) {
      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {
        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {
          const dyRCorner = dxR - padTop;
          const dyCCorner = dxC - padLeft;
          let dotProd = 0;
          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {
            const dyR = (dyRCorner + wR) / strideHeight;
            if (dyR < 0 || dyR >= convInfo.outHeight || Math.floor(dyR) !== dyR) {
              continue;
            }
            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {
              const dyC = (dyCCorner + wC) / strideWidth;
              if (dyC < 0 || dyC >= convInfo.outWidth || Math.floor(dyC) !== dyC) {
                continue;
              }
              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 - maxPosBuf.get(b, dyR, dyC, d);
              const curPos = wR * effectiveFilterWidth + wC;
              const mask = maxPos === curPos ? 1 : 0;
              if (mask === 0) {
                continue;
              }
              const pixel = dyBuf.get(b, dyR, dyC, d);
              dotProd += pixel * mask;
            }
          }
          dx.set(dotProd, b, dxR, dxC, d);
        }
      }
    }
  }
  return backend2.makeTensorInfo(dx.shape, dx.dtype, dx.values);
}
var maxPoolGradConfig2;
var init_MaxPoolGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js"() {
    init_dist();
    init_cpu_util();
    init_pool_utils();
    maxPoolGradConfig2 = {
      kernelName: MaxPoolGrad,
      backendName: "cpu",
      kernelFunc: maxPoolGrad2
    };
  }
});
function maxPoolWithArgmaxImpl(xValues, xShape, dtype, includeBatchInIndex, convInfo) {
  const strides = util_exports.computeStrides(xShape);
  const maxPools = pool2(xValues, xShape, dtype, strides, convInfo, "max");
  const maxPositions = maxPoolPositions(xValues, xShape, dtype, convInfo, true, includeBatchInIndex);
  return [maxPools.values, maxPositions.values];
}
var init_MaxPoolWithArgmax_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js"() {
    init_dist();
    init_pool_utils();
  }
});
var maxPoolWithArgmaxConfig;
var init_MaxPoolWithArgmax = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js"() {
    init_dist();
    init_dist();
    init_cpu_util();
    init_MaxPoolWithArgmax_impl();
    maxPoolWithArgmaxConfig = {
      kernelName: MaxPoolWithArgmax,
      backendName: "cpu",
      kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
        const { x } = inputs;
        const { filterSize, strides, pad: pad2, includeBatchInIndex } = attrs;
        const cpuBackend = backend2;
        assertNotComplex(x, "MaxPoolWithArgmax");
        const values = cpuBackend.data.get(x.dataId).values;
        const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, [1, 1], pad2);
        const [pooled, indexes] = maxPoolWithArgmaxImpl(values, x.shape, x.dtype, includeBatchInIndex, convInfo);
        const pooledDataId = cpuBackend.write(pooled, convInfo.outShape, x.dtype);
        const indexesDataId = cpuBackend.write(indexes, convInfo.outShape, x.dtype);
        return [
          { dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype },
          { dataId: indexesDataId, shape: convInfo.outShape, dtype: "int32" }
        ];
      }
    };
  }
});
function mean2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const axes = util_exports.parseAxisParam(axis, x.shape);
  const shapes = backend_util_exports.computeOutAndReduceShapes(x.shape, axes);
  const reduceShape = shapes[1];
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const toDispose = [];
  const reduceSizeScalar = backend2.makeTensorInfo([], "float32", new Float32Array([reduceSize]));
  toDispose.push(reduceSizeScalar);
  const $x = cast3({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
  toDispose.push($x);
  const res = div22({ inputs: { a: $x, b: reduceSizeScalar }, backend: backend2 });
  toDispose.push(res);
  const result = sum3({ inputs: { x: res }, backend: backend2, attrs: { axis, keepDims } });
  toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return result;
}
var meanConfig;
var init_Mean = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js"() {
    init_dist();
    init_Cast();
    init_RealDiv();
    init_Sum();
    meanConfig = {
      kernelName: Mean,
      backendName: "cpu",
      kernelFunc: mean2
    };
  }
});
function min3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  assertNotComplex(x, "min");
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  if (permutedAxes != null) {
    $x = transpose22({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("min", axes, $x.shape.length);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes($x.shape, axes);
  const reduceSize = util_exports.sizeFromShape(reduceShape);
  const vals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(outShape), $x.dtype);
  const aVals = backend2.data.get($x.dataId).values;
  for (let i = 0; i < vals.length; ++i) {
    const offset = i * reduceSize;
    let min5 = aVals[offset];
    for (let j = 0; j < reduceSize; ++j) {
      const value = aVals[offset + j];
      if (Number.isNaN(value) || value < min5) {
        min5 = value;
      }
    }
    vals[i] = min5;
  }
  if (permutedAxes != null) {
    backend2.disposeIntermediateTensorInfo($x);
  }
  const result = backend2.makeTensorInfo(outShape, $x.dtype, vals);
  if (keepDims) {
    const expandedShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
    const reshapedResult = reshape2({ inputs: { x: result }, backend: backend2, attrs: { shape: expandedShape } });
    backend2.disposeIntermediateTensorInfo(result);
    return reshapedResult;
  }
  return result;
}
var minConfig;
var init_Min = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Min.js"() {
    init_dist();
    init_cpu_util();
    init_Reshape();
    init_Transpose();
    minConfig = {
      kernelName: Min,
      backendName: "cpu",
      kernelFunc: min3
    };
  }
});
function mirrorPad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { paddings, mode } = attrs;
  assertNotComplex(x, "mirrorPad");
  const outShape = paddings.map(
    (p2, i) => p2[0] + x.shape[i] + p2[1]
    /* afterPad */
  );
  const start = paddings.map((p2) => p2[0]);
  const end = paddings.map((p2, i) => p2[0] + x.shape[i]);
  const offset = mode === "reflect" ? 0 : 1;
  const xVals = backend2.data.get(x.dataId).values;
  const xRank = x.shape.length;
  const xStrides = util_exports.computeStrides(x.shape);
  const resultSize = util_exports.sizeFromShape(outShape);
  const resultRank = outShape.length;
  const resultStrides = util_exports.computeStrides(outShape);
  const resVals = util_exports.getTypedArrayFromDType(x.dtype, resultSize);
  for (let i = 0; i < resultSize; i++) {
    let coords2 = util_exports.indexToLoc(i, resultRank, resultStrides);
    for (let i2 = 0; i2 < resultRank; i2++) {
      if (coords2[i2] < start[i2]) {
        coords2[i2] = start[i2] * 2 - coords2[i2] - offset;
      } else if (coords2[i2] >= end[i2]) {
        coords2[i2] = (end[i2] - 1) * 2 - coords2[i2] + offset;
      }
    }
    coords2 = coords2.map((c, i2) => c - start[i2]);
    const inIndex = util_exports.locToIndex(coords2, xRank, xStrides);
    resVals[i] = xVals[inIndex];
  }
  const outId = backend2.write(resVals, outShape, x.dtype);
  return { dataId: outId, shape: outShape, dtype: x.dtype };
}
var mirrorPadConfig;
var init_MirrorPad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js"() {
    init_dist();
    init_cpu_util();
    mirrorPadConfig = {
      kernelName: MirrorPad,
      backendName: "cpu",
      kernelFunc: mirrorPad2
    };
  }
});
var modImpl;
var mod2;
var modConfig;
var init_Mod = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    modImpl = createSimpleBinaryKernelImpl((aValue, bValue) => {
      const rem = aValue % bValue;
      if (aValue < 0 && bValue < 0 || aValue >= 0 && bValue >= 0) {
        return rem;
      } else {
        return (rem + bValue) % bValue;
      }
    });
    mod2 = binaryKernelFunc(Mod, modImpl);
    modConfig = {
      kernelName: Mod,
      backendName: "cpu",
      kernelFunc: mod2
    };
  }
});
function softmax2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { logits } = inputs;
  const { dim } = attrs;
  const logitsRank = logits.shape.length;
  let $dim = dim;
  if ($dim === -1) {
    $dim = logitsRank - 1;
  }
  if ($dim !== logitsRank - 1) {
    throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${logitsRank} and dim was ${$dim}`);
  }
  const axes = util_exports.parseAxisParam([$dim], logits.shape);
  const maxLogit = max3({
    inputs: { x: logits },
    backend: backend2,
    attrs: { reductionIndices: axes, keepDims: false }
  });
  const expandedShape = backend_util_exports.expandShapeToKeepDim(maxLogit.shape, axes);
  const maxLogitReshaped = reshape2({ inputs: { x: maxLogit }, backend: backend2, attrs: { shape: expandedShape } });
  const a = sub22({ inputs: { a: logits, b: maxLogitReshaped }, backend: backend2 });
  const b = exp22({ inputs: { x: a }, backend: backend2 });
  const sumExp = sum3({ inputs: { x: b }, backend: backend2, attrs: { axis: axes, keepDims: false } });
  const sumReshaped = reshape2({ inputs: { x: sumExp }, backend: backend2, attrs: { shape: expandedShape } });
  const result = div22({ inputs: { a: b, b: sumReshaped }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(maxLogit);
  backend2.disposeIntermediateTensorInfo(maxLogitReshaped);
  backend2.disposeIntermediateTensorInfo(a);
  backend2.disposeIntermediateTensorInfo(b);
  backend2.disposeIntermediateTensorInfo(sumExp);
  backend2.disposeIntermediateTensorInfo(sumReshaped);
  return result;
}
var softmaxConfig;
var init_Softmax = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js"() {
    init_dist();
    init_Exp();
    init_Max();
    init_RealDiv();
    init_Reshape();
    init_Sub();
    init_Sum();
    softmaxConfig = {
      kernelName: Softmax,
      backendName: "cpu",
      kernelFunc: softmax2
    };
  }
});
function multinomial(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { logits } = inputs;
  const { numSamples, seed, normalized } = attrs;
  assertNotComplex(logits, "multinomial");
  const probabilities = normalized ? logits : softmax2({ inputs: { logits }, backend: backend2, attrs: { dim: -1 } });
  const batchSize = probabilities.shape[0];
  const numEvents = probabilities.shape[1];
  const probVals = backend2.data.get(probabilities.dataId).values;
  const resShape = [batchSize, numSamples];
  const resVals = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(resShape), "int32");
  for (let b = 0; b < batchSize; ++b) {
    const offset = b * numEvents;
    const cdf = new Float32Array(numEvents - 1);
    cdf[0] = probVals[offset];
    for (let event = 1; event < cdf.length; ++event) {
      cdf[event] = cdf[event - 1] + probVals[offset + event];
    }
    const random3 = seedrandom4.alea(seed.toString());
    const outOffset = b * numSamples;
    for (let sampleId = 0; sampleId < numSamples; ++sampleId) {
      const r = random3();
      resVals[outOffset + sampleId] = cdf.length;
      for (let event = 0; event < cdf.length; event++) {
        if (r < cdf[event]) {
          resVals[outOffset + sampleId] = event;
          break;
        }
      }
    }
  }
  if (!normalized) {
    backend2.disposeIntermediateTensorInfo(probabilities);
  }
  return backend2.makeTensorInfo(resShape, "int32", resVals);
}
var seedrandom4;
var multinomialConfig;
var init_Multinomial = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js"() {
    init_dist();
    seedrandom4 = __toESM(require_seedrandom2());
    init_cpu_util();
    init_Softmax();
    multinomialConfig = {
      kernelName: Multinomial,
      backendName: "cpu",
      kernelFunc: multinomial
    };
  }
});
function nonMaxSuppressionV3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
  assertNotComplex(boxes, "NonMaxSuppression");
  const boxesVals = backend2.data.get(boxes.dataId).values;
  const scoresVals = backend2.data.get(scores.dataId).values;
  const { selectedIndices } = nonMaxSuppressionV3Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  return backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
}
var nonMaxSuppressionV3Impl2;
var nonMaxSuppressionV3Config;
var init_NonMaxSuppressionV3 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js"() {
    init_dist();
    init_cpu_util();
    nonMaxSuppressionV3Impl2 = kernel_impls_exports.nonMaxSuppressionV3Impl;
    nonMaxSuppressionV3Config = {
      kernelName: NonMaxSuppressionV3,
      backendName: "cpu",
      kernelFunc: nonMaxSuppressionV3
    };
  }
});
function nonMaxSuppressionV4(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
  assertNotComplex(boxes, "NonMaxSuppressionPadded");
  const boxesVals = backend2.data.get(boxes.dataId).values;
  const scoresVals = backend2.data.get(scores.dataId).values;
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl2(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
  return [
    backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend2.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
  ];
}
var nonMaxSuppressionV4Impl2;
var nonMaxSuppressionV4Config;
var init_NonMaxSuppressionV4 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js"() {
    init_dist();
    init_cpu_util();
    nonMaxSuppressionV4Impl2 = kernel_impls_exports.nonMaxSuppressionV4Impl;
    nonMaxSuppressionV4Config = {
      kernelName: NonMaxSuppressionV4,
      backendName: "cpu",
      kernelFunc: nonMaxSuppressionV4
    };
  }
});
function nonMaxSuppressionV5(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
  assertNotComplex(boxes, "NonMaxSuppressionWithScore");
  const boxesVals = backend2.data.get(boxes.dataId).values;
  const scoresVals = backend2.data.get(scores.dataId).values;
  const maxOutputSizeVal = maxOutputSize;
  const iouThresholdVal = iouThreshold;
  const scoreThresholdVal = scoreThreshold;
  const softNmsSigmaVal = softNmsSigma;
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl2(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
  return [
    backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend2.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
  ];
}
var nonMaxSuppressionV5Impl2;
var nonMaxSuppressionV5Config;
var init_NonMaxSuppressionV5 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js"() {
    init_dist();
    init_cpu_util();
    nonMaxSuppressionV5Impl2 = kernel_impls_exports.nonMaxSuppressionV5Impl;
    nonMaxSuppressionV5Config = {
      kernelName: NonMaxSuppressionV5,
      backendName: "cpu",
      kernelFunc: nonMaxSuppressionV5
    };
  }
});
function oneHot2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { indices } = inputs;
  const { dtype, depth, onValue, offValue } = attrs;
  assertNotComplex(indices, "oneHot");
  const indicesSize = util_exports.sizeFromShape(indices.shape);
  const res = new Float32Array(indicesSize * depth);
  res.fill(offValue);
  const indicesVal = backend2.data.get(indices.dataId).values;
  for (let event = 0; event < indicesSize; ++event) {
    if (indicesVal[event] >= 0 && indicesVal[event] < depth) {
      res[event * depth + indicesVal[event]] = onValue;
    }
  }
  return backend2.makeTensorInfo([...indices.shape, depth], dtype, res);
}
var oneHotConfig;
var init_OneHot = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js"() {
    init_dist();
    init_cpu_util();
    oneHotConfig = {
      kernelName: OneHot,
      backendName: "cpu",
      kernelFunc: oneHot2
    };
  }
});
function zerosLike2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("zerosLike is not supported for string tensors");
  } else if (x.dtype === "complex64") {
    const realPart = real2({ inputs: { input: x }, backend: backend2 });
    const r = zerosLike2({ inputs: { x: realPart }, backend: backend2 });
    const imagPart = imag2({ inputs: { input: x }, backend: backend2 });
    const i = zerosLike2({ inputs: { x: imagPart }, backend: backend2 });
    const result = complex2({ inputs: { real: r, imag: i }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(realPart);
    backend2.disposeIntermediateTensorInfo(r);
    backend2.disposeIntermediateTensorInfo(imagPart);
    backend2.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill2({ backend: backend2, attrs: { shape: x.shape, value: 0, dtype: x.dtype } });
  }
}
var zerosLikeConfig;
var init_ZerosLike = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js"() {
    init_dist();
    init_Complex();
    init_Fill();
    init_Imag();
    init_Real();
    zerosLikeConfig = {
      kernelName: ZerosLike,
      backendName: "cpu",
      kernelFunc: zerosLike2
    };
  }
});
function onesLike2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("onesLike is not supported for string tensors");
  } else if (x.dtype === "complex64") {
    const realPart = real2({ inputs: { input: x }, backend: backend2 });
    const r = onesLike2({ inputs: { x: realPart }, backend: backend2 });
    const imagPart = imag2({ inputs: { input: x }, backend: backend2 });
    const i = zerosLike2({ inputs: { x: imagPart }, backend: backend2 });
    const result = complex2({ inputs: { real: r, imag: i }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(realPart);
    backend2.disposeIntermediateTensorInfo(r);
    backend2.disposeIntermediateTensorInfo(imagPart);
    backend2.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill2({ backend: backend2, attrs: { shape: x.shape, value: 1, dtype: x.dtype } });
  }
}
var onesLikeConfig;
var init_OnesLike = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js"() {
    init_dist();
    init_Complex();
    init_Fill();
    init_Imag();
    init_Real();
    init_ZerosLike();
    onesLikeConfig = {
      kernelName: OnesLike,
      backendName: "cpu",
      kernelFunc: onesLike2
    };
  }
});
function pack(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { axis } = attrs;
  if (inputs.length === 1) {
    return expandDims3({ inputs: { input: inputs[0] }, backend: backend2, attrs: { dim: axis } });
  }
  const shape = inputs[0].shape;
  const dtype = inputs[0].dtype;
  inputs.forEach((t) => {
    util_exports.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
    util_exports.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const intermediateTensorInfos = [];
  const expandedTensors = inputs.map((t) => {
    const expandedT = expandDims3({ inputs: { input: t }, backend: backend2, attrs: { dim: axis } });
    intermediateTensorInfos.push(expandedT);
    return expandedT;
  });
  const result = concat2({ inputs: expandedTensors, backend: backend2, attrs: { axis } });
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return result;
}
var packConfig;
var init_Pack = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js"() {
    init_dist();
    init_Concat();
    init_ExpandDims();
    packConfig = {
      kernelName: Pack,
      backendName: "cpu",
      kernelFunc: pack
    };
  }
});
function padV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { paddings, constantValue } = attrs;
  assertNotComplex(x, "pad");
  const outShape = paddings.map(
    (p2, i) => p2[0] + x.shape[i] + p2[1]
    /* afterPad */
  );
  const start = paddings.map((p2) => p2[0]);
  const xVals = backend2.data.get(x.dataId).values;
  const xSize = util_exports.sizeFromShape(x.shape);
  const xRank = x.shape.length;
  const xStrides = util_exports.computeStrides(x.shape);
  const resultSize = util_exports.sizeFromShape(outShape);
  const resultRank = outShape.length;
  const resultStrides = util_exports.computeStrides(outShape);
  const resVals = util_exports.getTypedArrayFromDType(x.dtype, resultSize);
  if (constantValue !== 0) {
    resVals.fill(constantValue);
  }
  for (let i = 0; i < xSize; i++) {
    const coords2 = util_exports.indexToLoc(i, xRank, xStrides);
    const outCoords = coords2.map((c, i2) => c + start[i2]);
    const outIndex = util_exports.locToIndex(outCoords, resultRank, resultStrides);
    resVals[outIndex] = xVals[i];
  }
  const outId = backend2.write(resVals, outShape, x.dtype);
  return { dataId: outId, shape: outShape, dtype: x.dtype };
}
var padV2Config;
var init_PadV2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js"() {
    init_dist();
    init_cpu_util();
    padV2Config = {
      kernelName: PadV2,
      backendName: "cpu",
      kernelFunc: padV2
    };
  }
});
var powImpl;
var pow22;
var powConfig;
var init_Pow = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js"() {
    init_dist();
    init_binary_impl();
    init_binary_utils();
    powImpl = createSimpleBinaryKernelImpl((a, b) => Math.pow(a, b));
    pow22 = binaryKernelFunc(Pow, powImpl);
    powConfig = {
      kernelName: Pow,
      backendName: "cpu",
      kernelFunc: pow22
    };
  }
});
function raggedGather(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { paramsNestedSplits, paramsDenseValues, indices } = inputs;
  const { outputRaggedRank } = attrs;
  const $paramsNestedSplits = paramsNestedSplits.map((t) => backend2.data.get(t.dataId).values);
  const $paramsNestedSplitsShapes = paramsNestedSplits.map((t) => t.shape);
  const $paramsDenseValues = backend2.data.get(paramsDenseValues.dataId).values;
  const $indices = backend2.data.get(indices.dataId).values;
  const [outputNestedSplits, outputDenseValues, outputDenseValuesShape] = raggedGatherImpl($paramsNestedSplits, $paramsNestedSplitsShapes, $paramsDenseValues, paramsDenseValues.shape, paramsDenseValues.dtype, $indices, indices.shape, outputRaggedRank);
  const outputNestedSplitsTensors = outputNestedSplits.map((splits) => backend2.makeTensorInfo([splits.length], "int32", splits));
  const outputDenseValuesTensor = backend2.makeTensorInfo(outputDenseValuesShape, paramsDenseValues.dtype, outputDenseValues);
  return outputNestedSplitsTensors.concat([outputDenseValuesTensor]);
}
var raggedGatherConfig;
var init_RaggedGather = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather.js"() {
    init_dist();
    init_RaggedGather_impl();
    raggedGatherConfig = {
      kernelName: RaggedGather,
      backendName: "cpu",
      kernelFunc: raggedGather
    };
  }
});
function raggedRange(args) {
  const { inputs, backend: backend2 } = args;
  const { starts, limits, deltas } = inputs;
  const $starts = backend2.data.get(starts.dataId).values;
  const $limits = backend2.data.get(limits.dataId).values;
  const $deltas = backend2.data.get(deltas.dataId).values;
  const [rtNestedSplitsData, rtDenseValuesData] = raggedRangeImpl($starts, starts.shape, starts.dtype, $limits, limits.shape, $deltas, deltas.shape);
  const rtNestedSplits = backend2.makeTensorInfo([rtNestedSplitsData.length], "int32", rtNestedSplitsData);
  const rtDenseValues = backend2.makeTensorInfo([rtDenseValuesData.length], starts.dtype, rtDenseValuesData);
  return [rtNestedSplits, rtDenseValues];
}
var raggedRangeConfig;
var init_RaggedRange = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange.js"() {
    init_dist();
    init_RaggedRange_impl();
    raggedRangeConfig = {
      kernelName: RaggedRange,
      backendName: "cpu",
      kernelFunc: raggedRange
    };
  }
});
function raggedTensorToTensor(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { shape, values, defaultValue, rowPartitionTensors } = inputs;
  const { rowPartitionTypes } = attrs;
  const $shape = backend2.data.get(shape.dataId).values;
  const $values = backend2.data.get(values.dataId).values;
  const $defaultValue = backend2.data.get(defaultValue.dataId).values;
  const $rowPartitionValues = rowPartitionTensors.map((t) => backend2.data.get(t.dataId).values);
  const rowPartitionValuesShapes = rowPartitionTensors.map((t) => t.shape);
  const [outputShape, output] = raggedTensorToTensorImpl($shape, shape.shape, $values, values.shape, values.dtype, $defaultValue, defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes);
  return backend2.makeTensorInfo(outputShape, values.dtype, output);
}
var raggedTensorToTensorConfig;
var init_RaggedTensorToTensor = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor.js"() {
    init_dist();
    init_RaggedTensorToTensor_impl();
    raggedTensorToTensorConfig = {
      kernelName: RaggedTensorToTensor,
      backendName: "cpu",
      kernelFunc: raggedTensorToTensor
    };
  }
});
function range3(args) {
  const { backend: backend2, attrs } = args;
  const { start, stop, dtype, step: step4 } = attrs;
  const values = rangeImpl(start, stop, step4, dtype);
  return backend2.makeTensorInfo([values.length], dtype, values);
}
var rangeConfig;
var init_Range = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Range.js"() {
    init_dist();
    init_Range_impl();
    rangeConfig = {
      kernelName: Range,
      backendName: "cpu",
      kernelFunc: range3
    };
  }
});
var reciprocal2;
var reciprocalConfig;
var init_Reciprocal = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js"() {
    init_dist();
    init_unary_utils();
    reciprocal2 = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);
    reciprocalConfig = {
      kernelName: Reciprocal,
      backendName: "cpu",
      kernelFunc: reciprocal2
    };
  }
});
function resizeBilinear3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  assertNotComplex(images, "resizeBilinear");
  const imagesStrides = util_exports.computeStrides(images.shape);
  const [newHeight, newWidth] = size;
  const [batch, oldHeight, oldWidth, numChannels] = images.shape;
  const xValues = backend2.data.get(images.dataId).values;
  const result = new Float32Array(util_exports.sizeFromShape([batch, newHeight, newWidth, numChannels]));
  const effectiveInputSize = [
    alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
    alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
  ];
  const effectiveOutputSize = [
    alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
    alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
  ];
  let outputIdx = 0;
  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
  for (let b = 0; b < batch; b++) {
    for (let r = 0; r < newHeight; r++) {
      let sourceFracRow;
      if (halfPixelCenters) {
        sourceFracRow = effectiveRowSizeRatio * (r + 0.5) - 0.5;
      } else {
        sourceFracRow = effectiveRowSizeRatio * r;
      }
      const sourceRowFloor = Math.max(0, Math.floor(sourceFracRow));
      const rowFrac = sourceFracRow - sourceRowFloor;
      const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));
      const topRowOffset = b * imagesStrides[0] + sourceRowFloor * imagesStrides[1];
      const botRowOffset = b * imagesStrides[0] + sourceRowCeil * imagesStrides[1];
      for (let c = 0; c < newWidth; c++) {
        let sourceFracCol;
        if (halfPixelCenters) {
          sourceFracCol = effectiveColSizeRatio * (c + 0.5) - 0.5;
        } else {
          sourceFracCol = effectiveColSizeRatio * c;
        }
        const sourceColFloor = Math.max(0, Math.floor(sourceFracCol));
        const colFrac = sourceFracCol - sourceColFloor;
        const sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));
        const topLeftOffest = topRowOffset + sourceColFloor * imagesStrides[2];
        const botLeftOffset = botRowOffset + sourceColFloor * imagesStrides[2];
        const topRightOffset = topRowOffset + sourceColCeil * imagesStrides[2];
        const botRightOffest = botRowOffset + sourceColCeil * imagesStrides[2];
        for (let d = 0; d < numChannels; d++) {
          const topLeft = xValues[topLeftOffest + d];
          const bottomLeft = xValues[botLeftOffset + d];
          const topRight = xValues[topRightOffset + d];
          const bottomRight = xValues[botRightOffest + d];
          const top = topLeft + (topRight - topLeft) * colFrac;
          const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;
          const newValue = top + (bottom - top) * rowFrac;
          result[outputIdx++] = newValue;
        }
      }
    }
  }
  return backend2.makeTensorInfo([batch, newHeight, newWidth, numChannels], "float32", result);
}
var resizeBilinearConfig;
var init_ResizeBilinear = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js"() {
    init_dist();
    init_cpu_util();
    resizeBilinearConfig = {
      kernelName: ResizeBilinear,
      backendName: "cpu",
      kernelFunc: resizeBilinear3
    };
  }
});
function resizeBilinearGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  assertNotComplex([dy, images], "resizeBilinearGrad");
  const imagesStrides = util_exports.computeStrides(images.shape);
  const [batch, xHeight, xWidth, depth] = images.shape;
  const [, yHeight, yWidth] = dy.shape;
  const output = new Float32Array(batch * xHeight * xWidth * depth);
  const effectiveXSize = [
    alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
    alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
  ];
  const effectiveYSize = [
    alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
    alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
  ];
  const heightScale = effectiveXSize[0] / effectiveYSize[0];
  const widthScale = effectiveXSize[1] / effectiveYSize[1];
  const dyValues = backend2.data.get(dy.dataId).values;
  let offset = 0;
  for (let b = 0; b < batch; b++) {
    const bOffset = b * imagesStrides[0];
    for (let r = 0; r < yHeight; r++) {
      const dxR = r * heightScale;
      const topDxRIndex = Math.floor(dxR);
      const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);
      const topDxROffset = bOffset + topDxRIndex * imagesStrides[1];
      const bottomDxROffset = bOffset + bottomDxRIndex * imagesStrides[1];
      const dxRLerp = dxR - topDxRIndex;
      const inverseDxRLerp = 1 - dxRLerp;
      for (let c = 0; c < yWidth; c++) {
        const dxC = c * widthScale;
        const leftDxCIndex = Math.floor(dxC);
        const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);
        const dxCLerp = dxC - leftDxCIndex;
        const inverseDxCLerp = 1 - dxCLerp;
        const topLeftRCOffset = topDxROffset + leftDxCIndex * imagesStrides[2];
        const topRightRCOffset = topDxROffset + rightDxCIndex * imagesStrides[2];
        const bottomLeftRCOffset = bottomDxROffset + leftDxCIndex * imagesStrides[2];
        const bottomRightRCOffset = bottomDxROffset + rightDxCIndex * imagesStrides[2];
        const inverseDxRLerpTimesInverseDxCLerp = inverseDxRLerp * inverseDxCLerp;
        const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;
        const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;
        const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;
        for (let d = 0; d < depth; d++) {
          const dyVal = dyValues[offset++];
          output[topLeftRCOffset + d] += dyVal * inverseDxRLerpTimesInverseDxCLerp;
          output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;
          output[bottomLeftRCOffset + d] += dyVal * dxRLerpTimesInverseDxCLerp;
          output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;
        }
      }
    }
  }
  return backend2.makeTensorInfo([batch, xWidth, xHeight, depth], "float32", output);
}
var resizeBilinearGradConfig2;
var init_ResizeBilinearGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js"() {
    init_dist();
    init_cpu_util();
    resizeBilinearGradConfig2 = {
      kernelName: ResizeBilinearGrad,
      backendName: "cpu",
      kernelFunc: resizeBilinearGrad
    };
  }
});
function resizeNearestNeighbor2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  assertNotComplex(images, "resizeNearestNeighbor");
  const imagesStrides = util_exports.computeStrides(images.shape);
  const [newHeight, newWidth] = size;
  const [batch, oldHeight, oldWidth, numChannels] = images.shape;
  const xValues = backend2.data.get(images.dataId).values;
  const output = new Float32Array(batch * newHeight * newWidth * numChannels);
  const effectiveInputSize = [
    alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
    alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
  ];
  const effectiveOutputSize = [
    alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
    alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
  ];
  const effectiveRowSizeRatio = effectiveInputSize[0] / effectiveOutputSize[0];
  const effectiveColSizeRatio = effectiveInputSize[1] / effectiveOutputSize[1];
  let outputOffset = 0;
  for (let b = 0; b < batch; b++) {
    const batchOffset = b * imagesStrides[0];
    for (let r = 0; r < newHeight; r++) {
      const sourceFracRow = halfPixelCenters ? effectiveRowSizeRatio * (r + 0.5) : effectiveRowSizeRatio * r;
      let sourceNearestRow = Math.min(oldHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
      if (halfPixelCenters) {
        sourceNearestRow = Math.max(0, sourceNearestRow);
      }
      const rowOffset = batchOffset + sourceNearestRow * imagesStrides[1];
      for (let c = 0; c < newWidth; c++) {
        const sourceFracCol = halfPixelCenters ? effectiveColSizeRatio * (c + 0.5) : effectiveColSizeRatio * c;
        let sourceNearestCol = Math.min(oldWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
        if (halfPixelCenters) {
          sourceNearestCol = Math.max(0, sourceNearestCol);
        }
        const colOffset = rowOffset + sourceNearestCol * imagesStrides[2];
        for (let d = 0; d < numChannels; d++) {
          const newVal = xValues[colOffset + d];
          output[outputOffset++] = newVal;
        }
      }
    }
  }
  return backend2.makeTensorInfo([batch, newHeight, newWidth, numChannels], images.dtype, output);
}
var resizeNearestNeighborConfig;
var init_ResizeNearestNeighbor = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js"() {
    init_dist();
    init_cpu_util();
    resizeNearestNeighborConfig = {
      kernelName: ResizeNearestNeighbor,
      backendName: "cpu",
      kernelFunc: resizeNearestNeighbor2
    };
  }
});
function resizeNearestNeighborGrad(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  assertNotComplex([dy, images], "resizeNearestNeighborGrad");
  const imagesStrides = util_exports.computeStrides(images.shape);
  const dyStrides = util_exports.computeStrides(dy.shape);
  const [batch, xHeight, xWidth, depth] = images.shape;
  const [, yHeight, yWidth] = dy.shape;
  const output = new Float32Array(batch * xHeight * xWidth * depth);
  const dyValues = backend2.data.get(dy.dataId).values;
  const effectiveXSize = [
    alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
    alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
  ];
  const effectiveYSize = [
    alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
    alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
  ];
  const heightScale = effectiveXSize[0] / effectiveYSize[0];
  const widthScale = effectiveXSize[1] / effectiveYSize[1];
  const invHeightScale = 1 / heightScale;
  const invWidthScale = 1 / widthScale;
  const winHeight = Math.ceil(invHeightScale) * 2 + 2;
  const winWidth = Math.ceil(invWidthScale) * 2 + 2;
  for (let b = 0; b < batch; b++) {
    const batchOffset = b * imagesStrides[0];
    for (let r = 0; r < xHeight; r++) {
      const rowOffset = batchOffset + r * imagesStrides[1];
      const startRLerp = Math.floor(r * invHeightScale);
      const startDyR = Math.floor(startRLerp - winHeight / 2);
      for (let c = 0; c < xWidth; c++) {
        const colOffset = rowOffset + c * imagesStrides[2];
        const startCLerp = Math.floor(c * invWidthScale);
        const startDyC = Math.floor(startCLerp - winWidth / 2);
        for (let d = 0; d < depth; d++) {
          let accum = 0;
          for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {
            const dyR = dyRIndex + startDyR;
            if (dyR < 0 || dyR >= yHeight) {
              continue;
            }
            const dyROffset = batchOffset + dyR * dyStrides[1];
            const sourceFracRow = dyR * heightScale;
            const sourceNearestRow = Math.min(xHeight - 1, alignCorners ? Math.round(sourceFracRow) : Math.floor(sourceFracRow));
            if (r !== sourceNearestRow) {
              continue;
            }
            for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {
              const dyC = dyCIndex + startDyC;
              if (dyC < 0 || dyC >= yWidth) {
                continue;
              }
              const dyCOffset = dyROffset + dyC * dyStrides[2];
              const sourceFracCol = dyC * widthScale;
              const sourceNearestCol = Math.min(xWidth - 1, alignCorners ? Math.round(sourceFracCol) : Math.floor(sourceFracCol));
              if (c === sourceNearestCol) {
                accum += dyValues[dyCOffset + d];
              }
            }
          }
          output[colOffset + d] = accum;
        }
      }
    }
  }
  return backend2.makeTensorInfo(images.shape, images.dtype, output);
}
var resizeNearestNeighborGradConfig2;
var init_ResizeNearestNeighborGrad = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js"() {
    init_dist();
    init_cpu_util();
    resizeNearestNeighborGradConfig2 = {
      kernelName: ResizeNearestNeighborGrad,
      backendName: "cpu",
      kernelFunc: resizeNearestNeighborGrad
    };
  }
});
function reverse2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { dims } = attrs;
  assertNotComplex(x, "reverse");
  const xRank = x.shape.length;
  const $dims = util_exports.parseAxisParam(dims, x.shape);
  if (xRank === 0) {
    return identity4({ inputs: { x }, backend: backend2 });
  }
  const outBuf = new TensorBuffer(x.shape, x.dtype);
  const xBuf = backend2.bufferSync(x);
  for (let i = 0; i < outBuf.size; i++) {
    const outLoc = outBuf.indexToLoc(i);
    const inLoc = outLoc.slice();
    $dims.forEach((d) => inLoc[d] = x.shape[d] - 1 - inLoc[d]);
    outBuf.set(xBuf.get(...inLoc), ...outLoc);
  }
  return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
}
var reverseConfig;
var init_Reverse = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js"() {
    init_dist();
    init_cpu_util();
    init_Identity();
    reverseConfig = {
      kernelName: Reverse,
      backendName: "cpu",
      kernelFunc: reverse2
    };
  }
});
var rotateWithOffsetConfig;
var init_RotateWithOffset = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js"() {
    init_dist();
    rotateWithOffsetConfig = {
      kernelName: RotateWithOffset,
      backendName: "cpu",
      kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
        const { image: image2 } = inputs;
        const { radians, fillValue, center } = attrs;
        const cpuBackend = backend2;
        const output = util_exports.getTypedArrayFromDType(image2.dtype, util_exports.sizeFromShape(image2.shape));
        const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
        const [centerX, centerY] = backend_util_exports.getImageCenter(center, imageHeight, imageWidth);
        const fullOpacityValue = 255;
        const sinFactor = Math.sin(radians);
        const cosFactor = Math.cos(radians);
        const imageVals = cpuBackend.data.get(image2.dataId).values;
        for (let batchIdx = 0; batchIdx < batch; batchIdx++) {
          const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;
          for (let row = 0; row < imageHeight; row++) {
            const rowOffset = row * (imageWidth * numChannels);
            for (let col = 0; col < imageWidth; col++) {
              const colOffset = col * numChannels;
              for (let channel = 0; channel < numChannels; channel++) {
                const coords2 = [batch, row, col, channel];
                const x = coords2[2];
                const y = coords2[1];
                let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;
                let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;
                coordX = Math.round(coordX + centerX);
                coordY = Math.round(coordY + centerY);
                let outputValue = fillValue;
                if (typeof fillValue !== "number") {
                  if (channel === 3) {
                    outputValue = fullOpacityValue;
                  } else {
                    outputValue = fillValue[channel];
                  }
                }
                if (coordX >= 0 && coordX < imageWidth && coordY >= 0 && coordY < imageHeight) {
                  const rotatedRowOffset = coordY * (imageWidth * numChannels);
                  const rotatedColOffset = coordX * numChannels;
                  const imageIdx = batchOffset + rotatedRowOffset + rotatedColOffset + channel;
                  outputValue = imageVals[imageIdx];
                }
                const outIdx = batchOffset + rowOffset + colOffset + channel;
                output[outIdx] = outputValue;
              }
            }
          }
        }
        const dataId = cpuBackend.write(output, image2.shape, image2.dtype);
        return { dataId, shape: image2.shape, dtype: image2.dtype };
      }
    };
  }
});
var round3;
var roundConfig;
var init_Round = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Round.js"() {
    init_dist();
    init_unary_utils();
    round3 = unaryKernelFunc(Round, (xi) => {
      const base = Math.floor(xi);
      if (xi - base < 0.5) {
        return Math.floor(xi);
      } else if (xi - base > 0.5) {
        return Math.ceil(xi);
      } else {
        if (base % 2 === 0) {
          return base;
        } else {
          return base + 1;
        }
      }
    });
    roundConfig = {
      kernelName: Round,
      backendName: "cpu",
      kernelFunc: round3
    };
  }
});
function scatterNd(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { indices, updates } = inputs;
  const { shape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, shape);
  const sumDupeIndices = true;
  const indicesBuf = backend2.bufferSync(indices);
  const updatesBuf = backend2.bufferSync(updates);
  const outBuf = scatterImpl(indicesBuf, updatesBuf, shape, outputSize, sliceSize, numUpdates, sliceRank, strides, 0, sumDupeIndices);
  return backend2.makeTensorInfo(shape, outBuf.dtype, outBuf.values);
}
var scatterNdConfig;
var init_ScatterNd = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js"() {
    init_dist();
    init_Scatter_impl();
    scatterNdConfig = {
      kernelName: ScatterNd,
      backendName: "cpu",
      kernelFunc: scatterNd
    };
  }
});
function lowerBound(array2, value) {
  let left = 0;
  let right = array2.length;
  let mid = 0;
  while (left < right) {
    mid = Math.floor((left + right) / 2);
    if (array2[mid] < value) {
      left = mid + 1;
    } else {
      right = mid;
    }
  }
  return right;
}
function upperBound(array2, value) {
  let left = 0;
  let right = array2.length;
  let mid = 0;
  while (left < right) {
    mid = Math.floor((left + right) / 2);
    if (array2[mid] <= value) {
      left = mid + 1;
    } else {
      right = mid;
    }
  }
  return right;
}
function searchSortedImpl(sortedInputs, values, batchSize, numInputs, numValues, side) {
  const output = util_exports.getArrayFromDType("int32", batchSize * numValues);
  for (let b = 0; b < batchSize; ++b) {
    const sortedInputsSlice = sortedInputs.slice(b * numInputs, (b + 1) * numInputs);
    const outputOffset = b * numValues;
    for (let i = 0; i < numValues; ++i) {
      output[outputOffset + i] = side === "left" ? lowerBound(sortedInputsSlice, values[i + outputOffset]) : upperBound(sortedInputsSlice, values[i + outputOffset]);
    }
  }
  return output;
}
var init_SearchSorted_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted_impl.js"() {
    init_dist();
  }
});
function searchSorted(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { sortedSequence, values } = inputs;
  const { side } = attrs;
  const $sortedSequence = backend2.data.get(sortedSequence.dataId).values;
  const $values = backend2.data.get(values.dataId).values;
  const output = searchSortedImpl($sortedSequence, $values, sortedSequence.shape[0], sortedSequence.shape[1], values.shape[1], side);
  return backend2.makeTensorInfo(values.shape, "int32", output);
}
var searchSortedConfig;
var init_SearchSorted = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted.js"() {
    init_dist();
    init_SearchSorted_impl();
    searchSortedConfig = {
      kernelName: SearchSorted,
      backendName: "cpu",
      kernelFunc: searchSorted
    };
  }
});
function select2(args) {
  const { inputs, backend: backend2 } = args;
  const { condition, t, e } = inputs;
  assertNotComplex([condition, t, e], "select");
  const conditionRank = condition.shape.length;
  const values = backend2.data.get(condition.dataId).values;
  const tValues = backend2.data.get(t.dataId).values;
  const eValues = backend2.data.get(e.dataId).values;
  const resultDtype = upcastType(t.dtype, e.dtype);
  const newValues = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(t.shape), resultDtype);
  let index = 0;
  const offset = conditionRank === 0 || conditionRank > 1 || t.shape.length === 1 ? 1 : util_exports.sizeFromShape(t.shape.slice(1));
  for (let i = 0; i < values.length; i++) {
    for (let j = 0; j < offset; j++) {
      if (values[i] === 1) {
        newValues[index++] = tValues[i];
      } else {
        newValues[index++] = eValues[i];
      }
    }
  }
  return backend2.makeTensorInfo(t.shape, resultDtype, newValues);
}
var selectConfig;
var init_Select = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Select.js"() {
    init_dist();
    init_cpu_util();
    selectConfig = {
      kernelName: Select,
      backendName: "cpu",
      kernelFunc: select2
    };
  }
});
var scaleAlpha;
var scale6;
var selu2;
var seluConfig;
var init_Selu = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js"() {
    init_dist();
    init_unary_utils();
    scaleAlpha = backend_util_exports.SELU_SCALEALPHA;
    scale6 = backend_util_exports.SELU_SCALE;
    selu2 = unaryKernelFunc(Selu, (xi) => {
      if (xi >= 0) {
        return scale6 * xi;
      } else {
        return scaleAlpha * (Math.exp(xi) - 1);
      }
    });
    seluConfig = {
      kernelName: Selu,
      backendName: "cpu",
      kernelFunc: selu2
    };
  }
});
var sign2;
var signConfig;
var init_Sign = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js"() {
    init_dist();
    init_unary_utils();
    sign2 = unaryKernelFunc(Sign, (xi) => {
      if (xi < 0) {
        return -1;
      } else if (xi > 0) {
        return 1;
      } else {
        return 0;
      }
    });
    signConfig = {
      kernelName: Sign,
      backendName: "cpu",
      kernelFunc: sign2
    };
  }
});
var sin2;
var sinConfig;
var init_Sin = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js"() {
    init_dist();
    init_unary_utils();
    sin2 = unaryKernelFunc(Sin, (xi) => Math.sin(xi));
    sinConfig = {
      kernelName: Sin,
      backendName: "cpu",
      kernelFunc: sin2
    };
  }
});
var sinh2;
var sinhConfig;
var init_Sinh = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js"() {
    init_dist();
    init_unary_utils();
    sinh2 = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));
    sinhConfig = {
      kernelName: Sinh,
      backendName: "cpu",
      kernelFunc: sinh2
    };
  }
});
var epsilon2;
var threshold2;
var softplus2;
var softplusConfig;
var init_Softplus = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js"() {
    init_dist();
    init_unary_utils();
    epsilon2 = 11920928955078125e-23;
    threshold2 = Math.log(epsilon2) + 2;
    softplus2 = unaryKernelFunc(Softplus, (xi) => {
      const tooLarge = xi > -threshold2;
      const tooSmall = xi < threshold2;
      const expX = Math.exp(xi);
      let result;
      if (tooSmall) {
        result = expX;
      } else if (tooLarge) {
        result = xi;
      } else {
        result = Math.log(1 + expX);
      }
      return result;
    });
    softplusConfig = {
      kernelName: Softplus,
      backendName: "cpu",
      kernelFunc: softplus2
    };
  }
});
function spaceToBatchND2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockShape, paddings } = attrs;
  assertNotComplex([x], "spaceToBatchND");
  const prod4 = util_exports.sizeFromShape(blockShape);
  const completePaddings = [[0, 0]];
  completePaddings.push(...paddings);
  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
    completePaddings.push([0, 0]);
  }
  const paddedX = padV2Config.kernelFunc({
    inputs: { x },
    backend: backend2,
    attrs: { paddings: completePaddings, constantValue: 0 }
  });
  const reshapedPaddedShape = backend_util_exports.getReshaped(paddedX.shape, blockShape, prod4, false);
  const permutedReshapedPaddedPermutation = backend_util_exports.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
  const flattenShape = backend_util_exports.getReshapedPermuted(paddedX.shape, blockShape, prod4, false);
  const reshapeInputs = { x: paddedX };
  const reshapeAttrs = { shape: reshapedPaddedShape };
  const paddedXReshaped = reshape2({ inputs: reshapeInputs, backend: backend2, attrs: reshapeAttrs });
  const transposeInputs = { x: paddedXReshaped };
  const transposeAttrs = { perm: permutedReshapedPaddedPermutation };
  const paddedXT = transpose22({ inputs: transposeInputs, backend: backend2, attrs: transposeAttrs });
  const resultReshapeInputs = { x: paddedXT };
  const resultReshapeAttrs = { shape: flattenShape };
  const result = reshape2({ inputs: resultReshapeInputs, backend: backend2, attrs: resultReshapeAttrs });
  backend2.disposeIntermediateTensorInfo(paddedX);
  backend2.disposeIntermediateTensorInfo(paddedXReshaped);
  backend2.disposeIntermediateTensorInfo(paddedXT);
  return result;
}
var spaceToBatchNDConfig;
var init_SpaceToBatchND = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js"() {
    init_dist();
    init_cpu_util();
    init_PadV2();
    init_Reshape();
    init_Transpose();
    spaceToBatchNDConfig = {
      kernelName: SpaceToBatchND,
      backendName: "cpu",
      kernelFunc: spaceToBatchND2
    };
  }
});
function sparseFillEmptyRows(args) {
  const { inputs, backend: backend2 } = args;
  const { indices, values, denseShape, defaultValue } = inputs;
  if (denseShape.shape.length !== 1) {
    throw new Error(`Dense shape must be a vector, saw:
        ${denseShape.shape}`);
  }
  if (indices.shape.length !== 2) {
    throw new Error(`Indices must be a matrix, saw:
        ${indices.shape}`);
  }
  if (values.shape.length !== 1) {
    throw new Error(`Values must be a vector, saw:
        ${values.shape}`);
  }
  if (defaultValue.shape.length !== 0) {
    throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
  }
  const $indices = backend2.data.get(indices.dataId).values;
  const $values = backend2.data.get(values.dataId).values;
  const $denseShape = backend2.data.get(denseShape.dataId).values;
  const $defaultValue = backend2.data.get(defaultValue.dataId).values[0];
  const [outputIndices, outputIndicesShape, outputValues, emptyRowIndicator, reverseIndexMap] = sparseFillEmptyRowsImpl($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
  return [
    backend2.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
    backend2.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
    backend2.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
    backend2.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
  ];
}
var sparseFillEmptyRowsConfig;
var init_SparseFillEmptyRows = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js"() {
    init_dist();
    init_SparseFillEmptyRows_impl();
    sparseFillEmptyRowsConfig = {
      kernelName: SparseFillEmptyRows,
      backendName: "cpu",
      kernelFunc: sparseFillEmptyRows
    };
  }
});
function sparseReshape(args) {
  const { inputs, backend: backend2 } = args;
  const { inputIndices, inputShape, newShape } = inputs;
  if (inputIndices.shape.length !== 2) {
    throw new Error(`Input indices should be a matrix but received shape
        ${inputIndices.shape}`);
  }
  if (inputShape.shape.length !== 1) {
    throw new Error(`Input shape should be a vector but received shape
        ${inputShape.shape}`);
  }
  if (newShape.shape.length !== 1) {
    throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
  }
  const $inputShape = Array.from(backend2.data.get(inputShape.dataId).values);
  const $inputIndices = backend2.data.get(inputIndices.dataId).values;
  const targetShape = Array.from(backend2.data.get(newShape.dataId).values);
  const [newIndices, indicesShape, outputShape] = sparseReshapeImpl($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
  return [
    backend2.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
    backend2.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
  ];
}
var sparseReshapeConfig;
var init_SparseReshape = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js"() {
    init_dist();
    init_SparseReshape_impl();
    sparseReshapeConfig = {
      kernelName: SparseReshape,
      backendName: "cpu",
      kernelFunc: sparseReshape
    };
  }
});
function sparseSegmentMean(args) {
  const { inputs, backend: backend2 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
          ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
          ${segmentIds.shape}`);
  }
  if (indices.shape[0] !== segmentIds.shape[0]) {
    throw new Error(`segmentIds and indices should have same size.`);
  }
  const $data = backend2.data.get(data.dataId).values;
  const $indices = backend2.data.get(indices.dataId).values;
  const $segmentIds = backend2.data.get(segmentIds.dataId).values;
  const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds, true);
  return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentMeanConfig;
var init_SparseSegmentMean = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js"() {
    init_dist();
    init_SparseSegmentReduction_impl();
    sparseSegmentMeanConfig = {
      kernelName: SparseSegmentMean,
      backendName: "cpu",
      kernelFunc: sparseSegmentMean
    };
  }
});
function sparseSegmentSum(args) {
  const { inputs, backend: backend2 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
         ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
         ${segmentIds.shape}`);
  }
  if (indices.shape[0] !== segmentIds.shape[0]) {
    throw new Error(`segmentIds and indices should have same size.`);
  }
  const $data = backend2.data.get(data.dataId).values;
  const $indices = backend2.data.get(indices.dataId).values;
  const $segmentIds = backend2.data.get(segmentIds.dataId).values;
  const [outputData, outputDataShape] = sparseSegmentReductionImpl($data, data.shape, data.dtype, $indices, $segmentIds);
  return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentSumConfig;
var init_SparseSegmentSum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js"() {
    init_dist();
    init_SparseSegmentReduction_impl();
    sparseSegmentSumConfig = {
      kernelName: SparseSegmentSum,
      backendName: "cpu",
      kernelFunc: sparseSegmentSum
    };
  }
});
function sparseToDense(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { sparseIndices, sparseValues, defaultValue } = inputs;
  const { outputShape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(sparseValues, sparseIndices, outputShape);
  const sumDupeIndices = false;
  const indicesBuf = backend2.bufferSync(sparseIndices);
  let outBuf;
  switch (sparseValues.dtype) {
    case "bool": {
      const updatesBuf = backend2.bufferSync(sparseValues);
      const $defaultValue = Boolean(backend2.data.get(defaultValue.dataId).values[0]);
      outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
      break;
    }
    case "float32": {
      const updatesBuf = backend2.bufferSync(sparseValues);
      const $defaultValue = backend2.data.get(defaultValue.dataId).values[0];
      outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
      break;
    }
    case "int32": {
      const updatesBuf = backend2.bufferSync(sparseValues);
      const $defaultValue = backend2.data.get(defaultValue.dataId).values[0];
      outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
      break;
    }
    case "string": {
      const updatesBuf = backend2.bufferSync(sparseValues);
      const $defaultValue = util_exports.decodeString(backend2.data.get(defaultValue.dataId).values[0]);
      outBuf = scatterImpl(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
      break;
    }
    default:
      throw new Error(`Unsupported type ${sparseValues.dtype}`);
  }
  return backend2.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
}
var sparseToDenseConfig;
var init_SparseToDense = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js"() {
    init_dist();
    init_Scatter_impl();
    sparseToDenseConfig = {
      kernelName: SparseToDense,
      backendName: "cpu",
      kernelFunc: sparseToDense
    };
  }
});
function splitV(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { numOrSizeSplits, axis } = attrs;
  const $axis = util_exports.parseAxisParam(axis, x.shape)[0];
  const splitSizes = backend_util_exports.prepareSplitSize(x, numOrSizeSplits, $axis);
  const begin = new Array(x.shape.length).fill(0);
  const size = x.shape.slice();
  return splitSizes.map((s) => {
    const sliceSize = [...size];
    sliceSize[$axis] = s;
    const sliceT = slice2({ inputs: { x }, backend: backend2, attrs: { begin, size: sliceSize } });
    begin[$axis] += s;
    return sliceT;
  });
}
var splitVConfig;
var init_SplitV = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js"() {
    init_dist();
    init_dist();
    init_Slice();
    splitVConfig = {
      kernelName: SplitV,
      backendName: "cpu",
      kernelFunc: splitV
    };
  }
});
var squareConfig;
var init_Square = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Square.js"() {
    init_dist();
    init_cpu_util();
    squareConfig = {
      kernelName: Square,
      backendName: "cpu",
      kernelFunc: ({ inputs, backend: backend2 }) => {
        const { x } = inputs;
        const cpuBackend = backend2;
        assertNotComplex(x, "square");
        const values = cpuBackend.data.get(x.dataId).values;
        const newValues = new Float32Array(values.length);
        for (let i = 0; i < values.length; ++i) {
          const value = values[i];
          newValues[i] = value * value;
        }
        const dataId = cpuBackend.write(newValues, x.shape, x.dtype);
        return { dataId, shape: x.shape, dtype: x.dtype };
      }
    };
  }
});
var step2;
var stepConfig;
var init_Step = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Step.js"() {
    init_dist();
    init_unary_utils();
    step2 = unaryKernelFunc(Step, (xi, attrs) => {
      const stepAttrs = attrs;
      if (isNaN(xi)) {
        return NaN;
      } else {
        return xi > 0 ? 1 : stepAttrs.alpha;
      }
    });
    stepConfig = {
      kernelName: Step,
      backendName: "cpu",
      kernelFunc: step2
    };
  }
});
function stridedSlice2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
  assertNotComplex(x, "stridedSlice");
  const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = slice_util_exports.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
  let result;
  if (isIdentity) {
    result = reshape2({ inputs: { x }, backend: backend2, attrs: { shape: finalShape } });
  } else if (sliceDim0 || isSimpleSlice) {
    util_exports.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
    const size = slice_util_exports.computeOutShape($begin, $end, $strides);
    const sliced = slice2({ inputs: { x }, backend: backend2, attrs: { begin: $begin, size } });
    result = reshape2({ inputs: { x: sliced }, backend: backend2, attrs: { shape: finalShape } });
    backend2.disposeIntermediateTensorInfo(sliced);
  } else {
    const xBuf = backend2.bufferSync(x);
    const outBuf = stridedSliceImpl(finalShapeSparse, xBuf, $strides, $begin);
    result = backend2.makeTensorInfo(finalShape, outBuf.dtype, outBuf.values);
  }
  return result;
}
var stridedSliceConfig;
var init_StridedSlice = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js"() {
    init_dist();
    init_cpu_util();
    init_Reshape();
    init_Slice();
    init_StridedSlice_impl();
    stridedSliceConfig = {
      kernelName: StridedSlice,
      backendName: "cpu",
      kernelFunc: stridedSlice2
    };
  }
});
function stringNGrams(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { separator, nGramWidths, leftPad, rightPad: rightPad2, padWidth, preserveShortSequences } = attrs;
  const { data, dataSplits } = inputs;
  const $data = backend2.data.get(data.dataId).values;
  const $dataSplits = backend2.data.get(dataSplits.dataId).values;
  const [nGrams, nGramsSplits] = stringNGramsImpl($data, $dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences);
  return [
    backend2.makeTensorInfo([nGrams.length], "string", nGrams),
    backend2.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
  ];
}
var stringNGramsConfig;
var init_StringNGrams = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js"() {
    init_dist();
    init_StringNGrams_impl();
    stringNGramsConfig = {
      kernelName: StringNGrams,
      backendName: "cpu",
      kernelFunc: stringNGrams
    };
  }
});
function stringSplit(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { skipEmpty } = attrs;
  const { input: input2, delimiter } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (input2.shape.length !== 1) {
    throw new Error(`Input must be a vector, got shape: ${input2.shape}`);
  }
  if (delimiter.shape.length !== 0) {
    throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
  }
  const $input = backend2.data.get(input2.dataId).values;
  const $delimiter = backend2.data.get(delimiter.dataId).values[0];
  const [indices, values, shape] = stringSplitImpl($input, $delimiter, skipEmpty);
  const outputSize = values.length;
  return [
    backend2.makeTensorInfo([outputSize, 2], "int32", indices),
    backend2.makeTensorInfo([outputSize], "string", values),
    backend2.makeTensorInfo([2], "int32", new Int32Array(shape))
  ];
}
var stringSplitConfig;
var init_StringSplit = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js"() {
    init_dist();
    init_StringSplit_impl();
    stringSplitConfig = {
      kernelName: StringSplit,
      backendName: "cpu",
      kernelFunc: stringSplit
    };
  }
});
function stringToHashBucketFast(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { numBuckets } = attrs;
  const { input: input2 } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const $input = backend2.data.get(input2.dataId).values;
  const output = stringToHashBucketFastImpl($input, numBuckets);
  return backend2.makeTensorInfo(input2.shape, "int32", output);
}
var stringToHashBucketFastConfig;
var init_StringToHashBucketFast = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js"() {
    init_dist();
    init_StringToHashBucketFast_impl();
    stringToHashBucketFastConfig = {
      kernelName: StringToHashBucketFast,
      backendName: "cpu",
      kernelFunc: stringToHashBucketFast
    };
  }
});
var tan2;
var tanConfig;
var init_Tan = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js"() {
    init_dist();
    init_unary_utils();
    tan2 = unaryKernelFunc(Tan, (xi) => Math.tan(xi));
    tanConfig = {
      kernelName: Tan,
      backendName: "cpu",
      kernelFunc: tan2
    };
  }
});
var tanh3;
var tanhConfig;
var init_Tanh = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js"() {
    init_dist();
    init_unary_utils();
    tanh3 = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));
    tanhConfig = {
      kernelName: Tanh,
      backendName: "cpu",
      kernelFunc: tanh3
    };
  }
});
function tile3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { reps } = attrs;
  assertNotComplex(x, "tile");
  const outBuf = tileImpl(backend2.bufferSync(x), reps);
  return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
}
var tileConfig;
var init_Tile = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js"() {
    init_dist();
    init_cpu_util();
    init_Tile_impl();
    tileConfig = {
      kernelName: Tile,
      backendName: "cpu",
      kernelFunc: tile3
    };
  }
});
function topK(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { k, sorted } = attrs;
  assertNotComplex(x, "topk");
  const xVals = backend2.data.get(x.dataId).values;
  const [allTopKVals, allTopKIndices] = topKImpl(xVals, x.shape, x.dtype, k, sorted);
  return [
    backend2.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
    backend2.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
  ];
}
var topKConfig;
var init_TopK = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js"() {
    init_dist();
    init_cpu_util();
    init_TopK_impl();
    topKConfig = {
      kernelName: TopK,
      backendName: "cpu",
      kernelFunc: topK
    };
  }
});
function transform2(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { image: image2, transforms } = inputs;
  const { interpolation, fillMode, fillValue, outputShape } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
  const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
  const outShape = [batch, outHeight, outWidth, numChannels];
  const inStrides = util_exports.computeStrides(image2.shape);
  const batchInStride = inStrides[0];
  const rowInStride = inStrides[1];
  const colInStride = inStrides[2];
  const outStrides = util_exports.computeStrides(outShape);
  const batchOutStride = outStrides[0];
  const rowOutStride = outStrides[1];
  const colOutStride = outStrides[2];
  const outVals = util_exports.getTypedArrayFromDType(image2.dtype, util_exports.sizeFromShape(outShape));
  outVals.fill(fillValue);
  const imageVals = backend2.data.get(image2.dataId).values;
  const transformVals = backend2.data.get(transforms.dataId).values;
  for (let b = 0; b < batch; ++b) {
    const transform4 = transforms.shape[0] === 1 ? transformVals : transformVals.subarray(b * 8, b * 8 + 8);
    for (let outY = 0; outY < outHeight; ++outY) {
      for (let outX = 0; outX < outWidth; ++outX) {
        for (let channel = 0; channel < numChannels; ++channel) {
          let val;
          const projection = transform4[6] * outX + transform4[7] * outY + 1;
          if (projection === 0) {
            continue;
          }
          const inX = (transform4[0] * outX + transform4[1] * outY + transform4[2]) / projection;
          const inY = (transform4[3] * outX + transform4[4] * outY + transform4[5]) / projection;
          const x = mapCoord(inX, imageWidth, fillMode);
          const y = mapCoord(inY, imageHeight, fillMode);
          switch (interpolation) {
            case "nearest":
              val = nearestInterpolation(imageVals, imageHeight, imageWidth, batchInStride, rowInStride, colInStride, b, y, x, channel, fillValue);
              break;
            case "bilinear":
              val = bilinearInterpolation(imageVals, imageHeight, imageWidth, batchInStride, rowInStride, colInStride, b, y, x, channel, fillValue);
              break;
            default:
              throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${interpolation}`);
          }
          const ind = b * batchOutStride + outY * rowOutStride + outX * colOutStride + channel;
          outVals[ind] = val;
        }
      }
    }
    return backend2.makeTensorInfo(outShape, image2.dtype, outVals);
  }
  const dataId = backend2.write(outVals, outShape, image2.dtype);
  return { dataId, shape: image2.shape, dtype: image2.dtype };
}
function mapCoord(outCoord, len4, mode) {
  switch (mode) {
    case "reflect":
      return mapCoordReflect(outCoord, len4);
    case "wrap":
      return mapCoordWrap(outCoord, len4);
    case "nearest":
      return mapCoordNearest(outCoord, len4);
    case "constant":
    default:
      return mapCoordConstant(outCoord, len4);
  }
}
function mapCoordReflect(outCoord, len4) {
  let inCoord = outCoord;
  if (inCoord < 0) {
    if (len4 <= 1) {
      inCoord = 0;
    } else {
      const sz2 = 2 * len4;
      if (inCoord < sz2) {
        inCoord = sz2 * Math.trunc(-inCoord / sz2) + inCoord;
      }
      inCoord = inCoord < -len4 ? inCoord + sz2 : -inCoord - 1;
    }
  } else if (inCoord > len4 - 1) {
    if (len4 <= 1) {
      inCoord = 0;
    } else {
      const sz2 = 2 * len4;
      inCoord -= sz2 * Math.trunc(inCoord / sz2);
      if (inCoord >= len4) {
        inCoord = sz2 - inCoord - 1;
      }
    }
  }
  return util_exports.clamp(0, inCoord, len4 - 1);
}
function mapCoordWrap(outCoord, len4) {
  let inCoord = outCoord;
  if (inCoord < 0) {
    if (len4 <= 1) {
      inCoord = 0;
    } else {
      const sz = len4 - 1;
      inCoord += len4 * (Math.trunc(-inCoord / sz) + 1);
    }
  } else if (inCoord > len4 - 1) {
    if (len4 <= 1) {
      inCoord = 0;
    } else {
      const sz = len4 - 1;
      inCoord -= len4 * Math.trunc(inCoord / sz);
    }
  }
  return util_exports.clamp(0, inCoord, len4 - 1);
}
function mapCoordConstant(outCoord, len4) {
  return outCoord;
}
function mapCoordNearest(outCoord, len4) {
  return util_exports.clamp(0, outCoord, len4 - 1);
}
function readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
  const ind = batch * batchStride + y * rowStride + x * colStride + channel;
  if (0 <= y && y < imageHeight && 0 <= x && x < imageWidth) {
    return imageVals[ind];
  } else {
    return fillValue;
  }
}
function nearestInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
  const $y = Math.round(y);
  const $x = Math.round(x);
  return readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, $y, $x, channel, fillValue);
}
function bilinearInterpolation(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, y, x, channel, fillValue) {
  const yFloor = Math.floor(y);
  const xFloor = Math.floor(x);
  const yCeil = yFloor + 1;
  const xCeil = xFloor + 1;
  const valueYFloor = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yFloor, xCeil, channel, fillValue);
  const valueYCeil = (xCeil - x) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xFloor, channel, fillValue) + (x - xFloor) * readWithFillValue(imageVals, imageHeight, imageWidth, batchStride, rowStride, colStride, batch, yCeil, xCeil, channel, fillValue);
  return (yCeil - y) * valueYFloor + (y - yFloor) * valueYCeil;
}
var transformConfig;
var init_Transform = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js"() {
    init_dist();
    transformConfig = {
      kernelName: Transform,
      backendName: "cpu",
      kernelFunc: transform2
    };
  }
});
function unique3(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { axis } = attrs;
  const { x } = inputs;
  assertNotComplex(x, "unique");
  const values = backend2.data.get(x.dataId).values;
  const { outputValues, outputShape, indices } = uniqueImpl(values, axis, x.shape, x.dtype);
  return [
    backend2.makeTensorInfo(outputShape, x.dtype, outputValues),
    backend2.makeTensorInfo([indices.length], "int32", indices)
  ];
}
var uniqueConfig;
var init_Unique = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js"() {
    init_dist();
    init_cpu_util();
    init_Unique_impl();
    uniqueConfig = {
      kernelName: Unique,
      backendName: "cpu",
      kernelFunc: unique3
    };
  }
});
function unpack(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { value } = inputs;
  let { axis } = attrs;
  if (axis < 0) {
    axis += value.shape.length;
  }
  const valueRank = value.shape.length;
  const num = value.shape[axis];
  const outShape = new Array(valueRank - 1);
  let outIndex = 0;
  for (let i = 0; i < valueRank; i++) {
    if (i !== axis) {
      outShape[outIndex++] = value.shape[i];
    }
  }
  const begin = new Array(valueRank).fill(0);
  const size = value.shape.slice();
  size[axis] = 1;
  const res = new Array(num);
  for (let i = 0; i < res.length; i++) {
    begin[axis] = i;
    const tempRes = slice2({ inputs: { x: value }, backend: backend2, attrs: { begin, size } });
    res[i] = reshape2({ inputs: { x: tempRes }, backend: backend2, attrs: { shape: outShape } });
    backend2.disposeIntermediateTensorInfo(tempRes);
  }
  return res;
}
var unpackConfig;
var init_Unpack = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js"() {
    init_dist();
    init_Reshape();
    init_Slice();
    unpackConfig = {
      kernelName: Unpack,
      backendName: "cpu",
      kernelFunc: unpack
    };
  }
});
function unsortedSegmentSum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, segmentIds } = inputs;
  const { numSegments } = attrs;
  assertNotComplex(x, "unsortedSegmentSum");
  const xRank = x.shape.length;
  const segmentIdsRank = segmentIds.shape.length;
  const res = [];
  const intermediates = [];
  const numIters = xRank - segmentIdsRank;
  let $segmentIds = segmentIds;
  for (let i = 0; i < numIters; ++i) {
    const expanded = expandDims3({ inputs: { input: $segmentIds }, backend: backend2, attrs: { dim: i + 1 } });
    $segmentIds = expanded;
    intermediates.push(expanded);
  }
  for (let i = 0; i < numSegments; ++i) {
    const scalarValue = util_exports.createScalarValue(i, "int32");
    const segmentId = backend2.makeTensorInfo([], "int32", scalarValue);
    const mask = equal2({ inputs: { a: segmentId, b: $segmentIds }, backend: backend2 });
    const maskCasted = cast3({ inputs: { x: mask }, backend: backend2, attrs: { dtype: "float32" } });
    const mul22 = multiply5({ inputs: { a: maskCasted, b: x }, backend: backend2 });
    const sumTensorInfo = sum3({ inputs: { x: mul22 }, backend: backend2, attrs: { axis: 0, keepDims: false } });
    res.push(sumTensorInfo);
    intermediates.push(segmentId);
    intermediates.push(mask);
    intermediates.push(maskCasted);
    intermediates.push(mul22);
    intermediates.push(sumTensorInfo);
  }
  const result = pack({ inputs: res, backend: backend2, attrs: { axis: 0 } });
  intermediates.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return result;
}
var unsortedSegmentSumConfig;
var init_UnsortedSegmentSum = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js"() {
    init_dist();
    init_cpu_util();
    init_Cast();
    init_Equal();
    init_ExpandDims();
    init_Multiply();
    init_Pack();
    init_Sum();
    unsortedSegmentSumConfig = {
      kernelName: UnsortedSegmentSum,
      backendName: "cpu",
      kernelFunc: unsortedSegmentSum2
    };
  }
});
var kernelConfigs;
var init_register_all_kernels = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js"() {
    init_dist();
    init_FusedMatMul();
    init_Abs();
    init_Acos();
    init_Acosh();
    init_Add();
    init_AddN();
    init_All();
    init_Any();
    init_ArgMax();
    init_ArgMin();
    init_Asin();
    init_Asinh();
    init_Atan();
    init_Atan2();
    init_Atanh();
    init_AvgPool();
    init_AvgPool3D();
    init_AvgPool3DGrad();
    init_AvgPoolGrad();
    init_BatchMatMul();
    init_BatchNorm();
    init_BatchToSpaceND();
    init_Bincount();
    init_BroadcastArgs();
    init_Cast();
    init_Ceil();
    init_ClipByValue();
    init_Complex();
    init_ComplexAbs();
    init_Concat();
    init_Conv2D();
    init_Conv2DBackpropFilter();
    init_Conv2DBackpropInput();
    init_Conv3D();
    init_Conv3DBackpropFilterV2();
    init_Conv3DBackpropInputV2();
    init_Cos();
    init_Cosh();
    init_CropAndResize();
    init_Cumprod();
    init_Cumsum();
    init_DenseBincount();
    init_DepthToSpace();
    init_DepthwiseConv2dNative();
    init_DepthwiseConv2dNativeBackpropFilter();
    init_DepthwiseConv2dNativeBackpropInput();
    init_Diag();
    init_Dilation2D();
    init_Dilation2DBackpropFilter();
    init_Dilation2DBackpropInput();
    init_Einsum();
    init_Elu();
    init_EluGrad();
    init_Equal();
    init_Erf();
    init_Exp();
    init_ExpandDims();
    init_Expm1();
    init_FFT();
    init_Fill();
    init_FlipLeftRight();
    init_Floor();
    init_FloorDiv();
    init_FusedConv2D();
    init_FusedDepthwiseConv2D();
    init_GatherNd();
    init_GatherV2();
    init_Greater();
    init_GreaterEqual();
    init_Identity();
    init_IFFT();
    init_Imag();
    init_IsFinite();
    init_IsInf();
    init_IsNaN();
    init_LeakyRelu();
    init_Less();
    init_LessEqual();
    init_LinSpace();
    init_Log();
    init_Log1p();
    init_LogicalAnd();
    init_LogicalNot();
    init_LogicalOr();
    init_LRN();
    init_LRNGrad();
    init_Max();
    init_Maximum();
    init_MaxPool();
    init_MaxPool3D();
    init_MaxPool3DGrad();
    init_MaxPoolGrad();
    init_MaxPoolWithArgmax();
    init_Mean();
    init_Min();
    init_Minimum();
    init_MirrorPad();
    init_Mod();
    init_Multinomial();
    init_Multiply();
    init_Neg();
    init_NonMaxSuppressionV3();
    init_NonMaxSuppressionV4();
    init_NonMaxSuppressionV5();
    init_NotEqual();
    init_OneHot();
    init_OnesLike();
    init_Pack();
    init_PadV2();
    init_Pow();
    init_Prelu();
    init_Prod();
    init_RaggedGather();
    init_RaggedRange();
    init_RaggedTensorToTensor();
    init_Range();
    init_Real();
    init_RealDiv();
    init_Reciprocal();
    init_Relu();
    init_Relu6();
    init_Reshape();
    init_ResizeBilinear();
    init_ResizeBilinearGrad();
    init_ResizeNearestNeighbor();
    init_ResizeNearestNeighborGrad();
    init_Reverse();
    init_RotateWithOffset();
    init_Round();
    init_Rsqrt();
    init_ScatterNd();
    init_SearchSorted();
    init_Select();
    init_Selu();
    init_Sigmoid();
    init_Sign();
    init_Sin();
    init_Sinh();
    init_Slice();
    init_Softmax();
    init_Softplus();
    init_SpaceToBatchND();
    init_SparseFillEmptyRows();
    init_SparseReshape();
    init_SparseSegmentMean();
    init_SparseSegmentSum();
    init_SparseToDense();
    init_SplitV();
    init_Sqrt();
    init_Square();
    init_SquaredDifference();
    init_Step();
    init_StridedSlice();
    init_StringNGrams();
    init_StringSplit();
    init_StringToHashBucketFast();
    init_Sub();
    init_Sum();
    init_Tan();
    init_Tanh();
    init_Tile();
    init_TopK();
    init_Transform();
    init_Transpose();
    init_Unique();
    init_Unpack();
    init_UnsortedSegmentSum();
    init_ZerosLike();
    kernelConfigs = [
      _fusedMatMulConfig,
      absConfig,
      acosConfig,
      acoshConfig,
      addConfig,
      addNConfig,
      allConfig,
      anyConfig,
      argMaxConfig,
      argMinConfig,
      asinConfig,
      asinhConfig,
      atanConfig,
      atan2Config,
      atanhConfig,
      avgPoolConfig,
      avgPool3DConfig,
      avgPool3DGradConfig2,
      avgPoolGradConfig2,
      batchMatMulConfig,
      batchNormConfig,
      batchToSpaceNDConfig,
      bincountConfig,
      broadcastArgsConfig,
      castConfig,
      ceilConfig,
      clipByValueConfig,
      complexConfig,
      complexAbsConfig,
      concatConfig,
      conv2DConfig,
      conv2DBackpropFilterConfig,
      conv2DBackpropInputConfig,
      conv3DConfig,
      conv3DBackpropFilterV2Config,
      conv3DBackpropInputV2Config,
      cosConfig,
      coshConfig,
      cropAndResizeConfig,
      cumprodConfig,
      cumsumConfig,
      denseBincountConfig,
      depthToSpaceConfig,
      depthwiseConv2dNativeConfig,
      depthwiseConv2dNativeBackpropFilterConfig,
      depthwiseConv2dNativeBackpropInputConfig,
      diagConfig,
      dilation2DConfig,
      dilation2DBackpropFilterConfig,
      dilation2DBackpropInputConfig,
      einsumConfig,
      eluConfig,
      eluGradConfig2,
      equalConfig,
      erfConfig,
      expConfig,
      expandDimsConfig,
      expm1Config,
      fftConfig,
      fillConfig,
      flipLeftRightConfig,
      floorConfig,
      floorDivConfig,
      fusedConv2DConfig,
      fusedDepthwiseConv2DConfig,
      gatherNdConfig,
      gatherV2Config,
      greaterConfig,
      greaterEqualConfig,
      identityConfig,
      ifftConfig,
      imagConfig,
      isFiniteConfig,
      isInfConfig,
      isNaNConfig,
      leakyReluConfig,
      lessConfig,
      lessEqualConfig,
      linSpaceConfig,
      logConfig,
      log1pConfig,
      logicalAndConfig,
      logicalNotConfig,
      logicalOrConfig,
      LRNConfig,
      LRNGradConfig,
      maxConfig,
      maximumConfig,
      maxPoolConfig,
      maxPool3DConfig,
      maxPool3DGradConfig2,
      maxPoolGradConfig2,
      maxPoolWithArgmaxConfig,
      meanConfig,
      minConfig,
      minimumConfig,
      mirrorPadConfig,
      modConfig,
      multinomialConfig,
      multiplyConfig,
      negConfig,
      nonMaxSuppressionV3Config,
      nonMaxSuppressionV4Config,
      nonMaxSuppressionV5Config,
      notEqualConfig,
      oneHotConfig,
      onesLikeConfig,
      packConfig,
      padV2Config,
      powConfig,
      preluConfig,
      prodConfig,
      raggedGatherConfig,
      raggedRangeConfig,
      raggedTensorToTensorConfig,
      rangeConfig,
      realConfig,
      realDivConfig,
      reciprocalConfig,
      reluConfig,
      relu6Config,
      reshapeConfig,
      resizeBilinearConfig,
      resizeBilinearGradConfig2,
      resizeNearestNeighborConfig,
      resizeNearestNeighborGradConfig2,
      reverseConfig,
      rotateWithOffsetConfig,
      roundConfig,
      rsqrtConfig,
      scatterNdConfig,
      searchSortedConfig,
      selectConfig,
      seluConfig,
      sigmoidConfig,
      signConfig,
      sinConfig,
      sinhConfig,
      sliceConfig,
      softmaxConfig,
      softplusConfig,
      spaceToBatchNDConfig,
      sparseFillEmptyRowsConfig,
      sparseReshapeConfig,
      sparseSegmentMeanConfig,
      sparseSegmentSumConfig,
      sparseToDenseConfig,
      splitVConfig,
      sqrtConfig,
      squareConfig,
      squaredDifferenceConfig,
      stepConfig,
      stridedSliceConfig,
      stringNGramsConfig,
      stringSplitConfig,
      stringToHashBucketFastConfig,
      subConfig,
      sumConfig,
      tanConfig,
      tanhConfig,
      tileConfig,
      topKConfig,
      transformConfig,
      transposeConfig,
      uniqueConfig,
      unpackConfig,
      unsortedSegmentSumConfig,
      zerosLikeConfig
    ];
    for (const kernelConfig of kernelConfigs) {
      registerKernel(kernelConfig);
    }
  }
});
var init_dist5 = __esm({
  "node_modules/@tensorflow/tfjs-backend-cpu/dist/index.js"() {
    init_base2();
    init_register_all_kernels();
  }
});
function setWebGLContext(webGLVersion, gl) {
  contexts[webGLVersion] = gl;
}
function getWebGLContext(webGLVersion, customCanvas) {
  if (!(webGLVersion in contexts) || customCanvas != null) {
    const newCtx = getWebGLRenderingContext(webGLVersion, customCanvas);
    if (newCtx !== null) {
      contexts[webGLVersion] = newCtx;
    } else {
      console.log("Could not get context for WebGL version", webGLVersion);
      return null;
    }
  }
  const gl = contexts[webGLVersion];
  if (gl == null || gl.isContextLost()) {
    delete contexts[webGLVersion];
    return getWebGLContext(webGLVersion);
  }
  gl.disable(gl.DEPTH_TEST);
  gl.disable(gl.STENCIL_TEST);
  gl.disable(gl.BLEND);
  gl.disable(gl.DITHER);
  gl.disable(gl.POLYGON_OFFSET_FILL);
  gl.disable(gl.SAMPLE_COVERAGE);
  gl.enable(gl.SCISSOR_TEST);
  gl.enable(gl.CULL_FACE);
  gl.cullFace(gl.BACK);
  return contexts[webGLVersion];
}
function createCanvas(webGLVersion) {
  if (typeof OffscreenCanvas !== "undefined" && webGLVersion === 2) {
    return new OffscreenCanvas(300, 150);
  } else if (typeof document !== "undefined") {
    return document.createElement("canvas");
  } else {
    throw new Error("Cannot create a canvas in this context");
  }
}
function getWebGLRenderingContext(webGLVersion, customCanvas) {
  if (webGLVersion !== 1 && webGLVersion !== 2) {
    throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  }
  const canvas = customCanvas == null ? createCanvas(webGLVersion) : customCanvas;
  canvas.addEventListener("webglcontextlost", (ev) => {
    ev.preventDefault();
    delete contexts[webGLVersion];
  }, false);
  if (env().getBool("SOFTWARE_WEBGL_ENABLED")) {
    WEBGL_ATTRIBUTES.failIfMajorPerformanceCaveat = false;
  }
  if (webGLVersion === 1) {
    return canvas.getContext("webgl", WEBGL_ATTRIBUTES) || canvas.getContext("experimental-webgl", WEBGL_ATTRIBUTES);
  }
  return canvas.getContext("webgl2", WEBGL_ATTRIBUTES);
}
var contexts;
var WEBGL_ATTRIBUTES;
var init_canvas_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/canvas_util.js"() {
    init_dist();
    contexts = {};
    WEBGL_ATTRIBUTES = {
      alpha: false,
      antialias: false,
      premultipliedAlpha: false,
      preserveDrawingBuffer: false,
      depth: false,
      stencil: false,
      failIfMajorPerformanceCaveat: true
    };
  }
});
function getUnpackedMatrixTextureShapeWidthHeight(rows, columns) {
  return [columns, rows];
}
function getUnpackedArraySizeFromMatrixSize(matrixSize, channelsPerTexture) {
  return matrixSize * channelsPerTexture;
}
function getDenseTexShape(shape) {
  const size = util_exports.sizeFromShape(shape);
  const texelsNeeded = Math.ceil(size / 4);
  return util_exports.sizeToSquarishShape(texelsNeeded);
}
function getPackedMatrixTextureShapeWidthHeight(rows, columns) {
  return [
    Math.max(1, Math.ceil(columns / 2)),
    Math.max(1, Math.ceil(rows / 2))
  ];
}
function getPackedRGBAArraySizeFromMatrixShape(rows, columns) {
  const [w, h] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
  return w * h * 4;
}
function getTextureConfig(gl, textureHalfFloatExtension) {
  const glany = gl;
  let internalFormatFloat;
  let internalFormatHalfFloat;
  let internalFormatPackedHalfFloat;
  let internalFormatPackedFloat;
  let textureFormatFloat;
  let downloadTextureFormat;
  let downloadUnpackNumChannels;
  let defaultNumChannels;
  let textureTypeHalfFloat;
  let textureTypeFloat;
  if (env().getNumber("WEBGL_VERSION") === 2) {
    internalFormatFloat = glany.R32F;
    internalFormatHalfFloat = glany.R16F;
    internalFormatPackedHalfFloat = glany.RGBA16F;
    internalFormatPackedFloat = glany.RGBA32F;
    textureFormatFloat = glany.RED;
    downloadUnpackNumChannels = 4;
    defaultNumChannels = 1;
    textureTypeHalfFloat = glany.HALF_FLOAT;
    textureTypeFloat = glany.FLOAT;
    downloadTextureFormat = glany.RGBA8;
  } else {
    internalFormatFloat = gl.RGBA;
    internalFormatHalfFloat = gl.RGBA;
    internalFormatPackedHalfFloat = gl.RGBA;
    internalFormatPackedFloat = glany.RGBA;
    textureFormatFloat = gl.RGBA;
    downloadUnpackNumChannels = 4;
    defaultNumChannels = 4;
    textureTypeHalfFloat = textureHalfFloatExtension != null ? textureHalfFloatExtension.HALF_FLOAT_OES : null;
    textureTypeFloat = gl.FLOAT;
    downloadTextureFormat = gl.RGBA;
  }
  return {
    internalFormatFloat,
    internalFormatHalfFloat,
    internalFormatPackedHalfFloat,
    internalFormatPackedFloat,
    textureFormatFloat,
    downloadTextureFormat,
    downloadUnpackNumChannels,
    defaultNumChannels,
    textureTypeHalfFloat,
    textureTypeFloat
  };
}
var PackingScheme;
var TextureUsage;
var PhysicalTextureType;
var init_tex_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/tex_util.js"() {
    init_dist();
    (function(PackingScheme2) {
      PackingScheme2[PackingScheme2["DENSE"] = 0] = "DENSE";
      PackingScheme2[PackingScheme2["SHARED_BATCH"] = 1] = "SHARED_BATCH";
    })(PackingScheme || (PackingScheme = {}));
    (function(TextureUsage2) {
      TextureUsage2[TextureUsage2["RENDER"] = 0] = "RENDER";
      TextureUsage2[TextureUsage2["UPLOAD"] = 1] = "UPLOAD";
      TextureUsage2[TextureUsage2["PIXELS"] = 2] = "PIXELS";
      TextureUsage2[TextureUsage2["DOWNLOAD"] = 3] = "DOWNLOAD";
    })(TextureUsage || (TextureUsage = {}));
    (function(PhysicalTextureType2) {
      PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT16"] = 0] = "UNPACKED_FLOAT16";
      PhysicalTextureType2[PhysicalTextureType2["UNPACKED_FLOAT32"] = 1] = "UNPACKED_FLOAT32";
      PhysicalTextureType2[PhysicalTextureType2["PACKED_4X1_UNSIGNED_BYTE"] = 2] = "PACKED_4X1_UNSIGNED_BYTE";
      PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT32"] = 3] = "PACKED_2X2_FLOAT32";
      PhysicalTextureType2[PhysicalTextureType2["PACKED_2X2_FLOAT16"] = 4] = "PACKED_2X2_FLOAT16";
    })(PhysicalTextureType || (PhysicalTextureType = {}));
  }
});
function callAndCheck(gl, func2) {
  const returnValue = func2();
  if (env().getBool("DEBUG")) {
    checkWebGLError(gl);
  }
  return returnValue;
}
function checkWebGLError(gl) {
  const error = gl.getError();
  if (error !== gl.NO_ERROR) {
    throw new Error("WebGL Error: " + getWebGLErrorMessage(gl, error));
  }
}
function canBeRepresented(num) {
  if (env().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || num === 0 || MIN_FLOAT16 < Math.abs(num) && Math.abs(num) < MAX_FLOAT16) {
    return true;
  }
  return false;
}
function getWebGLErrorMessage(gl, status) {
  switch (status) {
    case gl.NO_ERROR:
      return "NO_ERROR";
    case gl.INVALID_ENUM:
      return "INVALID_ENUM";
    case gl.INVALID_VALUE:
      return "INVALID_VALUE";
    case gl.INVALID_OPERATION:
      return "INVALID_OPERATION";
    case gl.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";
    case gl.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";
    case gl.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";
    default:
      return `Unknown error code ${status}`;
  }
}
function getExtensionOrThrow(gl, extensionName) {
  return throwIfNull(gl, () => gl.getExtension(extensionName), 'Extension "' + extensionName + '" not supported on this browser.');
}
function createVertexShader(gl, vertexShaderSource) {
  const vertexShader = throwIfNull(gl, () => gl.createShader(gl.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  callAndCheck(gl, () => gl.shaderSource(vertexShader, vertexShaderSource));
  callAndCheck(gl, () => gl.compileShader(vertexShader));
  if (gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS) === false) {
    console.log(gl.getShaderInfoLog(vertexShader));
    throw new Error("Failed to compile vertex shader.");
  }
  return vertexShader;
}
function createFragmentShader(gl, fragmentShaderSource) {
  const fragmentShader = throwIfNull(gl, () => gl.createShader(gl.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  callAndCheck(gl, () => gl.shaderSource(fragmentShader, fragmentShaderSource));
  callAndCheck(gl, () => gl.compileShader(fragmentShader));
  if (env().get("ENGINE_COMPILE_ONLY")) {
    return fragmentShader;
  }
  if (gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS) === false) {
    logShaderSourceAndInfoLog(fragmentShaderSource, gl.getShaderInfoLog(fragmentShader));
    throw new Error("Failed to compile fragment shader.");
  }
  return fragmentShader;
}
function logShaderSourceAndInfoLog(shaderSource, shaderInfoLog) {
  const lineNumberRegexResult = lineNumberRegex.exec(shaderInfoLog);
  if (lineNumberRegexResult == null) {
    console.log(`Couldn't parse line number in error: ${shaderInfoLog}`);
    console.log(shaderSource);
    return;
  }
  const lineNumber = +lineNumberRegexResult[1];
  const shaderLines = shaderSource.split("\n");
  const pad2 = shaderLines.length.toString().length + 2;
  const linesWithLineNumbers = shaderLines.map((line, lineNumber2) => util_exports.rightPad((lineNumber2 + 1).toString(), pad2) + line);
  let maxLineLength = 0;
  for (let i = 0; i < linesWithLineNumbers.length; i++) {
    maxLineLength = Math.max(linesWithLineNumbers[i].length, maxLineLength);
  }
  const beforeErrorLines = linesWithLineNumbers.slice(0, lineNumber - 1);
  const errorLine = linesWithLineNumbers.slice(lineNumber - 1, lineNumber);
  const afterErrorLines = linesWithLineNumbers.slice(lineNumber);
  console.log(beforeErrorLines.join("\n"));
  console.log(shaderInfoLog.split("\n")[0]);
  console.log(`%c ${util_exports.rightPad(errorLine[0], maxLineLength)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717");
  console.log(afterErrorLines.join("\n"));
}
function createProgram(gl) {
  return throwIfNull(gl, () => gl.createProgram(), "Unable to create WebGLProgram.");
}
function linkProgram(gl, program) {
  callAndCheck(gl, () => gl.linkProgram(program));
  if (env().get("ENGINE_COMPILE_ONLY")) {
    return;
  }
  if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {
    console.log(gl.getProgramInfoLog(program));
    throw new Error("Failed to link vertex and fragment shaders.");
  }
}
function validateProgram(gl, program) {
  callAndCheck(gl, () => gl.validateProgram(program));
  if (gl.getProgramParameter(program, gl.VALIDATE_STATUS) === false) {
    console.log(gl.getProgramInfoLog(program));
    throw new Error("Shader program validation failed.");
  }
}
function createStaticVertexBuffer(gl, data) {
  const buffer2 = throwIfNull(gl, () => gl.createBuffer(), "Unable to create WebGLBuffer");
  callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, buffer2));
  callAndCheck(gl, () => gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW));
  return buffer2;
}
function createStaticIndexBuffer(gl, data) {
  const buffer2 = throwIfNull(gl, () => gl.createBuffer(), "Unable to create WebGLBuffer");
  callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffer2));
  callAndCheck(gl, () => gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, data, gl.STATIC_DRAW));
  return buffer2;
}
function createTexture(gl) {
  return throwIfNull(gl, () => gl.createTexture(), "Unable to create WebGLTexture.");
}
function validateTextureSize(width, height) {
  const maxTextureSize = env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (width <= 0 || height <= 0) {
    const requested = `[${width}x${height}]`;
    throw new Error("Requested texture size " + requested + " is invalid.");
  }
  if (width > maxTextureSize || height > maxTextureSize) {
    const requested = `[${width}x${height}]`;
    const max5 = `[${maxTextureSize}x${maxTextureSize}]`;
    throw new Error("Requested texture size " + requested + " greater than WebGL maximum on this browser / GPU " + max5 + ".");
  }
}
function createFramebuffer(gl) {
  return throwIfNull(gl, () => gl.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}
function bindVertexBufferToProgramAttribute(gl, program, attribute, buffer2, arrayEntriesPerItem, itemStrideInBytes, itemOffsetInBytes) {
  const loc = gl.getAttribLocation(program, attribute);
  if (loc === -1) {
    return false;
  }
  callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, buffer2));
  callAndCheck(gl, () => gl.vertexAttribPointer(loc, arrayEntriesPerItem, gl.FLOAT, false, itemStrideInBytes, itemOffsetInBytes));
  callAndCheck(gl, () => gl.enableVertexAttribArray(loc));
  return true;
}
function bindTextureUnit(gl, texture, textureUnit) {
  validateTextureUnit(gl, textureUnit);
  callAndCheck(gl, () => gl.activeTexture(gl.TEXTURE0 + textureUnit));
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
}
function getProgramUniformLocationOrThrow(gl, program, uniformName) {
  return throwIfNull(gl, () => gl.getUniformLocation(program, uniformName), 'uniform "' + uniformName + '" not present in program.');
}
function getProgramUniformLocation(gl, program, uniformName) {
  return gl.getUniformLocation(program, uniformName);
}
function bindTextureToProgramUniformSampler(gl, texture, uniformSamplerLocation, textureUnit) {
  callAndCheck(gl, () => bindTextureUnit(gl, texture, textureUnit));
  callAndCheck(gl, () => gl.uniform1i(uniformSamplerLocation, textureUnit));
}
function bindColorTextureToFramebuffer(gl, texture, framebuffer) {
  callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer));
  callAndCheck(gl, () => gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0));
}
function unbindColorTextureFromFramebuffer(gl, framebuffer) {
  callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer));
  callAndCheck(gl, () => gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, null, 0));
}
function validateFramebuffer(gl) {
  const status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
  if (status !== gl.FRAMEBUFFER_COMPLETE) {
    throw new Error("Error binding framebuffer: " + getFramebufferErrorMessage(gl, status));
  }
}
function getFramebufferErrorMessage(gl, status) {
  switch (status) {
    case gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
    case gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
    case gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
    case gl.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";
    default:
      return `unknown error ${status}`;
  }
}
function throwIfNull(gl, returnTOrNull, failureMessage) {
  const tOrNull = callAndCheck(gl, () => returnTOrNull());
  if (tOrNull == null) {
    throw new Error(failureMessage);
  }
  return tOrNull;
}
function validateTextureUnit(gl, textureUnit) {
  const maxTextureUnit = gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1;
  const glTextureUnit = textureUnit + gl.TEXTURE0;
  if (glTextureUnit < gl.TEXTURE0 || glTextureUnit > maxTextureUnit) {
    const textureUnitRange = `[gl.TEXTURE0, gl.TEXTURE${maxTextureUnit}]`;
    throw new Error(`textureUnit must be in ${textureUnitRange}.`);
  }
}
function getBatchDim(shape, dimsToSkip = 2) {
  return util_exports.sizeFromShape(shape.slice(0, shape.length - dimsToSkip));
}
function getRowsCols(shape) {
  if (shape.length === 0) {
    throw Error("Cannot get rows and columns of an empty shape array.");
  }
  return [
    shape.length > 1 ? shape[shape.length - 2] : 1,
    shape[shape.length - 1]
  ];
}
function getShapeAs3D(shape) {
  let shapeAs3D = [1, 1, 1];
  const isScalar = shape.length === 0 || shape.length === 1 && shape[0] === 1;
  if (!isScalar) {
    shapeAs3D = [getBatchDim(shape), ...getRowsCols(shape)];
  }
  return shapeAs3D;
}
function getTextureShapeFromLogicalShape(logShape, isPacked = false) {
  let maxTexSize = env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  let maxSizeForNarrowTex = env().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");
  if (maxSizeForNarrowTex === Infinity && env().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE")) {
    maxSizeForNarrowTex = maxTexSize / 2;
  }
  if (isPacked) {
    maxTexSize = maxTexSize * 2;
    maxSizeForNarrowTex = maxSizeForNarrowTex * 2;
    logShape = logShape.map((d, i) => i >= logShape.length - 2 ? util_exports.nearestLargerEven(logShape[i]) : logShape[i]);
    if (logShape.length === 1) {
      logShape = [2, logShape[0]];
    }
  }
  if (logShape.length !== 2) {
    const squeezeResult = util_exports.squeezeShape(logShape);
    logShape = squeezeResult.newShape;
  }
  let size = util_exports.sizeFromShape(logShape);
  let textureShape = null;
  if (logShape.length <= 1 && size <= maxTexSize) {
    textureShape = [1, size];
  } else if (logShape.length === 2 && logShape[0] <= maxTexSize && logShape[1] <= maxTexSize) {
    textureShape = logShape;
  } else if (logShape.length === 3 && logShape[0] * logShape[1] <= maxTexSize && logShape[2] <= maxTexSize) {
    textureShape = [logShape[0] * logShape[1], logShape[2]];
  } else if (logShape.length === 3 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] <= maxTexSize) {
    textureShape = [logShape[0], logShape[1] * logShape[2]];
  } else if (logShape.length === 4 && logShape[0] * logShape[1] * logShape[2] <= maxTexSize && logShape[3] <= maxTexSize) {
    textureShape = [logShape[0] * logShape[1] * logShape[2], logShape[3]];
  } else if (logShape.length === 4 && logShape[0] <= maxTexSize && logShape[1] * logShape[2] * logShape[3] <= maxTexSize) {
    textureShape = [logShape[0], logShape[1] * logShape[2] * logShape[3]];
  }
  const isLongNarrowTex = textureShape != null && Math.max(...textureShape) > maxSizeForNarrowTex && Math.min(...textureShape) <= (isPacked ? 2 : 1) && Math.min(...textureShape) > 0;
  if (textureShape == null || isLongNarrowTex) {
    if (isPacked) {
      const batchDim = getBatchDim(logShape);
      let rows = 2, cols = 2;
      if (logShape.length) {
        [rows, cols] = getRowsCols(logShape);
      }
      size = batchDim * (rows / 2) * (cols / 2);
      textureShape = util_exports.sizeToSquarishShape(size).map((d) => d * 2);
    } else {
      textureShape = util_exports.sizeToSquarishShape(size);
    }
  }
  return textureShape;
}
function isEven(n) {
  return n % 2 === 0;
}
function isReshapeFree(shape1, shape2) {
  shape1 = shape1.slice(-2);
  shape2 = shape2.slice(-2);
  if (util_exports.arraysEqual(shape1, shape2)) {
    return true;
  }
  if (!shape1.length || !shape2.length) {
    return true;
  }
  if (shape1[0] === 0 || shape1[1] === 0 || shape2[0] === 0 || shape2[1] === 0) {
    return true;
  }
  if (shape1.length !== shape2.length) {
    const shape1Cols = shape1.slice(-1)[0];
    const shape2Cols = shape2.slice(-1)[0];
    if (shape1Cols === shape2Cols) {
      return true;
    }
    if (isEven(shape1Cols) && isEven(shape2Cols) && (shape1[0] === 1 || shape2[0] === 1)) {
      return true;
    }
  }
  return shape1[1] === shape2[1] && isEven(shape1[0]) && isEven(shape2[0]);
}
function getWebGLMaxTextureSize(webGLVersion) {
  if (MAX_TEXTURE_SIZE == null) {
    const gl = getWebGLContext(webGLVersion);
    MAX_TEXTURE_SIZE = gl.getParameter(gl.MAX_TEXTURE_SIZE);
  }
  return MAX_TEXTURE_SIZE;
}
function getMaxTexturesInShader(webGLVersion) {
  if (MAX_TEXTURES_IN_SHADER == null) {
    const gl = getWebGLContext(webGLVersion);
    MAX_TEXTURES_IN_SHADER = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
  }
  return Math.min(16, MAX_TEXTURES_IN_SHADER);
}
function getWebGLDisjointQueryTimerVersion(webGLVersion) {
  if (webGLVersion === 0) {
    return 0;
  }
  let queryTimerVersion;
  const gl = getWebGLContext(webGLVersion);
  if (hasExtension(gl, "EXT_disjoint_timer_query_webgl2") && webGLVersion === 2) {
    queryTimerVersion = 2;
  } else if (hasExtension(gl, "EXT_disjoint_timer_query")) {
    queryTimerVersion = 1;
  } else {
    queryTimerVersion = 0;
  }
  return queryTimerVersion;
}
function hasExtension(gl, extensionName) {
  const ext = gl.getExtension(extensionName);
  return ext != null;
}
function isWebGLVersionEnabled(webGLVersion) {
  try {
    const gl = getWebGLContext(webGLVersion);
    if (gl != null) {
      return true;
    }
  } catch (e) {
    console.log("Error when getting WebGL context: ", e);
    return false;
  }
  return false;
}
function isCapableOfRenderingToFloatTexture(webGLVersion) {
  if (webGLVersion === 0) {
    return false;
  }
  const gl = getWebGLContext(webGLVersion);
  if (webGLVersion === 1) {
    if (!hasExtension(gl, "OES_texture_float")) {
      return false;
    }
  } else {
    if (!hasExtension(gl, "EXT_color_buffer_float")) {
      return false;
    }
  }
  const isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
  return isFrameBufferComplete;
}
function isDownloadFloatTextureEnabled(webGLVersion) {
  if (webGLVersion === 0) {
    return false;
  }
  const gl = getWebGLContext(webGLVersion);
  if (webGLVersion === 1) {
    if (!hasExtension(gl, "OES_texture_float")) {
      return false;
    }
    if (!hasExtension(gl, "WEBGL_color_buffer_float")) {
      return false;
    }
  } else {
    if (hasExtension(gl, "EXT_color_buffer_float")) {
      return createFloatTextureAndBindToFramebuffer(gl);
    }
    const COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
    if (hasExtension(gl, COLOR_BUFFER_HALF_FLOAT)) {
      const textureHalfFloatExtension = gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
      return createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension);
    }
    return false;
  }
  const isFrameBufferComplete = createFloatTextureAndBindToFramebuffer(gl);
  return isFrameBufferComplete;
}
function createFloatTextureAndBindToFramebuffer(gl) {
  const texConfig = getTextureConfig(gl);
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, texture);
  const width = 1;
  const height = 1;
  gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeFloat, null);
  const frameBuffer = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
  const isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
  gl.bindTexture(gl.TEXTURE_2D, null);
  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.deleteTexture(texture);
  gl.deleteFramebuffer(frameBuffer);
  return isFrameBufferComplete;
}
function createHalfFloatTextureAndBindToFramebuffer(gl, textureHalfFloatExtension) {
  const texConfig = getTextureConfig(gl, textureHalfFloatExtension);
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, texture);
  const width = 1;
  const height = 1;
  gl.texImage2D(gl.TEXTURE_2D, 0, texConfig.internalFormatHalfFloat, width, height, 0, texConfig.textureFormatFloat, texConfig.textureTypeHalfFloat, null);
  const frameBuffer = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
  const isFrameBufferComplete = gl.checkFramebufferStatus(gl.FRAMEBUFFER) === gl.FRAMEBUFFER_COMPLETE;
  gl.bindTexture(gl.TEXTURE_2D, null);
  gl.bindFramebuffer(gl.FRAMEBUFFER, null);
  gl.deleteTexture(texture);
  gl.deleteFramebuffer(frameBuffer);
  return isFrameBufferComplete;
}
function isWebGLFenceEnabled(webGLVersion) {
  if (webGLVersion !== 2) {
    return false;
  }
  const gl = getWebGLContext(webGLVersion);
  const isEnabled = gl.fenceSync != null;
  return isEnabled;
}
function assertNotComplex2(tensor2, opName) {
  if (!Array.isArray(tensor2)) {
    tensor2 = [tensor2];
  }
  tensor2.forEach((t) => {
    if (t != null) {
      util_exports.assert(t.dtype !== "complex64", () => `${opName} does not support complex64 tensors in the WebGL backend.`);
    }
  });
}
var MIN_FLOAT16;
var MAX_FLOAT16;
var lineNumberRegex;
var MAX_TEXTURE_SIZE;
var MAX_TEXTURES_IN_SHADER;
var init_webgl_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/webgl_util.js"() {
    init_dist();
    init_canvas_util();
    init_tex_util();
    MIN_FLOAT16 = 596e-10;
    MAX_FLOAT16 = 65504;
    lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;
  }
});
var ENV5;
var init_flags_webgl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/flags_webgl.js"() {
    init_dist();
    init_webgl_util();
    ENV5 = env();
    ENV5.registerFlag("HAS_WEBGL", () => ENV5.getNumber("WEBGL_VERSION") > 0);
    ENV5.registerFlag("WEBGL_VERSION", () => {
      if (isWebGLVersionEnabled(2)) {
        return 2;
      } else if (isWebGLVersionEnabled(1)) {
        return 1;
      }
      return 0;
    });
    ENV5.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => false);
    ENV5.registerFlag("WEBGL_BUFFER_SUPPORTED", () => ENV5.get("WEBGL_VERSION") === 2);
    ENV5.registerFlag("WEBGL_CPU_FORWARD", () => true);
    ENV5.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => false);
    ENV5.registerFlag("WEBGL_PACK", () => ENV5.getBool("HAS_WEBGL"));
    ENV5.registerFlag("WEBGL_PACK_NORMALIZATION", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_CLIP", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_PACK_REDUCE", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_LAZILY_UNPACK", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_CONV_IM2COL", () => ENV5.getBool("WEBGL_PACK"));
    ENV5.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => getWebGLMaxTextureSize(ENV5.getNumber("WEBGL_VERSION")));
    ENV5.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => getMaxTexturesInShader(ENV5.getNumber("WEBGL_VERSION")));
    ENV5.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
      const webGLVersion = ENV5.getNumber("WEBGL_VERSION");
      if (webGLVersion === 0) {
        return 0;
      }
      return getWebGLDisjointQueryTimerVersion(webGLVersion);
    });
    ENV5.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ENV5.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !device_util_exports.isMobile());
    ENV5.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => isCapableOfRenderingToFloatTexture(ENV5.getNumber("WEBGL_VERSION")));
    ENV5.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => {
      return ENV5.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : ENV5.getBool("WEBGL_RENDER_FLOAT32_CAPABLE");
    });
    ENV5.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => isDownloadFloatTextureEnabled(ENV5.getNumber("WEBGL_VERSION")));
    ENV5.registerFlag("WEBGL_FENCE_API_ENABLED", () => isWebGLFenceEnabled(ENV5.getNumber("WEBGL_VERSION")));
    ENV5.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => {
      const useUniforms = ENV5.getBool("WEBGL_RENDER_FLOAT32_ENABLED");
      return useUniforms ? 4 : 0;
    });
    ENV5.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => {
      return -1;
    }, (threshold3) => {
      if (threshold3 < 0 && threshold3 !== -1) {
        throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${threshold3}.`);
      }
    });
    ENV5.registerFlag("WEBGL_FLUSH_THRESHOLD", () => {
      return device_util_exports.isMobile() ? 1 : -1;
    }, (threshold3) => {
      if (threshold3 < 0 && threshold3 !== -1) {
        throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${threshold3}.`);
      }
    });
    ENV5.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128);
    ENV5.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => false);
    ENV5.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5);
    ENV5.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);
    ENV5.registerFlag("WEBGL_EXP_CONV", () => false);
    ENV5.registerFlag("SOFTWARE_WEBGL_ENABLED", () => ENV5.getBool("IS_TEST"));
    ENV5.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE", () => Infinity);
    ENV5.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE", () => false);
    ENV5.registerFlag("WEBGL2_ISNAN_CUSTOM", () => false);
    ENV5.registerFlag("ENGINE_COMPILE_ONLY", () => false);
  }
});
function getGlslDifferences() {
  let version8;
  let attribute;
  let varyingVs;
  let varyingFs;
  let texture2D;
  let output;
  let defineOutput;
  let defineSpecialNaN;
  let defineSpecialInf;
  let defineRound;
  if (env().getNumber("WEBGL_VERSION") === 2) {
    version8 = "#version 300 es";
    attribute = "in";
    varyingVs = "out";
    varyingFs = "in";
    texture2D = "texture";
    output = "outputColor";
    defineOutput = "out vec4 outputColor;";
    defineSpecialNaN = env().getBool("WEBGL2_ISNAN_CUSTOM") ? `
      bool isnan_custom(float val) {
        uint floatToUint = floatBitsToUint(val);
        return (floatToUint & 0x7fffffffu) > 0x7f800000u;
      }

      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan_custom(val.x),
          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));
      }

      #define isnan(value) isnan_custom(value)
    ` : "";
    defineSpecialInf = ``;
    defineRound = `
      #define round(value) newRound(value)
      int newRound(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 newRound(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `;
  } else {
    version8 = "";
    attribute = "attribute";
    varyingVs = "varying";
    varyingFs = "varying";
    texture2D = "texture2D";
    output = "gl_FragColor";
    defineOutput = "";
    defineSpecialNaN = `
      #define isnan(value) isnan_custom(value)
      bool isnan_custom(float val) {
        return (val > 0. || val < 1. || val == 0.) ? false : true;
      }
      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));
      }
    `;
    defineSpecialInf = `
      uniform float INFINITY;

      bool isinf(float val) {
        return abs(val) == INFINITY;
      }
      bvec4 isinf(vec4 val) {
        return equal(abs(val), vec4(INFINITY));
      }
    `;
    defineRound = `
      int round(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 round(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `;
  }
  return {
    version: version8,
    attribute,
    varyingVs,
    varyingFs,
    texture2D,
    output,
    defineOutput,
    defineSpecialNaN,
    defineSpecialInf,
    defineRound
  };
}
var init_glsl_version = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/glsl_version.js"() {
    init_dist();
  }
});
function getLogicalCoordinatesFromFlatIndex(coords2, shape, index = "index") {
  const strides = util_exports.computeStrides(shape);
  return strides.map((stride, i) => {
    const line1 = `int ${coords2[i]} = ${index} / ${stride}`;
    const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * ${stride}` : `index -= ${coords2[i]} * ${stride}`;
    return `${line1}; ${line2};`;
  }).join("");
}
function getOutputLogicalCoordinatesFromFlatIndexByUniform(coords2, shape, index = "index") {
  const strides = util_exports.computeStrides(shape);
  return strides.map((_, i) => {
    const line1 = `int ${coords2[i]} = ${index} / outShapeStrides[${i}]`;
    const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * outShapeStrides[${i}]` : `index -= ${coords2[i]} * outShapeStrides[${i}]`;
    return `${line1}; ${line2};`;
  }).join("");
}
function symbolicallyComputeStrides(indicesArr, variableName) {
  const numCoords = indicesArr.length;
  const shape = indicesArr.map((d) => `${variableName}[${d}]`);
  const strides = new Array(numCoords - 1);
  strides[numCoords - 2] = shape[numCoords - 1];
  for (let i = numCoords - 3; i >= 0; --i) {
    strides[i] = `(${strides[i + 1]} * ${shape[i + 1]})`;
  }
  return strides;
}
function getLogicalCoordinatesFromFlatIndexByUniform(coords2, variableName, index = "index") {
  const indicesArray = coords2.map((_, i) => i);
  const strides = symbolicallyComputeStrides(indicesArray, variableName);
  return strides.map((_, i) => {
    const line1 = `int ${coords2[i]} = ${index} / ${strides[i]}`;
    const line2 = i === strides.length - 1 ? `int ${coords2[i + 1]} = ${index} - ${coords2[i]} * ${strides[i]}` : `index -= ${coords2[i]} * ${strides[i]}`;
    return `${line1}; ${line2};`;
  }).join("");
}
function getFlatIndexFrom3D(shape) {
  const strides = util_exports.computeStrides(shape).map((d) => d.toString());
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * ${strides[0]} + coords.y * ${strides[1]} + coords.z;
  }
`;
}
function getFlatIndexFrom3DOutput() {
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;
  }
`;
}
var ENCODE_FLOAT_SNIPPET;
var init_shader_compiler_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/shader_compiler_util.js"() {
    init_dist();
    ENCODE_FLOAT_SNIPPET = `
  const float FLOAT_MAX = 1.70141184e38;
  const float FLOAT_MIN = 1.17549435e-38;

  lowp vec4 encode_float(highp float v) {
    if (isnan(v)) {
      return vec4(255, 255, 255, 255);
    }

    highp float av = abs(v);

    if(av < FLOAT_MIN) {
      return vec4(0.0, 0.0, 0.0, 0.0);
    } else if(v > FLOAT_MAX) {
      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
    } else if(v < -FLOAT_MAX) {
      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
    }

    highp vec4 c = vec4(0,0,0,0);

    highp float e = floor(log2(av));
    highp float m = exp2(fract(log2(av))) - 1.0;

    c[2] = floor(128.0 * m);
    m -= c[2] / 128.0;
    c[1] = floor(32768.0 * m);
    m -= c[1] / 32768.0;
    c[0] = floor(8388608.0 * m);

    highp float ebias = e + 127.0;
    c[3] = floor(ebias / 2.0);
    ebias -= c[3] * 2.0;
    c[2] += floor(ebias) * 128.0;

    c[3] += 128.0 * step(0.0, -v);

    return c / 255.0;
  }
`;
  }
});
function makeShader(inputsInfo, outputShape, program) {
  const prefixSnippets = [];
  inputsInfo.forEach((x) => {
    const size = util_exports.sizeFromShape(x.shapeInfo.logicalShape);
    if (x.shapeInfo.isUniform) {
      prefixSnippets.push(`uniform float ${x.name}${size > 1 ? `[${size}]` : ""};`);
    } else {
      prefixSnippets.push(`uniform sampler2D ${x.name};`);
      prefixSnippets.push(`uniform int offset${x.name};`);
    }
    if (program.enableShapeUniforms) {
      const { uniformShape } = getUniformInfoFromShape(program.packedInputs, x.shapeInfo.logicalShape, x.shapeInfo.texShape);
      switch (uniformShape.length) {
        case 1:
          prefixSnippets.push(`uniform int ${x.name}Shape;`);
          break;
        case 2:
          prefixSnippets.push(`uniform ivec2 ${x.name}Shape;`);
          break;
        case 3:
          prefixSnippets.push(`uniform ivec3 ${x.name}Shape;`);
          break;
        case 4:
          prefixSnippets.push(`uniform ivec4 ${x.name}Shape;`);
          break;
        default:
          break;
      }
      prefixSnippets.push(`uniform ivec2 ${x.name}TexShape;`);
    }
  });
  if (program.enableShapeUniforms) {
    switch (outputShape.logicalShape.length) {
      case 1:
        prefixSnippets.push(`uniform int outShape;`);
        break;
      case 2:
        prefixSnippets.push(`uniform ivec2 outShape;`);
        prefixSnippets.push(`uniform int outShapeStrides;`);
        break;
      case 3:
        prefixSnippets.push(`uniform ivec3 outShape;`);
        prefixSnippets.push(`uniform ivec2 outShapeStrides;`);
        break;
      case 4:
        prefixSnippets.push(`uniform ivec4 outShape;`);
        prefixSnippets.push(`uniform ivec3 outShapeStrides;`);
        break;
      default:
        break;
    }
    prefixSnippets.push(`uniform ivec2 outTexShape;`);
  }
  if (program.customUniforms) {
    program.customUniforms.forEach((d) => {
      prefixSnippets.push(`uniform ${d.type} ${d.name}${d.arrayIndex ? `[${d.arrayIndex}]` : ""};`);
    });
  }
  const inputPrefixSnippet = prefixSnippets.join("\n");
  const inputSamplingSnippet = inputsInfo.map((x) => getInputSamplingSnippet(x, outputShape, program.packedInputs, program.enableShapeUniforms)).join("\n");
  const outTexShape = outputShape.texShape;
  const glsl = getGlslDifferences();
  const floatTextureSampleSnippet = getFloatTextureSampleSnippet(glsl);
  let outputSamplingSnippet;
  let floatTextureSetOutputSnippet;
  let shaderPrefix = getShaderPrefix(glsl);
  if (outputShape.isPacked) {
    outputSamplingSnippet = getPackedOutputSamplingSnippet(outputShape.logicalShape, outTexShape, program.enableShapeUniforms);
    floatTextureSetOutputSnippet = getFloatTextureSetRGBASnippet(glsl);
  } else {
    outputSamplingSnippet = getOutputSamplingSnippet(outputShape.logicalShape, outTexShape, program.enableShapeUniforms);
    floatTextureSetOutputSnippet = getFloatTextureSetRSnippet(glsl);
  }
  if (program.packedInputs) {
    shaderPrefix += SHADER_PACKED_PREFIX;
  }
  const source = [
    shaderPrefix,
    floatTextureSampleSnippet,
    floatTextureSetOutputSnippet,
    inputPrefixSnippet,
    outputSamplingSnippet,
    inputSamplingSnippet,
    program.userCode
  ].join("\n");
  return source;
}
function getSamplerFromInInfo(inInfo, enableShapeUniforms = false) {
  const shape = inInfo.shapeInfo.logicalShape;
  switch (shape.length) {
    case 0:
      return getSamplerScalar(inInfo, enableShapeUniforms);
    case 1:
      return getSampler1D(inInfo, enableShapeUniforms);
    case 2:
      return getSampler2D(inInfo, enableShapeUniforms);
    case 3:
      return getSampler3D(inInfo, enableShapeUniforms);
    case 4:
      return getSampler4D(inInfo, enableShapeUniforms);
    case 5:
      return getSampler5D(inInfo);
    case 6:
      return getSampler6D(inInfo);
    default:
      throw new Error(`${shape.length}-D input sampling is not yet supported`);
  }
}
function getPackedSamplerFromInInfo(inInfo, enableShapeUniforms) {
  const shape = inInfo.shapeInfo.logicalShape;
  switch (shape.length) {
    case 0:
      return getPackedSamplerScalar(inInfo);
    case 1:
      return getPackedSampler1D(inInfo, enableShapeUniforms);
    case 2:
      return getPackedSampler2D(inInfo, enableShapeUniforms);
    case 3:
      return getPackedSampler3D(inInfo, enableShapeUniforms);
    default:
      return getPackedSamplerND(inInfo, enableShapeUniforms);
  }
}
function getInputSamplingSnippet(inInfo, outShapeInfo, usesPackedTextures = false, enableShapeUniforms) {
  let res = "";
  if (usesPackedTextures) {
    res += getPackedSamplerFromInInfo(inInfo, enableShapeUniforms);
  } else {
    res += getSamplerFromInInfo(inInfo, enableShapeUniforms);
  }
  const inShape = inInfo.shapeInfo.logicalShape;
  const outShape = outShapeInfo.logicalShape;
  if (inShape.length <= outShape.length) {
    if (usesPackedTextures) {
      res += getPackedSamplerAtOutputCoords(inInfo, outShapeInfo);
    } else {
      res += getSamplerAtOutputCoords(inInfo, outShapeInfo);
    }
  }
  return res;
}
function getPackedOutputSamplingSnippet(outShape, outTexShape, enableShapeUniforms) {
  switch (outShape.length) {
    case 0:
      return getOutputScalarCoords();
    case 1:
      return getOutputPacked1DCoords(outShape, outTexShape, enableShapeUniforms);
    case 2:
      return getOutputPacked2DCoords(outShape, outTexShape, enableShapeUniforms);
    case 3:
      return getOutputPacked3DCoords(outShape, outTexShape, enableShapeUniforms);
    default:
      return getOutputPackedNDCoords(outShape, outTexShape, enableShapeUniforms);
  }
}
function getOutputSamplingSnippet(outShape, outTexShape, enableShapeUniforms) {
  switch (outShape.length) {
    case 0:
      return getOutputScalarCoords();
    case 1:
      return getOutput1DCoords(outShape, outTexShape, enableShapeUniforms);
    case 2:
      return getOutput2DCoords(outShape, outTexShape, enableShapeUniforms);
    case 3:
      return getOutput3DCoords(outShape, outTexShape, enableShapeUniforms);
    case 4:
      return getOutput4DCoords(outShape, outTexShape, enableShapeUniforms);
    case 5:
      return getOutput5DCoords(outShape, outTexShape);
    case 6:
      return getOutput6DCoords(outShape, outTexShape);
    default:
      throw new Error(`${outShape.length}-D output sampling is not yet supported`);
  }
}
function getFloatTextureSampleSnippet(glsl) {
  return `
    float sampleTexture(sampler2D textureSampler, vec2 uv) {
      return ${glsl.texture2D}(textureSampler, uv).r;
    }
  `;
}
function getFloatTextureSetRSnippet(glsl) {
  return `
    void setOutput(float val) {
      ${glsl.output} = vec4(val, 0, 0, 0);
    }
  `;
}
function getFloatTextureSetRGBASnippet(glsl) {
  return `
    void setOutput(vec4 val) {
      ${glsl.output} = val;
    }
  `;
}
function getShaderPrefix(glsl) {
  const SHADER_PREFIX = `${glsl.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${glsl.varyingFs} vec2 resultUV;
    ${glsl.defineOutput}
    const vec2 halfCR = vec2(0.5, 0.5);

    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    uniform float NAN;
    ${glsl.defineSpecialNaN}
    ${glsl.defineSpecialInf}
    ${glsl.defineRound}

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    int idiv(int a, int b, float sign) {
      int res = a / b;
      int mod = imod(a, b);
      if (sign < 0. && mod != 0) {
        res -= 1;
      }
      return res;
    }

    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    #define HASHSCALE1 443.8975
    float random(float seed){
      vec2 p = resultUV * seed;
      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);
      p3 += dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${SAMPLE_1D_SNIPPET}
    ${SAMPLE_2D_SNIPPET}
    ${SAMPLE_3D_SNIPPET}
  `;
  return SHADER_PREFIX;
}
function getOutputScalarCoords() {
  return `
    int getOutputCoords() {
      return 0;
    }
  `;
}
function getOutputPacked1DCoords(shape, texShape, enableShapeUniforms) {
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  if (packedTexShape[0] === 1) {
    if (enableShapeUniforms) {
      return `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));
      }
    `;
    }
    return `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ${packedTexShape[1]}.0);
      }
    `;
  }
  if (packedTexShape[1] === 1) {
    if (enableShapeUniforms) {
      return `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));
      }
    `;
    }
    return `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ${packedTexShape[0]}.0);
      }
    `;
  }
  if (enableShapeUniforms) {
    return `
    int getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);
    }
  `;
  }
  return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      return 2 * (resTexRC.x * ${packedTexShape[1]} + resTexRC.y);
    }
  `;
}
function getOutput1DCoords(shape, texShape, enableShapeUniforms) {
  if (texShape[0] === 1) {
    if (enableShapeUniforms) {
      return `
      int getOutputCoords() {
        return int(resultUV.x * float(outTexShape[1]));
      }
    `;
    }
    return `
      int getOutputCoords() {
        return int(resultUV.x * ${texShape[1]}.0);
      }
    `;
  }
  if (texShape[1] === 1) {
    if (enableShapeUniforms) {
      return `
      int getOutputCoords() {
        return int(resultUV.y * float(outTexShape[0]));
      }
    `;
    }
    return `
      int getOutputCoords() {
        return int(resultUV.y * ${texShape[0]}.0);
      }
    `;
  }
  if (enableShapeUniforms) {
    return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      return resTexRC.x * outTexShape[1] + resTexRC.y;
    }
  `;
  }
  return `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      return resTexRC.x * ${texShape[1]} + resTexRC.y;
    }
  `;
}
function getOutputPacked3DCoords(shape, texShape, enableShapeUniforms) {
  if (enableShapeUniforms) {
    return `
    ivec3 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec3(b, r, c);
    }
  `;
  }
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const texelsInLogicalRow = Math.ceil(shape[2] / 2);
  const texelsInBatch = texelsInLogicalRow * Math.ceil(shape[1] / 2);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;

      int b = index / ${texelsInBatch};
      index -= b * ${texelsInBatch};

      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec3(b, r, c);
    }
  `;
}
function getOutput3DCoords(shape, texShape, enableShapeUniforms) {
  if (enableShapeUniforms) {
    const coordsFromIndexSnippet2 = getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], shape);
    return `
  ivec3 getOutputCoords() {
    ivec2 resTexRC = ivec2(resultUV.yx *
                           vec2(outTexShape[0], outTexShape[1]));
    int index = resTexRC.x * outTexShape[1] + resTexRC.y;
    ${coordsFromIndexSnippet2}
    return ivec3(r, c, d);
  }
`;
  }
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      ${coordsFromIndexSnippet}
      return ivec3(r, c, d);
    }
  `;
}
function getOutputPackedNDCoords(shape, texShape, enableShapeUniforms) {
  if (enableShapeUniforms) {
    return `
    ivec4 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatchN = texelsInBatch * outShape[1];

      int b2 = index / texelsInBatchN;
      index -= b2 * texelsInBatchN;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec4(b2, b, r, c);
    }
  `;
  }
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const texelsInLogicalRow = Math.ceil(shape[shape.length - 1] / 2);
  const texelsInBatch = texelsInLogicalRow * Math.ceil(shape[shape.length - 2] / 2);
  let texelsInBatchN = texelsInBatch;
  let batches = ``;
  let coords2 = "b, r, c";
  for (let b = 2; b < shape.length - 1; b++) {
    texelsInBatchN *= shape[shape.length - b - 1];
    batches = `
      int b${b} = index / ${texelsInBatchN};
      index -= b${b} * ${texelsInBatchN};
    ` + batches;
    coords2 = `b${b}, ` + coords2;
  }
  return `
    ivec${shape.length} getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;

      ${batches}

      int b = index / ${texelsInBatch};
      index -= b * ${texelsInBatch};

      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec${shape.length}(${coords2});
    }
  `;
}
function getOutput4DCoords(shape, texShape, enableShapeUniforms) {
  if (enableShapeUniforms) {
    const coordsFromIndexSnippet2 = getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d", "d2"], shape);
    return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      ${coordsFromIndexSnippet2}
      return ivec4(r, c, d, d2);
    }
  `;
  }
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2"], shape);
  return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      ${coordsFromIndexSnippet}
      return ivec4(r, c, d, d2);
    }
  `;
}
function getOutput5DCoords(shape, texShape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3"], shape);
  return `
    ivec5 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${texShape[0]},
                             ${texShape[1]}));

      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;

      ${coordsFromIndexSnippet}

      ivec5 outShape = ivec5(r, c, d, d2, d3);
      return outShape;
    }
  `;
}
function getOutput6DCoords(shape, texShape) {
  const coordsFromIndexSnippet = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3", "d4"], shape);
  return `
    ivec6 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;

      ${coordsFromIndexSnippet}

      ivec6 result = ivec6(r, c, d, d2, d3, d4);
      return result;
    }
  `;
}
function getOutputPacked2DCoords(shape, texShape, enableShapeUniforms) {
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  if (util_exports.arraysEqual(shape, texShape)) {
    if (enableShapeUniforms) {
      return `
      ivec2 getOutputCoords() {
        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));
      }
    `;
    }
    return `
      ivec2 getOutputCoords() {
        return 2 * ivec2(resultUV.yx * vec2(${packedTexShape[0]}, ${packedTexShape[1]}));
      }
    `;
  }
  const texelsInLogicalRow = Math.ceil(shape[1] / 2);
  if (enableShapeUniforms) {
    return `
    ivec2 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));

      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;
      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec2(r, c);
    }
  `;
  }
  return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${packedTexShape[0]}, ${packedTexShape[1]}));

      int index = resTexRC.x * ${packedTexShape[1]} + resTexRC.y;
      int r = 2 * (index / ${texelsInLogicalRow});
      int c = imod(index, ${texelsInLogicalRow}) * 2;

      return ivec2(r, c);
    }
  `;
}
function getOutput2DCoords(shape, texShape, enableShapeUniforms) {
  if (util_exports.arraysEqual(shape, texShape)) {
    if (enableShapeUniforms) {
      return `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));
      }
    `;
    }
    return `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(${texShape[0]}, ${texShape[1]}));
      }
    `;
  }
  if (shape[1] === 1) {
    if (enableShapeUniforms) {
      return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(index, 0);
      }
    `;
    }
    return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${texShape[0]}, ${texShape[1]}));
        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
        return ivec2(index, 0);
      }
    `;
  }
  if (shape[0] === 1) {
    if (enableShapeUniforms) {
      return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(0, index);
      }
    `;
    }
    return `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${texShape[0]}, ${texShape[1]}));
        int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
        return ivec2(0, index);
      }
    `;
  }
  if (enableShapeUniforms) {
    return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      int r = index / outShape[1];
      int c = index - r * outShape[1];
      return ivec2(r, c);
    }
  `;
  }
  return `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${texShape[0]}, ${texShape[1]}));
      int index = resTexRC.x * ${texShape[1]} + resTexRC.y;
      int r = index / ${shape[1]};
      int c = index - r * ${shape[1]};
      return ivec2(r, c);
    }
  `;
}
function getFlatOffsetUniformName(texName) {
  return `offset${texName}`;
}
function getPackedSamplerScalar(inputInfo) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const glsl = getGlslDifferences();
  return `
    vec4 ${funcName}() {
      return ${glsl.texture2D}(${texName}, halfCR);
    }
  `;
}
function getSamplerScalar(inputInfo, enableShapeUniforms) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  if (inputInfo.shapeInfo.isUniform) {
    return `float ${funcName}() {return ${texName};}`;
  }
  const [texNumR, texNumC] = inputInfo.shapeInfo.texShape;
  if (texNumR === 1 && texNumC === 1) {
    return `
      float ${funcName}() {
        return sampleTexture(${texName}, halfCR);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  if (enableShapeUniforms) {
    return `
    float ${funcName}() {
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  const [tNumR, tNumC] = inputInfo.shapeInfo.texShape;
  return `
    float ${funcName}() {
      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getPackedSampler1D(inputInfo, enableShapeUniforms) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const glsl = getGlslDifferences();
  if (enableShapeUniforms) {
    return `
    vec4 ${funcName}(int index) {
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      vec2 uv = packedUVfrom1D(
        packedTexShape[0], packedTexShape[1], index);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  return `
    vec4 ${funcName}(int index) {
      vec2 uv = packedUVfrom1D(
        ${packedTexShape[0]}, ${packedTexShape[1]}, index);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler1D(inputInfo, enableShapeUniforms) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int index) {
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const texShape = inputInfo.shapeInfo.texShape;
  const tNumR = texShape[0];
  const tNumC = texShape[1];
  if (tNumC === 1 && tNumR === 1) {
    return `
      float ${funcName}(int index) {
        return sampleTexture(${texName}, halfCR);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  if (tNumC === 1) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / float(${texName}TexShape[0]));
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
      float ${funcName}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${offset}) + 0.5) / ${tNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (tNumR === 1) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int index) {
        vec2 uv = vec2((float(index + ${offset}) + 0.5) / float(${texName}TexShape[1]), 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
      float ${funcName}(int index) {
        vec2 uv = vec2((float(index + ${offset}) + 0.5) / ${tNumC}.0, 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (enableShapeUniforms) {
    return `
    float ${funcName}(int index) {
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  return `
    float ${funcName}(int index) {
      vec2 uv = uvFromFlat(${tNumR}, ${tNumC}, index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getPackedSampler2D(inputInfo, enableShapeUniforms) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const glsl = getGlslDifferences();
  if (texShape != null && util_exports.arraysEqual(shape, texShape)) {
    if (enableShapeUniforms) {
      return `
      vec4 ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);

        return ${glsl.texture2D}(${texName}, uv);
      }
    `;
    }
    return `
      vec4 ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);

        return ${glsl.texture2D}(${texName}, uv);
      }
    `;
  }
  if (enableShapeUniforms) {
    return `
    vec4 ${funcName}(int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${texName}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const valuesPerRow = Math.ceil(shape[1] / 2);
  return `
    vec4 ${funcName}(int row, int col) {
      vec2 uv = packedUVfrom2D(${valuesPerRow}, ${packedTexShape[0]}, ${packedTexShape[1]}, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler2D(inputInfo, enableShapeUniforms) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  if (texShape != null && util_exports.arraysEqual(shape, texShape)) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    const texNumR2 = texShape[0];
    const texNumC2 = texShape[1];
    return `
    float ${funcName}(int row, int col) {
      vec2 uv = (vec2(col, row) + halfCR) / vec2(${texNumC2}.0, ${texNumR2}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  const { newShape, keptDims } = util_exports.squeezeShape(shape);
  const squeezedShape = newShape;
  if (squeezedShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
    const params = ["row", "col"];
    return `
      ${getSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
      float ${funcName}(int row, int col) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col) {
        int index = round(dot(vec2(row, col), vec2(${shape[1]}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const offset = getFlatOffsetUniformName(texName);
  if (texNumC === 1) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col) {
        float index = dot(vec3(row, col, ${offset}), vec3(${texName}Shape[1], 1, 1));
        vec2 uv = vec2(0.5, (index + 0.5) / float(${texName}TexShape[0]));
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
    float ${funcName}(int row, int col) {
      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));
      vec2 uv = vec2(0.5, (index + 0.5) / ${texNumR}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  if (texNumR === 1) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col) {
        float index = dot(vec3(row, col, ${offset}), vec3(${texName}Shape[1], 1, 1));
        vec2 uv = vec2((index + 0.5) / float(${texName}TexShape[1]), 0.5);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
    float ${funcName}(int row, int col) {
      float index = dot(vec3(row, col, ${offset}), vec3(${shape[1]}, 1, 1));
      vec2 uv = vec2((index + 0.5) / ${texNumC}.0, 0.5);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  if (enableShapeUniforms) {
    return `
      float ${funcName}(int row, int col) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${texName}Shape[1] + col + ${offset};
        vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  return `
  float ${funcName}(int row, int col) {
    // Explicitly use integer operations as dot() only works on floats.
    int index = row * ${shape[1]} + col + ${offset};
    vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
    return sampleTexture(${texName}, uv);
  }
`;
}
function getPackedSampler3D(inputInfo, enableShapeUniforms) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const texShape = inputInfo.shapeInfo.texShape;
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  if (shape[0] === 1) {
    const squeezedShape = shape.slice(1);
    const keptDims = [1, 2];
    const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
    const params = ["b", "row", "col"];
    return `
        ${getPackedSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
        vec4 ${funcName}(int b, int row, int col) {
          return ${funcName}(${getSqueezedParams(params, keptDims)});
        }
      `;
  }
  const glsl = getGlslDifferences();
  if (enableShapeUniforms) {
    return `
    vec4 ${funcName}(int b, int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${texName}Shape[2]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${texName}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom3D(
        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  const texNumR = packedTexShape[0];
  const texNumC = packedTexShape[1];
  const valuesPerRow = Math.ceil(shape[2] / 2);
  const texelsInBatch = valuesPerRow * Math.ceil(shape[1] / 2);
  return `
    vec4 ${funcName}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${texNumR}, ${texNumC}, ${texelsInBatch}, ${valuesPerRow}, b, row, col);
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler3D(inputInfo, enableShapeUniforms) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const stride0 = shape[1] * shape[2];
  const stride1 = shape[2];
  const { newShape, keptDims } = util_exports.squeezeShape(shape);
  const squeezedShape = newShape;
  if (squeezedShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, squeezedShape);
    const params = ["row", "col", "depth"];
    return `
        ${getSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
        float ${funcName}(int row, int col, int depth) {
          return ${funcName}(${getSqueezedParams(params, keptDims)});
        }
      `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth) {
        int index = round(dot(vec3(row, col, depth),
                          vec3(${stride0}, ${stride1}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  if (texNumC === stride0 && flatOffset == null) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col, int depth) {
        int stride1 = ${texName}Shape[2];
        float texR = float(row);
        float texC = dot(vec2(col, depth), vec2(stride1, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
        float ${funcName}(int row, int col, int depth) {
          float texR = float(row);
          float texC = dot(vec2(col, depth), vec2(${stride1}, 1));
          vec2 uv = (vec2(texC, texR) + halfCR) /
                     vec2(${texNumC}.0, ${texNumR}.0);
          return sampleTexture(${texName}, uv);
        }
      `;
  }
  if (texNumC === stride1 && flatOffset == null) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col, int depth) {
        float texR = dot(vec2(row, col), vec2(${texName}Shape[1], 1));
        float texC = float(depth);
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
    float ${funcName}(int row, int col, int depth) {
      float texR = dot(vec2(row, col), vec2(${shape[1]}, 1));
      float texC = float(depth);
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}.0, ${texNumR}.0);
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  const offset = getFlatOffsetUniformName(texName);
  if (enableShapeUniforms) {
    return `
    float ${funcName}(int row, int col, int depth) {
      // Explicitly use integer operations as dot() only works on floats.
      int stride0 = ${texName}Shape[1] * ${texName}Shape[2];
      int stride1 = ${texName}Shape[2];
      int index = row * stride0 + col * stride1 + depth + ${offset};
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index);
      return sampleTexture(${texName}, uv);
    }
    `;
  }
  return `
      float ${funcName}(int row, int col, int depth) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${stride0} + col * ${stride1} + depth + ${offset};
        vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
        return sampleTexture(${texName}, uv);
      }
  `;
}
function getPackedSamplerND(inputInfo, enableShapeUniforms) {
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const glsl = getGlslDifferences();
  if (enableShapeUniforms) {
    return `
    vec4 ${funcName}(int b2, int b, int row, int col) {
      int valuesPerRow = int(ceil(float(${texName}Shape[3]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${texName}Shape[2]) / 2.0));
      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);
      texelsInBatch *= ${texName}Shape[1];
      index = b2 * texelsInBatch + index;
      ivec2 packedTexShape = ivec2(ceil(float(${texName}TexShape[0]) / 2.0), ceil(float(${texName}TexShape[1]) / 2.0));
      int texR = index / packedTexShape[1];
      int texC = index - texR * packedTexShape[1];
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${glsl.texture2D}(${texName}, uv);
    }
  `;
  }
  const shape = inputInfo.shapeInfo.logicalShape;
  const rank = shape.length;
  const texShape = inputInfo.shapeInfo.texShape;
  const packedTexShape = [Math.ceil(texShape[0] / 2), Math.ceil(texShape[1] / 2)];
  const texNumR = packedTexShape[0];
  const texNumC = packedTexShape[1];
  const valuesPerRow = Math.ceil(shape[rank - 1] / 2);
  let texelsInBatch = valuesPerRow * Math.ceil(shape[rank - 2] / 2);
  let params = `int b, int row, int col`;
  let index = `b * ${texelsInBatch} + (row / 2) * ${valuesPerRow} + (col / 2)`;
  for (let b = 2; b < rank - 1; b++) {
    params = `int b${b}, ` + params;
    texelsInBatch *= shape[rank - b - 1];
    index = `b${b} * ${texelsInBatch} + ` + index;
  }
  return `
    vec4 ${funcName}(${params}) {
      int index = ${index};
      int texR = index / ${texNumC};
      int texC = index - texR * ${texNumC};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${texNumC}, ${texNumR});
      return ${glsl.texture2D}(${texName}, uv);
    }
  `;
}
function getSampler4D(inputInfo, enableShapeUniforms) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const stride2 = shape[3];
  const stride1 = shape[2] * stride2;
  const stride0 = shape[1] * stride1;
  const { newShape, keptDims } = util_exports.squeezeShape(shape);
  if (newShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, newShape);
    const params = ["row", "col", "depth", "depth2"];
    return `
      ${getSamplerFromInInfo(newInputInfo, enableShapeUniforms)}
      float ${funcName}(int row, int col, int depth, int depth2) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        int index = round(dot(vec4(row, col, depth, depth2),
                          vec4(${stride0}, ${stride1}, ${stride2}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  const stride2Str = `int stride2 = ${texName}Shape[3];`;
  const stride1Str = `int stride1 = ${texName}Shape[2] * stride2;`;
  const stride0Str = `int stride0 = ${texName}Shape[1] * stride1;`;
  if (texNumC === stride0 && flatOffset == null) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        ${stride2Str}
        ${stride1Str}
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(stride1, stride2, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(${stride1}, ${stride2}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (texNumC === stride2 && flatOffset == null) {
    if (enableShapeUniforms) {
      return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${texName}Shape[1] * ${texName}Shape[2], ${texName}Shape[2], 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texName}TexShape[1], ${texName}TexShape[0]);
        return sampleTexture(${texName}, uv);
      }
    `;
    }
    return `
      float ${funcName}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${shape[1] * shape[2]}, ${shape[2]}, 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  if (enableShapeUniforms) {
    return `
    float ${funcName}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      ${stride2Str}
      ${stride1Str}
      ${stride0Str}
      int index = row * stride0 + col * stride1 +
          depth * stride2 + depth2;
      vec2 uv = uvFromFlat(${texName}TexShape[0], ${texName}TexShape[1], index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
  }
  return `
    float ${funcName}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} +
          depth * ${stride2} + depth2;
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index + ${offset});
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getSampler5D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const stride3 = shape[4];
  const stride2 = shape[3] * stride3;
  const stride1 = shape[2] * stride2;
  const stride0 = shape[1] * stride1;
  const { newShape, keptDims } = util_exports.squeezeShape(shape);
  if (newShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, newShape);
    const params = ["row", "col", "depth", "depth2", "depth3"];
    return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        float index = dot(
          vec4(row, col, depth, depth2),
          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +
          depth3;
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  if (texNumC === stride0 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
                         vec4(${stride1}, ${stride2}, ${stride3}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (texNumC === stride3 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
        float texR = dot(
          vec4(row, col, depth, depth2),
          vec4(${shape[1] * shape[2] * shape[3]},
               ${shape[2] * shape[3]}, ${shape[3]}, 1));
        int texC = depth3;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  return `
    float ${funcName}(int row, int col, int depth, int depth2, int depth3) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +
          depth2 * ${stride3} + depth3 + ${offset};
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getSampler6D(inputInfo) {
  const shape = inputInfo.shapeInfo.logicalShape;
  const texName = inputInfo.name;
  const funcName = "get" + texName.charAt(0).toUpperCase() + texName.slice(1);
  const { newShape, keptDims } = util_exports.squeezeShape(shape);
  if (newShape.length < shape.length) {
    const newInputInfo = squeezeInputInfo(inputInfo, newShape);
    const params = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return `
      ${getSamplerFromInInfo(newInputInfo)}
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        return ${funcName}(${getSqueezedParams(params, keptDims)});
      }
    `;
  }
  const stride4 = shape[5];
  const stride3 = shape[4] * stride4;
  const stride2 = shape[3] * stride3;
  const stride1 = shape[2] * stride2;
  const stride0 = shape[1] * stride1;
  if (inputInfo.shapeInfo.isUniform) {
    return `
      float ${funcName}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
        int index = round(dot(
          vec4(row, col, depth, depth2),
          vec4(${stride0}, ${stride1}, ${stride2}, ${stride3})) +
          dot(
            vec2(depth3, depth4),
            vec2(${stride4}, 1)));
        ${getUniformSampler(inputInfo)}
      }
    `;
  }
  const flatOffset = inputInfo.shapeInfo.flatOffset;
  const texShape = inputInfo.shapeInfo.texShape;
  const texNumR = texShape[0];
  const texNumC = texShape[1];
  if (texNumC === stride0 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
          vec4(${stride1}, ${stride2}, ${stride3}, ${stride4})) +
               float(depth4);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  if (texNumC === stride4 && flatOffset == null) {
    return `
      float ${funcName}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        float texR = dot(vec4(row, col, depth, depth2),
          vec4(${shape[1] * shape[2] * shape[3] * shape[4]},
               ${shape[2] * shape[3] * shape[4]},
               ${shape[3] * shape[4]},
               ${shape[4]})) + float(depth3);
        int texC = depth4;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${texNumC}.0, ${texNumR}.0);
        return sampleTexture(${texName}, uv);
      }
    `;
  }
  const offset = getFlatOffsetUniformName(texName);
  return `
    float ${funcName}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${stride0} + col * ${stride1} + depth * ${stride2} +
          depth2 * ${stride3} + depth3 * ${stride4} + depth4 + ${offset};
      vec2 uv = uvFromFlat(${texNumR}, ${texNumC}, index);
      return sampleTexture(${texName}, uv);
    }
  `;
}
function getUniformSampler(inputInfo) {
  const texName = inputInfo.name;
  const inSize = util_exports.sizeFromShape(inputInfo.shapeInfo.logicalShape);
  if (inSize < 2) {
    return `return ${texName};`;
  }
  return `
    for (int i = 0; i < ${inSize}; i++) {
      if (i == index) {
        return ${texName}[i];
      }
    }
  `;
}
function getPackedSamplerAtOutputCoords(inputInfo, outShapeInfo) {
  const texName = inputInfo.name;
  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
  const funcName = "get" + texFuncSnippet + "AtOutCoords";
  const inRank = inputInfo.shapeInfo.logicalShape.length;
  const outRank = outShapeInfo.logicalShape.length;
  const broadcastDims = getBroadcastDims2(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
  const type = getCoordsDataType(outRank);
  const rankDiff = outRank - inRank;
  let coordsSnippet;
  const fields = ["x", "y", "z", "w", "u", "v"];
  if (inRank === 0) {
    coordsSnippet = "";
  } else if (outRank < 2 && broadcastDims.length >= 1) {
    coordsSnippet = "coords = 0;";
  } else {
    coordsSnippet = broadcastDims.map((d) => `coords.${fields[d + rankDiff]} = 0;`).join("\n");
  }
  let unpackedCoordsSnippet = "";
  if (outRank < 2 && inRank > 0) {
    unpackedCoordsSnippet = "coords";
  } else {
    unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map((s, i) => `coords.${fields[i + rankDiff]}`).join(", ");
  }
  let output = `return outputValue;`;
  const inSize = util_exports.sizeFromShape(inputInfo.shapeInfo.logicalShape);
  const isInputScalar = inSize === 1;
  const outSize = util_exports.sizeFromShape(outShapeInfo.logicalShape);
  const isOutputScalar = outSize === 1;
  if (inRank === 1 && !isInputScalar && !isOutputScalar) {
    output = `
      return vec4(outputValue.xy, outputValue.xy);
    `;
  } else if (isInputScalar && !isOutputScalar) {
    if (outRank === 1) {
      output = `
        return vec4(outputValue.x, outputValue.x, 0., 0.);
      `;
    } else {
      output = `
        return vec4(outputValue.x);
      `;
    }
  } else if (broadcastDims.length) {
    const rows = inRank - 2;
    const cols = inRank - 1;
    if (broadcastDims.indexOf(rows) > -1 && broadcastDims.indexOf(cols) > -1) {
      output = `return vec4(outputValue.x);`;
    } else if (broadcastDims.indexOf(rows) > -1) {
      output = `return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);`;
    } else if (broadcastDims.indexOf(cols) > -1) {
      output = `return vec4(outputValue.xx, outputValue.zz);`;
    }
  }
  return `
    vec4 ${funcName}() {
      ${type} coords = getOutputCoords();
      ${coordsSnippet}
      vec4 outputValue = get${texFuncSnippet}(${unpackedCoordsSnippet});
      ${output}
    }
  `;
}
function getSamplerAtOutputCoords(inputInfo, outShapeInfo) {
  const texName = inputInfo.name;
  const texFuncSnippet = texName.charAt(0).toUpperCase() + texName.slice(1);
  const funcName = "get" + texFuncSnippet + "AtOutCoords";
  const outTexShape = outShapeInfo.texShape;
  const inTexShape = inputInfo.shapeInfo.texShape;
  const inRank = inputInfo.shapeInfo.logicalShape.length;
  const outRank = outShapeInfo.logicalShape.length;
  if (!inputInfo.shapeInfo.isUniform && inRank === outRank && inputInfo.shapeInfo.flatOffset == null && util_exports.arraysEqual(inTexShape, outTexShape)) {
    return `
      float ${funcName}() {
        return sampleTexture(${texName}, resultUV);
      }
    `;
  }
  const type = getCoordsDataType(outRank);
  const broadcastDims = getBroadcastDims2(inputInfo.shapeInfo.logicalShape, outShapeInfo.logicalShape);
  const rankDiff = outRank - inRank;
  let coordsSnippet;
  const fields = ["x", "y", "z", "w", "u", "v"];
  if (inRank === 0) {
    coordsSnippet = "";
  } else if (outRank < 2 && broadcastDims.length >= 1) {
    coordsSnippet = "coords = 0;";
  } else {
    coordsSnippet = broadcastDims.map((d) => `coords.${fields[d + rankDiff]} = 0;`).join("\n");
  }
  let unpackedCoordsSnippet = "";
  if (outRank < 2 && inRank > 0) {
    unpackedCoordsSnippet = "coords";
  } else {
    unpackedCoordsSnippet = inputInfo.shapeInfo.logicalShape.map((s, i) => `coords.${fields[i + rankDiff]}`).join(", ");
  }
  return `
    float ${funcName}() {
      ${type} coords = getOutputCoords();
      ${coordsSnippet}
      return get${texFuncSnippet}(${unpackedCoordsSnippet});
    }
  `;
}
function getCoordsDataType(rank) {
  if (rank <= 1) {
    return "int";
  } else if (rank === 2) {
    return "ivec2";
  } else if (rank === 3) {
    return "ivec3";
  } else if (rank === 4) {
    return "ivec4";
  } else if (rank === 5) {
    return "ivec5";
  } else if (rank === 6) {
    return "ivec6";
  } else {
    throw Error(`GPU for rank ${rank} is not yet supported`);
  }
}
function getUniformInfoFromShape(isPacked, shape, texShape) {
  const { newShape, keptDims } = util_exports.squeezeShape(shape);
  const rank = shape.length;
  const useSqueezePackedShape = isPacked && rank === 3 && shape[0] === 1;
  const squeezeShape2 = useSqueezePackedShape ? shape.slice(1) : newShape;
  const useSqueezeShape = !isPacked && rank > 1 && !util_exports.arraysEqual(shape, texShape) && newShape.length < rank || useSqueezePackedShape;
  const uniformShape = useSqueezeShape ? squeezeShape2 : shape;
  return { useSqueezeShape, uniformShape, keptDims };
}
function squeezeInputInfo(inInfo, squeezedShape) {
  const newInputInfo = JSON.parse(JSON.stringify(inInfo));
  newInputInfo.shapeInfo.logicalShape = squeezedShape;
  return newInputInfo;
}
function getSqueezedParams(params, keptDims) {
  return keptDims.map((d) => params[d]).join(", ");
}
var getBroadcastDims2;
var SAMPLE_1D_SNIPPET;
var SAMPLE_2D_SNIPPET;
var SAMPLE_3D_SNIPPET;
var SHADER_PACKED_PREFIX;
var init_shader_compiler = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/shader_compiler.js"() {
    init_dist();
    init_glsl_version();
    init_shader_compiler_util();
    ({ getBroadcastDims: getBroadcastDims2 } = backend_util_exports);
    SAMPLE_1D_SNIPPET = `
vec2 uvFromFlat(int texNumR, int texNumC, int index) {
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {
  int texelIndex = index / 2;
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
    SAMPLE_2D_SNIPPET = `
vec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,
  int texNumC, int row, int col) {
  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
    SAMPLE_3D_SNIPPET = `
vec2 packedUVfrom3D(int texNumR, int texNumC,
    int texelsInBatch, int texelsInLogicalRow, int b,
    int row, int col) {
  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
    SHADER_PACKED_PREFIX = `
  float getChannel(vec4 frag, vec2 innerDims) {
    vec2 modCoord = mod(innerDims, 2.);
    return modCoord.x == 0. ?
      (modCoord.y == 0. ? frag.r : frag.g) :
      (modCoord.y == 0. ? frag.b : frag.a);
  }
  float getChannel(vec4 frag, int dim) {
    float modCoord = mod(float(dim), 2.);
    return modCoord == 0. ? frag.r : frag.g;
  }
`;
  }
});
function compileProgram(gpgpu, program, inputs, output) {
  const inputInfos = inputs.map((input2, i) => {
    const shapeInfo = {
      logicalShape: input2.shape,
      texShape: input2.isUniform ? null : input2.texData.texShape,
      isUniform: input2.isUniform,
      isPacked: input2.isUniform ? false : input2.texData.isPacked,
      flatOffset: null
    };
    if (input2.texData != null && input2.texData.slice != null && input2.texData.slice.flatOffset > 0) {
      shapeInfo.flatOffset = input2.texData.slice.flatOffset;
    }
    return { name: program.variableNames[i], shapeInfo };
  });
  const inShapeInfos = inputInfos.map((x) => x.shapeInfo);
  const outShapeInfo = {
    logicalShape: output.shape,
    texShape: output.texData.texShape,
    isUniform: false,
    isPacked: output.texData.isPacked,
    flatOffset: null
  };
  const source = makeShader(inputInfos, outShapeInfo, program);
  const fragmentShader = createFragmentShader(gpgpu.gl, source);
  const webGLProgram = gpgpu.createProgram(fragmentShader);
  if (!env().get("ENGINE_COMPILE_ONLY")) {
    return Object.assign({
      program,
      fragmentShader,
      source,
      webGLProgram,
      inShapeInfos,
      outShapeInfo
    }, getUniformLocations(gpgpu, program, webGLProgram));
  } else {
    return {
      program,
      fragmentShader,
      source,
      webGLProgram,
      inShapeInfos,
      outShapeInfo,
      uniformLocations: null,
      customUniformLocations: null,
      infLoc: null,
      nanLoc: null,
      inShapesLocations: null,
      inTexShapesLocations: null,
      outShapeLocation: null,
      outShapeStridesLocation: null,
      outTexShapeLocation: null
    };
  }
}
function getUniformLocations(gpgpu, program, webGLProgram) {
  const uniformLocations = {};
  const inShapesLocations = {};
  const inTexShapesLocations = {};
  const customUniformLocations = [];
  let outShapeLocation;
  let outTexShapeLocation;
  let outShapeStridesLocation;
  let infLoc = null;
  let nanLoc = null;
  nanLoc = gpgpu.getUniformLocation(webGLProgram, "NAN", false);
  if (env().getNumber("WEBGL_VERSION") === 1) {
    infLoc = gpgpu.getUniformLocation(webGLProgram, "INFINITY", false);
  }
  const shouldThrow = false;
  for (let i = 0; i < program.variableNames.length; i++) {
    const varName = program.variableNames[i];
    uniformLocations[varName] = gpgpu.getUniformLocation(webGLProgram, varName, shouldThrow);
    uniformLocations[`offset${varName}`] = gpgpu.getUniformLocation(webGLProgram, `offset${varName}`, shouldThrow);
    if (program.enableShapeUniforms) {
      inShapesLocations[`${varName}Shape`] = gpgpu.getUniformLocation(webGLProgram, `${varName}Shape`, shouldThrow);
      inTexShapesLocations[`${varName}TexShape`] = gpgpu.getUniformLocation(webGLProgram, `${varName}TexShape`, shouldThrow);
    }
  }
  if (program.enableShapeUniforms) {
    outShapeLocation = gpgpu.getUniformLocation(webGLProgram, "outShape", shouldThrow);
    outShapeStridesLocation = gpgpu.getUniformLocation(webGLProgram, "outShapeStrides", shouldThrow);
    outTexShapeLocation = gpgpu.getUniformLocation(webGLProgram, "outTexShape", shouldThrow);
  }
  if (program.customUniforms) {
    program.customUniforms.forEach((d, i) => {
      customUniformLocations[i] = gpgpu.getUniformLocation(webGLProgram, d.name, shouldThrow);
    });
  }
  return {
    uniformLocations,
    customUniformLocations,
    infLoc,
    nanLoc,
    inShapesLocations,
    inTexShapesLocations,
    outShapeLocation,
    outShapeStridesLocation,
    outTexShapeLocation
  };
}
function validateBinaryAndProgram(shapeInfos, inputs) {
  if (shapeInfos.length !== inputs.length) {
    throw Error(`Binary was compiled with ${shapeInfos.length} inputs, but was executed with ${inputs.length} inputs`);
  }
  shapeInfos.forEach((s, i) => {
    const shapeA = s.logicalShape;
    const input2 = inputs[i];
    const shapeB = input2.shape;
    if (!util_exports.arraysEqual(shapeA, shapeB)) {
      throw Error(`Binary was compiled with different shapes than the current args. Shapes ${shapeA} and ${shapeB} must match`);
    }
    if (s.isUniform && input2.isUniform) {
      return;
    }
    const texShapeA = s.texShape;
    const texShapeB = input2.isUniform ? null : input2.texData.texShape;
    if (!util_exports.arraysEqual(texShapeA, texShapeB)) {
      throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${texShapeA} and ${texShapeB} must match`);
    }
  });
}
function runProgram(gpgpu, binary, inputs, output, customUniformValues) {
  if (!binary.program.enableShapeUniforms) {
    validateBinaryAndProgram(binary.inShapeInfos, inputs);
    validateBinaryAndProgram([binary.outShapeInfo], [output]);
  }
  const outTex = output.texData.texture;
  const outTexShape = output.texData.texShape;
  if (output.texData.isPacked) {
    gpgpu.setOutputPackedMatrixTexture(outTex.texture, outTexShape[0], outTexShape[1]);
  } else {
    gpgpu.setOutputMatrixTexture(outTex.texture, outTexShape[0], outTexShape[1]);
  }
  gpgpu.setProgram(binary.webGLProgram);
  if (env().getNumber("WEBGL_VERSION") === 1) {
    if (binary.infLoc !== null) {
      gpgpu.gl.uniform1f(binary.infLoc, Infinity);
    }
  }
  if (binary.nanLoc !== null) {
    gpgpu.gl.uniform1f(binary.nanLoc, NaN);
  }
  inputs.forEach((input2, i) => {
    const varName = binary.program.variableNames[i];
    const varLoc = binary.uniformLocations[varName];
    const varOffsetLoc = binary.uniformLocations[`offset${varName}`];
    const varShapeLoc = binary.inShapesLocations[`${varName}Shape`];
    const varTexShapeLoc = binary.inTexShapesLocations[`${varName}TexShape`];
    if (varShapeLoc) {
      const { uniformShape } = getUniformInfoFromShape(binary.program.packedInputs, input2.shape, input2.texData.texShape);
      switch (uniformShape.length) {
        case 1:
          gpgpu.gl.uniform1iv(varShapeLoc, new Int32Array(uniformShape));
          break;
        case 2:
          gpgpu.gl.uniform2iv(varShapeLoc, new Int32Array(uniformShape));
          break;
        case 3:
          gpgpu.gl.uniform3iv(varShapeLoc, new Int32Array(uniformShape));
          break;
        case 4:
          gpgpu.gl.uniform4iv(varShapeLoc, new Int32Array(uniformShape));
          break;
        default:
          break;
      }
    }
    if (varTexShapeLoc) {
      gpgpu.gl.uniform2i(varTexShapeLoc, input2.texData.texShape[0], input2.texData.texShape[1]);
    }
    if (varLoc == null) {
      return;
    }
    if (input2.isUniform) {
      if (util_exports.sizeFromShape(input2.shape) < 2) {
        gpgpu.gl.uniform1f(varLoc, input2.uniformValues[0]);
      } else {
        let vals = input2.uniformValues;
        if (!(vals instanceof Float32Array)) {
          vals = new Float32Array(vals);
        }
        gpgpu.gl.uniform1fv(varLoc, vals);
      }
      return;
    }
    if (input2.texData.slice != null && varOffsetLoc != null) {
      gpgpu.gl.uniform1i(varOffsetLoc, input2.texData.slice.flatOffset);
    }
    gpgpu.setInputMatrixTexture(input2.texData.texture.texture, varLoc, i);
  });
  const outShapeLoc = binary.outShapeLocation;
  if (outShapeLoc) {
    switch (output.shape.length) {
      case 1:
        gpgpu.gl.uniform1iv(outShapeLoc, new Int32Array(output.shape));
        break;
      case 2:
        gpgpu.gl.uniform2iv(outShapeLoc, new Int32Array(output.shape));
        break;
      case 3:
        gpgpu.gl.uniform3iv(outShapeLoc, new Int32Array(output.shape));
        break;
      case 4:
        gpgpu.gl.uniform4iv(outShapeLoc, new Int32Array(output.shape));
        break;
      default:
        break;
    }
  }
  if (binary.outShapeStridesLocation) {
    const strides = util_exports.computeStrides(output.shape);
    switch (output.shape.length) {
      case 2:
        gpgpu.gl.uniform1iv(binary.outShapeStridesLocation, new Int32Array(strides));
        break;
      case 3:
        gpgpu.gl.uniform2iv(binary.outShapeStridesLocation, new Int32Array(strides));
        break;
      case 4:
        gpgpu.gl.uniform3iv(binary.outShapeStridesLocation, new Int32Array(strides));
        break;
      default:
        break;
    }
  }
  if (binary.outTexShapeLocation) {
    gpgpu.gl.uniform2i(binary.outTexShapeLocation, output.texData.texShape[0], output.texData.texShape[1]);
  }
  if (binary.program.customUniforms && customUniformValues) {
    binary.program.customUniforms.forEach((d, i) => {
      const customLoc = binary.customUniformLocations[i];
      const customValue = customUniformValues[i];
      if (d.type === "float") {
        gpgpu.gl.uniform1fv(customLoc, customValue);
      } else if (d.type === "vec2") {
        gpgpu.gl.uniform2fv(customLoc, customValue);
      } else if (d.type === "vec3") {
        gpgpu.gl.uniform3fv(customLoc, customValue);
      } else if (d.type === "vec4") {
        gpgpu.gl.uniform4fv(customLoc, customValue);
      } else if (d.type === "int") {
        gpgpu.gl.uniform1iv(customLoc, customValue);
      } else if (d.type === "ivec2") {
        gpgpu.gl.uniform2iv(customLoc, customValue);
      } else if (d.type === "ivec3") {
        gpgpu.gl.uniform3iv(customLoc, customValue);
      } else if (d.type === "ivec4") {
        gpgpu.gl.uniform4iv(customLoc, customValue);
      } else {
        throw Error(`uniform type ${d.type} is not supported yet.`);
      }
    });
  }
  gpgpu.executeProgram();
}
function makeShaderKey(program, inputs, output) {
  let keyInputs = "";
  inputs.concat(output).forEach((x) => {
    const hasOffset = x.texData != null && x.texData.slice != null && x.texData.slice.flatOffset > 0;
    if (program.enableShapeUniforms && !x.isUniform) {
      const xTexShape = x.texData.texShape;
      const { useSqueezeShape, uniformShape, keptDims } = getUniformInfoFromShape(program.packedInputs, x.shape, xTexShape);
      let rank1 = "", rank2 = "", rank34 = "";
      if (uniformShape.length === 1 && program.packedInputs) {
        const packedTexShape = [Math.ceil(xTexShape[0] / 2), Math.ceil(xTexShape[1] / 2)];
        rank1 = `${packedTexShape[0] > 1}_${packedTexShape[1] > 1}`;
      } else if (uniformShape.length === 2 && !program.packedInputs) {
        rank2 = `${uniformShape[0] > 1}_${uniformShape[1] > 1}`;
      } else if (uniformShape.length > 2 && !program.packedInputs) {
        const strides = util_exports.computeStrides(uniformShape);
        rank34 = `${strides[0] === xTexShape[1]}_${strides[strides.length - 1] === xTexShape[1]}`;
      }
      const xRank = x.shape.length;
      const isLogicalShapTexShapeEqual = uniformShape.length === 2 && util_exports.arraysEqual(x.shape, xTexShape);
      const isScalar = util_exports.sizeFromShape(x.shape) === 1;
      const broadcastDims = backend_util_exports.getBroadcastDims(x.shape, output.shape);
      const isInOutTexShapeEqual = !program.packedInputs && xRank === output.shape.length && util_exports.arraysEqual(xTexShape, output.texData.texShape);
      const isTexShapeGreaterThanOne = program.packedInputs || uniformShape.length > 2 ? "" : `${xTexShape[0] > 1}_${xTexShape[1] > 1}`;
      keyInputs += `${xRank}_${isInOutTexShapeEqual}_${useSqueezeShape ? keptDims : ""}_${uniformShape.length}_${isScalar}_${broadcastDims}_${isLogicalShapTexShapeEqual}_${rank1}_${rank2}_${rank34}_${isTexShapeGreaterThanOne}_${hasOffset}`;
    } else {
      const texShape = x.isUniform ? "uniform" : x.texData.texShape;
      keyInputs += `${x.shape}_${texShape}_${hasOffset}`;
    }
  });
  const keyUserCode = program.userCode;
  let key = program.constructor.name;
  key += "_" + keyInputs + "_" + keyUserCode + `${env().getNumber("WEBGL_VERSION")}`;
  return key;
}
function useShapeUniforms(rank) {
  return env().getBool("WEBGL_USE_SHAPES_UNIFORMS") && rank <= 4;
}
var init_gpgpu_math = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/gpgpu_math.js"() {
    init_dist();
    init_shader_compiler();
    init_webgl_util();
  }
});
var DecodeMatrixProgram;
var init_decode_matrix_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/decode_matrix_gpu.js"() {
    init_glsl_version();
    init_gpgpu_math();
    init_shader_compiler_util();
    init_tex_util();
    DecodeMatrixProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.packedInputs = false;
        this.packedOutput = true;
        this.outPackingScheme = PackingScheme.DENSE;
        this.customUniforms = [{ name: "texShape", type: "ivec2" }];
        const glsl = getGlslDifferences();
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], outputShape) : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getA(rc.x, rc.y, rc.z);
        }

        ${glsl.output} = result;
      }
    `;
      }
    };
  }
});
var DecodeMatrixPackedProgram;
var init_decode_matrix_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/decode_matrix_packed_gpu.js"() {
    init_glsl_version();
    init_gpgpu_math();
    init_shader_compiler_util();
    init_tex_util();
    DecodeMatrixPackedProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outPackingScheme = PackingScheme.DENSE;
        this.customUniforms = [{ name: "texShape", type: "ivec2" }];
        const glsl = getGlslDifferences();
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? getOutputLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], outputShape) : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], outputShape)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));
        }

        ${glsl.output} = result;
      }
    `;
      }
    };
  }
});
var EncodeFloatProgram;
var init_encode_float_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_float_gpu.js"() {
    init_glsl_version();
    init_shader_compiler_util();
    init_tex_util();
    EncodeFloatProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.outTexUsage = TextureUsage.DOWNLOAD;
        const glsl = getGlslDifferences();
        this.outputShape = outputShape;
        this.userCode = `
      ${ENCODE_FLOAT_SNIPPET}

      void main() {
        float x = getAAtOutCoords();
        ${glsl.output} = encode_float(x);
      }
    `;
      }
    };
  }
});
var EncodeFloatPackedProgram;
var init_encode_float_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_float_packed_gpu.js"() {
    init_glsl_version();
    init_shader_compiler_util();
    init_tex_util();
    EncodeFloatPackedProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = false;
        this.outTexUsage = TextureUsage.DOWNLOAD;
        const glsl = getGlslDifferences();
        this.outputShape = outputShape;
        this.userCode = `
      ${ENCODE_FLOAT_SNIPPET}

      void main() {
        ivec3 coords = getOutputCoords();
        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));
        ${glsl.output} = encode_float(x);
      }
    `;
      }
    };
  }
});
var CHANNEL_CHAR_TO_INDEX_MAP;
var EncodeMatrixProgram;
var init_encode_matrix_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_matrix_gpu.js"() {
    init_glsl_version();
    init_gpgpu_math();
    init_shader_compiler_util();
    CHANNEL_CHAR_TO_INDEX_MAP = {
      "R": 0,
      "G": 1,
      "B": 2,
      "A": 3
    };
    EncodeMatrixProgram = class {
      constructor(outputShape, inputIsUnsignedByte = false, usedChannels = "RGBA") {
        this.variableNames = ["A"];
        this.customUniforms = [{ name: "texShape", type: "ivec2" }];
        const glsl = getGlslDifferences();
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        let output = `result`;
        if (inputIsUnsignedByte) {
          output = `floor(result * 255. + 0.5)`;
        }
        let mainLoop = "";
        for (let usedChannelIndex = 0; usedChannelIndex < usedChannels.length; usedChannelIndex++) {
          const curChannel = usedChannels[usedChannelIndex];
          mainLoop += `
          if(offset == ${usedChannelIndex}) {
            result = values[${CHANNEL_CHAR_TO_INDEX_MAP[curChannel]}];
          }`;
        }
        this.userCode = `
      ${this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 coords = getOutputCoords();
        int flatIndex = getFlatIndex(coords);
        float result = 0.;
        int offset = imod(flatIndex, ${usedChannels.length});

        flatIndex = idiv(flatIndex, ${usedChannels.length}, 1.);

        int r = flatIndex / texShape[1];
        if (r < texShape[0]) {
          int c = imod(flatIndex, texShape[1]);
          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
          vec4 values = ${glsl.texture2D}(A, uv);
          ${mainLoop}
        }
        ${glsl.output} = vec4(${output}, 0., 0., 0.);
      }
    `;
      }
    };
  }
});
var EncodeMatrixPackedProgram;
var init_encode_matrix_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/encode_matrix_packed_gpu.js"() {
    init_glsl_version();
    init_gpgpu_math();
    init_shader_compiler_util();
    EncodeMatrixPackedProgram = class {
      constructor(outputShape, inputIsUnsignedByte = false) {
        this.variableNames = ["A"];
        this.packedInputs = false;
        this.packedOutput = true;
        this.customUniforms = [{ name: "texShape", type: "ivec2" }];
        const glsl = getGlslDifferences();
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        let mainLoop = "";
        let output = "result";
        if (inputIsUnsignedByte) {
          output = "floor(result * 255. + 0.5)";
        }
        for (let row = 0; row <= 1; row++) {
          for (let col = 0; col <= 1; col++) {
            const channel = row * 2 + col;
            mainLoop += `
          localCoords = coords;
          if(localCoords[2] + ${col} < ${this.enableShapeUniforms ? "outShape[2]" : `${outputShape[2]}`}) {
          localCoords[2] += ${col};
          if (localCoords[1] + ${row} < ${this.enableShapeUniforms ? "outShape[1]" : `${outputShape[1]}`}) {
            localCoords[1] += ${row};

            flatIndex = getFlatIndex(localCoords);
            offset = imod(flatIndex, 4);

            flatIndex = idiv(flatIndex, 4, 1.);

            int r = flatIndex / texShape[1];
            int c = imod(flatIndex, texShape[1]);
            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
            values = ${glsl.texture2D}(A, uv);

            if (offset == 0) {
              result[${channel}] = values[0];
            } else if (offset == 1) {
              result[${channel}] = values[1];
            } else if (offset == 2) {
              result[${channel}] = values[2];
            } else {
              result[${channel}] = values[3];
            }
          }
        }
        `;
          }
        }
        this.userCode = `
        ${this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape)}

        void main() {
          ivec3 coords = getOutputCoords();

          vec4 result = vec4(0.);
          int flatIndex, r, c, offset;
          ivec3 localCoords;
          vec2 uv;
          vec4 values;

          ${mainLoop}

          ${glsl.output} = ${output};
        }
    `;
      }
    };
  }
});
function createVertexShader2(gl) {
  const glsl = getGlslDifferences();
  const vertexShaderSource = `${glsl.version}
    precision highp float;
    ${glsl.attribute} vec3 clipSpacePos;
    ${glsl.attribute} vec2 uv;
    ${glsl.varyingVs} vec2 resultUV;

    void main() {
      gl_Position = vec4(clipSpacePos, 1);
      resultUV = uv;
    }`;
  return createVertexShader(gl, vertexShaderSource);
}
function createVertexBuffer(gl) {
  const vertexArray = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
  return createStaticVertexBuffer(gl, vertexArray);
}
function createIndexBuffer(gl) {
  const triangleVertexIndices = new Uint16Array([0, 1, 2, 2, 1, 3]);
  return createStaticIndexBuffer(gl, triangleVertexIndices);
}
function createAndConfigureTexture(gl, width, height, internalFormat, textureFormat, textureType) {
  validateTextureSize(width, height);
  const texture = createTexture(gl);
  const tex2d = gl.TEXTURE_2D;
  callAndCheck(gl, () => gl.bindTexture(tex2d, texture));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_MIN_FILTER, gl.NEAREST));
  callAndCheck(gl, () => gl.texParameteri(tex2d, gl.TEXTURE_MAG_FILTER, gl.NEAREST));
  if (env().getNumber("WEBGL_VERSION") === 1) {
    callAndCheck(gl, () => gl.texImage2D(tex2d, 0, internalFormat, width, height, 0, textureFormat, textureType, null));
  } else {
    callAndCheck(gl, () => gl.texStorage2D(tex2d, 1, internalFormat, width, height));
  }
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
  return { texture, texShape: [height, width] };
}
function getInternalFormatForFloat32MatrixTexture(textureConfig) {
  return textureConfig.internalFormatFloat;
}
function createFloat32MatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat32MatrixTexture(textureConfig), textureConfig.textureFormatFloat, gl.FLOAT);
}
function getInternalFormatForFloat16MatrixTexture(textureConfig) {
  return textureConfig.internalFormatHalfFloat;
}
function createFloat16MatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16MatrixTexture(textureConfig), textureConfig.textureFormatFloat, textureConfig.textureTypeHalfFloat);
}
function getInternalFormatForUnsignedBytesMatrixTexture(textureConfig) {
  return textureConfig.downloadTextureFormat;
}
function createUnsignedBytesMatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForUnsignedBytesMatrixTexture(textureConfig), gl.RGBA, gl.UNSIGNED_BYTE);
}
function getInternalFormatForPackedMatrixTexture(textureConfig) {
  return textureConfig.internalFormatPackedFloat;
}
function createPackedMatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForPackedMatrixTexture(textureConfig), gl.RGBA, gl.FLOAT);
}
function getInternalFormatForFloat16PackedMatrixTexture(textureConfig) {
  return textureConfig.internalFormatPackedHalfFloat;
}
function createFloat16PackedMatrixTexture(gl, rows, columns, textureConfig) {
  const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
  return createAndConfigureTexture(gl, width, height, getInternalFormatForFloat16PackedMatrixTexture(textureConfig), gl.RGBA, textureConfig.textureTypeHalfFloat);
}
function bindVertexProgramAttributeStreams(gl, program, vertexBuffer) {
  const posOffset = 0;
  const uvOffset = 3 * 4;
  const stride = 3 * 4 + 2 * 4;
  callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer));
  const success = bindVertexBufferToProgramAttribute(gl, program, "clipSpacePos", vertexBuffer, 3, stride, posOffset);
  return success && bindVertexBufferToProgramAttribute(gl, program, "uv", vertexBuffer, 2, stride, uvOffset);
}
function uploadDenseMatrixToTexture(gl, texture, width, height, data, textureConfig) {
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
  let dataForUpload, texelDataType, internalFormat;
  if (data instanceof Uint8Array) {
    dataForUpload = new Uint8Array(width * height * 4);
    texelDataType = gl.UNSIGNED_BYTE;
    internalFormat = gl.RGBA;
  } else {
    dataForUpload = new Float32Array(width * height * 4);
    texelDataType = gl.FLOAT;
    internalFormat = textureConfig.internalFormatPackedFloat;
  }
  dataForUpload.set(data);
  if (env().getNumber("WEBGL_VERSION") === 2) {
    callAndCheck(gl, () => gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, width, height, gl.RGBA, texelDataType, dataForUpload));
  } else {
    callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, internalFormat, width, height, 0, gl.RGBA, texelDataType, dataForUpload));
  }
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
}
function uploadPixelDataToTexture(gl, texture, pixels) {
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, texture));
  if (pixels.data instanceof Uint8Array) {
    if (env().getNumber("WEBGL_VERSION") === 2) {
      callAndCheck(gl, () => gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, pixels.width, pixels.height, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data));
    } else {
      callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, pixels.width, pixels.height, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels.data));
    }
  } else {
    if (env().getNumber("WEBGL_VERSION") === 2) {
      callAndCheck(gl, () => gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, gl.RGBA, gl.UNSIGNED_BYTE, pixels));
    } else {
      callAndCheck(gl, () => gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, pixels));
    }
  }
  callAndCheck(gl, () => gl.bindTexture(gl.TEXTURE_2D, null));
}
function createBufferFromOutputTexture(gl2, rows, columns, textureConfig) {
  const buffer2 = gl2.createBuffer();
  callAndCheck(gl2, () => gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer2));
  const bytesPerFloat = 4;
  const valuesPerTexel = 4;
  const bufferSizeBytes = bytesPerFloat * valuesPerTexel * rows * columns;
  callAndCheck(gl2, () => gl2.bufferData(gl2.PIXEL_PACK_BUFFER, bufferSizeBytes, gl2.STREAM_READ));
  callAndCheck(gl2, () => gl2.readPixels(0, 0, columns, rows, gl2.RGBA, gl2.FLOAT, 0));
  callAndCheck(gl2, () => gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null));
  return buffer2;
}
function downloadFloat32MatrixFromBuffer(gl, buffer2, size) {
  const gl2 = gl;
  const downloadTarget = new Float32Array(size);
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer2);
  gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
  return downloadTarget;
}
function downloadByteEncodedFloatMatrixFromOutputTexture(gl, rows, columns, textureConfig) {
  const [w, h] = getUnpackedMatrixTextureShapeWidthHeight(rows, columns);
  const numChannels = 4;
  const downloadTarget = new Uint8Array(getUnpackedArraySizeFromMatrixSize(rows * columns, numChannels));
  callAndCheck(gl, () => gl.readPixels(0, 0, w, h, textureConfig.downloadTextureFormat, gl.UNSIGNED_BYTE, downloadTarget));
  return new Float32Array(downloadTarget.buffer);
}
function downloadPackedMatrixFromBuffer(gl, buffer2, batch, rows, cols, physicalRows, physicalCols, textureConfig) {
  const gl2 = gl;
  const downloadTarget = new Float32Array(getPackedRGBAArraySizeFromMatrixShape(physicalRows, physicalCols));
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, buffer2);
  gl2.getBufferSubData(gl2.PIXEL_PACK_BUFFER, 0, downloadTarget);
  gl2.bindBuffer(gl2.PIXEL_PACK_BUFFER, null);
  return downloadTarget;
}
function downloadMatrixFromPackedOutputTexture(gl, physicalRows, physicalCols) {
  const packedRGBA = new Float32Array(physicalRows * physicalCols * 4);
  callAndCheck(gl, () => gl.readPixels(0, 0, physicalCols, physicalRows, gl.RGBA, gl.FLOAT, packedRGBA));
  return packedRGBA;
}
var init_gpgpu_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/gpgpu_util.js"() {
    init_dist();
    init_glsl_version();
    init_tex_util();
    init_webgl_util();
  }
});
function linearSearchLastTrue(arr) {
  let i = 0;
  for (; i < arr.length; ++i) {
    const isDone = arr[i]();
    if (!isDone) {
      break;
    }
  }
  return i - 1;
}
var GPGPUContext;
var init_gpgpu_context = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/gpgpu_context.js"() {
    init_dist();
    init_canvas_util();
    init_gpgpu_util();
    init_tex_util();
    init_webgl_util();
    GPGPUContext = class {
      constructor(gl) {
        this.outputTexture = null;
        this.program = null;
        this.disposed = false;
        this.itemsToPoll = [];
        const glVersion = env().getNumber("WEBGL_VERSION");
        if (gl != null) {
          this.gl = gl;
          setWebGLContext(glVersion, gl);
        } else {
          this.gl = getWebGLContext(glVersion);
        }
        gl = this.gl;
        if (env().getNumber("WEBGL_VERSION") === 2) {
          const gl2 = gl;
          this.createVertexArray = () => {
            return callAndCheck(gl2, () => gl2.createVertexArray());
          };
          this.bindVertexArray = (vao) => {
            return callAndCheck(gl2, () => gl2.bindVertexArray(vao));
          };
          this.deleteVertexArray = (vao) => {
            return callAndCheck(gl2, () => gl2.deleteVertexArray(vao));
          };
          this.getVertexArray = () => {
            return callAndCheck(gl2, () => gl2.getParameter(gl2.VERTEX_ARRAY_BINDING));
          };
        } else if (gl != null) {
          const ext = gl.getExtension("OES_vertex_array_object");
          if (ext == null) {
            throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");
          }
          this.createVertexArray = () => {
            return callAndCheck(gl, () => ext.createVertexArrayOES());
          };
          this.bindVertexArray = (vao) => {
            return callAndCheck(gl, () => ext.bindVertexArrayOES(vao));
          };
          this.deleteVertexArray = (vao) => {
            return callAndCheck(gl, () => ext.deleteVertexArrayOES(vao));
          };
          this.getVertexArray = () => {
            return callAndCheck(gl, () => gl.getParameter(ext.VERTEX_ARRAY_BINDING_OES));
          };
        }
        let COLOR_BUFFER_FLOAT = "WEBGL_color_buffer_float";
        const COLOR_BUFFER_HALF_FLOAT = "EXT_color_buffer_half_float";
        this.parallelCompilationExtension = this.gl.getExtension("KHR_parallel_shader_compile");
        if (env().getNumber("WEBGL_VERSION") === 1) {
          const TEXTURE_FLOAT = "OES_texture_float";
          const TEXTURE_HALF_FLOAT = "OES_texture_half_float";
          this.textureFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_FLOAT);
          if (hasExtension(this.gl, TEXTURE_HALF_FLOAT)) {
            this.textureHalfFloatExtension = getExtensionOrThrow(this.gl, TEXTURE_HALF_FLOAT);
          } else if (env().get("WEBGL_FORCE_F16_TEXTURES")) {
            throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
          }
          this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
          if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
            this.colorBufferHalfFloatExtension = getExtensionOrThrow(this.gl, COLOR_BUFFER_HALF_FLOAT);
          } else if (env().get("WEBGL_FORCE_F16_TEXTURES")) {
            throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
          }
        } else {
          COLOR_BUFFER_FLOAT = "EXT_color_buffer_float";
          if (hasExtension(this.gl, COLOR_BUFFER_FLOAT)) {
            this.colorBufferFloatExtension = this.gl.getExtension(COLOR_BUFFER_FLOAT);
          } else if (hasExtension(this.gl, COLOR_BUFFER_HALF_FLOAT)) {
            this.colorBufferHalfFloatExtension = this.gl.getExtension(COLOR_BUFFER_HALF_FLOAT);
          } else {
            throw new Error("GL context does not support color renderable floats");
          }
        }
        this.vertexBuffer = createVertexBuffer(this.gl);
        this.indexBuffer = createIndexBuffer(this.gl);
        this.framebuffer = createFramebuffer(this.gl);
        this.textureConfig = getTextureConfig(this.gl, this.textureHalfFloatExtension);
      }
      get debug() {
        return env().getBool("DEBUG");
      }
      dispose() {
        if (this.disposed) {
          return;
        }
        if (this.program != null) {
          console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing.");
        }
        if (this.outputTexture != null) {
          console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
        }
        const gl = this.gl;
        callAndCheck(gl, () => gl.finish());
        callAndCheck(gl, () => gl.bindFramebuffer(gl.FRAMEBUFFER, null));
        callAndCheck(gl, () => gl.deleteFramebuffer(this.framebuffer));
        callAndCheck(gl, () => gl.bindBuffer(gl.ARRAY_BUFFER, null));
        callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, null));
        callAndCheck(gl, () => gl.deleteBuffer(this.indexBuffer));
        this.disposed = true;
      }
      createFloat32MatrixTexture(rows, columns) {
        this.throwIfDisposed();
        return createFloat32MatrixTexture(this.gl, rows, columns, this.textureConfig);
      }
      createFloat16MatrixTexture(rows, columns) {
        this.throwIfDisposed();
        return createFloat16MatrixTexture(this.gl, rows, columns, this.textureConfig);
      }
      createUnsignedBytesMatrixTexture(rows, columns) {
        this.throwIfDisposed();
        return createUnsignedBytesMatrixTexture(this.gl, rows, columns, this.textureConfig);
      }
      uploadPixelDataToTexture(texture, pixels) {
        this.throwIfDisposed();
        uploadPixelDataToTexture(this.gl, texture, pixels);
      }
      uploadDenseMatrixToTexture(texture, width, height, data) {
        this.throwIfDisposed();
        uploadDenseMatrixToTexture(this.gl, texture, width, height, data, this.textureConfig);
      }
      createFloat16PackedMatrixTexture(rows, columns) {
        this.throwIfDisposed();
        return createFloat16PackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
      }
      createPackedMatrixTexture(rows, columns) {
        this.throwIfDisposed();
        return createPackedMatrixTexture(this.gl, rows, columns, this.textureConfig);
      }
      deleteMatrixTexture(texture) {
        this.throwIfDisposed();
        if (this.outputTexture === texture) {
          unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
          this.outputTexture = null;
        }
        callAndCheck(this.gl, () => this.gl.deleteTexture(texture));
      }
      downloadByteEncodedFloatMatrixFromOutputTexture(texture, rows, columns) {
        return this.downloadMatrixDriver(texture, () => downloadByteEncodedFloatMatrixFromOutputTexture(this.gl, rows, columns, this.textureConfig));
      }
      downloadPackedMatrixFromBuffer(buffer2, batch, rows, columns, physicalRows, physicalCols) {
        return downloadPackedMatrixFromBuffer(this.gl, buffer2, batch, rows, columns, physicalRows, physicalCols, this.textureConfig);
      }
      downloadFloat32MatrixFromBuffer(buffer2, size) {
        return downloadFloat32MatrixFromBuffer(this.gl, buffer2, size);
      }
      createBufferFromTexture(texture, rows, columns) {
        this.bindTextureToFrameBuffer(texture);
        const result = createBufferFromOutputTexture(this.gl, rows, columns, this.textureConfig);
        this.unbindTextureToFrameBuffer();
        return result;
      }
      createAndWaitForFence() {
        const fenceContext = this.createFence(this.gl);
        return this.pollFence(fenceContext);
      }
      createFence(gl) {
        let query;
        let isFencePassed;
        if (env().getBool("WEBGL_FENCE_API_ENABLED")) {
          const gl2 = gl;
          const sync = gl2.fenceSync(gl2.SYNC_GPU_COMMANDS_COMPLETE, 0);
          gl.flush();
          isFencePassed = () => {
            const status = gl2.clientWaitSync(sync, 0, 0);
            return status === gl2.ALREADY_SIGNALED || status === gl2.CONDITION_SATISFIED;
          };
          query = sync;
        } else if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0) {
          query = this.beginQuery();
          this.endQuery();
          isFencePassed = () => this.isQueryAvailable(query, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
        } else {
          isFencePassed = () => true;
        }
        return { query, isFencePassed };
      }
      downloadMatrixFromPackedTexture(texture, physicalRows, physicalCols) {
        return this.downloadMatrixDriver(texture, () => downloadMatrixFromPackedOutputTexture(this.gl, physicalRows, physicalCols));
      }
      createProgram(fragmentShader) {
        this.throwIfDisposed();
        const gl = this.gl;
        if (this.vertexShader == null) {
          this.vertexShader = createVertexShader2(gl);
        }
        const program = createProgram(gl);
        callAndCheck(gl, () => gl.attachShader(program, this.vertexShader));
        callAndCheck(gl, () => gl.attachShader(program, fragmentShader));
        linkProgram(gl, program);
        let program2;
        {
          program2 = Object.assign(program, {
            vao: this.createVertexArray()
          });
          this.bindVertexArray(program2.vao);
          callAndCheck(gl, () => gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, this.indexBuffer));
          console.assert(bindVertexProgramAttributeStreams(gl, program2, this.vertexBuffer), "gpgpu_util.bindVertexProgramAttributeStreams not fully successful.");
          if (this.debug) {
            validateProgram(gl, program2);
          }
        }
        this.setProgram(program2);
        return program2;
      }
      deleteProgram(program) {
        this.throwIfDisposed();
        if (program === this.program) {
          this.program = null;
        }
        if (program != null) {
          callAndCheck(this.gl, () => this.gl.deleteProgram(program));
          this.deleteVertexArray(program.vao);
        }
      }
      setProgram(program) {
        this.throwIfDisposed();
        this.program = program;
        if (this.program != null) {
          this.bindVertexArray(this.program.vao);
          if (this.debug) {
            validateProgram(this.gl, this.program);
          }
        }
        callAndCheck(this.gl, () => this.gl.useProgram(program));
      }
      getUniformLocation(program, uniformName, shouldThrow = true) {
        this.throwIfDisposed();
        if (shouldThrow) {
          return getProgramUniformLocationOrThrow(this.gl, program, uniformName);
        } else {
          return getProgramUniformLocation(this.gl, program, uniformName);
        }
      }
      getAttributeLocation(program, attribute) {
        this.throwIfDisposed();
        return callAndCheck(this.gl, () => this.gl.getAttribLocation(program, attribute));
      }
      getUniformLocationNoThrow(program, uniformName) {
        this.throwIfDisposed();
        return this.gl.getUniformLocation(program, uniformName);
      }
      setInputMatrixTexture(inputMatrixTexture, uniformLocation, textureUnit) {
        this.throwIfDisposed();
        this.throwIfNoProgram();
        bindTextureToProgramUniformSampler(this.gl, inputMatrixTexture, uniformLocation, textureUnit);
      }
      setOutputMatrixTexture(outputMatrixTexture, rows, columns) {
        this.setOutputMatrixTextureDriver(outputMatrixTexture, columns, rows);
      }
      setOutputPackedMatrixTexture(outputPackedMatrixTexture, rows, columns) {
        this.throwIfDisposed();
        const [width, height] = getPackedMatrixTextureShapeWidthHeight(rows, columns);
        this.setOutputMatrixTextureDriver(outputPackedMatrixTexture, width, height);
      }
      setOutputMatrixWriteRegion(startRow, numRows, startColumn, numColumns) {
        this.setOutputMatrixWriteRegionDriver(startColumn, startRow, numColumns, numRows);
      }
      setOutputPackedMatrixWriteRegion(startRow, numRows, startColumn, numColumns) {
        throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
      }
      debugValidate() {
        if (this.program != null) {
          validateProgram(this.gl, this.program);
        }
        validateFramebuffer(this.gl);
      }
      executeProgram() {
        this.throwIfDisposed();
        this.throwIfNoProgram();
        const gl = this.gl;
        if (this.debug) {
          const boundVao = this.getVertexArray();
          console.assert(boundVao === this.program.vao, "VAO changed between setProgram and executeProgram!");
          this.debugValidate();
        }
        callAndCheck(gl, () => gl.drawElements(gl.TRIANGLES, 6, gl.UNSIGNED_SHORT, 0));
      }
      blockUntilAllProgramsCompleted() {
        this.throwIfDisposed();
        callAndCheck(this.gl, () => this.gl.finish());
      }
      getQueryTimerExtension() {
        if (this.disjointQueryTimerExtension == null) {
          this.disjointQueryTimerExtension = getExtensionOrThrow(this.gl, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query");
        }
        return this.disjointQueryTimerExtension;
      }
      getQueryTimerExtensionWebGL2() {
        return this.getQueryTimerExtension();
      }
      getQueryTimerExtensionWebGL1() {
        return this.getQueryTimerExtension();
      }
      beginQuery() {
        if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
          const gl2 = this.gl;
          const ext2 = this.getQueryTimerExtensionWebGL2();
          const query2 = gl2.createQuery();
          gl2.beginQuery(ext2.TIME_ELAPSED_EXT, query2);
          return query2;
        }
        const ext = this.getQueryTimerExtensionWebGL1();
        const query = ext.createQueryEXT();
        ext.beginQueryEXT(ext.TIME_ELAPSED_EXT, query);
        return query;
      }
      endQuery() {
        if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
          const gl2 = this.gl;
          const ext2 = this.getQueryTimerExtensionWebGL2();
          gl2.endQuery(ext2.TIME_ELAPSED_EXT);
          return;
        }
        const ext = this.getQueryTimerExtensionWebGL1();
        ext.endQueryEXT(ext.TIME_ELAPSED_EXT);
      }
      async waitForQueryAndGetTime(query) {
        await util_exports.repeatedTry(() => this.disposed || // while testing contexts are created / disposed
        // in rapid succession, so without this check we
        // may poll for the query timer indefinitely
        this.isQueryAvailable(query, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")));
        return this.getQueryTime(query, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
      }
      getQueryTime(query, queryTimerVersion) {
        if (queryTimerVersion === 0) {
          return null;
        }
        if (queryTimerVersion === 2) {
          const gl2 = this.gl;
          const timeElapsedNanos = gl2.getQueryParameter(query, gl2.QUERY_RESULT);
          return timeElapsedNanos / 1e6;
        } else {
          const ext = this.getQueryTimerExtensionWebGL1();
          const timeElapsedNanos = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_EXT);
          return timeElapsedNanos / 1e6;
        }
      }
      isQueryAvailable(query, queryTimerVersion) {
        if (queryTimerVersion === 0) {
          return true;
        }
        if (queryTimerVersion === 2) {
          const gl2 = this.gl;
          const ext = this.getQueryTimerExtensionWebGL2();
          const available = gl2.getQueryParameter(query, gl2.QUERY_RESULT_AVAILABLE);
          if (this.disjoint == null) {
            this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
          }
          return available && !this.disjoint;
        } else {
          const ext = this.getQueryTimerExtensionWebGL1();
          const available = ext.getQueryObjectEXT(query, ext.QUERY_RESULT_AVAILABLE_EXT);
          if (this.disjoint == null) {
            this.disjoint = this.gl.getParameter(ext.GPU_DISJOINT_EXT);
          }
          return available && !this.disjoint;
        }
      }
      pollFence(fenceContext) {
        return new Promise((resolve) => {
          this.addItemToPoll(() => fenceContext.isFencePassed(), () => resolve());
        });
      }
      pollItems() {
        const index = linearSearchLastTrue(this.itemsToPoll.map((x) => x.isDoneFn));
        for (let i = 0; i <= index; ++i) {
          const { resolveFn } = this.itemsToPoll[i];
          resolveFn();
        }
        this.itemsToPoll = this.itemsToPoll.slice(index + 1);
      }
      addItemToPoll(isDoneFn, resolveFn) {
        this.itemsToPoll.push({ isDoneFn, resolveFn });
        if (this.itemsToPoll.length > 1) {
          return;
        }
        let scheduleFn = void 0;
        if ("setTimeoutCustom" in env().platform) {
          scheduleFn = env().platform.setTimeoutCustom.bind(env().platform);
        }
        util_exports.repeatedTry(() => {
          this.pollItems();
          return this.itemsToPoll.length === 0;
        }, () => 0, null, scheduleFn);
      }
      bindTextureToFrameBuffer(texture) {
        this.throwIfDisposed();
        bindColorTextureToFramebuffer(this.gl, texture, this.framebuffer);
        if (this.debug) {
          validateFramebuffer(this.gl);
        }
      }
      unbindTextureToFrameBuffer() {
        if (this.outputTexture != null) {
          bindColorTextureToFramebuffer(this.gl, this.outputTexture, this.framebuffer);
          if (this.debug) {
            validateFramebuffer(this.gl);
          }
        } else {
          unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
        }
      }
      downloadMatrixDriver(texture, downloadAndDecode) {
        this.bindTextureToFrameBuffer(texture);
        const result = downloadAndDecode();
        this.unbindTextureToFrameBuffer();
        return result;
      }
      setOutputMatrixTextureDriver(outputMatrixTextureMaybePacked, width, height) {
        this.throwIfDisposed();
        const gl = this.gl;
        bindColorTextureToFramebuffer(gl, outputMatrixTextureMaybePacked, this.framebuffer);
        if (this.debug) {
          validateFramebuffer(gl);
        }
        this.outputTexture = outputMatrixTextureMaybePacked;
        callAndCheck(gl, () => gl.viewport(0, 0, width, height));
        callAndCheck(gl, () => gl.scissor(0, 0, width, height));
      }
      setOutputMatrixWriteRegionDriver(x, y, width, height) {
        this.throwIfDisposed();
        callAndCheck(this.gl, () => this.gl.scissor(x, y, width, height));
      }
      throwIfDisposed() {
        if (this.disposed) {
          throw new Error("Attempted to use disposed GPGPUContext.");
        }
      }
      throwIfNoProgram() {
        if (this.program == null) {
          throw new Error("No GPU program is currently set.");
        }
      }
    };
  }
});
var addImplCPU;
var bincountImplCPU;
var bincountReduceImplCPU;
var castImplCPU;
var ceilImplCPU;
var concatImplCPU;
var equalImplCPU;
var expImplCPU;
var expm1ImplCPU;
var floorImplCPU;
var gatherNdImplCPU;
var gatherV2ImplCPU;
var greaterImplCPU;
var greaterEqualImplCPU;
var lessImplCPU;
var lessEqualImplCPU;
var linSpaceImplCPU;
var logImplCPU;
var maxImplCPU;
var maximumImplCPU;
var minimumImplCPU;
var multiplyImplCPU;
var negImplCPU;
var notEqualImplCPU;
var prodImplCPU;
var raggedGatherImplCPU;
var raggedRangeImplCPU;
var raggedTensorToTensorImplCPU;
var rangeImplCPU;
var rsqrtImplCPU;
var scatterImplCPU;
var sigmoidImplCPU;
var simpleAbsImplCPU;
var sliceImplCPU;
var sparseFillEmptyRowsImplCPU;
var sparseReshapeImplCPU;
var sparseSegmentReductionImplCPU;
var sqrtImplCPU;
var stridedSliceImplCPU;
var stringNGramsImplCPU;
var stringSplitImplCPU;
var stringToHashBucketFastImplCPU;
var subImplCPU;
var tileImplCPU;
var topKImplCPU;
var transposeImplCPU;
var uniqueImplCPU;
var init_shared2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/shared.js"() {
    init_shared();
    ({ addImpl: addImplCPU, bincountImpl: bincountImplCPU, bincountReduceImpl: bincountReduceImplCPU, castImpl: castImplCPU, ceilImpl: ceilImplCPU, concatImpl: concatImplCPU, equalImpl: equalImplCPU, expImpl: expImplCPU, expm1Impl: expm1ImplCPU, floorImpl: floorImplCPU, gatherNdImpl: gatherNdImplCPU, gatherV2Impl: gatherV2ImplCPU, greaterImpl: greaterImplCPU, greaterEqualImpl: greaterEqualImplCPU, lessImpl: lessImplCPU, lessEqualImpl: lessEqualImplCPU, linSpaceImpl: linSpaceImplCPU, logImpl: logImplCPU, maxImpl: maxImplCPU, maximumImpl: maximumImplCPU, minimumImpl: minimumImplCPU, multiplyImpl: multiplyImplCPU, negImpl: negImplCPU, notEqualImpl: notEqualImplCPU, prodImpl: prodImplCPU, raggedGatherImpl: raggedGatherImplCPU, raggedRangeImpl: raggedRangeImplCPU, raggedTensorToTensorImpl: raggedTensorToTensorImplCPU, rangeImpl: rangeImplCPU, rsqrtImpl: rsqrtImplCPU, scatterImpl: scatterImplCPU, sigmoidImpl: sigmoidImplCPU, simpleAbsImpl: simpleAbsImplCPU, sliceImpl: sliceImplCPU, sparseFillEmptyRowsImpl: sparseFillEmptyRowsImplCPU, sparseReshapeImpl: sparseReshapeImplCPU, sparseSegmentReductionImpl: sparseSegmentReductionImplCPU, sqrtImpl: sqrtImplCPU, stridedSliceImpl: stridedSliceImplCPU, stringNGramsImpl: stringNGramsImplCPU, stringSplitImpl: stringSplitImplCPU, stringToHashBucketFastImpl: stringToHashBucketFastImplCPU, subImpl: subImplCPU, tileImpl: tileImplCPU, topKImpl: topKImplCPU, transposeImpl: transposeImplCPU, uniqueImpl: uniqueImplCPU } = shared_exports);
  }
});
function getVecChannels(name, rank) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, rank).map((d) => `${name}.${d}`);
}
function getChannels(name, rank) {
  if (rank === 1) {
    return [name];
  }
  return getVecChannels(name, rank);
}
function getSourceCoords(rank, dims) {
  if (rank === 1) {
    return "rc";
  }
  let coords2 = "";
  for (let i = 0; i < rank; i++) {
    coords2 += dims[i];
    if (i < rank - 1) {
      coords2 += ",";
    }
  }
  return coords2;
}
var init_packing_util = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/packing_util.js"() {
  }
});
var PackProgram;
var init_pack_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/pack_gpu.js"() {
    init_gpgpu_math();
    init_packing_util();
    init_shader_compiler();
    PackProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.packedInputs = false;
        this.packedOutput = true;
        this.outputShape = outputShape;
        this.rank = outputShape.length;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        if (this.rank === 0) {
          this.userCode = `
        void main() {
          setOutput(vec4(getA(), 0., 0., 0.));
        }
      `;
        } else {
          const channels = getChannels("rc", this.rank);
          const dtype = getCoordsDataType(this.rank);
          const outOfBoundsCondition = this.getOutOfBoundsCondition(channels);
          const setup = this.getSetup(channels);
          const output = this.getOutput(channels);
          this.userCode = `
        void main() {
          ${dtype} rc = getOutputCoords();

          if(${outOfBoundsCondition}) {
            setOutput(vec4(0));
          } else {
            ${setup}

            setOutput(vec4(${output}));
          }
        }
      `;
        }
      }
      getSourceCoordsArr(dims) {
        const coords2 = [];
        for (let row = 0; row <= 1; row++) {
          for (let col = 0; col <= 1; col++) {
            let coord = `${row === 0 ? "r" : "rp1"}, ${col === 0 ? "c" : "cp1"}`;
            for (let d = 2; d < this.rank; d++) {
              coord = `${dims[dims.length - 1 - d]},` + coord;
            }
            coords2.push(coord);
          }
        }
        return coords2;
      }
      getOutOfBoundsCondition(dims) {
        if (this.rank === 1) {
          return `rc > ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]}`;
        }
        let cond = "";
        for (let i = this.rank - 2; i < this.rank; i++) {
          cond += `${dims[i]} >= ${this.enableShapeUniforms ? `outShape[${i}]` : this.outputShape[i]}`;
          if (i < this.rank - 1) {
            cond += "||";
          }
        }
        return cond;
      }
      getSetup(dims) {
        if (this.rank === 1) {
          return "";
        }
        const innerDims = dims.slice(-2);
        const col = this.enableShapeUniforms ? `outShape[${this.rank} - 1]` : this.outputShape[this.rank - 1];
        const row = this.enableShapeUniforms ? `outShape[${this.rank} - 2]` : this.outputShape[this.rank - 2];
        return `
      int r = ${innerDims[0]};
      int c = ${innerDims[1]};
      int rp1 = r + 1;
      int cp1 = c + 1;

      bool cEdge = cp1 >= ${col};
      bool rEdge = rp1 >= ${row};
    `;
      }
      getOutput(dims) {
        const sourceCoords = this.getSourceCoordsArr(dims);
        if (this.rank === 1) {
          const outShape = this.enableShapeUniforms ? "outShape" : this.outputShape[0];
          return `getA(rc), (rc + 1 >= ${outShape} ? 0. : getA(rc + 1)), 0, 0`;
        }
        return `getA(${sourceCoords[0]}),
            cEdge ? 0. : getA(${sourceCoords[1]}),
            rEdge ? 0. : getA(${sourceCoords[2]}),
            rEdge || cEdge ? 0. : getA(${sourceCoords[3]})`;
      }
    };
  }
});
function getReshapedInputCoords(shape, enableShapeUniforms) {
  const coordsFromIndexSnippet = enableShapeUniforms ? getLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], "inputShape") : getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], shape);
  return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${coordsFromIndexSnippet}
      return ivec3(r, c, d);
    }
  `;
}
var ReshapePackedProgram;
var init_reshape_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/reshape_packed_gpu.js"() {
    init_gpgpu_math();
    init_shader_compiler_util();
    ReshapePackedProgram = class {
      constructor(outputShape, inputShape) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.customUniforms = [{ name: "inputShape", type: "ivec3" }];
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        let mainLoop = ``;
        for (let i = 0; i < 4; i++) {
          let thisRC = `thisRC = rc;`;
          if (i % 2 === 1) {
            thisRC += `thisRC.z += 1;`;
          }
          if (i > 1) {
            thisRC += `thisRC.y += 1;`;
          }
          mainLoop += `
        ${thisRC}
        ${i > 0 ? `if(thisRC.y < rows && thisRC.z < cols){` : ""}
          int flatIndex = getFlatIndex(thisRC);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);
          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${i}] =
            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);
        ${i > 0 ? "}" : ""}
      `;
        }
        this.userCode = `
      ${getReshapedInputCoords(inputShape, this.enableShapeUniforms)}
      ${this.enableShapeUniforms ? getFlatIndexFrom3DOutput() : getFlatIndexFrom3D(outputShape)}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.);

        ivec3 thisRC;
        int rows = ${this.enableShapeUniforms ? "outShape[1]" : outputShape[1]};
        int cols = ${this.enableShapeUniforms ? "outShape[2]" : outputShape[2]};

        ${mainLoop}

        setOutput(result);
      }
    `;
      }
    };
  }
});
function numBytesForInternalFormat(gl, internalFormat) {
  const glany = gl;
  if (internalFormat === glany.R32F) {
    return 4;
  } else if (internalFormat === glany.R16F) {
    return 2;
  } else if (internalFormat === glany.RGBA32F) {
    return 16;
  } else if (internalFormat === gl.RGBA) {
    return 16;
  } else if (internalFormat === glany.RGBA16F) {
    return 8;
  } else if (internalFormat === glany.RGBA8) {
    return 4;
  }
  throw new Error(`Unknown internal format ${internalFormat}`);
}
function computeBytes(shape, physicalTexType, gl, textureConfig, isPacked) {
  const internalFormat = internalFormatForPhysicalTexType(physicalTexType, textureConfig);
  let numElements;
  if (isPacked) {
    const [packedWidth, packedHeight] = getPackedMatrixTextureShapeWidthHeight(shape[0], shape[1]);
    numElements = packedWidth * packedHeight;
  } else {
    const [width, height] = getUnpackedMatrixTextureShapeWidthHeight(shape[0], shape[1]);
    numElements = width * height;
  }
  const bytesPerElement2 = numBytesForInternalFormat(gl, internalFormat);
  return numElements * bytesPerElement2;
}
function internalFormatForPhysicalTexType(physicalTexType, textureConfig) {
  switch (physicalTexType) {
    case PhysicalTextureType.PACKED_2X2_FLOAT32:
      return getInternalFormatForPackedMatrixTexture(textureConfig);
    case PhysicalTextureType.PACKED_2X2_FLOAT16:
      return getInternalFormatForFloat16PackedMatrixTexture(textureConfig);
    case PhysicalTextureType.UNPACKED_FLOAT32:
      return getInternalFormatForFloat32MatrixTexture(textureConfig);
    case PhysicalTextureType.UNPACKED_FLOAT16:
      return getInternalFormatForFloat16MatrixTexture(textureConfig);
    case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:
      return getInternalFormatForUnsignedBytesMatrixTexture(textureConfig);
    default:
      throw new Error(`Unknown physical texture type ${physicalTexType}`);
  }
}
function getPhysicalTextureForRendering(isPacked) {
  if (env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")) {
    if (isPacked) {
      return PhysicalTextureType.PACKED_2X2_FLOAT32;
    }
    return PhysicalTextureType.UNPACKED_FLOAT32;
  }
  if (isPacked) {
    return PhysicalTextureType.PACKED_2X2_FLOAT16;
  }
  return PhysicalTextureType.UNPACKED_FLOAT16;
}
function getPhysicalFromLogicalTextureType(logicalTexType, isPacked) {
  if (logicalTexType === TextureUsage.UPLOAD) {
    return PhysicalTextureType.PACKED_2X2_FLOAT32;
  } else if (logicalTexType === TextureUsage.RENDER || logicalTexType == null) {
    return getPhysicalTextureForRendering(isPacked);
  } else if (logicalTexType === TextureUsage.DOWNLOAD || logicalTexType === TextureUsage.PIXELS) {
    return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;
  }
  throw new Error(`Unknown logical texture type ${logicalTexType}`);
}
function getKeyFromTextureShape(shapeRowsCol, physicalTexType, isPacked) {
  return `${shapeRowsCol[0]}_${shapeRowsCol[1]}_${physicalTexType}_${isPacked}`;
}
var TextureManager2;
var init_texture_manager = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/texture_manager.js"() {
    init_dist();
    init_gpgpu_util();
    init_tex_util();
    TextureManager2 = class {
      constructor(gpgpu) {
        this.gpgpu = gpgpu;
        this.numUsedTextures = 0;
        this.numFreeTextures = 0;
        this._numBytesAllocated = 0;
        this._numBytesFree = 0;
        this.freeTextures = {};
        this.logEnabled = false;
        this.usedTextures = {};
      }
      acquireTexture(shapeRC, usage, isPacked) {
        const physicalTexType = getPhysicalFromLogicalTextureType(usage, isPacked);
        const shapeKey = getKeyFromTextureShape(shapeRC, physicalTexType, isPacked);
        if (!(shapeKey in this.freeTextures)) {
          this.freeTextures[shapeKey] = [];
        }
        if (!(shapeKey in this.usedTextures)) {
          this.usedTextures[shapeKey] = [];
        }
        const texBytes = computeBytes(shapeRC, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
        if (this.freeTextures[shapeKey].length > 0) {
          this.numFreeTextures--;
          this.numUsedTextures++;
          this._numBytesFree -= texBytes;
          this.log();
          const newTexture2 = this.freeTextures[shapeKey].shift();
          this.usedTextures[shapeKey].push(newTexture2);
          return newTexture2;
        }
        let newTexture;
        if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT32) {
          newTexture = this.gpgpu.createPackedMatrixTexture(shapeRC[0], shapeRC[1]);
        } else if (physicalTexType === PhysicalTextureType.PACKED_2X2_FLOAT16) {
          newTexture = this.gpgpu.createFloat16PackedMatrixTexture(shapeRC[0], shapeRC[1]);
        } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT32) {
          newTexture = this.gpgpu.createFloat32MatrixTexture(shapeRC[0], shapeRC[1]);
        } else if (physicalTexType === PhysicalTextureType.UNPACKED_FLOAT16) {
          newTexture = this.gpgpu.createFloat16MatrixTexture(shapeRC[0], shapeRC[1]);
        } else if (physicalTexType === PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE) {
          newTexture = this.gpgpu.createUnsignedBytesMatrixTexture(shapeRC[0], shapeRC[1]);
        }
        this.usedTextures[shapeKey].push(newTexture);
        this.numUsedTextures++;
        this._numBytesAllocated += texBytes;
        this.log();
        return newTexture;
      }
      releaseTexture(texture, shape, logicalTexType, isPacked) {
        if (this.freeTextures == null) {
          return;
        }
        const physicalTexType = getPhysicalFromLogicalTextureType(logicalTexType, isPacked);
        const shapeKey = getKeyFromTextureShape(shape, physicalTexType, isPacked);
        if (!(shapeKey in this.freeTextures)) {
          this.freeTextures[shapeKey] = [];
        }
        const texBytes = computeBytes(shape, physicalTexType, this.gpgpu.gl, this.gpgpu.textureConfig, isPacked);
        const deleteTexThreshold = env().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
        if (deleteTexThreshold !== -1 && this._numBytesAllocated > deleteTexThreshold) {
          this.gpgpu.deleteMatrixTexture(texture.texture);
          this._numBytesAllocated -= texBytes;
        } else {
          this.freeTextures[shapeKey].push(texture);
          this.numFreeTextures++;
          this._numBytesFree += texBytes;
        }
        this.numUsedTextures--;
        const texList = this.usedTextures[shapeKey];
        const texIndex = texList.indexOf(texture);
        if (texIndex < 0) {
          throw new Error("Cannot release a texture that was never provided by this texture manager");
        }
        texList.splice(texIndex, 1);
        this.log();
      }
      log() {
        if (!this.logEnabled) {
          return;
        }
        const total = this.numFreeTextures + this.numUsedTextures;
        console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${total})`);
        const freeRatio = this._numBytesFree / this._numBytesAllocated;
        console.log(`Bytes allocated: ${this._numBytesAllocated}`);
        console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * freeRatio)}%)`);
      }
      get numBytesAllocated() {
        return this._numBytesAllocated;
      }
      get numBytesFree() {
        return this._numBytesFree;
      }
      getNumUsedTextures() {
        return this.numUsedTextures;
      }
      getNumFreeTextures() {
        return this.numFreeTextures;
      }
      dispose() {
        if (this.freeTextures == null) {
          return;
        }
        for (const texShape in this.freeTextures) {
          this.freeTextures[texShape].forEach((tex) => {
            this.gpgpu.deleteMatrixTexture(tex.texture);
          });
        }
        for (const texShape in this.usedTextures) {
          this.usedTextures[texShape].forEach((tex) => {
            this.gpgpu.deleteMatrixTexture(tex.texture);
          });
        }
        this.freeTextures = null;
        this.usedTextures = null;
        this.numUsedTextures = 0;
        this.numFreeTextures = 0;
        this._numBytesAllocated = 0;
        this._numBytesFree = 0;
      }
    };
  }
});
var UnaryOpProgram;
var CHECK_NAN_SNIPPET;
var LINEAR;
var ABS;
var ELU2;
var RELU;
var RELU6;
var CLONE;
var SIGMOID;
var init_unaryop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/unaryop_gpu.js"() {
    init_gpgpu_math();
    UnaryOpProgram = class {
      constructor(aShape, opSnippet) {
        this.variableNames = ["A"];
        this.outputShape = aShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        this.userCode = `
      float unaryOperation(float x) {
        ${opSnippet}
      }

      void main() {
        float x = getAAtOutCoords();
        float y = unaryOperation(x);

        setOutput(y);
      }
    `;
      }
    };
    CHECK_NAN_SNIPPET = `if (isnan(x)) return x;`;
    LINEAR = `return x;`;
    ABS = `return abs(x);`;
    ELU2 = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;
    RELU = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : x;
`;
    RELU6 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
    CLONE = "return x;";
    SIGMOID = `return 1.0 / (1.0 + exp(-1.0 * x));`;
  }
});
var LINEAR2;
var ELU3;
var RELU2;
var RELU62;
var SIGMOID2;
var UnaryOpPackedProgram;
var init_unaryop_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/unaryop_packed_gpu.js"() {
    init_gpgpu_math();
    LINEAR2 = `return x;`;
    ELU3 = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
    RELU2 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    RELU62 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    SIGMOID2 = `return 1.0 / (1.0 + exp(-1.0 * x));`;
    UnaryOpPackedProgram = class {
      constructor(aShape, opSnippet) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = aShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        this.userCode = `
      vec4 unaryOperation(vec4 x) {
        ${opSnippet}
      }

      void main() {
        vec4 x = getAAtOutCoords();
        vec4 y = unaryOperation(x);

        setOutput(y);
      }
    `;
      }
    };
  }
});
var UnpackProgram;
var init_unpack_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/unpack_gpu.js"() {
    init_gpgpu_math();
    init_packing_util();
    init_shader_compiler();
    UnpackProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = false;
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        const rank = outputShape.length;
        const channels = getChannels("rc", rank);
        const dtype = getCoordsDataType(rank);
        const sourceCoords = getSourceCoords(rank, channels);
        const innerDims = channels.slice(-2);
        const coords2 = rank <= 1 ? "rc" : `vec2(${innerDims.join(",")})`;
        this.userCode = `
      void main() {
        ${dtype} rc = getOutputCoords();
        vec4 packedInput = getA(${sourceCoords});

        setOutput(getChannel(packedInput, ${coords2}));
      }
    `;
      }
    };
  }
});
function getBinaryCache(webGLVersion) {
  if (webGLVersion in binaryCaches) {
    return binaryCaches[webGLVersion];
  }
  binaryCaches[webGLVersion] = {};
  return binaryCaches[webGLVersion];
}
function numMBBeforeWarning() {
  if (env().global.screen == null) {
    return 1024;
  }
  return env().global.screen.height * env().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;
}
function float32ToTypedArray(a, dtype) {
  if (dtype === "float32" || dtype === "complex64") {
    return a;
  } else if (dtype === "int32" || dtype === "bool") {
    const result = dtype === "int32" ? new Int32Array(a.length) : new Uint8Array(a.length);
    for (let i = 0; i < result.length; ++i) {
      result[i] = Math.round(a[i]);
    }
    return result;
  } else {
    throw new Error(`Unknown dtype ${dtype}`);
  }
}
var whereImpl3;
var EPSILON_FLOAT322;
var EPSILON_FLOAT162;
var binaryCaches;
var CPU_HANDOFF_SIZE_THRESHOLD;
var BEFORE_PAGING_CONSTANT;
var MathBackendWebGL;
var init_backend_webgl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/backend_webgl.js"() {
    init_flags_webgl();
    init_dist();
    init_canvas_util();
    init_decode_matrix_gpu();
    init_decode_matrix_packed_gpu();
    init_encode_float_gpu();
    init_encode_float_packed_gpu();
    init_encode_matrix_gpu();
    init_encode_matrix_packed_gpu();
    init_gpgpu_context();
    init_gpgpu_math();
    init_gpgpu_math();
    init_shared2();
    init_pack_gpu();
    init_reshape_packed_gpu();
    init_tex_util();
    init_tex_util();
    init_texture_manager();
    init_unaryop_gpu();
    init_unaryop_gpu();
    init_unaryop_packed_gpu();
    init_unpack_gpu();
    init_webgl_util();
    whereImpl3 = kernel_impls_exports.whereImpl;
    EPSILON_FLOAT322 = 1e-7;
    EPSILON_FLOAT162 = 1e-4;
    binaryCaches = {};
    CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
    BEFORE_PAGING_CONSTANT = 600;
    MathBackendWebGL = class extends KernelBackend {
      constructor(gpuResource) {
        super();
        this.pendingRead = /* @__PURE__ */ new WeakMap();
        this.pendingDisposal = /* @__PURE__ */ new WeakSet();
        this.dataRefCount = /* @__PURE__ */ new WeakMap();
        this.numBytesInGPU = 0;
        this.uploadWaitMs = 0;
        this.downloadWaitMs = 0;
        this.lastGlFlushTime = 0;
        this.warnedAboutMemory = false;
        this.pendingDeletes = 0;
        this.disposed = false;
        if (!env().getBool("HAS_WEBGL")) {
          throw new Error("WebGL is not supported on this device");
        }
        let newGPGPU;
        if (gpuResource != null) {
          if (gpuResource instanceof GPGPUContext) {
            newGPGPU = gpuResource;
          } else {
            const gl = getWebGLContext(env().getNumber("WEBGL_VERSION"), gpuResource);
            newGPGPU = new GPGPUContext(gl);
          }
          this.binaryCache = {};
          this.gpgpuCreatedLocally = false;
        } else {
          const gl = getWebGLContext(env().getNumber("WEBGL_VERSION"));
          newGPGPU = new GPGPUContext(gl);
          this.binaryCache = getBinaryCache(env().getNumber("WEBGL_VERSION"));
          this.gpgpuCreatedLocally = true;
        }
        this.gpgpu = newGPGPU;
        this.canvas = this.gpgpu.gl.canvas;
        this.textureManager = new TextureManager2(this.gpgpu);
        this.numMBBeforeWarning = numMBBeforeWarning();
        this.texData = new DataStorage(this, engine());
      }
      nextDataId() {
        return MathBackendWebGL.nextDataId++;
      }
      numDataIds() {
        return this.texData.numDataIds() - this.pendingDeletes;
      }
      // Writes a new entry to the data store with a WebGL texture, and registers it
      // to the texture manager.
      writeTexture(texture, shape, dtype, texHeight, texWidth, channels) {
        const input2 = this.makeTensorInfo(shape, dtype);
        const inData = this.texData.get(input2.dataId);
        inData.isPacked = false;
        inData.texture = { texture, texShape: [texHeight, texWidth] };
        inData.texShape = [texHeight, texWidth];
        const shapeAs3D = getShapeAs3D(shape);
        const program = new EncodeMatrixProgram(shapeAs3D, false, channels);
        const output = this.runWebGLProgram(program, [input2], dtype, [[texHeight, texWidth]]);
        output.shape = shape;
        inData.texture = null;
        this.disposeIntermediateTensorInfo(input2);
        return output.dataId;
      }
      write(values, shape, dtype) {
        if (env().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || env().getBool("DEBUG")) {
          this.checkNumericalProblems(values);
        }
        if (dtype === "complex64" && values != null) {
          throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
        }
        const dataId = { id: this.nextDataId() };
        this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount: 1 });
        return dataId;
      }
      /** Return refCount of a `TensorData`. */
      refCount(dataId) {
        if (this.texData.has(dataId)) {
          const tensorData = this.texData.get(dataId);
          return tensorData.refCount;
        }
        return 0;
      }
      /** Increase refCount of a `TextureData`. */
      incRef(dataId) {
        const texData = this.texData.get(dataId);
        texData.refCount++;
      }
      /** Decrease refCount of a `TextureData`. */
      decRef(dataId) {
        if (this.texData.has(dataId)) {
          const texData = this.texData.get(dataId);
          texData.refCount--;
        }
      }
      move(dataId, values, shape, dtype, refCount) {
        if (env().getBool("DEBUG")) {
          this.checkNumericalProblems(values);
        }
        if (dtype === "complex64") {
          throw new Error(`Cannot write to a complex64 dtype. Please use tf.complex(real, imag).`);
        }
        this.texData.set(dataId, { shape, dtype, values, usage: TextureUsage.UPLOAD, refCount });
      }
      disposeIntermediateTensorInfo(tensorInfo) {
        this.disposeData(tensorInfo.dataId);
      }
      readSync(dataId) {
        const texData = this.texData.get(dataId);
        const { values, dtype, complexTensorInfos, slice: slice4, shape, isPacked } = texData;
        if (slice4 != null) {
          let program;
          if (isPacked) {
            program = new UnaryOpPackedProgram(shape, CLONE);
          } else {
            program = new UnaryOpProgram(shape, CLONE);
          }
          const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
          const data = this.readSync(res.dataId);
          this.disposeIntermediateTensorInfo(res);
          return data;
        }
        if (values != null) {
          return this.convertAndCacheOnCPU(dataId);
        }
        if (dtype === "string") {
          return values;
        }
        const shouldTimeProgram = this.activeTimers != null;
        let start;
        if (shouldTimeProgram) {
          start = util_exports.now();
        }
        let result;
        if (dtype === "complex64") {
          const realValues = this.readSync(complexTensorInfos.real.dataId);
          const imagValues = this.readSync(complexTensorInfos.imag.dataId);
          result = backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
        } else {
          result = this.getValuesFromTexture(dataId);
        }
        if (shouldTimeProgram) {
          this.downloadWaitMs += util_exports.now() - start;
        }
        return this.convertAndCacheOnCPU(dataId, result);
      }
      async read(dataId) {
        if (this.pendingRead.has(dataId)) {
          const subscribers2 = this.pendingRead.get(dataId);
          return new Promise((resolve) => subscribers2.push(resolve));
        }
        const texData = this.texData.get(dataId);
        const { values, shape, slice: slice4, dtype, complexTensorInfos, isPacked } = texData;
        if (slice4 != null) {
          let program;
          if (isPacked) {
            program = new UnaryOpPackedProgram(shape, CLONE);
          } else {
            program = new UnaryOpProgram(shape, CLONE);
          }
          const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
          const data = this.read(res.dataId);
          this.disposeIntermediateTensorInfo(res);
          return data;
        }
        if (values != null) {
          return this.convertAndCacheOnCPU(dataId);
        }
        if (env().getBool("DEBUG")) {
          if (!env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && env().getNumber("WEBGL_VERSION") === 2) {
            throw new Error(`tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.`);
          }
        }
        let buffer2 = null;
        let tmpDownloadTarget;
        if (dtype !== "complex64" && env().get("WEBGL_BUFFER_SUPPORTED")) {
          tmpDownloadTarget = this.decode(dataId);
          const tmpData = this.texData.get(tmpDownloadTarget.dataId);
          buffer2 = this.gpgpu.createBufferFromTexture(tmpData.texture.texture, ...getDenseTexShape(shape));
        }
        this.pendingRead.set(dataId, []);
        if (dtype !== "complex64") {
          await this.gpgpu.createAndWaitForFence();
        }
        let vals;
        if (dtype === "complex64") {
          const ps = await Promise.all([
            this.read(complexTensorInfos.real.dataId),
            this.read(complexTensorInfos.imag.dataId)
          ]);
          const realValues = ps[0];
          const imagValues = ps[1];
          vals = backend_util_exports.mergeRealAndImagArrays(realValues, imagValues);
        } else if (buffer2 == null) {
          vals = this.getValuesFromTexture(dataId);
        } else {
          const size = util_exports.sizeFromShape(shape);
          vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer2, size);
        }
        if (tmpDownloadTarget != null) {
          this.disposeIntermediateTensorInfo(tmpDownloadTarget);
        }
        if (buffer2 != null) {
          const gl = this.gpgpu.gl;
          callAndCheck(gl, () => gl.deleteBuffer(buffer2));
        }
        const dTypeVals = this.convertAndCacheOnCPU(dataId, vals);
        const subscribers = this.pendingRead.get(dataId);
        this.pendingRead.delete(dataId);
        subscribers.forEach((resolve) => resolve(dTypeVals));
        if (this.pendingDisposal.has(dataId)) {
          this.pendingDisposal.delete(dataId);
          if (this.disposeData(dataId)) {
            engine().removeDataId(dataId, this);
          }
          this.pendingDeletes--;
        }
        return dTypeVals;
      }
      /**
       * Read tensor to a new texture that is densely packed for ease of use.
       * @param dataId The source tensor.
       * @param options
       *     customTexShape: Optional. If set, will use the user defined texture
       *     shape to create the texture.
       */
      readToGPU(dataId, options = {}) {
        const texData = this.texData.get(dataId);
        const { values, shape, slice: slice4, dtype, isPacked, texture } = texData;
        if (dtype === "complex64") {
          throw new Error("Does not support reading texture for complex64 dtype.");
        }
        if (slice4 != null) {
          let program;
          if (isPacked) {
            program = new UnaryOpPackedProgram(shape, CLONE);
          } else {
            program = new UnaryOpProgram(shape, CLONE);
          }
          const res = this.runWebGLProgram(program, [{ dataId, shape, dtype }], dtype);
          const gpuResouorce = this.readToGPU(res, options);
          this.disposeIntermediateTensorInfo(res);
          return gpuResouorce;
        }
        if (texture == null) {
          if (values != null) {
            throw new Error("Data is not on GPU but on CPU.");
          } else {
            throw new Error("There is no data on GPU or CPU.");
          }
        }
        const tmpTarget = this.decode(dataId, options.customTexShape);
        const tensorRef = engine().makeTensorFromTensorInfo(tmpTarget);
        const tmpData = this.texData.get(tmpTarget.dataId);
        return Object.assign({ tensorRef }, tmpData.texture);
      }
      bufferSync(t) {
        const data = this.readSync(t.dataId);
        if (t.dtype === "string") {
          try {
            const strings = data.map((d) => util_exports.decodeString(d));
            return buffer(t.shape, t.dtype, strings);
          } catch (_a2) {
            throw new Error("Failed to decode encoded string bytes into utf-8");
          }
        }
        return buffer(t.shape, t.dtype, data);
      }
      checkNumericalProblems(values) {
        if (values == null) {
          return;
        }
        for (let i = 0; i < values.length; i++) {
          const num = values[i];
          if (!canBeRepresented(num)) {
            if (env().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")) {
              throw Error(`The value ${num} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);
            }
            throw Error(`The value ${num} cannot be represented on this device.`);
          }
        }
      }
      getValuesFromTexture(dataId) {
        const { shape, dtype, isPacked } = this.texData.get(dataId);
        const size = util_exports.sizeFromShape(shape);
        if (env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
          const tmpTarget = this.decode(dataId);
          const tmpData2 = this.texData.get(tmpTarget.dataId);
          const vals2 = this.gpgpu.downloadMatrixFromPackedTexture(tmpData2.texture.texture, ...getDenseTexShape(shape)).subarray(0, size);
          this.disposeIntermediateTensorInfo(tmpTarget);
          return vals2;
        }
        const shouldUsePackedProgram = env().getBool("WEBGL_PACK") && isPacked === true;
        const outputShape = shouldUsePackedProgram ? getShapeAs3D(shape) : shape;
        const program = shouldUsePackedProgram ? new EncodeFloatPackedProgram(outputShape) : new EncodeFloatProgram(outputShape);
        const output = this.runWebGLProgram(program, [{ shape: outputShape, dtype, dataId }], "float32");
        const tmpData = this.texData.get(output.dataId);
        const vals = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture.texture, tmpData.texShape[0], tmpData.texShape[1]).subarray(0, size);
        this.disposeIntermediateTensorInfo(output);
        return vals;
      }
      timerAvailable() {
        return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
      }
      time(f) {
        const oldActiveTimers = this.activeTimers;
        const newActiveTimers = [];
        let outerMostTime = false;
        if (this.programTimersStack == null) {
          this.programTimersStack = newActiveTimers;
          outerMostTime = true;
        } else {
          this.activeTimers.push(newActiveTimers);
        }
        this.activeTimers = newActiveTimers;
        f();
        const flattenedActiveTimerQueries = util_exports.flatten(this.activeTimers.map((d) => d.query)).filter((d) => d != null);
        const flattenedActiveTimerNames = util_exports.flatten(this.activeTimers.map((d) => d.name)).filter((d) => d != null);
        this.activeTimers = oldActiveTimers;
        if (outerMostTime) {
          this.programTimersStack = null;
        }
        const res = {
          uploadWaitMs: this.uploadWaitMs,
          downloadWaitMs: this.downloadWaitMs,
          kernelMs: null,
          wallMs: null
          // will be filled by the engine
        };
        return (async () => {
          if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
            const kernelMs = await Promise.all(flattenedActiveTimerQueries);
            res["kernelMs"] = util_exports.sum(kernelMs);
            res["getExtraProfileInfo"] = () => kernelMs.map((d, i) => ({ name: flattenedActiveTimerNames[i], ms: d })).map((d) => `${d.name}: ${d.ms}`).join(", ");
          } else {
            res["kernelMs"] = {
              error: "WebGL query timers are not supported in this environment."
            };
          }
          this.uploadWaitMs = 0;
          this.downloadWaitMs = 0;
          return res;
        })();
      }
      memory() {
        return {
          unreliable: false,
          numBytesInGPU: this.numBytesInGPU,
          numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
          numBytesInGPUFree: this.textureManager.numBytesFree
        };
      }
      startTimer() {
        if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
          return this.gpgpu.beginQuery();
        }
        return { startMs: util_exports.now(), endMs: null };
      }
      endTimer(query) {
        if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
          this.gpgpu.endQuery();
          return query;
        }
        query.endMs = util_exports.now();
        return query;
      }
      async getQueryTime(query) {
        if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
          return this.gpgpu.waitForQueryAndGetTime(query);
        }
        const timerQuery = query;
        return timerQuery.endMs - timerQuery.startMs;
      }
      /**
       * Decrease the RefCount on the dataId and dispose the memory if the dataId
       * has 0 refCount. If there are pending read on the data, the disposal would
       * added to the pending delete queue. Return true if the dataId is removed
       * from backend or the backend does not contain the dataId, false if the
       * dataId is not removed. Memory may or may not be released even when dataId
       * is removed, which also depends on dataRefCount, see `releaseGPU`.
       * @param dataId
       * @oaram force Optional, remove the data regardless of refCount
       */
      disposeData(dataId, force = false) {
        if (this.pendingDisposal.has(dataId)) {
          return false;
        }
        if (!this.texData.has(dataId)) {
          return true;
        }
        if (force) {
          this.texData.get(dataId).refCount = 0;
        } else {
          this.texData.get(dataId).refCount--;
        }
        if (!force && this.texData.get(dataId).refCount > 0) {
          return false;
        }
        if (this.pendingRead.has(dataId)) {
          this.pendingDisposal.add(dataId);
          this.pendingDeletes++;
          return false;
        }
        this.releaseGPUData(dataId);
        const { complexTensorInfos } = this.texData.get(dataId);
        if (complexTensorInfos != null) {
          this.disposeData(complexTensorInfos.real.dataId, force);
          this.disposeData(complexTensorInfos.imag.dataId, force);
        }
        this.texData.delete(dataId);
        return true;
      }
      releaseGPUData(dataId) {
        const { texture, dtype, texShape, usage, isPacked, slice: slice4 } = this.texData.get(dataId);
        const key = slice4 && slice4.origDataId || dataId;
        const refCount = this.dataRefCount.get(key);
        if (refCount > 1) {
          this.dataRefCount.set(key, refCount - 1);
        } else {
          this.dataRefCount.delete(key);
          if (texture != null) {
            this.numBytesInGPU -= this.computeBytes(texShape, dtype);
            this.textureManager.releaseTexture(texture, texShape, usage, isPacked);
          }
        }
        const texData = this.texData.get(dataId);
        texData.texture = null;
        texData.texShape = null;
        texData.isPacked = false;
        texData.slice = null;
      }
      getTexture(dataId) {
        this.uploadToGPU(dataId);
        return this.texData.get(dataId).texture.texture;
      }
      /**
       * Returns internal information for the specific data bucket. Used in unit
       * tests.
       */
      getDataInfo(dataId) {
        return this.texData.get(dataId);
      }
      /*
      Tests whether all the inputs to an op are small and on the CPU. This heuristic
      determines when it would be faster to execute a kernel on the CPU. WebGL
      kernels opt into running this check and forwarding when appropriate.
      TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more
      sustainable strategy for optimizing backend execution of ops.
       */
      shouldExecuteOnCPU(inputs, sizeThreshold = CPU_HANDOFF_SIZE_THRESHOLD) {
        return env().getBool("WEBGL_CPU_FORWARD") && inputs.every((input2) => this.texData.get(input2.dataId).texture == null && util_exports.sizeFromShape(input2.shape) < sizeThreshold);
      }
      getGPGPUContext() {
        return this.gpgpu;
      }
      where(condition) {
        backend_util_exports.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
        const condVals = condition.dataSync();
        return whereImpl3(condition.shape, condVals);
      }
      packedUnaryOp(x, op2, dtype) {
        const program = new UnaryOpPackedProgram(x.shape, op2);
        const outInfo = this.compileAndRun(program, [x], dtype);
        return engine().makeTensorFromTensorInfo(outInfo);
      }
      // TODO(msoulanille) remove this once the backend has been modularized
      // a copy is needed here to break a circular dependency.
      // Also remove the op from unary_op.
      abs(x) {
        if (this.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
          const outValues = simpleAbsImplCPU(this.texData.get(x.dataId).values);
          return this.makeOutput(x.shape, x.dtype, outValues);
        }
        if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
          return this.packedUnaryOp(x, ABS, x.dtype);
        }
        const program = new UnaryOpProgram(x.shape, ABS);
        const outInfo = this.compileAndRun(program, [x]);
        return engine().makeTensorFromTensorInfo(outInfo);
      }
      makeTensorInfo(shape, dtype, values) {
        let dataId;
        if (dtype === "string" && values != null && values.length > 0 && util_exports.isString(values[0])) {
          const encodedValues = values.map((d) => util_exports.encodeString(d));
          dataId = this.write(encodedValues, shape, dtype);
        } else {
          dataId = this.write(values, shape, dtype);
        }
        this.texData.get(dataId).usage = null;
        return { dataId, shape, dtype };
      }
      makeOutput(shape, dtype, values) {
        return engine().makeTensorFromTensorInfo(this.makeTensorInfo(shape, dtype, values), this);
      }
      unpackTensor(input2) {
        const program = new UnpackProgram(input2.shape);
        return this.runWebGLProgram(program, [input2], input2.dtype);
      }
      packTensor(input2) {
        const program = new PackProgram(input2.shape);
        const preventEagerUnpackingOutput = true;
        return this.runWebGLProgram(program, [input2], input2.dtype, null, preventEagerUnpackingOutput);
      }
      packedReshape(input2, afterShape) {
        const input3DShape = [
          getBatchDim(input2.shape),
          ...getRowsCols(input2.shape)
        ];
        const input3D = {
          dtype: input2.dtype,
          shape: input3DShape,
          dataId: input2.dataId
        };
        const afterShapeAs3D = [
          getBatchDim(afterShape),
          ...getRowsCols(afterShape)
        ];
        const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
        const preventEagerUnpackingOfOutput = true;
        const customValues = [input3DShape];
        const output = this.runWebGLProgram(program, [input3D], input2.dtype, customValues, preventEagerUnpackingOfOutput);
        return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
      }
      decode(dataId, customTexShape) {
        const texData = this.texData.get(dataId);
        const { isPacked, shape, dtype } = texData;
        if (customTexShape != null) {
          const size = util_exports.sizeFromShape(shape);
          const texSize = customTexShape[0] * customTexShape[1] * 4;
          util_exports.assert(size <= texSize, () => "customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data.");
        }
        const shapeAs3D = getShapeAs3D(shape);
        let program;
        if (isPacked) {
          program = new DecodeMatrixPackedProgram(shapeAs3D);
        } else {
          program = new DecodeMatrixProgram(shapeAs3D);
        }
        const preventEagerUnpackingOfOutput = true;
        const customValues = [customTexShape != null ? customTexShape : getDenseTexShape(shapeAs3D)];
        const out = this.runWebGLProgram(program, [{ shape: shapeAs3D, dtype, dataId }], dtype, customValues, preventEagerUnpackingOfOutput, customTexShape);
        return { dtype, shape, dataId: out.dataId };
      }
      runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput = false, customTexShape) {
        const output = this.makeTensorInfo(program.outputShape, outputDtype);
        const outData = this.texData.get(output.dataId);
        if (program.packedOutput) {
          outData.isPacked = true;
        }
        if (program.outPackingScheme === PackingScheme.DENSE) {
          const texelShape = customTexShape != null ? customTexShape : getDenseTexShape(program.outputShape);
          outData.texShape = texelShape.map((d) => d * 2);
        }
        if (program.outTexUsage != null) {
          outData.usage = program.outTexUsage;
        }
        if (util_exports.sizeFromShape(output.shape) === 0) {
          outData.values = util_exports.getTypedArrayFromDType(output.dtype, 0);
          return output;
        }
        const dataToDispose = [];
        const inputsData = inputs.map((input2) => {
          if (input2.dtype === "complex64") {
            throw new Error(`GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.`);
          }
          let texData = this.texData.get(input2.dataId);
          if (texData.texture == null) {
            if (!program.packedInputs && util_exports.sizeFromShape(input2.shape) <= env().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) {
              return {
                shape: input2.shape,
                texData: null,
                isUniform: true,
                uniformValues: texData.values
              };
            }
            if (program.packedInputs) {
              texData.isPacked = true;
              texData.shape = input2.shape;
            }
          }
          this.uploadToGPU(input2.dataId);
          if (!!texData.isPacked !== !!program.packedInputs) {
            input2 = texData.isPacked ? this.unpackTensor(input2) : this.packTensor(input2);
            dataToDispose.push(input2);
            texData = this.texData.get(input2.dataId);
          } else if (texData.isPacked && !isReshapeFree(texData.shape, input2.shape)) {
            const savedInput = input2;
            const targetShape = input2.shape;
            input2.shape = texData.shape;
            input2 = this.packedReshape(input2, targetShape);
            dataToDispose.push(input2);
            texData = this.texData.get(input2.dataId);
            savedInput.shape = targetShape;
          }
          return { shape: input2.shape, texData, isUniform: false };
        });
        this.uploadToGPU(output.dataId);
        const outputData = { shape: output.shape, texData: outData, isUniform: false };
        const key = makeShaderKey(program, inputsData, outputData);
        const binary = this.getAndSaveBinary(key, () => {
          return compileProgram(this.gpgpu, program, inputsData, outputData);
        });
        const shouldTimeProgram = this.activeTimers != null;
        let query;
        if (shouldTimeProgram) {
          query = this.startTimer();
        }
        if (!env().get("ENGINE_COMPILE_ONLY")) {
          runProgram(this.gpgpu, binary, inputsData, outputData, customUniformValues);
        }
        dataToDispose.forEach((info) => this.disposeIntermediateTensorInfo(info));
        if (shouldTimeProgram) {
          query = this.endTimer(query);
          this.activeTimers.push({ name: program.constructor.name, query: this.getQueryTime(query) });
        }
        const glFlushThreshold = env().get("WEBGL_FLUSH_THRESHOLD");
        if (glFlushThreshold > 0) {
          const time = util_exports.now();
          if (time - this.lastGlFlushTime > glFlushThreshold) {
            this.gpgpu.gl.flush();
            this.lastGlFlushTime = time;
          }
        }
        if (!env().getBool("WEBGL_LAZILY_UNPACK") && outData.isPacked && preventEagerUnpackingOfOutput === false) {
          const unpacked = this.unpackTensor(output);
          this.disposeIntermediateTensorInfo(output);
          return unpacked;
        }
        return output;
      }
      compileAndRun(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput = false) {
        outputDtype = outputDtype || inputs[0].dtype;
        const outInfo = this.runWebGLProgram(program, inputs, outputDtype, customUniformValues, preventEagerUnpackingOfOutput);
        return outInfo;
      }
      getAndSaveBinary(key, getBinary) {
        if (!(key in this.binaryCache)) {
          this.binaryCache[key] = getBinary();
        }
        return this.binaryCache[key];
      }
      getTextureManager() {
        return this.textureManager;
      }
      dispose() {
        if (this.disposed) {
          return;
        }
        if (!env().getBool("IS_TEST")) {
          const allKeys = Object.keys(this.binaryCache);
          allKeys.forEach((key) => {
            this.gpgpu.deleteProgram(this.binaryCache[key].webGLProgram);
            delete this.binaryCache[key];
          });
        }
        this.textureManager.dispose();
        if (this.canvas != null && (typeof HTMLCanvasElement !== "undefined" && this.canvas instanceof HTMLCanvasElement)) {
          this.canvas.remove();
        } else {
          this.canvas = null;
        }
        if (this.gpgpuCreatedLocally) {
          this.gpgpu.program = null;
          this.gpgpu.dispose();
        }
        this.disposed = true;
      }
      floatPrecision() {
        if (this.floatPrecisionValue == null) {
          this.floatPrecisionValue = tidy(() => {
            if (!env().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
              const debugFlag = env().getBool("DEBUG");
              env().set("DEBUG", false);
              const underflowCheckValue = this.abs(scalar(1e-8)).dataSync()[0];
              env().set("DEBUG", debugFlag);
              if (underflowCheckValue > 0) {
                return 32;
              }
            }
            return 16;
          });
        }
        return this.floatPrecisionValue;
      }
      /** Returns the smallest representable number.  */
      epsilon() {
        return this.floatPrecision() === 32 ? EPSILON_FLOAT322 : EPSILON_FLOAT162;
      }
      uploadToGPU(dataId) {
        const texData = this.texData.get(dataId);
        const { shape, dtype, values, texture, usage, isPacked } = texData;
        if (texture != null) {
          return;
        }
        const shouldTimeProgram = this.activeTimers != null;
        let start;
        if (shouldTimeProgram) {
          start = util_exports.now();
        }
        let texShape = texData.texShape;
        if (texShape == null) {
          texShape = getTextureShapeFromLogicalShape(shape, isPacked);
          texData.texShape = texShape;
        }
        if (values != null) {
          const shapeAs3D = getShapeAs3D(shape);
          let program;
          let width = texShape[1], height = texShape[0];
          const isByteArray = values instanceof Uint8Array || values instanceof Uint8ClampedArray;
          if (isPacked || !isByteArray) {
            [width, height] = getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]);
          }
          if (isPacked) {
            program = new EncodeMatrixPackedProgram(shapeAs3D, isByteArray);
          } else {
            program = new EncodeMatrixProgram(shapeAs3D, isByteArray);
          }
          const tempDenseInputTexShape = isByteArray ? [height, width] : texShape;
          const tempDenseInputHandle = this.makeTensorInfo(tempDenseInputTexShape, dtype);
          const tempDenseInputTexData = this.texData.get(tempDenseInputHandle.dataId);
          if (isByteArray) {
            tempDenseInputTexData.usage = TextureUsage.PIXELS;
          } else {
            tempDenseInputTexData.usage = TextureUsage.UPLOAD;
          }
          tempDenseInputTexData.texShape = tempDenseInputTexShape;
          this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values);
          const customValues = [[height, width]];
          const preventEagerUnpacking = true;
          const encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, customValues, preventEagerUnpacking);
          const outputTexData = this.texData.get(encodedOutputTarget.dataId);
          texData.texShape = outputTexData.texShape;
          texData.isPacked = outputTexData.isPacked;
          texData.usage = outputTexData.usage;
          if (!env().get("ENGINE_COMPILE_ONLY")) {
            texData.texture = outputTexData.texture;
            texData.values = null;
            this.texData.delete(encodedOutputTarget.dataId);
          } else {
            this.disposeData(encodedOutputTarget.dataId);
          }
          this.disposeIntermediateTensorInfo(tempDenseInputHandle);
          if (shouldTimeProgram) {
            this.uploadWaitMs += util_exports.now() - start;
          }
        } else {
          const newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);
          texData.texture = newTexture;
        }
      }
      convertAndCacheOnCPU(dataId, float32Values) {
        const texData = this.texData.get(dataId);
        const { dtype } = texData;
        if (float32Values != null) {
          texData.values = float32ToTypedArray(float32Values, dtype);
        }
        return texData.values;
      }
      acquireTexture(texShape, texType, dtype, isPacked) {
        this.numBytesInGPU += this.computeBytes(texShape, dtype);
        if (!this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
          const mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
          this.warnedAboutMemory = true;
          console.warn(`High memory usage in GPU: ${mb} MB, most likely due to a memory leak`);
        }
        return this.textureManager.acquireTexture(texShape, texType, isPacked);
      }
      computeBytes(shape, dtype) {
        return shape[0] * shape[1] * util_exports.bytesPerElement(dtype);
      }
      checkCompileCompletion() {
        for (const [, binary] of Object.entries(this.binaryCache)) {
          this.checkCompletion_(binary);
        }
      }
      async checkCompileCompletionAsync() {
        const ps = [];
        if (this.gpgpu.parallelCompilationExtension) {
          for (const [, binary] of Object.entries(this.binaryCache)) {
            ps.push(this.checkCompletionAsync_(binary));
          }
          return Promise.all(ps);
        } else {
          for (const [, binary] of Object.entries(this.binaryCache)) {
            const p2 = new Promise((resolve) => {
              try {
                this.checkCompletion_(binary);
                resolve(true);
              } catch (error) {
                throw error;
              }
            });
            ps.push(p2);
          }
          return Promise.all(ps);
        }
      }
      async checkCompletionAsync_(binary) {
        if (this.gpgpu.gl.getProgramParameter(binary.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR)) {
          return this.checkCompletion_(binary);
        } else {
          await nextFrame();
          return this.checkCompletionAsync_(binary);
        }
      }
      checkCompletion_(binary) {
        if (this.gpgpu.gl.getProgramParameter(binary.webGLProgram, this.gpgpu.gl.LINK_STATUS) === false) {
          console.log(this.gpgpu.gl.getProgramInfoLog(binary.webGLProgram));
          if (this.gpgpu.gl.getShaderParameter(binary.fragmentShader, this.gpgpu.gl.COMPILE_STATUS) === false) {
            logShaderSourceAndInfoLog(binary.source, this.gpgpu.gl.getShaderInfoLog(binary.fragmentShader));
            throw new Error("Failed to compile fragment shader.");
          }
          throw new Error("Failed to link vertex and fragment shaders.");
        }
        return true;
      }
      getUniformLocations() {
        for (const [, binary] of Object.entries(this.binaryCache)) {
          const { uniformLocations, customUniformLocations, infLoc, nanLoc, inShapesLocations, inTexShapesLocations, outShapeLocation, outShapeStridesLocation, outTexShapeLocation } = getUniformLocations(this.gpgpu, binary.program, binary.webGLProgram);
          binary.uniformLocations = uniformLocations;
          binary.customUniformLocations = customUniformLocations;
          binary.infLoc = infLoc;
          binary.nanLoc = nanLoc;
          binary.inShapesLocations = inShapesLocations;
          binary.inTexShapesLocations = inTexShapesLocations;
          binary.outShapeLocation = outShapeLocation;
          binary.outShapeStridesLocation = outShapeStridesLocation;
          binary.outTexShapeLocation = outTexShapeLocation;
        }
      }
      /**
       * Create a TF.js tensor out of an existing WebGL texture. A new texture will
       * be created.
       */
      createTensorFromGPUData(values, shape, dtype) {
        values.channels = values.channels || "RGBA";
        const { texture, height, width, channels } = values;
        const backend2 = engine().backend;
        if (!backend2.gpgpu.gl.isTexture(texture)) {
          throw new Error(`The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.`);
        }
        const dataId = backend2.writeTexture(texture, shape, dtype, height, width, channels);
        return engine().makeTensorFromDataId(dataId, shape, dtype, backend2);
      }
    };
    MathBackendWebGL.nextDataId = 0;
  }
});
var init_webgl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/webgl.js"() {
    init_dist();
  }
});
var init_base3 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/base.js"() {
    init_dist();
    init_backend_webgl();
    init_webgl();
    if (device_util_exports.isBrowser()) {
      registerBackend(
        "webgl",
        () => new MathBackendWebGL(),
        2
        /* priority */
      );
    }
  }
});
var CHECK_NAN_SNIPPET2;
var BinaryOpProgram;
var init_binaryop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/binaryop_gpu.js"() {
    init_dist();
    init_gpgpu_math();
    CHECK_NAN_SNIPPET2 = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
    BinaryOpProgram = class {
      constructor(op2, aShape, bShape) {
        this.variableNames = ["A", "B"];
        this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        this.userCode = `
      float binaryOperation(float a, float b) {
        ${op2}
      }

      void main() {
        float a = getAAtOutCoords();
        float b = getBAtOutCoords();
        setOutput(binaryOperation(a, b));
      }
    `;
      }
    };
  }
});
var CHECK_NAN_SNIPPET_PACKED;
var BinaryOpPackedProgram;
var init_binaryop_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/binaryop_packed_gpu.js"() {
    init_dist();
    init_gpgpu_math();
    init_packing_util();
    init_shader_compiler();
    CHECK_NAN_SNIPPET_PACKED = `
  result.r = isNaN.r ? NAN : result.r;
  result.g = isNaN.g ? NAN : result.g;
  result.b = isNaN.b ? NAN : result.b;
  result.a = isNaN.a ? NAN : result.a;
`;
    BinaryOpPackedProgram = class {
      constructor(op2, aShape, bShape, checkOutOfBounds = false) {
        this.variableNames = ["A", "B"];
        this.supportsBroadcasting = true;
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
        const rank = this.outputShape.length;
        this.enableShapeUniforms = useShapeUniforms(rank);
        let checkOutOfBoundsString = "";
        if (checkOutOfBounds) {
          if (rank === 0 || util_exports.sizeFromShape(this.outputShape) === 1) {
            checkOutOfBoundsString = `
          result.y = 0.;
          result.z = 0.;
          result.w = 0.;
        `;
          } else {
            const dtype = getCoordsDataType(rank);
            checkOutOfBoundsString = `
          ${dtype} coords = getOutputCoords();
        `;
            if (rank === 1) {
              if (this.enableShapeUniforms) {
                checkOutOfBoundsString += `
            result.y = (coords + 1) >= outShape ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
              } else {
                checkOutOfBoundsString += `
            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
              }
            } else {
              const channels = getChannels("coords", rank);
              if (this.enableShapeUniforms) {
                checkOutOfBoundsString += `
            bool nextRowOutOfBounds =
              (${channels[rank - 2]} + 1) >= outShape[${rank} - 2];
            bool nextColOutOfBounds =
              (${channels[rank - 1]} + 1) >= outShape[${rank} - 1];
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
              } else {
                checkOutOfBoundsString += `
            bool nextRowOutOfBounds =
              (${channels[rank - 2]} + 1) >= ${this.outputShape[rank - 2]};
            bool nextColOutOfBounds =
              (${channels[rank - 1]} + 1) >= ${this.outputShape[rank - 1]};
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
              }
            }
          }
        }
        this.userCode = `
      vec4 binaryOperation(vec4 a, vec4 b) {
        ${op2}
      }

      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();

        vec4 result = binaryOperation(a, b);
        ${checkOutOfBoundsString}

        setOutput(result);
      }
    `;
      }
    };
  }
});
function identity22(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  backend2.incRef(x.dataId);
  return { dataId: x.dataId, shape: x.shape, dtype: x.dtype };
}
var identityConfig2;
var init_Identity2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Identity.js"() {
    init_dist();
    identityConfig2 = {
      kernelName: Identity,
      backendName: "webgl",
      kernelFunc: identity22
    };
  }
});
function complex3(args) {
  const { inputs, backend: backend2 } = args;
  const { real: real4, imag: imag4 } = inputs;
  const complexInfo = backend2.makeTensorInfo(real4.shape, "complex64");
  const complex4 = backend2.texData.get(complexInfo.dataId);
  const realTensorInfo = identity22({ inputs: { x: real4 }, backend: backend2 });
  const imagTensorInfo = identity22({ inputs: { x: imag4 }, backend: backend2 });
  complex4.complexTensorInfos = { real: realTensorInfo, imag: imagTensorInfo };
  return complexInfo;
}
var complexConfig2;
var init_Complex2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Complex.js"() {
    init_dist();
    init_Identity2();
    complexConfig2 = {
      kernelName: Complex,
      backendName: "webgl",
      kernelFunc: complex3
    };
  }
});
function leakyRelu3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { alpha } = attrs;
  const $alpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(alpha, "float32"));
  const program = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(LEAKYRELU_PACKED, x.shape, $alpha.shape) : new BinaryOpProgram(LEAKYRELU, x.shape, $alpha.shape);
  const result = backend2.runWebGLProgram(program, [x, $alpha], "float32");
  backend2.disposeIntermediateTensorInfo($alpha);
  return result;
}
var LEAKYRELU;
var LEAKYRELU_PACKED;
var leakyReluConfig2;
var init_LeakyRelu2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LeakyRelu.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    LEAKYRELU = `return (a < 0.) ? b * a : a;`;
    LEAKYRELU_PACKED = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
    leakyReluConfig2 = {
      kernelName: LeakyRelu,
      backendName: "webgl",
      kernelFunc: leakyRelu3
    };
  }
});
function prelu3(args) {
  const { inputs, backend: backend2 } = args;
  const { x, alpha } = inputs;
  const program = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(PRELU_PACKED, x.shape, alpha.shape) : new BinaryOpProgram(PRELU, x.shape, alpha.shape);
  return backend2.runWebGLProgram(program, [x, alpha], "float32");
}
var PRELU;
var PRELU_PACKED;
var preluConfig2;
var init_Prelu2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Prelu.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    PRELU = `return (a < 0.) ? b * a : a;`;
    PRELU_PACKED = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
    preluConfig2 = {
      kernelName: Prelu,
      backendName: "webgl",
      kernelFunc: prelu3
    };
  }
});
function unaryKernelFunc2({ opSnippet, packedOpSnippet, cpuKernelImpl, dtype }) {
  return ({ inputs, backend: backend2 }) => {
    const { x } = inputs;
    const webglBackend = backend2;
    const $dtype = dtype || x.dtype;
    if (webglBackend.shouldExecuteOnCPU([x]) && cpuKernelImpl != null) {
      const xData = webglBackend.texData.get(x.dataId);
      const outValues = cpuKernelImpl(xData.values, $dtype);
      return webglBackend.makeTensorInfo(x.shape, $dtype, outValues);
    }
    const shouldUsePackedProgram = env().getBool("WEBGL_PACK_UNARY_OPERATIONS") && packedOpSnippet != null;
    let program;
    if (shouldUsePackedProgram) {
      program = new UnaryOpPackedProgram(x.shape, packedOpSnippet);
    } else {
      program = new UnaryOpProgram(x.shape, opSnippet);
    }
    return webglBackend.runWebGLProgram(program, [x], $dtype);
  };
}
function binaryKernelFunc2({ opSnippet, packedOpSnippet, checkOutOfBounds = false, supportsComplex = false, cpuKernelImpl, dtype }) {
  return ({ inputs, backend: backend2 }) => {
    const { a, b } = inputs;
    const webglBackend = backend2;
    if (supportsComplex && a.dtype === "complex64") {
      const aData = webglBackend.texData.get(a.dataId);
      const bData = webglBackend.texData.get(b.dataId);
      const [real4, imag4] = [
        [aData.complexTensorInfos.real, bData.complexTensorInfos.real],
        [aData.complexTensorInfos.imag, bData.complexTensorInfos.imag]
      ].map((complexParts) => {
        const [aPart, bPart] = complexParts;
        const aHandle = {
          dataId: aPart.dataId,
          dtype: aPart.dtype,
          shape: a.shape
        };
        const bHandle = {
          dataId: bPart.dataId,
          dtype: bPart.dtype,
          shape: b.shape
        };
        const program2 = new BinaryOpProgram(opSnippet, a.shape, b.shape);
        return webglBackend.runWebGLProgram(program2, [aHandle, bHandle], upcastType(aPart.dtype, bPart.dtype));
      });
      const complexOutput = complex3({ inputs: { real: real4, imag: imag4 }, backend: webglBackend });
      webglBackend.disposeIntermediateTensorInfo(real4);
      webglBackend.disposeIntermediateTensorInfo(imag4);
      return complexOutput;
    }
    const $dtype = dtype || upcastType(a.dtype, b.dtype);
    if ((a.dtype === "string" || b.dtype === "string" || webglBackend.shouldExecuteOnCPU([a, b])) && cpuKernelImpl != null) {
      const aVals = webglBackend.texData.get(a.dataId).values;
      const bVals = webglBackend.texData.get(b.dataId).values;
      const decodedAVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(aVals)
      ) : aVals;
      const decodedBVals = a.dtype === "string" ? (
        // tslint:disable-next-line: no-any
        backend_util_exports.fromUint8ToStringArray(bVals)
      ) : bVals;
      const [outValues, outShape] = cpuKernelImpl(a.shape, b.shape, decodedAVals, decodedBVals, $dtype);
      const out = webglBackend.makeTensorInfo(outShape, $dtype);
      const outData = webglBackend.texData.get(out.dataId);
      outData.values = outValues;
      return out;
    }
    const shouldUsePackedProgram = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") && packedOpSnippet != null;
    let program;
    if (shouldUsePackedProgram) {
      program = new BinaryOpPackedProgram(packedOpSnippet, a.shape, b.shape, checkOutOfBounds);
    } else {
      program = new BinaryOpProgram(opSnippet, a.shape, b.shape);
    }
    return webglBackend.runWebGLProgram(program, [a, b], $dtype);
  };
}
function mapActivationToShaderProgram(activation, packed = false) {
  if (activation === "linear") {
    if (packed) {
      return LINEAR2;
    }
    return LINEAR;
  } else if (activation === "relu") {
    if (packed) {
      return RELU2;
    }
    return RELU;
  } else if (activation === "elu") {
    if (packed) {
      return ELU3;
    }
    return ELU2;
  } else if (activation === "relu6") {
    if (packed) {
      return RELU62;
    }
    return RELU6;
  } else if (activation === "prelu") {
    if (packed) {
      return PRELU_PACKED;
    }
    return PRELU;
  } else if (activation === "leakyrelu") {
    if (packed) {
      return LEAKYRELU_PACKED;
    }
    return LEAKYRELU;
  } else if (activation === "sigmoid") {
    if (packed) {
      return SIGMOID2;
    }
    return SIGMOID;
  }
  throw new Error(`Activation ${activation} has not been implemented for the WebGL backend.`);
}
var CHECK_NAN_SNIPPET_UNARY;
var init_kernel_funcs_utils = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/kernel_funcs_utils.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    init_Complex2();
    init_LeakyRelu2();
    init_Prelu2();
    init_unaryop_gpu();
    init_unaryop_gpu();
    init_unaryop_packed_gpu();
    init_unaryop_packed_gpu();
    CHECK_NAN_SNIPPET_UNARY = `if (isnan(x)) return x;`;
  }
});
var MatMulPackedProgram;
var init_mulmat_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/mulmat_packed_gpu.js"() {
    init_gpgpu_math();
    MatMulPackedProgram = class {
      constructor(aShape, bShape, outputShape, transposeA = false, transposeB = false, addBias = false, activation = null, hasPreluActivation = false, hasLeakyreluActivation = false) {
        this.variableNames = ["matrixA", "matrixB"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        const sharedDim = transposeA ? aShape[1] : aShape[2];
        const sharedDimensionPacked = Math.ceil(sharedDim / 2);
        const aSample = transposeA ? "i * 2, rc.y" : "rc.y, i * 2";
        const bSample = transposeB ? "rc.z, i * 2" : "i * 2, rc.z";
        const aSwizzle = transposeA ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"];
        const bSwizzle = transposeB ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
        let activationSnippet = "", applyActivationSnippet = "";
        if (activation) {
          if (hasPreluActivation) {
            activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
          } else if (hasLeakyreluActivation) {
            activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
          } else {
            activationSnippet = `vec4 activation(vec4 x) {
          ${activation}
        }`;
          }
          applyActivationSnippet = `result = activation(result);`;
        }
        const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
        if (addBias) {
          this.variableNames.push("bias");
        }
        if (hasPreluActivation) {
          this.variableNames.push("preluActivationWeights");
        }
        if (hasLeakyreluActivation) {
          this.variableNames.push("leakyreluAlpha");
        }
        let batchASnippet = "rc.x";
        let batchBSnippet = "rc.x";
        if (aShape[0] < bShape[0]) {
          batchASnippet = `imod(rc.x, ${aShape[0]})`;
        } else if (bShape[0] < aShape[0]) {
          batchBSnippet = `imod(rc.x, ${bShape[0]})`;
        }
        this.userCode = `
      ${activationSnippet}
      // Don't use uniform for sharedDimensionPacked for performance.
      const float sharedDimension = ${sharedDimensionPacked}.0;

      vec4 dot2x2ARowBCol(ivec3 rc) {
        vec4 result = vec4(0);
        int batchA = ${batchASnippet};
        int batchB = ${batchBSnippet};
        for (int i = 0; i < ${sharedDimensionPacked}; i++) {
          vec4 a = getMatrixA(batchA, ${aSample});
          vec4 b = getMatrixB(batchB, ${bSample});

          // These swizzled products need to be separately added.
          // See: https://github.com/tensorflow/tfjs/issues/1735
          result += (${aSwizzle[0]} * ${bSwizzle[0]});
          result += (${aSwizzle[1]} * ${bSwizzle[1]});
        }
        return result;
      }

      void main() {
        ivec3 rc = getOutputCoords();
        vec4 result = dot2x2ARowBCol(rc);

        ${addBiasSnippet}

        ${applyActivationSnippet}

        setOutput(result);
      }
    `;
      }
    };
  }
});
var COMPLEX_MULTIPLY;
var BinaryOpComplexProgram;
var init_binaryop_complex_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/binaryop_complex_gpu.js"() {
    init_dist();
    COMPLEX_MULTIPLY = {
      REAL: "return areal * breal - aimag * bimag;",
      IMAG: "return areal * bimag + aimag * breal;"
    };
    BinaryOpComplexProgram = class {
      constructor(op2, aShape, bShape) {
        this.variableNames = ["AReal", "AImag", "BReal", "BImag"];
        this.outputShape = backend_util_exports.assertAndGetBroadcastShape(aShape, bShape);
        this.userCode = `
      float binaryOpComplex(
          float areal, float aimag, float breal, float bimag) {
        ${op2}
      }

      void main() {
        float areal = getARealAtOutCoords();
        float aimag = getAImagAtOutCoords();
        float breal = getBRealAtOutCoords();
        float bimag = getBImagAtOutCoords();
        setOutput(binaryOpComplex(areal, aimag, breal, bimag));
      }
    `;
      }
    };
  }
});
function multiply22(args) {
  const { inputs, backend: backend2 } = args;
  const { a, b } = inputs;
  const dtype = backend_util_exports.upcastType(a.dtype, b.dtype);
  if (a.dtype === "complex64") {
    const aData = backend2.texData.get(a.dataId);
    const bData = backend2.texData.get(b.dataId);
    const realProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL, a.shape, b.shape);
    const imagProgram = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG, a.shape, b.shape);
    const inputs2 = [
      {
        dataId: aData.complexTensorInfos.real.dataId,
        dtype: aData.complexTensorInfos.real.dtype,
        shape: a.shape
      },
      {
        dataId: aData.complexTensorInfos.imag.dataId,
        dtype: aData.complexTensorInfos.imag.dtype,
        shape: a.shape
      },
      {
        dataId: bData.complexTensorInfos.real.dataId,
        dtype: bData.complexTensorInfos.real.dtype,
        shape: b.shape
      },
      {
        dataId: bData.complexTensorInfos.imag.dataId,
        dtype: bData.complexTensorInfos.imag.dtype,
        shape: b.shape
      }
    ];
    const realPart = backend2.runWebGLProgram(realProgram, inputs2, "float32");
    const imagPart = backend2.runWebGLProgram(imagProgram, inputs2, "float32");
    const complexOutput = complex3({ inputs: { real: realPart, imag: imagPart }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(realPart);
    backend2.disposeIntermediateTensorInfo(imagPart);
    return complexOutput;
  }
  if (backend2.shouldExecuteOnCPU([a, b])) {
    const aData = backend2.texData.get(a.dataId);
    const bData = backend2.texData.get(b.dataId);
    const [outValues, outShape] = multiplyImplCPU(a.shape, b.shape, aData.values, bData.values, dtype);
    const out = backend2.makeTensorInfo(outShape, dtype);
    const outData = backend2.texData.get(out.dataId);
    outData.values = outValues;
    return out;
  }
  let program;
  if (env().getBool("WEBGL_PACK_BINARY_OPERATIONS")) {
    program = new BinaryOpPackedProgram(MUL, a.shape, b.shape);
  } else {
    program = new BinaryOpProgram(MUL, a.shape, b.shape);
  }
  return backend2.runWebGLProgram(program, [a, b], dtype);
}
var MUL;
var multiplyConfig2;
var init_Multiply2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Multiply.js"() {
    init_dist();
    init_binaryop_complex_gpu();
    init_binaryop_complex_gpu();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    init_shared2();
    init_Complex2();
    MUL = "return a * b;";
    multiplyConfig2 = {
      kernelName: Multiply,
      backendName: "webgl",
      kernelFunc: multiply22
    };
  }
});
function packedReshape(input2, afterShape, backend2) {
  const input3DShape = [
    getBatchDim(input2.shape),
    ...getRowsCols(input2.shape)
  ];
  const input3D = {
    dtype: input2.dtype,
    shape: input3DShape,
    dataId: input2.dataId
  };
  const afterShapeAs3D = [
    getBatchDim(afterShape),
    ...getRowsCols(afterShape)
  ];
  const program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);
  const preventEagerUnpackingOfOutput = true;
  const customValues = [input3DShape];
  const output = backend2.runWebGLProgram(program, [input3D], input2.dtype, customValues, preventEagerUnpackingOfOutput);
  return { dataId: output.dataId, shape: afterShape, dtype: output.dtype };
}
var init_reshape3 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/reshape.js"() {
    init_reshape_packed_gpu();
    init_webgl_util();
  }
});
function reshape3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { shape } = attrs;
  const webglBackend = backend2;
  const xSize = util_exports.sizeFromShape(x.shape);
  const $shape = util_exports.inferFromImplicitShape(shape, xSize);
  const $xSize = util_exports.sizeFromShape($shape);
  util_exports.assert(xSize === $xSize, () => `The new shape (${$shape}) has ${$xSize} elements and the old shape (${x.shape}) has ${xSize} elements. The new shape and old shape must have the same number of elements.`);
  const xTexData = webglBackend.texData.get(x.dataId);
  if (xTexData.isPacked && !isReshapeFree(x.shape, $shape) && !(xTexData.texture !== null && isReshapeFree(xTexData.shape, $shape))) {
    return packedReshape(x, $shape, webglBackend);
  }
  webglBackend.incRef(x.dataId);
  return { dataId: x.dataId, shape: $shape, dtype: x.dtype };
}
var reshapeConfig2;
var init_Reshape2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Reshape.js"() {
    init_dist();
    init_reshape3();
    init_webgl_util();
    reshapeConfig2 = {
      kernelName: Reshape,
      backendName: "webgl",
      kernelFunc: reshape3
    };
  }
});
var MeanProgram;
var init_mean_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/mean_gpu.js"() {
    init_dist();
    MeanProgram = class {
      constructor(reduceInfo, divisor) {
        this.variableNames = ["x"];
        const { windowSize, batchSize, inSize, outSize } = reduceInfo;
        this.outputShape = [batchSize, outSize];
        const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
        const windowSizeVec4Remainder = windowSize % 4;
        let updateSnippet = `sumValue += dot(values, ones);`;
        if (divisor != null) {
          const denominator = 1 / divisor;
          updateSnippet = `sumValue += dot(values * ${util_exports.isInt(denominator) ? denominator.toPrecision(2) : denominator}, ones);`;
        }
        let checkOutOfBounds = "";
        if (inSize % windowSize > 0) {
          checkOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return 0.0;
        }
      `;
        }
        this.userCode = `
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${checkOutOfBounds}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        float sumValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1), 0.0, 0.0);

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2), 0.0);

          ${updateSnippet}
        }
        setOutput(sumValue);
      }
    `;
      }
    };
  }
});
var ReduceProgram;
var init_reduce_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/reduce_gpu.js"() {
    ReduceProgram = class {
      constructor(reduceInfo, reduceType) {
        this.variableNames = ["x"];
        const { windowSize, batchSize, inSize, outSize } = reduceInfo;
        this.outputShape = [batchSize, outSize];
        let initializationValue = "0.0";
        let compareOp = ``;
        if (reduceType === "prod") {
          initializationValue = "1.0";
        } else if (reduceType === "min") {
          initializationValue = "1.0 / 1e-20";
          compareOp = `min`;
        } else if (reduceType === "max") {
          initializationValue = "-1.0 / 1e-20";
          compareOp = `max`;
        }
        let returnValue = `${reduceType}(${reduceType}(${reduceType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
        if (reduceType === "sum") {
          returnValue = `sumValue`;
        } else if (reduceType === "prod") {
          returnValue = `prodValue`;
        } else if (reduceType === "all") {
          returnValue = `allValue`;
        } else if (reduceType === "any") {
          returnValue = `anyValue`;
        }
        const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
        const windowSizeVec4Remainder = windowSize % 4;
        let updateSnippet = `
      if (${reduceType === "sum"}) {
        sumValue += dot(values, ones);
      } else if (${reduceType === "prod"}) {
        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);
        prodValue *= tmp[0] * tmp[1];
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
        if (${reduceType === "min"} || ${reduceType === "max"}) {
          minMaxValue = ${compareOp}(values, minMaxValue);
          bvec4 isNaN = isnan(values);
          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {
            minMaxValue = vec4(NAN);
          }
        }
      }
    `;
        let vecType = `vec4`;
        if (reduceType === "all") {
          initializationValue = "1.0";
          updateSnippet = `
        bool reducedAllValue = all(values);
        float floatedReducedAllValue = float(reducedAllValue);
        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);
      `;
          vecType = `bvec4`;
        } else if (reduceType === "any") {
          initializationValue = "0.0";
          updateSnippet = `
        bool reducedAnyValue = any(values);
        float floatedReducedAnyValue = float(reducedAnyValue);
        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);
      `;
          vecType = `bvec4`;
        }
        let checkOutOfBounds = "";
        if (inSize % windowSize > 0) {
          checkOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return initializationValue;
        }
      `;
        }
        this.userCode = `
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${checkOutOfBounds}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        vec4 minMaxValue = vec4(${initializationValue});
        float prodValue = 1.0;
        float sumValue = 0.0;
        float allValue = 1.0;
        float anyValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          ${vecType} values = ${vecType}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          ${updateSnippet}
        }
        setOutput(${returnValue});
      }
    `;
      }
    };
  }
});
function getReductionStages(inShape) {
  const stages = [];
  while (stages.length === 0 || stages[stages.length - 1].outSize !== 1) {
    const outSize = stages.length ? stages[stages.length - 1].outSize : inShape[1];
    const windowSize = backend_util_exports.computeOptimalWindowSize(outSize);
    stages.push({
      inSize: outSize,
      windowSize,
      outSize: Math.ceil(outSize / windowSize)
    });
  }
  return stages;
}
function reduce(x, dtype, reductionType, backend2) {
  const reductionStages = getReductionStages(x.shape);
  let result = x;
  for (let i = 0; i < reductionStages.length; i++) {
    const { inSize, windowSize, outSize } = reductionStages[i];
    let program;
    let previousResult;
    if (reductionType === "mean") {
      program = i === 0 ? new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, inSize) : new MeanProgram({ windowSize, inSize, batchSize: x.shape[0], outSize });
    } else {
      program = new ReduceProgram({ windowSize, inSize, batchSize: x.shape[0], outSize }, reductionType);
    }
    previousResult = result;
    result = backend2.runWebGLProgram(program, [result], dtype);
    if (previousResult.dataId !== x.dataId) {
      backend2.disposeIntermediateTensorInfo(previousResult);
    }
  }
  return result;
}
var init_reduce = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/reduce.js"() {
    init_dist();
    init_mean_gpu();
    init_reduce_gpu();
  }
});
function getSwitchedCoords(newDim) {
  const rank = newDim.length;
  if (rank > 6) {
    throw Error(`Transpose for rank ${rank} is not yet supported`);
  }
  const originalOrder = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"];
  const switchedCoords = new Array(rank);
  for (let i = 0; i < newDim.length; i++) {
    switchedCoords[newDim[i]] = originalOrder[i];
  }
  return switchedCoords.join();
}
var TransposeProgram;
var init_transpose_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/transpose_gpu.js"() {
    init_shader_compiler();
    TransposeProgram = class {
      constructor(aShape, newDim) {
        this.variableNames = ["A"];
        const outputShape = new Array(aShape.length);
        for (let i = 0; i < outputShape.length; i++) {
          outputShape[i] = aShape[newDim[i]];
        }
        this.outputShape = outputShape;
        this.rank = outputShape.length;
        const dtype = getCoordsDataType(this.rank);
        const switched = getSwitchedCoords(newDim);
        this.userCode = `
    void main() {
      ${dtype} resRC = getOutputCoords();
      setOutput(getA(${switched}));
    }
    `;
      }
    };
  }
});
var TransposePackedProgram;
var init_transpose_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/transpose_packed_gpu.js"() {
    init_packing_util();
    init_shader_compiler();
    TransposePackedProgram = class {
      constructor(aShape, newDim) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        const outputShape = new Array(aShape.length);
        for (let i = 0; i < outputShape.length; i++) {
          outputShape[i] = aShape[newDim[i]];
        }
        this.outputShape = outputShape;
        this.rank = outputShape.length;
        if (this.rank > 6) {
          throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
        }
        const dtype = getCoordsDataType(this.rank);
        const outputOrder = getVecChannels("rc", this.rank);
        const switchedOrder = new Array(this.rank);
        for (let i = 0; i < newDim.length; i++) {
          switchedOrder[newDim[i]] = outputOrder[i];
        }
        const innerDims = `vec2(${switchedOrder.slice(-2).join()})`;
        const nextColumn = `++${outputOrder[this.rank - 1]} < ${outputShape[this.rank - 1]}`;
        const getc = `getChannel(getA(${switchedOrder.join()}), ${innerDims})`;
        this.userCode = `
    void main() {
      ${dtype} rc = getOutputCoords();
      vec4 result = vec4(0.);
      result[0] = ${getc};
      if(${nextColumn}) {
        result[1] = ${getc};
      }
      --${outputOrder[this.rank - 1]};
      if(++${outputOrder[this.rank - 2]} < ${outputShape[this.rank - 2]}) {
        result[2] = ${getc};
        if(${nextColumn}) {
          result[3] = ${getc};
        }
      }
      setOutput(result);
    }
    `;
      }
    };
  }
});
function transposeImpl2(x, perm, backend2) {
  const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TransposePackedProgram(x.shape, perm) : new TransposeProgram(x.shape, perm);
  return backend2.runWebGLProgram(program, [x], x.dtype);
}
var init_Transpose_impl2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Transpose_impl.js"() {
    init_dist();
    init_shared2();
    init_transpose_gpu();
    init_transpose_packed_gpu();
  }
});
function sumImpl(x, axis, keepDims, backend2) {
  const reductionIndices = axis;
  const xRank = x.shape.length;
  const origAxes = util_exports.parseAxisParam(reductionIndices, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  const sumInputIsTransposed = permutedAxes != null;
  let sumInput = x;
  if (sumInputIsTransposed) {
    sumInput = transposeImpl2(x, permutedAxes, backend2);
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports.assertAxesAreInnerMostDims("sum", axes, xRank);
  const [sumOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(sumInput.shape, axes);
  let outShape = sumOutShape;
  if (keepDims) {
    outShape = backend_util_exports.expandShapeToKeepDim(sumOutShape, origAxes);
  }
  const inSize = util_exports.sizeFromShape(reduceShape);
  const xSize = util_exports.sizeFromShape(x.shape);
  const batchSize = xSize / inSize;
  const reshapedInput = reshape3({ inputs: { x: sumInput }, attrs: { shape: [batchSize, inSize] }, backend: backend2 });
  const outType = sumOutType(x.dtype);
  const reduced = reduce(reshapedInput, outType, "sum", backend2);
  const out = reshape3({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(reshapedInput);
  backend2.disposeIntermediateTensorInfo(reduced);
  if (sumInputIsTransposed) {
    backend2.disposeIntermediateTensorInfo(sumInput);
  }
  return out;
}
var init_Sum_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sum_impl.js"() {
    init_dist();
    init_reduce();
    init_Reshape2();
    init_Transpose_impl2();
  }
});
function sum4(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  return sumImpl(x, axis, keepDims, backend2);
}
var sumConfig2;
var init_Sum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sum.js"() {
    init_dist();
    init_Sum_impl();
    sumConfig2 = {
      kernelName: Sum,
      backendName: "webgl",
      kernelFunc: sum4
    };
  }
});
function transpose3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { perm } = attrs;
  const webglBackend = backend2;
  const xRank = x.shape.length;
  const newShape = new Array(xRank);
  for (let i = 0; i < newShape.length; i++) {
    newShape[i] = x.shape[perm[i]];
  }
  let out;
  if (webglBackend.shouldExecuteOnCPU([x])) {
    const xTexData = webglBackend.texData.get(x.dataId);
    const values = xTexData.values;
    const outValues = transposeImplCPU(values, x.shape, x.dtype, perm, newShape);
    out = webglBackend.makeTensorInfo(newShape, x.dtype);
    const outData = webglBackend.texData.get(out.dataId);
    outData.values = outValues;
  } else {
    out = transposeImpl2(x, perm, webglBackend);
  }
  return out;
}
var transposeConfig2;
var init_Transpose2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Transpose.js"() {
    init_dist();
    init_Transpose_impl2();
    init_Transpose_impl2();
    transposeConfig2 = {
      kernelName: Transpose,
      backendName: "webgl",
      kernelFunc: transpose3
    };
  }
});
function batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const aRank = a.shape.length;
  const bRank = b.shape.length;
  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];
  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];
  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];
  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];
  const outerDimsA = a.shape.slice(0, -2);
  const outerDimsB = b.shape.slice(0, -2);
  const batchDimA = util_exports.sizeFromShape(outerDimsA);
  const batchDimB = util_exports.sizeFromShape(outerDimsB);
  const outShapeOuterDims = broadcast_util_exports.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));
  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);
  util_exports.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (${innerShapeB}) of Tensors with shapes ${a.shape} and ${b.shape} and transposeA=${transposeA} and transposeB=${transposeB} must match.`);
  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];
  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];
  const a3d = reshape3({ inputs: { x: a }, backend: backend2, attrs: { shape: a3dShape } });
  const b3d = reshape3({ inputs: { x: b }, backend: backend2, attrs: { shape: b3dShape } });
  const intermediates = [a3d, b3d];
  const batchDim = Math.max(batchDimA, batchDimB);
  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation === "leakyrelu";
  const fusedActivation = activation != null ? mapActivationToShaderProgram(activation, true) : null;
  const containsFusedOps = hasBias || hasPreluActivationWeights || hasLeakyreluAlpha || fusedActivation != null;
  let out;
  if ((outerShapeA === 1 || outerShapeB === 1) && sharedDim > MATMUL_SHARED_DIM_THRESHOLD && containsFusedOps === false) {
    let aVec = a3d;
    let bVec = b3d;
    if (transposeA) {
      aVec = transpose3({ inputs: { x: a3d }, backend: backend2, attrs: { perm: [0, 2, 1] } });
      intermediates.push(aVec);
    }
    if (transposeB) {
      bVec = transpose3({ inputs: { x: b3d }, backend: backend2, attrs: { perm: [0, 2, 1] } });
      intermediates.push(bVec);
    }
    const shouldReshapeA = outerShapeB !== 1;
    const shouldReshapeB = outerShapeB === 1;
    let aVec3d = aVec;
    if (shouldReshapeA) {
      aVec3d = reshape3({
        inputs: { x: aVec },
        backend: backend2,
        attrs: { shape: [batchDim, sharedDim, 1] }
      });
      intermediates.push(aVec3d);
    }
    const axis = outerShapeB === 1 ? 2 : 1;
    let bVec3d = bVec;
    if (shouldReshapeB) {
      bVec3d = reshape3({
        inputs: { x: bVec },
        backend: backend2,
        attrs: { shape: [batchDim, 1, sharedDim] }
      });
      intermediates.push(bVec3d);
    }
    const product = multiply22({ inputs: { a: aVec3d, b: bVec3d }, backend: backend2 });
    out = sum4({ inputs: { x: product }, backend: backend2, attrs: { axis, keepDims: true } });
    intermediates.push(product);
  } else {
    const dtype = upcastType(a.dtype, b.dtype);
    const program = new MatMulPackedProgram(a3dShape, b3dShape, [batchDim, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    const inputs = [a3d, b3d];
    if (bias != null) {
      inputs.push(bias);
    }
    if (hasPreluActivationWeights) {
      inputs.push(preluActivationWeights);
    }
    if (hasLeakyreluAlpha) {
      const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
      inputs.push($leakyreluAlpha);
      intermediates.push($leakyreluAlpha);
    }
    out = backend2.runWebGLProgram(program, inputs, dtype);
  }
  const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: outShape } });
  intermediates.push(out);
  for (const i of intermediates) {
    backend2.disposeIntermediateTensorInfo(i);
  }
  return outReshaped;
}
var MATMUL_SHARED_DIM_THRESHOLD;
var init_BatchMatMul_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul_impl.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_mulmat_packed_gpu();
    init_Multiply2();
    init_Reshape2();
    init_Sum2();
    init_Transpose2();
    MATMUL_SHARED_DIM_THRESHOLD = 1e3;
  }
});
function _fusedMatMul2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { a, b, bias, preluActivationWeights } = inputs;
  const { transposeA, transposeB, activation, leakyreluAlpha } = attrs;
  return batchMatMulImpl({
    a,
    b,
    transposeA,
    transposeB,
    backend: backend2,
    bias,
    preluActivationWeights,
    leakyreluAlpha,
    activation
  });
}
var _fusedMatMulConfig2;
var init_FusedMatMul2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/_FusedMatMul.js"() {
    init_dist();
    init_BatchMatMul_impl();
    _fusedMatMulConfig2 = {
      kernelName: _FusedMatMul,
      backendName: "webgl",
      kernelFunc: _fusedMatMul2
    };
  }
});
function abs3(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (backend2.shouldExecuteOnCPU([x]) && x.dtype !== "complex64") {
    const xData = backend2.texData.get(x.dataId);
    const outValues = simpleAbsImplCPU(xData.values);
    return backend2.makeTensorInfo(x.shape, x.dtype, outValues);
  }
  let program;
  if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
    program = new UnaryOpPackedProgram(x.shape, ABS2);
  } else {
    program = new UnaryOpProgram(x.shape, ABS2);
  }
  return backend2.runWebGLProgram(program, [x], x.dtype);
}
var ABS2;
var absConfig2;
var init_Abs2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Abs.js"() {
    init_dist();
    init_shared2();
    init_unaryop_gpu();
    init_unaryop_packed_gpu();
    ABS2 = `return abs(x);`;
    absConfig2 = {
      kernelName: Abs,
      backendName: "webgl",
      kernelFunc: abs3
    };
  }
});
var ACOS;
var acos3;
var acosConfig2;
var init_Acos2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Acos.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    ACOS = CHECK_NAN_SNIPPET + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return acos(x);
`;
    acos3 = unaryKernelFunc2({ opSnippet: ACOS });
    acosConfig2 = {
      kernelName: Acos,
      backendName: "webgl",
      kernelFunc: acos3
    };
  }
});
var ACOSH;
var acosh3;
var acoshConfig2;
var init_Acosh2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Acosh.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    ACOSH = CHECK_NAN_SNIPPET + `
  if (x < 1.0) return NAN;
return log(x + sqrt(x * x - 1.0));`;
    acosh3 = unaryKernelFunc2({ opSnippet: ACOSH });
    acoshConfig2 = {
      kernelName: Acosh,
      backendName: "webgl",
      kernelFunc: acosh3
    };
  }
});
var ADD;
var addKernelFunc;
var addConfig2;
var init_Add2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Add.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    ADD = "return a + b;";
    addKernelFunc = binaryKernelFunc2({
      opSnippet: ADD,
      packedOpSnippet: ADD,
      supportsComplex: true,
      cpuKernelImpl: addImplCPU
    });
    addConfig2 = {
      kernelName: Add,
      backendName: "webgl",
      kernelFunc: addKernelFunc
    };
  }
});
var AddNProgram;
var init_addn_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/addn_gpu.js"() {
    AddNProgram = class {
      constructor(outputShape, shapes) {
        this.outputShape = [];
        this.outputShape = outputShape;
        this.variableNames = shapes.map((_, i) => `T${i}`);
        const snippets = [];
        this.variableNames.forEach((variable2) => {
          snippets.push(`float v${variable2} = get${variable2}AtOutCoords();`);
        });
        const operation = this.variableNames.map((variable2) => {
          return `v${variable2}`;
        }).join(" + ");
        this.userCode = `
      void main() {
        ${snippets.join("\n        ")}

        float result = ${operation};
        setOutput(result);
      }
    `;
      }
    };
  }
});
var AddNPackedProgram;
var init_addn_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/addn_packed_gpu.js"() {
    AddNPackedProgram = class {
      constructor(outputShape, shapes) {
        this.outputShape = [];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = outputShape;
        this.variableNames = shapes.map((_, i) => `T${i}`);
        const snippets = [];
        this.variableNames.forEach((variable2) => {
          snippets.push(`vec4 v${variable2} = get${variable2}AtOutCoords();`);
        });
        const operation = this.variableNames.map((variable2) => {
          return `v${variable2}`;
        }).join(" + ");
        this.userCode = `
      void main() {
        ${snippets.join("\n        ")}

        vec4 result = ${operation};
        setOutput(result);
      }
    `;
      }
    };
  }
});
function addN2(args) {
  const { inputs, backend: backend2 } = args;
  const tensors = inputs;
  if (tensors.length === 1) {
    return identity22({ inputs: { x: tensors[0] }, backend: backend2 });
  }
  if (tensors.length > env().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    const midIndex = Math.floor(tensors.length / 2);
    const leftSide = addN2({ inputs: tensors.slice(0, midIndex), backend: backend2 });
    const rightSide = addN2({ inputs: tensors.slice(midIndex), backend: backend2 });
    return addN2({ inputs: [leftSide, rightSide], backend: backend2 });
  }
  const dtype = tensors.map((t) => t.dtype).reduce((d1, d2) => upcastType(d1, d2));
  const shapes = tensors.map((t) => t.shape);
  const usePackedOp = env().getBool("WEBGL_PACK");
  const program = usePackedOp ? new AddNPackedProgram(tensors[0].shape, shapes) : new AddNProgram(tensors[0].shape, shapes);
  return backend2.runWebGLProgram(program, tensors, dtype);
}
var addNConfig2;
var init_AddN2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AddN.js"() {
    init_dist();
    init_addn_gpu();
    init_addn_packed_gpu();
    init_Identity2();
    addNConfig2 = {
      kernelName: AddN,
      backendName: "webgl",
      kernelFunc: addN2
    };
  }
});
function all3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports.assertAxesAreInnerMostDims("all", axes, xRank);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
  const inSize = util_exports.sizeFromShape(reduceShape);
  const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
  const reduced = reduce(a2D, a2D.dtype, "all", backend2);
  let res;
  if (keepDims) {
    const newShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: newShape } });
  } else {
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
  }
  backend2.disposeIntermediateTensorInfo(a2D);
  backend2.disposeIntermediateTensorInfo(reduced);
  if (permutedAxes != null) {
    backend2.disposeIntermediateTensorInfo(permutedX);
  }
  return res;
}
var allConfig2;
var init_All2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/All.js"() {
    init_dist();
    init_reduce();
    init_Reshape2();
    init_Transpose2();
    allConfig2 = {
      kernelName: All,
      backendName: "webgl",
      kernelFunc: all3
    };
  }
});
function any3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports.assertAxesAreInnerMostDims("any", axes, xRank);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
  const inSize = util_exports.sizeFromShape(reduceShape);
  const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
  const reduced = reduce(a2D, a2D.dtype, "any", backend2);
  let res;
  if (keepDims) {
    const newShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: newShape } });
  } else {
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
  }
  backend2.disposeIntermediateTensorInfo(a2D);
  backend2.disposeIntermediateTensorInfo(reduced);
  if (permutedAxes != null) {
    backend2.disposeIntermediateTensorInfo(permutedX);
  }
  return res;
}
var anyConfig2;
var init_Any2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Any.js"() {
    init_dist();
    init_reduce();
    init_Reshape2();
    init_Transpose2();
    anyConfig2 = {
      kernelName: Any,
      backendName: "webgl",
      kernelFunc: any3
    };
  }
});
var ArgMinMaxProgram;
var init_argminmax_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/argminmax_gpu.js"() {
    ArgMinMaxProgram = class {
      constructor(reduceInfo, op2, firstPass) {
        this.variableNames = ["A"];
        const { windowSize, batchSize, outSize } = reduceInfo;
        if (!firstPass) {
          this.variableNames.push("bestIndicesA");
        }
        this.outputShape = [batchSize, outSize];
        const compOp = op2 === "max" ? ">" : "<";
        const indexSnippet = firstPass ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
        this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${windowSize};

        int bestIndex = inOffset;
        float bestValue = getA(batch, bestIndex);

        for (int i = 0; i < ${windowSize}; i++) {
          int inIdx = ${indexSnippet};
          float candidate = getA(batch, inIdx);
          if (candidate ${compOp} bestValue) {
            bestValue = candidate;
            bestIndex = inIdx;
          }
        }
        setOutput(float(bestIndex));
      }
    `;
      }
    };
  }
});
var ArgMinMaxPackedProgram;
var init_argminmax_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/argminmax_packed_gpu.js"() {
    init_dist();
    init_packing_util();
    init_shader_compiler();
    ArgMinMaxPackedProgram = class {
      constructor(shape, windowSize, op2, firstPass) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        util_exports.assert(shape.length > 2, () => `Packed arg${op2.charAt(0).toUpperCase() + op2.slice(1)} supports only inputs with rank above 2.`);
        const inSize = shape[shape.length - 1];
        const outSize = Math.ceil(inSize / windowSize);
        this.outputShape = shape.slice(0, -1);
        if (outSize > 1) {
          this.outputShape.push(outSize);
        }
        if (!firstPass) {
          this.variableNames.push("bestIndicesA");
        }
        const outShape = this.outputShape;
        const rank = outShape.length;
        const dtype = getCoordsDataType(rank);
        const coords2 = getChannels("coords", rank);
        let sourceLocSetup;
        let sourceRank;
        if (outSize === 1) {
          sourceRank = rank + 1;
          const sourceLocDType = getCoordsDataType(sourceRank);
          sourceLocSetup = `
        ${sourceLocDType} sourceLocR = ${sourceLocDType}(${coords2.join()}, 0);
        ++${coords2[rank - 1]};
        ${sourceLocDType} sourceLocG = ${sourceLocDType}(${coords2.join()}, 0);
        ++${coords2[rank - 2]};
        ${sourceLocDType} sourceLocA = ${sourceLocDType}(${coords2.join()}, 0);
        --${coords2[rank - 1]};
        ${sourceLocDType} sourceLocB = ${sourceLocDType}(${coords2.join()}, 0);
        --${coords2[rank - 2]};`;
        } else {
          sourceRank = rank;
          sourceLocSetup = `
        ${dtype} sourceLocR = coords;
        ++${coords2[rank - 1]};
        ${dtype} sourceLocG = coords;
        ++${coords2[rank - 2]};
        ${dtype} sourceLocA = coords;
        --${coords2[rank - 1]};
        ${dtype} sourceLocB = coords;
        --${coords2[rank - 2]};`;
        }
        const channels = ["x", "y", "z", "w", "u", "v"].slice(0, sourceRank);
        const inChannel = "." + channels[sourceRank - 1];
        const intChannels = channels.map((x) => "int " + x);
        const srcRCoords = getChannels("sourceLocR", sourceRank - 1).concat("inIdx.r");
        const srcGCoords = getChannels("sourceLocG", sourceRank - 1).concat("inIdx.g");
        const srcBCoords = getChannels("sourceLocB", sourceRank - 1).concat("inIdx.b");
        const srcACoords = getChannels("sourceLocA", sourceRank - 1).concat("inIdx.a");
        const compOp = op2 === "max" ? "greaterThan" : "lessThan";
        const fetchCandidateIdx = firstPass ? "" : `
          inIdx = round(vec4(getBestIndicesAChannel(${srcRCoords.join()}),
                             getBestIndicesAChannel(${srcGCoords.join()}),
                             getBestIndicesAChannel(${srcBCoords.join()}),
                             getBestIndicesAChannel(${srcACoords.join()})));`;
        const fetchValue = `vec4(
            getAChannel(${srcRCoords.join()}),
            hasNextCol ? getAChannel(${srcGCoords.join()}) : 0.,
            hasNextRow ? getAChannel(${srcBCoords.join()}) : 0.,
            hasNextRow && hasNextCol ? getAChannel(${srcACoords.join()}) : 0.)`;
        const getBestIndicesAChannelSnippet = firstPass ? "" : `
      float getBestIndicesAChannel(${intChannels.join()}) {
        return getChannel(getBestIndicesA(${channels.join()}),
                                          vec2(${channels.slice(-2).join()}));
      }`;
        this.userCode = `
      float getAChannel(${intChannels.join()}) {
        return getChannel(getA(${channels.join()}),
                               vec2(${channels.slice(-2).join()}));
      }
      ${getBestIndicesAChannelSnippet}
      void main() {
        ${dtype} coords = getOutputCoords();
        bool hasNextCol = ${coords2[rank - 1]} < ${outShape[rank - 1] - 1};
        bool hasNextRow = ${coords2[rank - 2]} < ${outShape[rank - 2] - 1};
        ${sourceLocSetup}
        ivec4 srcIdx = ivec4(sourceLocR${inChannel}, sourceLocG${inChannel},
          sourceLocB${inChannel}, sourceLocA${inChannel}) * ${windowSize};
        ivec4 inIdx = srcIdx;
        vec4 bestIndex = vec4(inIdx);
        vec4 bestValue = ${fetchValue};

        for (int i = 0; i < ${windowSize}; i++) {
          inIdx = srcIdx;
          ${fetchCandidateIdx}
          vec4 candidate = ${fetchValue};
          bvec4 nan = isnan(candidate);
          bvec4 replace = bvec4(
            vec4(${compOp}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));

          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,
                           replace.y  ? candidate.y : bestValue.y,
                           replace.z  ? candidate.z : bestValue.z,
                           replace.w  ? candidate.w : bestValue.w);
          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));
          srcIdx++;
        }
        setOutput(bestIndex);
      }
    `;
      }
    };
  }
});
function argReduce(backend2, x, reduceType, bestIndicesA = null) {
  let batchSize = x.shape[0];
  let inSize = x.shape[1];
  if (bestIndicesA != null) {
    batchSize = bestIndicesA.shape[0];
    inSize = bestIndicesA.shape[1];
  }
  const windowSize = backend_util_exports.computeOptimalWindowSize(inSize);
  const reduceInfo = { windowSize, inSize, batchSize, outSize: Math.ceil(inSize / windowSize) };
  const program = new ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);
  const inputs = [x];
  if (bestIndicesA != null) {
    inputs.push(bestIndicesA);
  }
  const output = backend2.runWebGLProgram(program, inputs, "int32");
  if (output.shape[1] === 1) {
    return output;
  }
  const result = argReduce(backend2, x, reduceType, output);
  backend2.disposeIntermediateTensorInfo(output);
  return result;
}
function argReducePacked(backend2, x, reduceType, bestIndicesA = null) {
  const inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;
  const inSize = inShape[inShape.length - 1];
  const windowSize = backend_util_exports.computeOptimalWindowSize(inSize);
  const program = new ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);
  const inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];
  const output = backend2.runWebGLProgram(program, inputs, "int32");
  if (output.shape.length === x.shape.length) {
    const result = argReducePacked(backend2, x, reduceType, output);
    backend2.disposeIntermediateTensorInfo(output);
    return result;
  }
  return output;
}
function argMinMaxReduce(backend2, x, axis, reduceType) {
  const axes = [axis];
  backend_util_exports.assertAxesAreInnerMostDims("arg" + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.shape.length);
  if (!env().getBool("WEBGL_PACK_REDUCE") || x.shape.length <= 2) {
    const intermediateTensorInfos = [];
    const xtexData = backend2.texData.get(x.dataId);
    const xIsPacked = xtexData !== null && xtexData.isPacked;
    let xUnPacked = x;
    if (xIsPacked) {
      xUnPacked = backend2.unpackTensor(x);
      intermediateTensorInfos.push(xUnPacked);
    }
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(xUnPacked.shape, axes);
    const inSize = util_exports.sizeFromShape(reduceShape);
    const a2D = reshape3({ inputs: { x: xUnPacked }, backend: backend2, attrs: { shape: [-1, inSize] } });
    intermediateTensorInfos.push(a2D);
    const reduced = argReduce(backend2, a2D, reduceType);
    intermediateTensorInfos.push(reduced);
    const reshaped = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
    intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return reshaped;
  }
  return argReducePacked(backend2, x, reduceType);
}
var init_arg_min_max = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/arg_min_max.js"() {
    init_dist();
    init_argminmax_gpu();
    init_argminmax_packed_gpu();
    init_Reshape2();
  }
});
function argMax3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  let axes = util_exports.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("argMax", [axes[0]], $x.shape.length);
  const out = argMinMaxReduce(backend2, $x, axes[0], "max");
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return out;
}
var argMaxConfig2;
var init_ArgMax2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ArgMax.js"() {
    init_dist();
    init_arg_min_max();
    init_Transpose2();
    argMaxConfig2 = {
      kernelName: ArgMax,
      backendName: "webgl",
      kernelFunc: argMax3
    };
  }
});
function argMin3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis } = attrs;
  let axes = util_exports.parseAxisParam(axis, x.shape);
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, x.shape.length);
  let $x = x;
  const intermediateTensorInfos = [];
  if (permutedAxes != null) {
    $x = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    intermediateTensorInfos.push($x);
    axes = backend_util_exports.getInnerMostAxes(axes.length, $x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("argMin", [axes[0]], $x.shape.length);
  const out = argMinMaxReduce(backend2, $x, axes[0], "min");
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return out;
}
var argMinConfig2;
var init_ArgMin2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ArgMin.js"() {
    init_dist();
    init_arg_min_max();
    init_Transpose2();
    argMinConfig2 = {
      kernelName: ArgMin,
      backendName: "webgl",
      kernelFunc: argMin3
    };
  }
});
var ASIN;
var asin3;
var asinConfig2;
var init_Asin2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Asin.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    ASIN = CHECK_NAN_SNIPPET + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return asin(x);
`;
    asin3 = unaryKernelFunc2({ opSnippet: ASIN });
    asinConfig2 = {
      kernelName: Asin,
      backendName: "webgl",
      kernelFunc: asin3
    };
  }
});
var ASINH;
var asinh3;
var asinhConfig2;
var init_Asinh2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Asinh.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    ASINH = CHECK_NAN_SNIPPET + `return log(x + sqrt(x * x + 1.0));`;
    asinh3 = unaryKernelFunc2({ opSnippet: ASINH });
    asinhConfig2 = {
      kernelName: Asinh,
      backendName: "webgl",
      kernelFunc: asinh3
    };
  }
});
var ATAN;
var atan4;
var atanConfig2;
var init_Atan3 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Atan.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    ATAN = CHECK_NAN_SNIPPET + `
  return atan(x);
`;
    atan4 = unaryKernelFunc2({ opSnippet: ATAN });
    atanConfig2 = {
      kernelName: Atan,
      backendName: "webgl",
      kernelFunc: atan4
    };
  }
});
var ATAN2;
var ATAN2_PACKED;
var atan23;
var atan2Config2;
var init_Atan22 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Atan2.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    init_kernel_funcs_utils();
    ATAN2 = CHECK_NAN_SNIPPET2 + `
  return atan(a, b);
`;
    ATAN2_PACKED = `
  vec4 result = atan(a, b);
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + CHECK_NAN_SNIPPET_PACKED + `
  return result;
`;
    atan23 = binaryKernelFunc2({ opSnippet: ATAN2, packedOpSnippet: ATAN2_PACKED });
    atan2Config2 = {
      kernelName: Atan2,
      backendName: "webgl",
      kernelFunc: atan23
    };
  }
});
var ATANH;
var atanh3;
var atanhConfig2;
var init_Atanh2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Atanh.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    ATANH = CHECK_NAN_SNIPPET + `
  if ((x < -1.0) || (x > 1.0)) return NAN;
return (log(1.0 + x) - log(1.0 - x)) / 2.0;`;
    atanh3 = unaryKernelFunc2({ opSnippet: ATANH });
    atanhConfig2 = {
      kernelName: Atanh,
      backendName: "webgl",
      kernelFunc: atanh3
    };
  }
});
var Pool2DProgram;
var Pool3DProgram;
var init_pool_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/pool_gpu.js"() {
    Pool2DProgram = class {
      constructor(convInfo, poolType, computePositions, flattenPositions = false, includeBatchInIndex = false) {
        this.variableNames = ["x"];
        if (poolType === "avg" && computePositions) {
          throw new Error("Cannot compute positions for average pool.");
        }
        const filterWidth = convInfo.filterWidth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const effectiveFilterHeight = convInfo.effectiveFilterHeight;
        const effectiveFilterWidth = convInfo.effectiveFilterWidth;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        this.outputShape = convInfo.outShape;
        const isAvgPool = poolType === "avg";
        const batchFlattenPositionStr = `((batch  * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;
        const flattenPositionStr = `(xR * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + d`;
        let initializationValue = "0.0";
        if (!isAvgPool) {
          initializationValue = "-1.0 / 1e-20";
        }
        if (computePositions) {
          const compareOp2 = ">=";
          this.userCode = `
        const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
        const ivec2 pads = ivec2(${padTop}, ${padLeft});

        void main() {
          ivec4 coords = getOutputCoords();
          int batch = coords[0];
          int d = coords[3];

          ivec2 xRCCorner = coords.yz * strides - pads;
          int xRCorner = xRCCorner.x;
          int xCCorner = xRCCorner.y;

          // max/min x(?, ?, d) to get y(yR, yC, d).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;
          float avgValue = 0.0;

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              int xC = xCCorner + wC;

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              float value = getX(batch, xR, xC, d);

              // If a min / max value has already been found, use it. If not,
              // use the current value.
              float currMinMaxValue = mix(
                  value, minMaxValue, minMaxValueFound);
              if (value ${compareOp2} currMinMaxValue) {
                minMaxValue = value;
                minMaxValueFound = 1.0;
                minMaxPosition = ${flattenPositions ? includeBatchInIndex ? batchFlattenPositionStr : flattenPositionStr : `wR * ${effectiveFilterWidth} + wC`};
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
          return;
        }
        const compareOp = "max";
        let returnValue = `${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
        if (poolType === "avg") {
          returnValue = `avgValue / max(count, 1.0)`;
        }
        const filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
        const filterWidthVec4Remainder = filterWidth % 4;
        const updateSnippet = `
      if (${isAvgPool}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
      }
    `;
        this.userCode = `
      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xR, int xC, int d) {
        if (xC < 0 || xC >= ${convInfo.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xR, xC, d);
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d = coords[3];

        ivec2 xRCCorner = coords.yz * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // max/min x(?, ?, d) to get y(yR, yC, d).
        // ? = to be determined
        vec4 minMaxValue = vec4(${initializationValue});
        float avgValue = 0.0;
        count = 0.0;

        for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
          int xR = xRCorner + wR;

          if (xR < 0 || xR >= ${convInfo.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {
            int xC = xCCorner + wC * ${dilationWidth};

            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),
              getValue(batch, xR, xC + 3 * ${dilationWidth}, d)
            );

            ${updateSnippet}
          }

          int xC = xCCorner + ${filterWidthNearestVec4};
          if (${filterWidthVec4Remainder === 1}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              initializationValue,
              initializationValue,
              initializationValue
            );

            ${updateSnippet}
          } else if (${filterWidthVec4Remainder === 2}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              initializationValue,
              initializationValue
            );

            ${updateSnippet}
          } else if (${filterWidthVec4Remainder === 3}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${dilationWidth}, d),
              getValue(batch, xR, xC + 2 * ${dilationWidth}, d),
              initializationValue
            );

            ${updateSnippet}
          }
        }
        setOutput(${returnValue});
      }
    `;
      }
    };
    Pool3DProgram = class {
      constructor(convInfo, poolType, computePositions, flattenPositions = false, includeBatchInIndex = false) {
        this.variableNames = ["x"];
        if (poolType === "avg" && computePositions) {
          throw new Error("Cannot compute positions for average pool.");
        }
        const filterWidth = convInfo.filterWidth;
        const strideDepth = convInfo.strideDepth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationDepth = convInfo.dilationDepth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const effectiveFilterDepth = convInfo.effectiveFilterDepth;
        const effectiveFilterHeight = convInfo.effectiveFilterHeight;
        const effectiveFilterWidth = convInfo.effectiveFilterWidth;
        const padFront = convInfo.padInfo.front;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        this.outputShape = convInfo.outShape;
        const isAvgPool = poolType === "avg";
        let initializationValue = "0.0";
        if (!isAvgPool) {
          initializationValue = "-1.0 / 1e-20";
        }
        if (computePositions) {
          const compareOp2 = ">=";
          this.userCode = `
        const ivec3 strides =
            ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
        const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

        void main() {
          ivec5 coords = getOutputCoords();
          int batch = coords.x;
          int ch = coords.u;

          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
          int xDCorner = xCorner.x;
          int xRCorner = xCorner.y;
          int xCCorner = xCorner.z;

          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;

          for (int wD = 0; wD < ${effectiveFilterDepth};
              wD += ${dilationDepth}) {
            int xD = xDCorner + wD;

            if (xD < 0 || xD >= ${convInfo.inDepth}) {
              continue;
            }

            for (int wR = 0; wR < ${effectiveFilterHeight};
                wR += ${dilationHeight}) {
              int xR = xRCorner + wR;

              if (xR < 0 || xR >= ${convInfo.inHeight}) {
                continue;
              }

              for (int wC = 0; wC < ${effectiveFilterWidth};
                  wC += ${dilationWidth}) {
                int xC = xCCorner + wC;

                if (xC < 0 || xC >= ${convInfo.inWidth}) {
                  continue;
                }

                float value = getX(batch, xD, xR, xC, ch);

                // If a min / max value has already been found, use it. If not,
                // use the current value.
                float currMinMaxValue = mix(
                    value, minMaxValue, minMaxValueFound);
                if (value ${compareOp2} currMinMaxValue) {
                  minMaxValue = value;
                  minMaxValueFound = 1.0;
                  minMaxPosition = ${flattenPositions ? includeBatchInIndex ? `(((batch * ${convInfo.inDepth} + xD) * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch` : `((xD * ${convInfo.inHeight} + xR) * ${convInfo.inWidth} + xC) * ${convInfo.inChannels} + ch` : `wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +
                      wR * ${effectiveFilterWidth} + wC`};
                }
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
          return;
        }
        const compareOp = "max";
        let returnValue = `${poolType}(${poolType}(${poolType}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
        if (poolType === "avg") {
          returnValue = `avgValue / max(count, 1.0)`;
        }
        const filterWidthNearestVec4 = Math.floor(filterWidth / 4) * 4;
        const filterWidthVec4Remainder = filterWidth % 4;
        const updateSnippet = `
      if (${isAvgPool}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${compareOp}(values, minMaxValue);
      }
    `;
        this.userCode = `
      const ivec3 strides =
        ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});
      const float initializationValue = ${initializationValue};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xD, int xR, int xC, int ch) {
        if (xC < 0 || xC >= ${convInfo.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xD, xR, xC, ch);
      }

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xDCorner = xCorner.x;
        int xRCorner = xCorner.y;
        int xCCorner = xCorner.z;

        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).
        // ? = to be determined
        vec4 minMaxValue = vec4(${initializationValue});
        float avgValue = 0.0;
        count = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
            wD += ${dilationDepth}) {
          int xD = xDCorner + wD;

          if (xD < 0 || xD >= ${convInfo.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${filterWidthNearestVec4}; wC += 4) {
              int xC = xCCorner + wC * ${dilationWidth};

              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 3 * ${dilationWidth}, ch)
              );

              ${updateSnippet}
            }

            int xC = xCCorner + ${filterWidthNearestVec4};
            if (${filterWidthVec4Remainder === 1}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                initializationValue,
                initializationValue,
                initializationValue
              );

              ${updateSnippet}
            } else if (${filterWidthVec4Remainder === 2}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                initializationValue,
                initializationValue
              );

              ${updateSnippet}
            } else if (${filterWidthVec4Remainder === 3}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${dilationWidth}, ch),
                getValue(batch, xD, xR, xC + 2 * ${dilationWidth}, ch),
                initializationValue
              );

              ${updateSnippet}
            }
          }
        }
        setOutput(${returnValue});
      }
    `;
      }
    };
  }
});
function avgPool3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  assertNotComplex2(x, "avgPool");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    return identity22({ inputs: { x }, backend: backend2 });
  }
  const avgPoolProgram = new Pool2DProgram(convInfo, "avg", false);
  return backend2.runWebGLProgram(avgPoolProgram, [x], "float32");
}
var avgPoolConfig2;
var init_AvgPool2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool.js"() {
    init_dist();
    init_pool_gpu();
    init_webgl_util();
    init_Identity2();
    avgPoolConfig2 = {
      kernelName: AvgPool,
      backendName: "webgl",
      kernelFunc: avgPool3
    };
  }
});
function avgPool3D2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dimRoundingMode, dataFormat } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode, dataFormat);
  const avgPoolProgram = new Pool3DProgram(convInfo, "avg", false);
  return backend2.runWebGLProgram(avgPoolProgram, [x], "float32");
}
var avgPool3DConfig2;
var init_AvgPool3D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3D.js"() {
    init_dist();
    init_pool_gpu();
    avgPool3DConfig2 = {
      kernelName: AvgPool3D,
      backendName: "webgl",
      kernelFunc: avgPool3D2
    };
  }
});
var AvgPool2DBackpropProgram;
var AvgPool3DBackpropProgram;
var init_avg_pool_backprop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/avg_pool_backprop_gpu.js"() {
    AvgPool2DBackpropProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy"];
        this.outputShape = convInfo.inShape;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const effectiveFilterHeight = convInfo.effectiveFilterHeight;
        const effectiveFilterWidth = convInfo.effectiveFilterWidth;
        const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
        const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
        const avgMultiplier = 1 / (filterHeight * filterWidth);
        this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float avgMultiplier = float(${avgMultiplier});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${effectiveFilterHeight};
            wR += ${dilationHeight}) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${effectiveFilterWidth};
            wC+= ${dilationWidth}) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);

            dotProd += dyValue * avgMultiplier;
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
    AvgPool3DBackpropProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy"];
        this.outputShape = convInfo.inShape;
        const filterDepth = convInfo.filterDepth;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const strideDepth = convInfo.strideDepth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationDepth = convInfo.dilationDepth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const effectiveFilterDepth = convInfo.effectiveFilterDepth;
        const effectiveFilterHeight = convInfo.effectiveFilterHeight;
        const effectiveFilterWidth = convInfo.effectiveFilterWidth;
        const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
        const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
        const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
        const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);
        this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});
      const float avgMultiplier = float(${avgMultiplier});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
            wD += ${dilationDepth}) {
          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;

          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);

              dotProd += dyValue * avgMultiplier;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
  }
});
function avgPool3DGrad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  const avgPoolBackpropProgram = new AvgPool3DBackpropProgram(convInfo);
  return backend2.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
}
var avgPool3DGradConfig3;
var init_AvgPool3DGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3DGrad.js"() {
    init_dist();
    init_avg_pool_backprop_gpu();
    avgPool3DGradConfig3 = {
      kernelName: AvgPool3DGrad,
      backendName: "webgl",
      kernelFunc: avgPool3DGrad2
    };
  }
});
function avgPoolGrad3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  assertNotComplex2([dy, input2], "avgPoolGrad");
  const { filterSize, strides, pad: pad2 } = attrs;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2);
  const avgPoolBackpropProgram = new AvgPool2DBackpropProgram(convInfo);
  return backend2.runWebGLProgram(avgPoolBackpropProgram, [dy], x.dtype);
}
var avgPoolGradConfig3;
var init_AvgPoolGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPoolGrad.js"() {
    init_dist();
    init_avg_pool_backprop_gpu();
    init_webgl_util();
    avgPoolGradConfig3 = {
      kernelName: AvgPoolGrad,
      backendName: "webgl",
      kernelFunc: avgPoolGrad3
    };
  }
});
function batchMatMul2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { a, b } = inputs;
  const { transposeA, transposeB } = attrs;
  return batchMatMulImpl({ a, b, transposeA, transposeB, backend: backend2 });
}
var batchMatMulConfig2;
var init_BatchMatMul2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul.js"() {
    init_dist();
    init_BatchMatMul_impl();
    batchMatMulConfig2 = {
      kernelName: BatchMatMul,
      backendName: "webgl",
      kernelFunc: batchMatMul2
    };
  }
});
var BatchNormProgram;
var init_batchnorm_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/batchnorm_gpu.js"() {
    init_dist();
    BatchNormProgram = class {
      constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
        this.outputShape = [];
        this.variableNames = ["x", "mean", "variance"];
        backend_util_exports.assertAndGetBroadcastShape(xShape, meanShape);
        backend_util_exports.assertAndGetBroadcastShape(xShape, varianceShape);
        let offsetSnippet = "0.0";
        if (offsetShape != null) {
          backend_util_exports.assertAndGetBroadcastShape(xShape, offsetShape);
          this.variableNames.push("offset");
          offsetSnippet = "getOffsetAtOutCoords()";
        }
        let scaleSnippet = "1.0";
        if (scaleShape != null) {
          backend_util_exports.assertAndGetBroadcastShape(xShape, scaleShape);
          this.variableNames.push("scale");
          scaleSnippet = "getScaleAtOutCoords()";
        }
        this.outputShape = xShape;
        this.userCode = `
      void main() {
        float x = getXAtOutCoords();
        float mean = getMeanAtOutCoords();
        float variance = getVarianceAtOutCoords();
        float offset = ${offsetSnippet};
        float scale = ${scaleSnippet};
        float inv = scale * inversesqrt(variance + float(${varianceEpsilon}));
        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));
      }
    `;
      }
    };
  }
});
var BatchNormPackedProgram;
var init_batchnorm_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/batchnorm_packed_gpu.js"() {
    init_dist();
    BatchNormPackedProgram = class {
      constructor(xShape, meanShape, varianceShape, offsetShape, scaleShape, varianceEpsilon) {
        this.packedInputs = true;
        this.packedOutput = true;
        this.variableNames = ["x", "mean", "variance"];
        backend_util_exports.assertAndGetBroadcastShape(xShape, meanShape);
        backend_util_exports.assertAndGetBroadcastShape(xShape, varianceShape);
        let offsetSnippet = "vec4(0.0)";
        if (offsetShape != null) {
          backend_util_exports.assertAndGetBroadcastShape(xShape, offsetShape);
          this.variableNames.push("offset");
          offsetSnippet = "getOffsetAtOutCoords()";
        }
        let scaleSnippet = "vec4(1.0)";
        if (scaleShape != null) {
          backend_util_exports.assertAndGetBroadcastShape(xShape, scaleShape);
          this.variableNames.push("scale");
          scaleSnippet = "getScaleAtOutCoords()";
        }
        this.outputShape = xShape;
        this.userCode = `
      void main() {
        vec4 offset = ${offsetSnippet};
        vec4 scale = ${scaleSnippet};

        vec4 x = getXAtOutCoords();
        vec4 mean = getMeanAtOutCoords();
        vec4 variance = getVarianceAtOutCoords();

        vec4 inv = scale * inversesqrt(variance + vec4(${varianceEpsilon}));

        setOutput((x - mean) * inv + offset);
      }
    `;
      }
    };
  }
});
var batchNorm3;
var batchNormConfig2;
var init_BatchNorm2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchNorm.js"() {
    init_dist();
    init_batchnorm_gpu();
    init_batchnorm_packed_gpu();
    batchNorm3 = ({ inputs, backend: backend2, attrs }) => {
      const { x, mean: mean3, variance, offset, scale: scale22 } = inputs;
      util_exports.assert(mean3.shape.length === variance.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks.");
      util_exports.assert(offset == null || mean3.shape.length === offset.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks.");
      util_exports.assert(scale22 == null || mean3.shape.length === scale22.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
      let { varianceEpsilon } = attrs;
      if (varianceEpsilon == null) {
        varianceEpsilon = 1e-3;
      }
      const finalInputs = [x, mean3, variance];
      let offsetShape = null;
      if (offset != null) {
        offsetShape = offset.shape;
        finalInputs.push(offset);
      }
      let scaleShape = null;
      if (scale22 != null) {
        scaleShape = scale22.shape;
        finalInputs.push(scale22);
      }
      const program = env().getBool("WEBGL_PACK_NORMALIZATION") ? new BatchNormPackedProgram(x.shape, mean3.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon) : new BatchNormProgram(x.shape, mean3.shape, variance.shape, offsetShape, scaleShape, varianceEpsilon);
      const output = backend2.runWebGLProgram(program, finalInputs, finalInputs[0].dtype);
      return output;
    };
    batchNormConfig2 = {
      kernelName: FusedBatchNorm,
      backendName: "webgl",
      kernelFunc: batchNorm3
    };
  }
});
function getCoords(rank) {
  if (rank === 1) {
    return "sourceLoc";
  } else if (rank <= 6) {
    return coords.slice(0, rank).map((x) => "sourceLoc." + x).join(",");
  } else {
    throw Error(`Slicing for rank ${rank} is not yet supported`);
  }
}
var SliceProgram;
var coords;
var init_slice_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/slice_gpu.js"() {
    init_shader_compiler();
    SliceProgram = class {
      constructor(destSize) {
        this.variableNames = ["source"];
        this.outputShape = destSize;
        this.rank = destSize.length;
        const dtype = getCoordsDataType(this.rank);
        this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
        const sourceCoords = getCoords(this.rank);
        let body;
        const coordSum = destSize.map((_, i) => {
          return `sourceLoc.${coords[i]} = start[${i}] + coords.${coords[i]};`;
        });
        body = `
        ${dtype} sourceLoc;
        ${dtype} coords = getOutputCoords();
        ${coordSum.join("\n")}
      `;
        this.userCode = `
      void main() {
        ${body}
        setOutput(getSource(${sourceCoords}));
      }
    `;
      }
    };
    coords = ["x", "y", "z", "w", "u", "v"];
  }
});
var SlicePackedProgram;
var init_slice_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/slice_packed_gpu.js"() {
    init_packing_util();
    init_shader_compiler();
    SlicePackedProgram = class {
      constructor(destSize) {
        this.variableNames = ["source"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = destSize;
        this.rank = destSize.length;
        this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
        const dtype = getCoordsDataType(this.rank);
        const coords2 = getChannels("coords", this.rank);
        const sourceLoc = getChannels("sourceLoc", this.rank);
        const innerDims = this.rank === 1 ? "sourceLoc" : `vec2(${sourceLoc.slice(-2).join()})`;
        const getChannel = `getChannel(getSource(${sourceLoc.join()}), ${innerDims})`;
        const upperRow = `
      result.x = ${getChannel};
      if (++${coords2[this.rank - 1]} < ${destSize[this.rank - 1]}) {
        ++${sourceLoc[this.rank - 1]};
        result.y = ${getChannel};
        --${sourceLoc[this.rank - 1]};
      }
    `;
        const lowerRow = this.rank === 1 ? "" : `
      --${coords2[this.rank - 1]};
      if (++${coords2[this.rank - 2]} < ${destSize[this.rank - 2]}) {
        ++${sourceLoc[this.rank - 2]};
        result.z = ${getChannel};
        if (++${coords2[this.rank - 1]} < ${destSize[this.rank - 1]}) {
          ++${sourceLoc[this.rank - 1]};
          result.w = ${getChannel};
        }
      }
    `;
        const sourceLocSetup = this.rank <= 4 ? `sourceLoc = coords +
            ${dtype}(${destSize.map((_, i) => `start[${i}]`).join()});` : destSize.map((_, i) => `${sourceLoc[i]} = ${coords2[i]} + start[${i}];`).join("\n");
        this.userCode = `
      void main() {
        ${dtype} coords = getOutputCoords();
        ${dtype} sourceLoc;
        ${sourceLocSetup}
        vec4 result = vec4(0.);
        ${upperRow}
        ${lowerRow}
        setOutput(result);
      }
    `;
      }
    };
  }
});
function shallowSlice(x, begin, size, backend2) {
  const xTexData = backend2.texData.get(x.dataId);
  const t = backend2.makeTensorInfo(size, x.dtype);
  const newTexData = backend2.texData.get(t.dataId);
  Object.assign(newTexData, xTexData);
  newTexData.refCount = 1;
  newTexData.shape = size;
  newTexData.dtype = x.dtype;
  let flatOffset = slice_util_exports.computeFlatOffset(begin, util_exports.computeStrides(x.shape));
  if (xTexData.slice) {
    flatOffset += xTexData.slice.flatOffset;
  }
  newTexData.slice = {
    flatOffset,
    // Point to the original dataId, which is used to do ref counting.
    origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId
  };
  const refCount = backend2.dataRefCount.get(newTexData.slice.origDataId) || 1;
  backend2.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);
  return t;
}
function slice3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { begin, size } = attrs;
  const [$begin, $size] = slice_util_exports.parseSliceParams(x, begin, size);
  slice_util_exports.assertParamsValid(x, $begin, $size);
  if (util_exports.sizeFromShape($size) === 0) {
    return backend2.makeTensorInfo($size, x.dtype, []);
  }
  if (backend2.shouldExecuteOnCPU([x]) || x.dtype === "string") {
    const xTexData = backend2.texData.get(x.dataId);
    const outValues = sliceImplCPU(xTexData.values, $begin, $size, x.shape, x.dtype);
    return backend2.makeTensorInfo($size, x.dtype, outValues);
  }
  const { isPacked } = backend2.texData.get(x.dataId);
  const isContinous = slice_util_exports.isSliceContinous(x.shape, $begin, $size);
  if (isPacked || !isContinous) {
    const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new SlicePackedProgram($size) : new SliceProgram($size);
    const customValues = [$begin];
    return backend2.runWebGLProgram(program, [x], x.dtype, customValues);
  }
  backend2.uploadToGPU(x.dataId);
  return shallowSlice(x, $begin, $size, backend2);
}
var sliceConfig2;
var init_Slice2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Slice.js"() {
    init_dist();
    init_shared2();
    init_slice_gpu();
    init_slice_packed_gpu();
    sliceConfig2 = {
      kernelName: Slice,
      backendName: "webgl",
      kernelFunc: slice3
    };
  }
});
var batchToSpaceND3;
var batchToSpaceNDConfig2;
var init_BatchToSpaceND2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BatchToSpaceND.js"() {
    init_dist();
    init_Reshape2();
    init_Slice2();
    init_Transpose2();
    batchToSpaceND3 = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { x } = inputs;
      const { blockShape, crops } = attrs;
      util_exports.assert(x.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
      const prod4 = blockShape.reduce((a, b) => a * b);
      const reshaped = backend_util_exports.getReshaped(x.shape, blockShape, prod4);
      const permuted = backend_util_exports.getPermuted(reshaped.length, blockShape.length);
      const reshapedPermuted = backend_util_exports.getReshapedPermuted(x.shape, blockShape, prod4);
      const sliceBeginCoords = backend_util_exports.getSliceBeginCoords(crops, blockShape.length);
      const sliceSize = backend_util_exports.getSliceSize(reshapedPermuted, crops, blockShape.length);
      const toDispose = [];
      const reshapedIntermediate = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: reshaped } });
      const transposedIntermediate = transpose3({ inputs: { x: reshapedIntermediate }, backend: backend2, attrs: { perm: permuted } });
      const reshapedIntermediate2 = reshape3({
        inputs: { x: transposedIntermediate },
        backend: backend2,
        attrs: { shape: reshapedPermuted }
      });
      const sliced = slice3({
        inputs: { x: reshapedIntermediate2 },
        backend: backend2,
        attrs: { begin: sliceBeginCoords, size: sliceSize }
      });
      toDispose.push(reshapedIntermediate);
      toDispose.push(transposedIntermediate);
      toDispose.push(reshapedIntermediate2);
      toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
      return sliced;
    };
    batchToSpaceNDConfig2 = {
      kernelName: BatchToSpaceND,
      backendName: "webgl",
      kernelFunc: batchToSpaceND3
    };
  }
});
function bincount3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, weights } = inputs;
  const { size } = attrs;
  const xVals = backend2.readSync(x.dataId);
  const weightsVals = backend2.readSync(weights.dataId);
  const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);
  return backend2.makeTensorInfo([size], weights.dtype, outVals);
}
var bincountConfig2;
var init_Bincount2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Bincount.js"() {
    init_dist();
    init_shared2();
    bincountConfig2 = {
      kernelName: Bincount,
      backendName: "webgl",
      kernelFunc: bincount3
    };
  }
});
function broadcastArgs2(args) {
  const { inputs, backend: backend2 } = args;
  const { s0, s1 } = inputs;
  const s0Vals = backend2.readSync(s0.dataId);
  const s1Vals = backend2.readSync(s1.dataId);
  const broadcastShape = backend_util_exports.assertAndGetBroadcastShape(Array.from(s0Vals), Array.from(s1Vals));
  return backend2.makeTensorInfo([broadcastShape.length], "int32", Int32Array.from(broadcastShape));
}
var broadcastArgsConfig2;
var init_BroadcastArgs2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/BroadcastArgs.js"() {
    init_dist();
    broadcastArgsConfig2 = {
      kernelName: BroadcastArgs,
      backendName: "webgl",
      kernelFunc: broadcastArgs2
    };
  }
});
var NOT_EQUAL;
var notEqual3;
var notEqualConfig2;
var init_NotEqual2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NotEqual.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    NOT_EQUAL = `return float(a != b);`;
    notEqual3 = binaryKernelFunc2({ opSnippet: NOT_EQUAL, cpuKernelImpl: notEqualImplCPU, dtype: "bool" });
    notEqualConfig2 = {
      kernelName: NotEqual,
      backendName: "webgl",
      kernelFunc: notEqual3
    };
  }
});
function real3(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  const inputData = backend2.texData.get(input2.dataId);
  return identity22({ inputs: { x: inputData.complexTensorInfos.real }, backend: backend2 });
}
var realConfig2;
var init_Real2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Real.js"() {
    init_dist();
    init_Identity2();
    realConfig2 = {
      kernelName: Real,
      backendName: "webgl",
      kernelFunc: real3
    };
  }
});
function int(input2, backend2) {
  const program = new UnaryOpProgram(input2.shape, TO_INT);
  const output = backend2.runWebGLProgram(program, [input2], "int32");
  return { dataId: output.dataId, shape: output.shape, dtype: output.dtype };
}
var TO_INT;
var init_int = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernel_utils/int.js"() {
    init_unaryop_gpu();
    TO_INT = `return float(int(x));`;
  }
});
function cast4(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { dtype } = attrs;
  if (dtype === "complex64") {
    if (x.dtype === "complex64") {
      return identity22({ inputs: { x }, backend: backend2 });
    }
    const zerosTensor = zeros(x.shape);
    const floatX = cast4({ inputs: { x }, backend: backend2, attrs: { dtype: "float32" } });
    const result = complex3({ inputs: { real: floatX, imag: zerosTensor }, backend: backend2 });
    zerosTensor.dispose();
    backend2.disposeIntermediateTensorInfo(floatX);
    return result;
  }
  if (x.dtype === "complex64") {
    const realPart = real3({ inputs: { input: x }, backend: backend2 });
    const result = cast4({ inputs: { x: realPart }, backend: backend2, attrs: { dtype } });
    backend2.disposeIntermediateTensorInfo(realPart);
    return result;
  }
  if (!util_exports.hasEncodingLoss(x.dtype, dtype)) {
    const result = identity22({ inputs: { x }, backend: backend2 });
    return { dataId: result.dataId, shape: result.shape, dtype };
  }
  if (backend2.shouldExecuteOnCPU([x])) {
    const values = backend2.texData.get(x.dataId).values;
    const [resultShape, resultType, resultData] = castImplCPU(values, x.shape, x.dtype, dtype);
    return backend2.makeTensorInfo(resultShape, resultType, resultData);
  }
  if (dtype === "int32") {
    return int(x, backend2);
  }
  if (dtype === "bool") {
    const zerosTensorInfo = backend2.makeTensorInfo([], "bool", util_exports.getTypedArrayFromDType("bool", 1));
    const binaryInputs = { a: x, b: zerosTensorInfo };
    const result = notEqual3({ inputs: binaryInputs, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(zerosTensorInfo);
    return result;
  }
  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);
}
var castConfig2;
var init_Cast2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cast.js"() {
    init_dist();
    init_dist();
    init_shared2();
    init_Complex2();
    init_Identity2();
    init_NotEqual2();
    init_Real2();
    init_int();
    castConfig2 = {
      kernelName: Cast,
      backendName: "webgl",
      kernelFunc: cast4
    };
  }
});
var CEIL;
var ceil3;
var ceilConfig2;
var init_Ceil2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Ceil.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    CEIL = `return ceil(x);`;
    ceil3 = unaryKernelFunc2({ opSnippet: CEIL, packedOpSnippet: CEIL, cpuKernelImpl: ceilImplCPU });
    ceilConfig2 = {
      kernelName: Ceil,
      backendName: "webgl",
      kernelFunc: ceil3
    };
  }
});
var ClipProgram;
var init_clip_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/clip_gpu.js"() {
    ClipProgram = class {
      constructor(aShape) {
        this.variableNames = ["A"];
        this.customUniforms = [
          { name: "minVal", type: "float" },
          { name: "maxVal", type: "float" }
        ];
        this.outputShape = aShape;
        this.userCode = `

      void main() {
        float value = getAAtOutCoords();
        if (isnan(value)) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, minVal, maxVal));
      }
    `;
      }
    };
  }
});
var ClipPackedProgram;
var init_clip_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/clip_packed_gpu.js"() {
    ClipPackedProgram = class {
      constructor(aShape) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.customUniforms = [
          { name: "minVal", type: "float" },
          { name: "maxVal", type: "float" }
        ];
        this.outputShape = aShape;
        this.userCode = `
      void main() {
        vec4 value = getAAtOutCoords();

        if (any(isnan(value))) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));
      }
    `;
      }
    };
  }
});
function clipByValue3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { clipValueMin, clipValueMax } = attrs;
  let program;
  if (env().getBool("WEBGL_PACK_CLIP")) {
    program = new ClipPackedProgram(x.shape);
  } else {
    program = new ClipProgram(x.shape);
  }
  const customValues = [[clipValueMin], [clipValueMax]];
  return backend2.runWebGLProgram(program, [x], x.dtype, customValues);
}
var clipByValueConfig2;
var init_ClipByValue2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ClipByValue.js"() {
    init_dist();
    init_clip_gpu();
    init_clip_packed_gpu();
    clipByValueConfig2 = {
      kernelName: ClipByValue,
      backendName: "webgl",
      kernelFunc: clipByValue3
    };
  }
});
var ComplexAbsProgram;
var init_complex_abs_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/complex_abs_gpu.js"() {
    ComplexAbsProgram = class {
      constructor(shape) {
        this.variableNames = ["real", "imag"];
        this.outputShape = shape;
        this.userCode = `
      void main() {
        float re = abs(getRealAtOutCoords());
        float im = abs(getImagAtOutCoords());
        float mx = max(re, im);

        // sadly the length function in glsl is not underflow-safe
        // (at least not on Intel GPUs). So the safe solution is
        // to ensure underflow-safety in all cases.
        setOutput(
          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))
        );
      }
    `;
      }
    };
  }
});
function makeComplexComponentTensorInfo(complexTensor, complexPart) {
  return {
    dataId: complexPart.dataId,
    dtype: complexPart.dtype,
    shape: complexTensor.shape
  };
}
function complexAbs2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  const xData = backend2.texData.get(x.dataId);
  const program = new ComplexAbsProgram(x.shape);
  const programInputs = [
    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real),
    makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag)
  ];
  return backend2.runWebGLProgram(program, programInputs, programInputs[0].dtype);
}
var complexAbsConfig2;
var init_ComplexAbs2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ComplexAbs.js"() {
    init_dist();
    init_complex_abs_gpu();
    complexAbsConfig2 = {
      kernelName: ComplexAbs,
      backendName: "webgl",
      kernelFunc: complexAbs2
    };
  }
});
var ConcatProgram;
var init_concat_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/concat_gpu.js"() {
    init_dist();
    ConcatProgram = class {
      // Concats 2d tensors along axis=1. See comments in MathBackendWebGL.concat().
      constructor(shapes) {
        this.outputShape = [];
        this.outputShape = backend_util_exports.computeOutShape(
          shapes,
          1
          /* axis */
        );
        this.variableNames = shapes.map((_, i) => `T${i}`);
        const offsets = new Array(shapes.length - 1);
        offsets[0] = shapes[0][1];
        for (let i = 1; i < offsets.length; i++) {
          offsets[i] = offsets[i - 1] + shapes[i][1];
        }
        const snippets = [`if (yC < ${offsets[0]}) setOutput(getT0(yR, yC));`];
        for (let i = 1; i < offsets.length; i++) {
          const shift = offsets[i - 1];
          snippets.push(`else if (yC < ${offsets[i]}) setOutput(getT${i}(yR, yC-${shift}));`);
        }
        const lastIndex = offsets.length;
        const lastShift = offsets[offsets.length - 1];
        snippets.push(`else setOutput(getT${lastIndex}(yR, yC-${lastShift}));`);
        this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int yR = coords.x;
        int yC = coords.y;

        ${snippets.join("\n        ")}
      }
    `;
      }
    };
  }
});
function shiftedChannels(channels, channel, shift) {
  const channelIdx = channels.indexOf(channel);
  const res = channels.map((c, idx) => {
    if (idx === channelIdx) {
      return `${c} - ${shift}`;
    } else {
      return c;
    }
  });
  return res.join();
}
var ConcatPackedProgram;
var init_concat_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/concat_packed_gpu.js"() {
    init_dist();
    init_packing_util();
    init_shader_compiler();
    ConcatPackedProgram = class {
      constructor(shapes, axis) {
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = [];
        this.outputShape = backend_util_exports.computeOutShape(shapes, axis);
        const shape = this.outputShape;
        const rank = shape.length;
        const dtype = getCoordsDataType(rank);
        const coords2 = getChannels("coords", rank);
        const channels = ["x", "y", "z", "w", "u", "v"].slice(0, rank);
        this.variableNames = shapes.map((_, i) => `T${i}`);
        const offsets = new Array(shapes.length - 1);
        offsets[0] = shapes[0][axis];
        for (let i = 1; i < offsets.length; i++) {
          offsets[i] = offsets[i - 1] + shapes[i][axis];
        }
        const channel = channels[axis];
        const lastChannels = channels.slice(-2);
        const allChannels = channels.join();
        let getValueSnippet = `if (${channel} < ${offsets[0]}) {
        return getChannel(
            getT0(${allChannels}), vec2(${lastChannels.join()}));
        }`;
        for (let i = 1; i < offsets.length; i++) {
          const shift2 = offsets[i - 1];
          getValueSnippet += `
        if (${channel} < ${offsets[i]}  && ${channel} >= ${offsets[i - 1]}) {
          return getChannel(
            getT${i}(${shiftedChannels(channels, channel, shift2)}),
            vec2(${shiftedChannels(lastChannels, channel, shift2)}));
        }`;
        }
        const lastIndex = offsets.length;
        const shift = offsets[offsets.length - 1];
        getValueSnippet += `
        return getChannel(
          getT${lastIndex}(${shiftedChannels(channels, channel, shift)}),
          vec2(${shiftedChannels(lastChannels, channel, shift)}));`;
        this.userCode = `
      float getValue(${channels.map((x) => "int " + x)}) {
        ${getValueSnippet}
      }

      void main() {
        ${dtype} coords = getOutputCoords();
        vec4 result = vec4(getValue(${coords2}), 0., 0., 0.);

        ${coords2[rank - 1]} = ${coords2[rank - 1]} + 1;
        if (${coords2[rank - 1]} < ${shape[rank - 1]}) {
          result.g = getValue(${coords2});
        }

        ${coords2[rank - 2]} = ${coords2[rank - 2]} + 1;
        if (${coords2[rank - 2]} < ${shape[rank - 2]}) {
          result.a = getValue(${coords2});
        }

        ${coords2[rank - 1]} = ${coords2[rank - 1]} - 1;
        if (${coords2[rank - 2]} < ${shape[rank - 2]} &&
            ${coords2[rank - 1]} < ${shape[rank - 1]}) {
          result.b = getValue(${coords2});
        }
        setOutput(result);
      }
    `;
      }
    };
  }
});
function imag3(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  const inputData = backend2.texData.get(input2.dataId);
  return identity22({ inputs: { x: inputData.complexTensorInfos.imag }, backend: backend2 });
}
var imagConfig2;
var init_Imag2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Imag.js"() {
    init_dist();
    init_Identity2();
    imagConfig2 = {
      kernelName: Imag,
      backendName: "webgl",
      kernelFunc: imag3
    };
  }
});
function concatImpl2(inputs, axis, backend2) {
  const dtype = inputs[0].dtype;
  if (dtype === "complex64") {
    const reals = inputs.map((t) => real3({ inputs: { input: t }, backend: backend2 }));
    const imags = inputs.map((t) => imag3({ inputs: { input: t }, backend: backend2 }));
    const realConcated = concatImpl2(reals, axis, backend2);
    const imagConcated = concatImpl2(imags, axis, backend2);
    const result2 = complex3({ inputs: { real: realConcated, imag: imagConcated }, backend: backend2 });
    reals.forEach((r) => backend2.disposeIntermediateTensorInfo(r));
    imags.forEach((i) => backend2.disposeIntermediateTensorInfo(i));
    backend2.disposeIntermediateTensorInfo(realConcated);
    backend2.disposeIntermediateTensorInfo(imagConcated);
    return result2;
  }
  let runOnCpu = backend2.shouldExecuteOnCPU(inputs);
  if (dtype === "string") {
    runOnCpu = true;
  }
  if (runOnCpu) {
    const tensors2D2 = inputs.map((t) => {
      const innerSize = util_exports.sizeFromShape(t.shape.slice(axis));
      const shape = [-1, innerSize];
      return reshape3({ inputs: { x: t }, backend: backend2, attrs: { shape } });
    });
    const inputsValShapes = tensors2D2.map((t) => {
      return { vals: backend2.readSync(t.dataId), shape: t.shape };
    });
    const outShape2 = backend_util_exports.computeOutShape(
      tensors2D2.map((t) => t.shape),
      1
      /* axis */
    );
    const simplyConcat = tensors2D2[0].shape[0] === 1;
    const outVals = concatImplCPU(inputsValShapes, outShape2, dtype, simplyConcat);
    const finalOutShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), axis);
    const outInfo = backend2.makeTensorInfo(finalOutShape, dtype, outVals);
    tensors2D2.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return outInfo;
  }
  const $inputs = inputs.filter((t) => util_exports.sizeFromShape(t.shape) > 0);
  const shouldPack = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && $inputs[0].shape.length > 1;
  if ($inputs.length === 1) {
    const program2 = shouldPack ? new UnaryOpProgram(inputs[0].shape, CLONE) : new UnaryOpPackedProgram(inputs[0].shape, CLONE);
    return backend2.runWebGLProgram(program2, inputs, dtype);
  }
  const maxTexturesInShader = env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");
  if ($inputs.length > maxTexturesInShader) {
    const reducedInputs = [];
    for (let i = 0; i < $inputs.length; i += maxTexturesInShader) {
      const subArray = $inputs.slice(i, i + maxTexturesInShader);
      reducedInputs.push(concatImpl2(subArray, axis, backend2));
    }
    const result2 = concatImpl2(reducedInputs, axis, backend2);
    for (const i of reducedInputs) {
      backend2.disposeIntermediateTensorInfo(i);
    }
    return result2;
  }
  if (shouldPack) {
    const program2 = new ConcatPackedProgram($inputs.map((t) => t.shape), axis);
    return backend2.runWebGLProgram(program2, $inputs, dtype);
  }
  const { tensors2D, outShape } = computeTensors2D($inputs, axis, backend2);
  const program = new ConcatProgram(tensors2D.map((t) => t.shape));
  const result = backend2.runWebGLProgram(program, tensors2D, dtype);
  tensors2D.forEach((r) => backend2.disposeIntermediateTensorInfo(r));
  const reshapedResult = reshape3({ inputs: { x: result }, attrs: { shape: outShape }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(result);
  return reshapedResult;
}
function computeTensors2D(inputs, axis, backend2) {
  const outShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), axis);
  const tensors2D = inputs.map((x) => reshape3({
    inputs: { x },
    attrs: { shape: [-1, util_exports.sizeFromShape(x.shape.slice(axis))] },
    backend: backend2
  }));
  return { tensors2D, outShape };
}
var init_Concat_impl2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Concat_impl.js"() {
    init_dist();
    init_concat_gpu();
    init_concat_packed_gpu();
    init_shared2();
    init_unaryop_gpu();
    init_unaryop_packed_gpu();
    init_Complex2();
    init_Imag2();
    init_Real2();
    init_Reshape2();
  }
});
function concat3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { axis } = attrs;
  const $axis = util_exports.parseAxisParam(axis, inputs[0].shape)[0];
  const shapes = inputs.map((t) => t.shape);
  backend_util_exports.assertParamsConsistent(shapes, $axis);
  const outShape = backend_util_exports.computeOutShape(inputs.map((t) => t.shape), $axis);
  if (util_exports.sizeFromShape(outShape) === 0) {
    return backend2.makeTensorInfo(outShape, inputs[0].dtype, []);
  }
  const $inputs = inputs.filter((t) => util_exports.sizeFromShape(t.shape) > 0);
  if ($inputs.length === 1) {
    return identity22({ inputs: { x: $inputs[0] }, backend: backend2 });
  }
  return concatImpl2($inputs, $axis, backend2);
}
var concatConfig2;
var init_Concat2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Concat.js"() {
    init_dist();
    init_Concat_impl2();
    init_Identity2();
    concatConfig2 = {
      kernelName: Concat,
      backendName: "webgl",
      kernelFunc: concat3
    };
  }
});
var Conv2DProgram;
var Conv3DProgram;
var init_conv_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_gpu.js"() {
    Conv2DProgram = class {
      constructor(convInfo, addBias = false, activation = null, hasPreluActivationWeights = false, hasLeakyreluAlpha = false) {
        this.variableNames = ["x", "W"];
        this.outputShape = convInfo.outShape;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
        const inputDepthVec4Remainder = convInfo.inChannels % 4;
        const isChannelsLast = convInfo.dataFormat === "channelsLast";
        const rowDim = isChannelsLast ? 1 : 2;
        const colDim = isChannelsLast ? 2 : 3;
        const channelDim = isChannelsLast ? 3 : 1;
        let activationSnippet = "", applyActivationSnippet = "";
        if (activation) {
          if (hasPreluActivationWeights) {
            activationSnippet = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
          } else if (hasLeakyreluAlpha) {
            activationSnippet = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
          } else {
            activationSnippet = `
          float activation(float x) {
            ${activation}
          }
        `;
          }
          applyActivationSnippet = `result = activation(result);`;
        }
        const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
        if (addBias) {
          this.variableNames.push("bias");
        }
        if (hasPreluActivationWeights) {
          this.variableNames.push("preluActivationWeights");
        }
        if (hasLeakyreluAlpha) {
          this.variableNames.push("leakyreluAlpha");
        }
        this.userCode = `
      ${activationSnippet}

      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d2 = coords[${channelDim}];

        ivec2 xRCCorner =
            ivec2(coords[${rowDim}], coords[${colDim}]) * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          int xR = xRCorner + wR * ${dilationHeight};

          if (xR < 0 || xR >= ${convInfo.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            int xC = xCCorner + wC * ${dilationWidth};

            if (xC < 0 || xC >= ${convInfo.inWidth}) {
              continue;
            }

            for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {
              vec4 wValues = vec4(
                getW(wR, wC, d1, d2),
                getW(wR, wC, d1 + 1, d2),
                getW(wR, wC, d1 + 2, d2),
                getW(wR, wC, d1 + 3, d2)
              );

              if (${isChannelsLast}) {
                vec4 xValues = vec4(
                  getX(batch, xR, xC, d1),
                  getX(batch, xR, xC, d1 + 1),
                  getX(batch, xR, xC, d1 + 2),
                  getX(batch, xR, xC, d1 + 3)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec4 xValues = vec4(
                  getX(batch, d1, xR, xC),
                  getX(batch, d1 + 1, xR, xC),
                  getX(batch, d1 + 2, xR, xC),
                  getX(batch, d1 + 3, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }
            }

            if (${inputDepthVec4Remainder === 1}) {

              if (${isChannelsLast}) {
                dotProd +=
                    getX(batch, xR, xC, ${inputDepthNearestVec4}) *
                    getW(wR, wC, ${inputDepthNearestVec4}, d2);
              } else {
                dotProd +=
                    getX(batch, ${inputDepthNearestVec4}, xR, xC) *
                    getW(wR, wC, ${inputDepthNearestVec4}, d2);
              }

            } else if (${inputDepthVec4Remainder === 2}) {
              vec2 wValues = vec2(
                getW(wR, wC, ${inputDepthNearestVec4}, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2)
              );

              if (${isChannelsLast}) {
                vec2 xValues = vec2(
                  getX(batch, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec2 xValues = vec2(
                  getX(batch, ${inputDepthNearestVec4}, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            } else if (${inputDepthVec4Remainder === 3}) {
              vec3 wValues = vec3(
                getW(wR, wC, ${inputDepthNearestVec4}, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 1, d2),
                getW(wR, wC, ${inputDepthNearestVec4} + 2, d2)
              );

              if (${isChannelsLast}) {
                vec3 xValues = vec3(
                  getX(batch, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 1),
                  getX(batch, xR, xC, ${inputDepthNearestVec4} + 2)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec3 xValues = vec3(
                  getX(batch, ${inputDepthNearestVec4}, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 1, xR, xC),
                  getX(batch, ${inputDepthNearestVec4} + 2, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            }
          }
        }

        float result = dotProd;
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
      }
    };
    Conv3DProgram = class {
      constructor(convInfo) {
        this.variableNames = ["x", "W"];
        this.outputShape = convInfo.outShape;
        const padFront = convInfo.padInfo.front;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        const strideDepth = convInfo.strideDepth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationDepth = convInfo.dilationDepth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const filterDepth = convInfo.filterDepth;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const inputDepthNearestVec4 = Math.floor(convInfo.inChannels / 4) * 4;
        const inputDepthVec4Remainder = convInfo.inChannels % 4;
        this.userCode = `
      const ivec3 strides = ivec3(${strideDepth}, ${strideHeight}, ${strideWidth});
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d2 = coords.u;

        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xFCorner = xFRCCorner.x;
        int xRCorner = xFRCCorner.y;
        int xCCorner = xFRCCorner.z;

        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get
        // y(yF, yR, yC, d2). ? = to be determined. : = across all
        // values in that axis.
        float dotProd = 0.0;
        for (int wF = 0; wF < ${filterDepth}; wF++) {
          int xF = xFCorner + wF * ${dilationDepth};

          if (xF < 0 || xF >= ${convInfo.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${filterHeight}; wR++) {
            int xR = xRCorner + wR * ${dilationHeight};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${filterWidth}; wC++) {
              int xC = xCCorner + wC * ${dilationWidth};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              for (int d1 = 0; d1 < ${inputDepthNearestVec4}; d1 += 4) {
                vec4 xValues = vec4(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                vec4 wValues = vec4(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (${inputDepthVec4Remainder === 1}) {
                dotProd +=
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}) *
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2);
              } else if (${inputDepthVec4Remainder === 2}) {
                vec2 xValues = vec2(
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1)
                );
                vec2 wValues = vec2(
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (${inputDepthVec4Remainder === 3}) {
                vec3 xValues = vec3(
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4}),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 1),
                  getX(batch, xF, xR, xC, ${inputDepthNearestVec4} + 2)
                );
                vec3 wValues = vec3(
                  getW(wF, wR, wC, ${inputDepthNearestVec4}, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 1, d2),
                  getW(wF, wR, wC, ${inputDepthNearestVec4} + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
  }
});
var Conv2DPackedProgram;
var init_conv_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu.js"() {
    init_dist();
    init_gpgpu_math();
    Conv2DPackedProgram = class {
      constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
        this.variableNames = ["x", "W"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.customUniforms = [
          { name: "pads", type: "ivec2" },
          { name: "strides", type: "ivec2" },
          { name: "dilations", type: "ivec2" },
          { name: "inDims", type: "ivec2" }
        ];
        this.outputShape = convInfo.outShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        const padLeft = convInfo.padInfo.left;
        const strideWidth = convInfo.strideWidth;
        const dilationWidth = convInfo.dilationWidth;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const texelsAcross = filterWidth;
        let mainLoop = `
       int xR; int xC; int xCOffset;
       vec4 wTexel; vec4 previous; vec4 final;`;
        for (let c = 0; c < filterWidth; c++) {
          mainLoop += `
           vec4 xTexelC${c * 2};
           int xTexelC${c * 2}Ready;
           vec4 xTexelC${c * 2 + 1};
           int xTexelC${c * 2 + 1}Ready;
           vec4 xC${c};`;
        }
        mainLoop += `
     for (int r = 0; r < ${filterHeight}; r++) {
      for (int d1 = 0; d1 < ${convInfo.inChannels}; d1 += 2) {
       `;
        for (let c = 0; c < filterWidth; c++) {
          mainLoop += `
           xTexelC${c * 2} = vec4(0.0);
           xTexelC${c * 2}Ready = 0;
           xTexelC${c * 2 + 1} = vec4(0.0);
           xTexelC${c * 2 + 1}Ready = 0;
           xC${c} = vec4(0.0);`;
        }
        mainLoop += `
         xR = xRCorner + r * dilations[0];
         if (xR >=0 && xR < inDims[0]) {
       `;
        for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {
          const colIndex = texelC * 2;
          mainLoop += `
           xC = xCCorner + ${colIndex * dilationWidth};
           `;
          if (strideWidth === 1) {
            if (colIndex < filterWidth) {
              if (padLeft % 2 === 1) {
                mainLoop += `
                 xCOffset = xC + 1;
                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                   xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);

                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${colIndex}.zw = vec2(0.0);
                   }
                   xTexelC${colIndex}Ready = 1;
                 }
               `;
                if (dilationWidth === 1 && colIndex > 0) {
                  mainLoop += `
                 xC${colIndex} = vec4(xTexelC${colIndex - 2}.zw, xTexelC${colIndex}.xy);
                 `;
                } else {
                  mainLoop += `
                   xCOffset = xC + 1 - 2;

                   if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       previous.zw = vec2(0.0);
                     }

                     xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);
                   } else {
                     xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);
                   }
                   `;
                }
              } else {
                mainLoop += `
                 if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {
                   xTexelC${colIndex} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${colIndex}.zw = vec2(0.0);
                   }
                   xTexelC${colIndex}Ready = 1;
                 }

                 xC${colIndex} = xTexelC${colIndex};
                 `;
              }
              if (colIndex + 1 < filterWidth) {
                const nextTexelOffset = padLeft % 2 === 0 ? util_exports.nearestLargerEven(dilationWidth) : dilationWidth;
                if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {
                  mainLoop += `
                   xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};

                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                     xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       xTexelC${colIndex + 1}.zw = vec2(0.0);
                     }
                     xTexelC${colIndex + 1}Ready = 1;
                   }
                   `;
                  if (dilationWidth > 1) {
                    mainLoop += `
                     xCOffset -= 2;
                     if (xCOffset >= 0 && xCOffset < inDims[1]) {
                      previous = getX(batch, xR, xCOffset, d1);
                      xC${colIndex + 1} = vec4(previous.zw, xTexelC${colIndex + 1}.xy);
                     } else {
                      xC${colIndex + 1} = vec4(0.0, 0.0, xTexelC${colIndex + 1}.xy);
                     }
                     `;
                  } else {
                    mainLoop += `
                     xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.xy);
                     `;
                  }
                } else {
                  if (nextTexelOffset === 1) {
                    mainLoop += `
                     xC${colIndex + 1} = xTexelC${colIndex};
                     `;
                  } else {
                    mainLoop += `
                     xCOffset = xC + ${nextTexelOffset};

                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                       xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);
                       if (xCOffset + 1 >= inDims[1]) {
                         xTexelC${colIndex + 1}.zw = vec2(0.0);
                       }
                       xTexelC${colIndex + 1}Ready = 1;
                     }

                     xC${colIndex + 1} = xTexelC${colIndex + 1};
                     `;
                  }
                }
              }
            }
          } else {
            if (colIndex < filterWidth) {
              if (padLeft % 2 === 1) {
                mainLoop += `
                 xCOffset = xC + 1 - strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                   xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${colIndex}.zw = vec2(0.0);
                   }
                   xTexelC${colIndex}Ready = 1;
                 }

                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                   xTexelC${colIndex + 1} = getX(batch, xR, xC + 1, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xC + 2 >= inDims[1]) {
                     xTexelC${colIndex + 1}.zw = vec2(0.0);
                   }
                   xTexelC${colIndex + 1}Ready = 1;
                 }

                 xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.zw);
               `;
                if (colIndex + 1 < filterWidth) {
                  mainLoop += `
                   final = vec4(0.0);
                   xCOffset = xC + 1 + strides[1];
                   if(xCOffset >= 0 && xCOffset < inDims[1]) {
                     final = getX(batch, xR, xCOffset, d1);
                   }
                   xC${colIndex + 1} = vec4(xTexelC${colIndex + 1}.xy, final.xy);
                 `;
                }
              } else {
                mainLoop += `
                 if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {
                   xTexelC${colIndex} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${colIndex}.zw = vec2(0.0);
                   }
                   xTexelC${colIndex}Ready = 1;
                 }

                 xCOffset = xC + strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                   xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${colIndex + 1}.zw = vec2(0.);
                   }
                   xTexelC${colIndex + 1}Ready = 1;
                 }

                 xC${colIndex} = vec4(
                   xTexelC${colIndex}.xy, xTexelC${colIndex + 1}.xy);
               `;
                if (colIndex + 1 < filterWidth) {
                  mainLoop += `
                   xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.zw);
                 `;
                }
              }
            }
          }
          if (colIndex < filterWidth) {
            mainLoop += `
             wTexel = getW(r, ${colIndex}, d1, d2);
             dotProd += xC${colIndex}.xxzz * vec4(wTexel.xy, wTexel.xy);
             if(d1 + 1 < ${convInfo.inChannels}) {
               dotProd += xC${colIndex}.yyww * vec4(wTexel.zw, wTexel.zw);
             }
           `;
            if (colIndex + 1 < filterWidth) {
              mainLoop += `
               wTexel = getW(r, ${colIndex + 1}, d1, d2);
               dotProd += xC${colIndex + 1}.xxzz * vec4(wTexel.xy, wTexel.xy);
               if(d1 + 1 < ${convInfo.inChannels}) {
                 dotProd += xC${colIndex + 1}.yyww * vec4(wTexel.zw, wTexel.zw);
               }
             `;
            }
          }
        }
        mainLoop += `
     }
   `;
        mainLoop += `
     }
   `;
        mainLoop += `
     }
   `;
        let activationSnippet = "", applyActivationSnippet = "";
        if (activation) {
          if (hasPreluActivation) {
            activationSnippet = `vec4 activation(vec4 a) {
           vec4 b = getPreluActivationWeightsAtOutCoords();
           ${activation}
         }`;
          } else if (hasLeakyReluAlpha) {
            activationSnippet = `vec4 activation(vec4 a) {
           vec4 b = getLeakyreluAlphaAtOutCoords();
           ${activation}
         }`;
          } else {
            activationSnippet = `vec4 activation(vec4 x) {
           ${activation}
         }`;
          }
          applyActivationSnippet = `result = activation(result);`;
        }
        const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
        if (addBias) {
          this.variableNames.push("bias");
        }
        if (hasPreluActivation) {
          this.variableNames.push("preluActivationWeights");
        }
        if (hasLeakyReluAlpha) {
          this.variableNames.push("leakyreluAlpha");
        }
        this.userCode = `
       ${activationSnippet}

       void main() {
         ivec4 coords = getOutputCoords();
         int batch = coords.x;
         ivec2 xRCCorner = coords.yz * strides - pads;
         int d2 = coords.w;
         int xRCorner = xRCCorner.x;
         int xCCorner = xRCCorner.y;

         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
         vec4 dotProd = vec4(0.000000000000001);

         ${mainLoop}

         vec4 result = dotProd - vec4(0.000000000000001);
         ${addBiasSnippet}
         ${applyActivationSnippet}
         setOutput(result);
       }
     `;
      }
    };
  }
});
var Im2ColPackedProgram;
var init_im2col_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/im2col_packed_gpu.js"() {
    init_glsl_version();
    init_gpgpu_math();
    Im2ColPackedProgram = class {
      constructor(outputShape, convInfo) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.customUniforms = [
          { name: "inputShape", type: "ivec4" },
          { name: "pad", type: "ivec2" },
          { name: "stride", type: "ivec2" },
          { name: "dilation", type: "ivec2" },
          { name: "inChannels", type: "int" },
          { name: "itemsPerBlockRow", type: "int" },
          { name: "outWidth", type: "int" }
        ];
        this.outputShape = outputShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        const { dataFormat } = convInfo;
        const glsl = getGlslDifferences();
        const isChannelsLast = dataFormat === "channelsLast";
        const rowDim = isChannelsLast ? 1 : 2;
        const colDim = isChannelsLast ? 2 : 3;
        const boundsCheckingSnippet = this.enableShapeUniforms ? "if(blockIndex < outShape[2] && pos < outShape[1]) {" : `if(blockIndex < ${outputShape[2]} && pos < ${outputShape[1]}) {`;
        let unrolled = ``;
        for (let row = 0; row <= 1; row++) {
          for (let col = 0; col <= 1; col++) {
            unrolled += `
          blockIndex = rc.z + ${col};
          pos = rc.y + ${row};

          ${boundsCheckingSnippet}
            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];
            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);

            if(d0 < inputShape[${rowDim}] && d0 >= 0) {
              // Use custom imod instead mod. On Intel GPU, mod may generate
              // unexpected value.
              // https://github.com/tensorflow/tfjs/issues/5447
              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];
              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /
                  inChannels);

              if(d1 < inputShape[${colDim}] && d1 >= 0) {

                ch = imod(pos, inChannels);

                if (${isChannelsLast}) {
                  innerDims = vec2(d1, ch);
                  result[${row * 2 + col}] = getChannel(
                    getA(rc.x, d0, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                } else {
                  innerDims = vec2(d0, d1);
                  result[${row * 2 + col}] = getChannel(
                    getA(rc.x, ch, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                }
              }
            }
          }
        `;
          }
        }
        this.userCode = `
      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0);

        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
        vec2 innerDims;

        ${unrolled}

        ${glsl.output} = result;
      }
    `;
      }
    };
  }
});
function getShapeForBatchMatMul(shape, isChannelsLast) {
  const length5 = shape.length;
  if (length5 >= 3) {
    return isChannelsLast ? [
      ...shape.slice(0, -3),
      shape[length5 - 3] * shape[length5 - 2],
      shape[length5 - 1]
      /* channel */
    ] : [
      ...shape.slice(0, -3),
      shape[length5 - 3],
      shape[length5 - 2] * shape[length5 - 1]
      /* height * width */
    ];
  } else if (!isChannelsLast && length5 === 1 && shape[0] > 1) {
    return [shape[0], 1];
  } else {
    return null;
  }
}
function conv2dByMatMul({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const xShape = x.shape;
  const xTexData = backend2.texData.get(x.dataId);
  const sharedMatMulDim = convInfo.inChannels;
  const outerShapeX = xShape[0] * xShape[1] * xShape[2];
  const outerShapeFilter = convInfo.outChannels;
  const isChannelsLast = convInfo.dataFormat === "channelsLast";
  const transposeA = false;
  const transposeB = false;
  let out;
  const intermediates = [];
  if (preluActivationWeights != null) {
    const targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
    if (targetShape != null) {
      preluActivationWeights = reshape3({
        inputs: { x: preluActivationWeights },
        backend: backend2,
        attrs: { shape: targetShape }
      });
      intermediates.push(preluActivationWeights);
    }
  }
  if (bias != null) {
    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
    if (targetShape != null) {
      bias = reshape3({ inputs: { x: bias }, backend: backend2, attrs: { shape: targetShape } });
      intermediates.push(bias);
    }
  }
  const batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;
  const canOptimize = !batchMatMulWillBeUnpacked && xTexData.isPacked && isChannelsLast && xTexData.texture != null && xShape[2] % 2 !== 0 && util_exports.arraysEqual(xTexData.shape.slice(-3), xShape.slice(-3));
  if (canOptimize) {
    const targetShape = xShape[0] * xShape[1] * (xShape[2] + 1);
    const xReshaped = {
      dataId: x.dataId,
      shape: [1, targetShape, convInfo.inChannels],
      dtype: x.dtype
    };
    const originalXTexDataShape = xTexData.shape;
    xTexData.shape = xTexData.shape.slice();
    xTexData.shape[xTexData.shape.length - 2]++;
    util_exports.assert(isReshapeFree(xTexData.shape, xReshaped.shape), () => `packed reshape ${xTexData.shape} to ${xReshaped.shape} isn't free`);
    const filterReshaped = reshape3({
      inputs: { x: filter },
      backend: backend2,
      attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
    });
    intermediates.push(filterReshaped);
    const pointwiseConv = batchMatMulImpl({
      a: xReshaped,
      b: filterReshaped,
      backend: backend2,
      transposeA,
      transposeB,
      bias,
      activation,
      preluActivationWeights,
      leakyreluAlpha
    });
    const pointwiseConvTexData = backend2.texData.get(pointwiseConv.dataId);
    util_exports.assert(pointwiseConvTexData.isPacked, () => "batchMatMul result is expected to be packed");
    xTexData.shape = originalXTexDataShape;
    pointwiseConvTexData.shape = convInfo.outShape;
    out = identity22({ inputs: { x: pointwiseConv }, backend: backend2 });
    out.shape = convInfo.outShape;
    intermediates.push(pointwiseConv);
  } else {
    const numCols = convInfo.outHeight * convInfo.outWidth;
    const xReshaped = reshape3({
      inputs: { x },
      backend: backend2,
      attrs: {
        shape: isChannelsLast ? [convInfo.batchSize, numCols, convInfo.inChannels] : [convInfo.batchSize, convInfo.inChannels, numCols]
      }
    });
    const filterReshaped = reshape3({
      inputs: { x: filter },
      backend: backend2,
      attrs: { shape: [1, convInfo.inChannels, convInfo.outChannels] }
    });
    const result = batchMatMulImpl({
      a: isChannelsLast ? xReshaped : filterReshaped,
      b: isChannelsLast ? filterReshaped : xReshaped,
      transposeA: !isChannelsLast,
      transposeB,
      backend: backend2,
      bias,
      activation,
      preluActivationWeights,
      leakyreluAlpha
    });
    out = reshape3({ inputs: { x: result }, backend: backend2, attrs: { shape: convInfo.outShape } });
    intermediates.push(xReshaped);
    intermediates.push(filterReshaped);
    intermediates.push(result);
  }
  for (const i of intermediates) {
    backend2.disposeIntermediateTensorInfo(i);
  }
  return out;
}
function conv2dWithIm2Row({ x, filter, convInfo, backend: backend2, bias = null, preluActivationWeights = null, leakyreluAlpha = 0, activation = null }) {
  const { filterWidth, filterHeight, inChannels, outWidth, outHeight, dataFormat } = convInfo;
  const isChannelsLast = dataFormat === "channelsLast";
  const sharedDim = filterWidth * filterHeight * inChannels;
  const numCols = outHeight * outWidth;
  const x2ColShape = [convInfo.batchSize, sharedDim, numCols];
  const transposeA = true;
  const transposeB = false;
  const intermediates = [];
  if (preluActivationWeights != null) {
    const targetShape = getShapeForBatchMatMul(preluActivationWeights.shape, isChannelsLast);
    if (targetShape != null) {
      preluActivationWeights = reshape3({
        inputs: { x: preluActivationWeights },
        backend: backend2,
        attrs: { shape: targetShape }
      });
      intermediates.push(preluActivationWeights);
    }
  }
  if (bias != null) {
    const targetShape = getShapeForBatchMatMul(bias.shape, isChannelsLast);
    if (targetShape != null) {
      bias = reshape3({ inputs: { x: bias }, backend: backend2, attrs: { shape: targetShape } });
      intermediates.push(bias);
    }
  }
  const w2Row = reshape3({
    inputs: { x: filter },
    backend: backend2,
    attrs: { shape: [1, sharedDim, util_exports.sizeFromShape(filter.shape) / sharedDim] }
  });
  intermediates.push(w2Row);
  const im2ColProgram = new Im2ColPackedProgram(x2ColShape, convInfo);
  const customValues = [
    x.shape,
    [convInfo.padInfo.top, convInfo.padInfo.left],
    [convInfo.strideHeight, convInfo.strideWidth],
    [convInfo.dilationHeight, convInfo.dilationWidth],
    [convInfo.inChannels],
    [convInfo.filterWidth * convInfo.inChannels],
    [convInfo.outWidth]
  ];
  const im2Col = backend2.runWebGLProgram(im2ColProgram, [x], "float32", customValues);
  const im2ColReshaped = reshape3({ inputs: { x: im2Col }, backend: backend2, attrs: { shape: x2ColShape } });
  intermediates.push(im2Col);
  intermediates.push(im2ColReshaped);
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation === "leakyrelu";
  const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;
  const matmulProgram = new MatMulPackedProgram(isChannelsLast ? im2ColReshaped.shape : w2Row.shape, isChannelsLast ? w2Row.shape : im2ColReshaped.shape, isChannelsLast ? [convInfo.batchSize, numCols, convInfo.outChannels] : [convInfo.batchSize, convInfo.outChannels, numCols], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
  const inputs = isChannelsLast ? [im2ColReshaped, w2Row] : [w2Row, im2ColReshaped];
  if (bias) {
    inputs.push(bias);
  }
  if (hasPreluActivationWeights) {
    inputs.push(preluActivationWeights);
  }
  if (hasLeakyreluAlpha) {
    const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
    inputs.push($leakyreluAlpha);
    intermediates.push($leakyreluAlpha);
  }
  const product = backend2.runWebGLProgram(matmulProgram, inputs, "float32");
  const out = reshape3({ inputs: { x: product }, backend: backend2, attrs: { shape: convInfo.outShape } });
  intermediates.push(product);
  for (const i of intermediates) {
    backend2.disposeIntermediateTensorInfo(i);
  }
  return out;
}
var init_Conv2D_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D_impl.js"() {
    init_dist();
    init_im2col_packed_gpu();
    init_kernel_funcs_utils();
    init_mulmat_packed_gpu();
    init_webgl_util();
    init_BatchMatMul_impl();
    init_Identity2();
    init_Reshape2();
  }
});
function conv2d3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
  let out;
  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
    out = conv2dByMatMul({ x, filter, convInfo, backend: backend2 });
  } else if (convInfo.strideWidth <= 2 && $dataFormat === "channelsLast" && env().getBool("WEBGL_EXP_CONV")) {
    const program = new Conv2DPackedProgram(convInfo);
    const customValues = [
      [convInfo.padInfo.top, convInfo.padInfo.left],
      [convInfo.strideHeight, convInfo.strideWidth],
      [convInfo.dilationHeight, convInfo.dilationWidth],
      [convInfo.inHeight, convInfo.inWidth]
    ];
    out = backend2.runWebGLProgram(program, [x, filter], "float32", customValues);
  } else if (env().getBool("WEBGL_CONV_IM2COL")) {
    out = conv2dWithIm2Row({ x, filter, convInfo, backend: backend2 });
  } else {
    const program = new Conv2DProgram(convInfo);
    out = backend2.runWebGLProgram(program, [x, filter], "float32");
  }
  const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: convInfo.outShape } });
  backend2.disposeIntermediateTensorInfo(out);
  return outReshaped;
}
var conv2DConfig2;
var init_Conv2D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D.js"() {
    init_dist();
    init_conv_gpu();
    init_conv_packed_gpu();
    init_Conv2D_impl();
    init_Reshape2();
    conv2DConfig2 = {
      kernelName: Conv2D,
      backendName: "webgl",
      kernelFunc: conv2d3
    };
  }
});
var Conv2DDerFilterProgram;
var Conv2DDerInputProgram;
var Conv3DDerFilterProgram;
var Conv3DDerInputProgram;
var init_conv_backprop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu.js"() {
    Conv2DDerFilterProgram = class {
      constructor(convInfo) {
        this.variableNames = ["x", "dy"];
        this.outputShape = convInfo.filterShape;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        const isChannelsLast = convInfo.dataFormat === "channelsLast";
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int d2 = coords.w;

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
            int xR = wR + yR * ${strideHeight} - ${padTop};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
              int xC = wC + yC * ${strideWidth} - ${padLeft};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              if (${isChannelsLast}) {
                float dyValue = getDy(b, yR, yC, d2);
                float xValue = getX(b, xR, xC, d1);
                dotProd += (xValue * dyValue);
              } else {
                float dyValue = getDy(b, d2, yR, yC);
                float xValue = getX(b, d1, xR, xC);
                dotProd += (xValue * dyValue);
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
    Conv2DDerInputProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy", "W"];
        this.outputShape = convInfo.inShape;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const isChannelsLast = convInfo.dataFormat === "channelsLast";
        const padTop = filterHeight - 1 - convInfo.padInfo.top;
        const padLeft = filterWidth - 1 - convInfo.padInfo.left;
        const rowDim = isChannelsLast ? 1 : 2;
        const colDim = isChannelsLast ? 2 : 3;
        const channelDim = isChannelsLast ? 3 : 1;
        this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[${channelDim}];

        ivec2 dyCorner = ivec2(coords[${rowDim}], coords[${colDim}]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${filterHeight} - 1 - wR;

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${filterWidth} - 1 - wC;

            for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {

              if (${isChannelsLast}) {
                float xValue = getDy(batch, idyR, idyC, d2);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              } else {
                float xValue = getDy(batch, d2, idyR, idyC);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
    Conv3DDerFilterProgram = class {
      constructor(convInfo) {
        this.variableNames = ["x", "dy"];
        this.outputShape = convInfo.filterShape;
        const strideDepth = convInfo.strideDepth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const padFront = convInfo.padInfo.front;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        this.userCode = `
      void main() {
        ivec5 coords = getOutputCoords();
        int wF = coords.x;
        int wR = coords.y;
        int wC = coords.z;
        int d1 = coords.w;
        int d2 = coords.u;

        float dotProd = 0.0;

        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yF = 0; yF < ${convInfo.outDepth}; yF++) {
            int xF = wF + yF * ${strideDepth} - ${padFront};

            if (xF < 0 || xF >= ${convInfo.inDepth}) {
              continue;
            }

            for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
              int xR = wR + yR * ${strideHeight} - ${padTop};

              if (xR < 0 || xR >= ${convInfo.inHeight}) {
                continue;
              }

              for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
                int xC = wC + yC * ${strideWidth} - ${padLeft};

                if (xC < 0 || xC >= ${convInfo.inWidth}) {
                  continue;
                }

                float dyValue = getDy(b, yF, yR, yC, d2);
                float xValue = getX(b, xF, xR, xC, d1);
                dotProd += (xValue * dyValue);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
    Conv3DDerInputProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy", "W"];
        this.outputShape = convInfo.inShape;
        const filterDepth = convInfo.filterDepth;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const strideDepth = convInfo.strideDepth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const padFront = filterDepth - 1 - convInfo.padInfo.front;
        const padTop = filterHeight - 1 - convInfo.padInfo.top;
        const padLeft = filterWidth - 1 - convInfo.padInfo.left;
        this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.u;


        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyFCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        float dotProd = 0.0;
        for (int wF = 0; wF < ${filterDepth}; wF++) {
          float dyF = float(dyFCorner + wF) / ${strideDepth}.0;

          if (dyF < 0.0 || dyF >= ${convInfo.outDepth}.0 || fract(dyF) > 0.0) {
            continue;
          }
          int idyF = int(dyF);

          int wFPerm = ${filterDepth} - 1 - wF;

          for (int wR = 0; wR < ${filterHeight}; wR++) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
              fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            int wRPerm = ${filterHeight} - 1 - wR;

            for (int wC = 0; wC < ${filterWidth}; wC++) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              int wCPerm = ${filterWidth} - 1 - wC;

              for (int d2 = 0; d2 < ${convInfo.outChannels}; d2++) {
                float xValue = getDy(batch, idyF, idyR, idyC, d2);
                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
  }
});
function conv2DBackpropFilter3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad2, dataFormat, dimRoundingMode, filterShape } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filterShape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
  const program = new Conv2DDerFilterProgram(convInfo);
  return backend2.runWebGLProgram(program, [x, dy], "float32");
}
var conv2DBackpropFilterConfig2;
var init_Conv2DBackpropFilter2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropFilter.js"() {
    init_dist();
    init_conv_backprop_gpu();
    conv2DBackpropFilterConfig2 = {
      kernelName: Conv2DBackpropFilter,
      backendName: "webgl",
      kernelFunc: conv2DBackpropFilter3
    };
  }
});
function conv2DBackpropInput3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { inputShape, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(inputShape, filter.shape, strides, 1, pad2, dimRoundingMode, false, $dataFormat);
  const program = new Conv2DDerInputProgram(convInfo);
  return backend2.runWebGLProgram(program, [dy, filter], "float32");
}
var conv2DBackpropInputConfig2;
var init_Conv2DBackpropInput2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropInput.js"() {
    init_dist();
    init_conv_backprop_gpu();
    conv2DBackpropInputConfig2 = {
      kernelName: Conv2DBackpropInput,
      backendName: "webgl",
      kernelFunc: conv2DBackpropInput3
    };
  }
});
function conv3D2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filter.shape, strides, dilations, pad2);
  const program = new Conv3DProgram(convInfo);
  return backend2.runWebGLProgram(program, [x, filter], "float32");
}
var conv3DConfig2;
var init_Conv3D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3D.js"() {
    init_dist();
    init_conv_gpu();
    conv3DConfig2 = {
      kernelName: Conv3D,
      backendName: "webgl",
      kernelFunc: conv3D2
    };
  }
});
function conv3DBackpropFilterV22(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, pad: pad2, filterShape } = attrs;
  const convInfo = backend_util_exports.computeConv3DInfo(x.shape, filterShape, strides, 1, pad2);
  const program = new Conv3DDerFilterProgram(convInfo);
  return backend2.runWebGLProgram(program, [x, dy], "float32");
}
var conv3DBackpropFilterV2Config2;
var init_Conv3DBackpropFilterV22 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropFilterV2.js"() {
    init_dist();
    init_conv_backprop_gpu();
    conv3DBackpropFilterV2Config2 = {
      kernelName: Conv3DBackpropFilterV2,
      backendName: "webgl",
      kernelFunc: conv3DBackpropFilterV22
    };
  }
});
function conv3DBackpropInput2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { pad: pad2, strides, inputShape } = attrs;
  const convInfo = backend_util_exports.computeConv3DInfo(inputShape, filter.shape, strides, 1, pad2);
  const program = new Conv3DDerInputProgram(convInfo);
  return backend2.runWebGLProgram(program, [dy, filter], "float32");
}
var conv3DBackpropInputConfig;
var init_Conv3DBackpropInputV22 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropInputV2.js"() {
    init_dist();
    init_conv_backprop_gpu();
    conv3DBackpropInputConfig = {
      kernelName: Conv3DBackpropInputV2,
      backendName: "webgl",
      kernelFunc: conv3DBackpropInput2
    };
  }
});
var COS;
var cos3;
var cosConfig2;
var init_Cos2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cos.js"() {
    init_dist();
    init_kernel_funcs_utils();
    COS = CHECK_NAN_SNIPPET_UNARY + `
  return cos(x);
`;
    cos3 = unaryKernelFunc2({ opSnippet: COS });
    cosConfig2 = {
      kernelName: Cos,
      backendName: "webgl",
      kernelFunc: cos3
    };
  }
});
var COSH;
var cosh3;
var coshConfig2;
var init_Cosh2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cosh.js"() {
    init_dist();
    init_kernel_funcs_utils();
    COSH = `
  float e2x = exp(-x);
  return (e2x + 1.0 / e2x) / 2.0;
`;
    cosh3 = unaryKernelFunc2({ opSnippet: COSH });
    coshConfig2 = {
      kernelName: Cosh,
      backendName: "webgl",
      kernelFunc: cosh3
    };
  }
});
var CropAndResizeProgram;
var init_crop_and_resize_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/crop_and_resize_gpu.js"() {
    CropAndResizeProgram = class {
      constructor(imageShape, boxShape, cropSize, method, extrapolationValue) {
        this.variableNames = ["Image", "Boxes", "BoxInd"];
        this.outputShape = [];
        const [batch, imageHeight, imageWidth, depth] = imageShape;
        const [numBoxes] = boxShape;
        const [cropHeight, cropWidth] = cropSize;
        this.outputShape = [numBoxes, cropHeight, cropWidth, depth];
        const methodId = method === "bilinear" ? 1 : 0;
        const [inputHeightFloat, inputWidthFloat] = [`${imageHeight - 1}.0`, `${imageWidth - 1}.0`];
        const [heightRatio, heightScale, inY] = cropHeight > 1 ? [
          `${(imageHeight - 1) / (cropHeight - 1)}`,
          "(y2-y1) * height_ratio",
          `y1*${inputHeightFloat} + float(y)*(height_scale)`
        ] : [
          "0.0",
          "0.0",
          `0.5 * (y1+y2) * ${inputHeightFloat}`
        ];
        const [widthRatio, widthScale, inX] = cropWidth > 1 ? [
          `${(imageWidth - 1) / (cropWidth - 1)}`,
          "(x2-x1) * width_ratio",
          `x1*${inputWidthFloat} + float(x)*(width_scale)`
        ] : [
          "0.0",
          "0.0",
          `0.5 * (x1+x2) * ${inputWidthFloat}`
        ];
        this.userCode = `
      const float height_ratio = float(${heightRatio});
      const float width_ratio = float(${widthRatio});
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int y = coords[1];
        int x = coords[2];
        int d = coords[3];

        // get box vals
        float y1 = getBoxes(b,0);
        float x1 = getBoxes(b,1);
        float y2 = getBoxes(b,2);
        float x2 = getBoxes(b,3);

        // get image in batch index
        int bInd = round(getBoxInd(b));
        if(bInd < 0 || bInd >= ${batch}) {
          return;
        }

        float height_scale = ${heightScale};
        float width_scale = ${widthScale};

        float in_y = ${inY};
        if( in_y < 0.0 || in_y > ${inputHeightFloat} ) {
          setOutput(float(${extrapolationValue}));
          return;
        }
        float in_x = ${inX};
        if( in_x < 0.0 || in_x > ${inputWidthFloat} ) {
          setOutput(float(${extrapolationValue}));
          return;
        }

        vec2 sourceFracIndexCR = vec2(in_x,in_y);
        if(${methodId} == 1) {
          // Compute the four integer indices.
          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);
          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));

          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);
          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);
          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);
          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);

          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);

          float top = topLeft + (topRight - topLeft) * fracCR.x;
          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          float newValue = top + (bottom - top) * fracCR.y;
          setOutput(newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          ivec2 sourceNearestCR = ivec2(floor(
            sourceFracIndexCR + vec2(0.5,0.5)));
          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutput(newValue);
        }
      }
    `;
      }
    };
  }
});
var cropAndResize4;
var cropAndResizeConfig2;
var init_CropAndResize2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/CropAndResize.js"() {
    init_dist();
    init_crop_and_resize_gpu();
    cropAndResize4 = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { image: image2, boxes, boxInd } = inputs;
      const { cropSize, method, extrapolationValue } = attrs;
      const program = new CropAndResizeProgram(image2.shape, boxes.shape, cropSize, method, extrapolationValue);
      return backend2.runWebGLProgram(program, [image2, boxes, boxInd], "float32");
    };
    cropAndResizeConfig2 = {
      kernelName: CropAndResize,
      backendName: "webgl",
      kernelFunc: cropAndResize4
    };
  }
});
function getCoords2(rank, name, op2) {
  if (rank === 1) {
    return `${name}`;
  } else if (rank === 2) {
    return `${name}.x, ${name}.y`;
  } else if (rank === 3) {
    return `${name}.x, ${name}.y, ${name}.z`;
  } else if (rank === 4) {
    return `${name}.x, ${name}.y, ${name}.z, ${name}.w`;
  } else {
    throw new Error(`Cumulative ${op2} for rank ${rank} is not yet supported`);
  }
}
function getFinalCoord(rank, name, op2) {
  if (rank === 1) {
    return `${name}`;
  } else if (rank === 2) {
    return `${name}.y`;
  } else if (rank === 3) {
    return `${name}.z`;
  } else if (rank === 4) {
    return `${name}.w`;
  } else {
    throw new Error(`Cumulative ${op2} for rank ${rank} is not yet supported`);
  }
}
var CumOpType;
var CumProgram;
var init_cum_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/cum_gpu.js"() {
    init_shader_compiler();
    (function(CumOpType2) {
      CumOpType2["Prod"] = "*";
      CumOpType2["Sum"] = "+";
    })(CumOpType || (CumOpType = {}));
    CumProgram = class {
      constructor(op2, outputShape, exclusive, reverse4) {
        this.op = op2;
        this.outputShape = outputShape;
        this.variableNames = ["x"];
        this.customUniforms = [{ name: "index", type: "float" }];
        const rank = this.outputShape.length;
        const initVal = this.op === CumOpType.Prod ? "1.0" : "0.0";
        const val = exclusive ? initVal : `getX(${getCoords2(rank, "coords", this.op)})`;
        const length5 = this.outputShape[this.outputShape.length - 1];
        let condition = "";
        let idxString = "";
        if (exclusive) {
          condition = reverse4 ? `end != ${length5 - 1}` : "end != 0";
          idxString = reverse4 ? "end + 1" : "end - 1";
        } else {
          condition = reverse4 ? `end + pow2 < ${length5}` : "end >= pow2";
          idxString = reverse4 ? "end + pow2" : "end - pow2";
        }
        this.userCode = `
      void main() {
        ${getCoordsDataType(rank)} coords = getOutputCoords();
        int end = ${getFinalCoord(rank, "coords", this.op)};
        float val = ${val};
        int pow2 = int(pow(2.0, index));
        if (${condition}) {
          int idx = ${idxString};
          ${getFinalCoord(rank, "coords", this.op)} = idx;
          val ${this.op}= getX(${getCoords2(rank, "coords", this.op)});
        }
        setOutput(val);
      }
    `;
      }
    };
  }
});
function cumImpl(op2, x, backend2, axis, exclusive, reverse4) {
  const xRank = x.shape.length;
  const permutation = backend_util_exports.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
  }
  const permutedAxis = backend_util_exports.getInnerMostAxes(1, xRank)[0];
  if (permutedAxis !== xRank - 1) {
    throw new Error(`WebGL cumprod shader expects an inner-most axis=${x.shape.length - 1} but got axis=${axis}`);
  }
  const size = permutedX.shape[permutedAxis];
  let result = identity22({ inputs: { x: permutedX }, backend: backend2 });
  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {
    const program = new CumProgram(op2, permutedX.shape, false, reverse4);
    const customValues = [[i]];
    const prevResult = result;
    result = backend2.runWebGLProgram(program, [result], result.dtype, customValues);
    backend2.disposeIntermediateTensorInfo(prevResult);
  }
  if (exclusive) {
    const program = new CumProgram(op2, permutedX.shape, exclusive, reverse4);
    const prevResult = result;
    result = backend2.runWebGLProgram(program, [result], result.dtype);
    backend2.disposeIntermediateTensorInfo(prevResult);
  }
  if (permutation != null) {
    const reversePermutation = backend_util_exports.getUndoAxesPermutation(permutation);
    const reverseTransposedResult = transpose3({ inputs: { x: result }, backend: backend2, attrs: { perm: reversePermutation } });
    backend2.disposeIntermediateTensorInfo(result);
    backend2.disposeIntermediateTensorInfo(permutedX);
    return reverseTransposedResult;
  }
  return result;
}
var init_Cum_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cum_impl.js"() {
    init_dist();
    init_cum_gpu();
    init_Identity2();
    init_Transpose2();
  }
});
function cumprod3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse4 } = attrs;
  return cumImpl(CumOpType.Prod, x, backend2, axis, exclusive, reverse4);
}
var cumprodConfig2;
var init_Cumprod2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cumprod.js"() {
    init_dist();
    init_cum_gpu();
    init_Cum_impl();
    cumprodConfig2 = {
      kernelName: Cumprod,
      backendName: "webgl",
      kernelFunc: cumprod3
    };
  }
});
function cumsum3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, exclusive, reverse: reverse4 } = attrs;
  return cumImpl(CumOpType.Sum, x, backend2, axis, exclusive, reverse4);
}
var cumsumConfig2;
var init_Cumsum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Cumsum.js"() {
    init_dist();
    init_cum_gpu();
    init_Cum_impl();
    cumsumConfig2 = {
      kernelName: Cumsum,
      backendName: "webgl",
      kernelFunc: cumsum3
    };
  }
});
function denseBincount3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, weights } = inputs;
  const { size, binaryOutput } = attrs;
  if (x.shape.length === 1) {
    const xVals = backend2.readSync(x.dataId);
    const weightsVals = backend2.readSync(weights.dataId);
    const outVals = bincountImplCPU(xVals, weightsVals, weights.dtype, weights.shape, size);
    return backend2.makeTensorInfo([size], weights.dtype, outVals);
  } else if (x.shape.length === 2) {
    const xBuf = backend2.bufferSync(x);
    const weightsBuf = backend2.bufferSync(weights);
    const outBuf = bincountReduceImplCPU(xBuf, weightsBuf, size, binaryOutput);
    return backend2.makeTensorInfo(outBuf.shape, weights.dtype, outBuf.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${x.shape.length}.`);
}
var denseBincountConfig2;
var init_DenseBincount2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DenseBincount.js"() {
    init_dist();
    init_shared2();
    denseBincountConfig2 = {
      kernelName: DenseBincount,
      backendName: "webgl",
      kernelFunc: denseBincount3
    };
  }
});
var DepthToSpaceProgram;
var init_depth_to_space_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/depth_to_space_gpu.js"() {
    DepthToSpaceProgram = class {
      constructor(outputShape, blockSize, dataFormat) {
        this.variableNames = ["x"];
        this.outputShape = [];
        this.outputShape = outputShape;
        this.blockSize = blockSize;
        this.dataFormat = dataFormat;
        this.userCode = `
    void main() {
      ivec4 coords = getOutputCoords();
      int b = coords[0];
      int h = ${this.getHeightCoordString()};
      int w = ${this.getWidthCoordString()};
      int d = ${this.getDepthCoordString()};

      int in_h = h / ${blockSize};
      int offset_h = imod(h, ${blockSize});
      int in_w = w / ${blockSize};
      int offset_w = imod(w, ${blockSize});
      int offset_d = (offset_h * ${blockSize} + offset_w) *
        ${this.getOutputDepthSize()};
      int in_d = d + offset_d;

      float result = ${this.getInputSamplingString()};
      setOutput(result);
    }
  `;
      }
      getHeightCoordString() {
        if (this.dataFormat === "NHWC") {
          return `coords[1]`;
        } else {
          return `coords[2]`;
        }
      }
      getWidthCoordString() {
        if (this.dataFormat === "NHWC") {
          return `coords[2]`;
        } else {
          return `coords[3]`;
        }
      }
      getDepthCoordString() {
        if (this.dataFormat === "NHWC") {
          return `coords[3]`;
        } else {
          return `coords[1]`;
        }
      }
      getOutputDepthSize() {
        if (this.dataFormat === "NHWC") {
          return this.outputShape[3];
        } else {
          return this.outputShape[1];
        }
      }
      getInputSamplingString() {
        if (this.dataFormat === "NHWC") {
          return `getX(b, in_h, in_w, in_d)`;
        } else {
          return `getX(b, in_d, in_h, in_w)`;
        }
      }
    };
  }
});
function depthToSpace3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { blockSize, dataFormat } = attrs;
  const batchSize = x.shape[0];
  const inputHeight = dataFormat === "NHWC" ? x.shape[1] : x.shape[2];
  const inputWidth = dataFormat === "NHWC" ? x.shape[2] : x.shape[3];
  const inputDepth = dataFormat === "NHWC" ? x.shape[3] : x.shape[1];
  const outputHeight = inputHeight * blockSize;
  const outputWidth = inputWidth * blockSize;
  const outputDepth = inputDepth / (blockSize * blockSize);
  const outputShape = dataFormat === "NHWC" ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];
  const program = new DepthToSpaceProgram(outputShape, blockSize, dataFormat);
  return backend2.runWebGLProgram(program, [x], x.dtype);
}
var depthToSpaceConfig2;
var init_DepthToSpace2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthToSpace.js"() {
    init_dist();
    init_depth_to_space_gpu();
    depthToSpaceConfig2 = {
      kernelName: DepthToSpace,
      backendName: "webgl",
      kernelFunc: depthToSpace3
    };
  }
});
var DepthwiseConv2DProgram;
var init_conv_gpu_depthwise = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_gpu_depthwise.js"() {
    init_gpgpu_math();
    DepthwiseConv2DProgram = class {
      constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
        this.variableNames = ["x", "W"];
        this.customUniforms = [
          { name: "pads", type: "ivec2" },
          { name: "strides", type: "ivec2" },
          { name: "dilations", type: "ivec2" },
          { name: "inDims", type: "ivec2" }
        ];
        this.outputShape = convInfo.outShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const channelMul = convInfo.outChannels / convInfo.inChannels;
        let activationSnippet = "", applyActivationSnippet = "";
        if (activation) {
          if (hasPreluActivation) {
            activationSnippet = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
          } else if (hasLeakyReluAlpha) {
            activationSnippet = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
          } else {
            activationSnippet = `
          float activation(float x) {
            ${activation}
          }
        `;
          }
          applyActivationSnippet = `result = activation(result);`;
        }
        const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
        if (addBias) {
          this.variableNames.push("bias");
        }
        if (hasPreluActivation) {
          this.variableNames.push("preluActivationWeights");
        }
        if (hasLeakyReluAlpha) {
          this.variableNames.push("leakyreluAlpha");
        }
        this.userCode = `
      ${activationSnippet}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${channelMul};
        int q = d2 - d1 * ${channelMul};

        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.
        for (int wR = 0; wR < ${filterHeight}; wR++) {
          int xR = xRCorner + wR * dilations[0];

          if (xR < 0 || xR >= inDims[0]) {
            continue;
          }

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            int xC = xCCorner + wC * dilations[1];

            if (xC < 0 || xC >= inDims[1]) {
              continue;
            }

            float xVal = getX(batch, xR, xC, d1);
            float wVal = getW(wR, wC, d1, q);
            dotProd += xVal * wVal;
          }
        }

        float result = dotProd;
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
      }
    };
  }
});
var DepthwiseConvPacked2DProgram;
var init_conv_packed_gpu_depthwise = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu_depthwise.js"() {
    init_dist();
    init_gpgpu_math();
    DepthwiseConvPacked2DProgram = class {
      constructor(convInfo, addBias = false, activation = null, hasPreluActivation = false, hasLeakyReluAlpha = false) {
        this.variableNames = ["x", "W"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.customUniforms = [
          { name: "pads", type: "ivec2" },
          { name: "strides", type: "ivec2" },
          { name: "dilations", type: "ivec2" },
          { name: "inDims", type: "ivec2" }
        ];
        this.outputShape = convInfo.outShape;
        this.enableShapeUniforms = useShapeUniforms(this.outputShape.length);
        const channelMul = convInfo.outChannels / convInfo.inChannels;
        const padLeft = convInfo.padInfo.left;
        const strideWidth = convInfo.strideWidth;
        const dilationWidth = convInfo.dilationWidth;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const texelsAcross = filterWidth;
        let mainLoop = `
      int xR; int xC; int xCOffset;
      vec4 wTexel; vec4 previous; vec4 final;`;
        for (let c = 0; c < filterWidth; c++) {
          mainLoop += `
          vec4 xTexelC${c * 2};
          int xTexelC${c * 2}Ready;
          vec4 xTexelC${c * 2 + 1};
          int xTexelC${c * 2 + 1}Ready;
          vec4 xC${c};`;
        }
        mainLoop += `
    for (int r = 0; r < ${filterHeight}; r++) {
      `;
        for (let c = 0; c < filterWidth; c++) {
          mainLoop += `
          xTexelC${c * 2} = vec4(0.0);
          xTexelC${c * 2}Ready = 0;
          xTexelC${c * 2 + 1} = vec4(0.0);
          xTexelC${c * 2 + 1}Ready = 0;
          xC${c} = vec4(0.0);`;
        }
        mainLoop += `
        xR = xRCorner + r * dilations[0];
        if (xR >=0 && xR < inDims[0]) {
      `;
        for (let texelC = 0; texelC < (texelsAcross + 1) / 2; texelC++) {
          const colIndex = texelC * 2;
          mainLoop += `
          xC = xCCorner + ${colIndex * dilationWidth};
          `;
          if (strideWidth === 1) {
            if (colIndex < filterWidth) {
              if (padLeft % 2 === 1) {
                mainLoop += `
                xCOffset = xC + 1;
                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);

                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }
              `;
                if (dilationWidth === 1 && colIndex > 0) {
                  mainLoop += `
                xC${colIndex} = vec4(xTexelC${colIndex - 2}.zw, xTexelC${colIndex}.xy);
                `;
                } else {
                  mainLoop += `
                  xCOffset = xC + 1 - 2;

                  if (xCOffset >= 0 && xCOffset < inDims[1]) {
                    previous = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      previous.zw = vec2(0.0);
                    }

                    xC${colIndex} = vec4(previous.zw, xTexelC${colIndex}.xy);
                  } else {
                    xC${colIndex} = vec4(0.0, 0.0, xTexelC${colIndex}.xy);
                  }
                  `;
                }
              } else {
                mainLoop += `
                if (xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }

                xC${colIndex} = xTexelC${colIndex};
                `;
              }
              if (colIndex + 1 < filterWidth) {
                const nextTexelOffset = padLeft % 2 === 0 ? util_exports.nearestLargerEven(dilationWidth) : dilationWidth;
                if (dilationWidth % 2 === 0 && padLeft % 2 === 1 || dilationWidth % 2 !== 0 && padLeft % 2 !== 1) {
                  mainLoop += `
                  xCOffset = xC + imod(pads[1], 2) + ${nextTexelOffset};

                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                    xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      xTexelC${colIndex + 1}.zw = vec2(0.0);
                    }
                    xTexelC${colIndex + 1}Ready = 1;
                  }
                  `;
                  if (dilationWidth > 1) {
                    mainLoop += `
                    xCOffset -= 2;
                    if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);
                     xC${colIndex + 1} = vec4(previous.zw, xTexelC${colIndex + 1}.xy);
                    } else {
                     xC${colIndex + 1} = vec4(0.0, 0.0, xTexelC${colIndex + 1}.xy);
                    }
                    `;
                  } else {
                    mainLoop += `
                    xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.xy);
                    `;
                  }
                } else {
                  if (nextTexelOffset === 1) {
                    mainLoop += `
                    xC${colIndex + 1} = xTexelC${colIndex};
                    `;
                  } else {
                    mainLoop += `
                    xCOffset = xC + ${nextTexelOffset};

                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                      xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);
                      if (xCOffset + 1 >= inDims[1]) {
                        xTexelC${colIndex + 1}.zw = vec2(0.0);
                      }
                      xTexelC${colIndex + 1}Ready = 1;
                    }

                    xC${colIndex + 1} = xTexelC${colIndex + 1};
                    `;
                  }
                }
              }
            }
          } else {
            if (colIndex < filterWidth) {
              if (padLeft % 2 === 1) {
                mainLoop += `
                xCOffset = xC + 1 - strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xCOffset, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }

                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                  xTexelC${colIndex + 1} = getX(batch, xR, xC + 1, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xC + 2 >= inDims[1]) {
                    xTexelC${colIndex + 1}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex + 1}Ready = 1;
                }

                xC${colIndex} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.zw);
              `;
                if (colIndex + 1 < filterWidth) {
                  mainLoop += `
                  final = vec4(0.0);
                  xCOffset = xC + 1 + strides[1];
                  if(xCOffset >= 0 && xCOffset < inDims[1]) {
                    final = getX(batch, xR, xCOffset, d1);
                  }
                  xC${colIndex + 1} = vec4(xTexelC${colIndex + 1}.xy, final.xy);
                `;
                }
              } else {
                mainLoop += `
                if(xC >= 0 && xC < inDims[1] && xTexelC${colIndex}Ready == 0) {
                  xTexelC${colIndex} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${colIndex}.zw = vec2(0.0);
                  }
                  xTexelC${colIndex}Ready = 1;
                }

                xCOffset = xC + strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${colIndex + 1}Ready == 0) {
                  xTexelC${colIndex + 1} = getX(batch, xR, xCOffset, d1);
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${colIndex + 1}.zw = vec2(0.);
                  }
                  xTexelC${colIndex + 1}Ready = 1;
                }

                xC${colIndex} = vec4(
                  xTexelC${colIndex}.xy, xTexelC${colIndex + 1}.xy);
              `;
                if (colIndex + 1 < filterWidth) {
                  mainLoop += `
                  xC${colIndex + 1} = vec4(xTexelC${colIndex}.zw, xTexelC${colIndex + 1}.zw);
                `;
                }
              }
            }
          }
          if (colIndex < filterWidth) {
            mainLoop += `
            wTexel = getW(r, ${colIndex}, d1, q);
            dotProd += xC${colIndex} * vec4(wTexel.xz, wTexel.xz);
          `;
            if (colIndex + 1 < filterWidth) {
              mainLoop += `
              wTexel = getW(r, ${colIndex + 1}, d1, q);
              dotProd += xC${colIndex + 1} * vec4(wTexel.xz, wTexel.xz);
            `;
            }
          }
        }
        mainLoop += `
    }
  `;
        mainLoop += `
      }
    `;
        let activationSnippet = "", applyActivationSnippet = "";
        if (activation) {
          if (hasPreluActivation) {
            activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${activation}
        }`;
          } else if (hasLeakyReluAlpha) {
            activationSnippet = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${activation}
        }`;
          } else {
            activationSnippet = `vec4 activation(vec4 x) {
          ${activation}
        }`;
          }
          applyActivationSnippet = `result = activation(result);`;
        }
        const addBiasSnippet = addBias ? "result += getBiasAtOutCoords();" : "";
        if (addBias) {
          this.variableNames.push("bias");
        }
        if (hasPreluActivation) {
          this.variableNames.push("preluActivationWeights");
        }
        if (hasLeakyReluAlpha) {
          this.variableNames.push("leakyreluAlpha");
        }
        this.userCode = `
      ${activationSnippet}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${channelMul};
        int q = d2 - d1 * ${channelMul};
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
        vec4 dotProd = vec4(0.000000000000001);

        ${mainLoop}

        vec4 result = dotProd - vec4(0.000000000000001);
        ${addBiasSnippet}
        ${applyActivationSnippet}
        setOutput(result);
      }
    `;
      }
    };
  }
});
function depthwiseConv2dNative2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations, dimRoundingMode } = attrs;
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filter.shape,
    strides,
    $dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  let program;
  if (env().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1) {
    program = new DepthwiseConvPacked2DProgram(convInfo);
  } else {
    program = new DepthwiseConv2DProgram(convInfo);
  }
  const customValues = [
    [convInfo.padInfo.top, convInfo.padInfo.left],
    [convInfo.strideHeight, convInfo.strideWidth],
    [convInfo.dilationHeight, convInfo.dilationWidth],
    [convInfo.inHeight, convInfo.inWidth]
  ];
  return backend2.runWebGLProgram(program, [x, filter], "float32", customValues);
}
var depthwiseConv2dNativeConfig2;
var init_DepthwiseConv2dNative2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNative.js"() {
    init_dist();
    init_conv_gpu_depthwise();
    init_conv_packed_gpu_depthwise();
    depthwiseConv2dNativeConfig2 = {
      kernelName: DepthwiseConv2dNative,
      backendName: "webgl",
      kernelFunc: depthwiseConv2dNative2
    };
  }
});
var DepthwiseConv2DDerFilterProgram;
var DepthwiseConv2DDerInputProgram;
var init_conv_backprop_gpu_depthwise = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu_depthwise.js"() {
    DepthwiseConv2DDerFilterProgram = class {
      constructor(convInfo) {
        this.variableNames = ["x", "dy"];
        this.outputShape = convInfo.filterShape;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const padTop = convInfo.padInfo.top;
        const padLeft = convInfo.padInfo.left;
        const channelMul = convInfo.outChannels / convInfo.inChannels;
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int dm = coords.w;
        int d2 = d1 * ${channelMul} + dm;

        float dotProd = 0.0;

        // TO DO: Vec4 over the batch size
        for (int b = 0; b < ${convInfo.batchSize}; b++) {
          for (int yR = 0; yR < ${convInfo.outHeight}; yR++) {
            int xR = wR + yR * ${strideHeight} - ${padTop};

            if (xR < 0 || xR >= ${convInfo.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${convInfo.outWidth}; yC++) {
              int xC = wC + yC * ${strideWidth} - ${padLeft};

              if (xC < 0 || xC >= ${convInfo.inWidth}) {
                continue;
              }

              float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
    DepthwiseConv2DDerInputProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy", "W"];
        this.outputShape = convInfo.inShape;
        const filterHeight = convInfo.filterHeight;
        const filterWidth = convInfo.filterWidth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const padTop = filterHeight - 1 - convInfo.padInfo.top;
        const padLeft = filterWidth - 1 - convInfo.padInfo.left;
        const channelMul = convInfo.outChannels / convInfo.inChannels;
        this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];
        ivec2 dyCorner = coords.yz - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        float dotProd = 0.0;

        for (int wR = 0; wR < ${filterHeight}; wR++) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${filterHeight} - 1 - wR;

          for (int wC = 0; wC < ${filterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${filterWidth} - 1 - wC;

            // TO DO: Vec4 over the channelMul
            for (int dm = 0; dm < ${channelMul}; dm++) {
              int d2 = d1 * ${channelMul} + dm;
              float xValue = getDy(batch, idyR, idyC, d2);
              float wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
  }
});
function depthwiseConv2dNativeBackpropFilter3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, dy } = inputs;
  const { strides, dilations, pad: pad2, dimRoundingMode, filterShape } = attrs;
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filterShape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const program = new DepthwiseConv2DDerFilterProgram(convInfo);
  return backend2.runWebGLProgram(program, [x, dy], "float32");
}
var depthwiseConv2dNativeBackpropFilterConfig2;
var init_DepthwiseConv2dNativeBackpropFilter2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js"() {
    init_dist();
    init_conv_backprop_gpu_depthwise();
    depthwiseConv2dNativeBackpropFilterConfig2 = {
      kernelName: DepthwiseConv2dNativeBackpropFilter,
      backendName: "webgl",
      kernelFunc: depthwiseConv2dNativeBackpropFilter3
    };
  }
});
function depthwiseConv2dNativeBackpropInput3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, filter } = inputs;
  const { strides, dilations, pad: pad2, dimRoundingMode, inputShape } = attrs;
  const convInfo = backend_util_exports.computeConv2DInfo(
    inputShape,
    filter.shape,
    strides,
    dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const program = new DepthwiseConv2DDerInputProgram(convInfo);
  return backend2.runWebGLProgram(program, [dy, filter], "float32");
}
var depthwiseConv2dNativeBackpropInputConfig2;
var init_DepthwiseConv2dNativeBackpropInput2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropInput.js"() {
    init_dist();
    init_conv_backprop_gpu_depthwise();
    depthwiseConv2dNativeBackpropInputConfig2 = {
      kernelName: DepthwiseConv2dNativeBackpropInput,
      backendName: "webgl",
      kernelFunc: depthwiseConv2dNativeBackpropInput3
    };
  }
});
var DiagProgram;
var init_diag_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/diag_gpu.js"() {
    DiagProgram = class {
      constructor(size) {
        this.variableNames = ["X"];
        this.outputShape = [size, size];
        this.userCode = `
      void main() {
          ivec2 coords = getOutputCoords();
          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;
          setOutput(val);
      }
    `;
      }
    };
  }
});
function diag2(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  const outShape = [...x.shape, ...x.shape];
  const xSize = util_exports.sizeFromShape(x.shape);
  const flat = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: [xSize] } });
  const program = new DiagProgram(xSize);
  const res = backend2.runWebGLProgram(program, [flat], flat.dtype);
  const out = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: outShape } });
  backend2.disposeIntermediateTensorInfo(flat);
  backend2.disposeIntermediateTensorInfo(res);
  return out;
}
var diagConfig2;
var init_Diag2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Diag.js"() {
    init_dist();
    init_diag_gpu();
    init_Reshape2();
    diagConfig2 = {
      kernelName: Diag,
      backendName: "webgl",
      kernelFunc: diag2
    };
  }
});
var Dilation2DProgram;
var init_dilation_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/dilation_gpu.js"() {
    Dilation2DProgram = class {
      constructor(convInfo) {
        this.variableNames = ["x", "W"];
        this.outputShape = convInfo.outShape;
        const { inHeight, inWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth } = convInfo;
        const { top: padTop, left: padLeft } = padInfo;
        this.userCode = `
      const ivec2 strides = ivec2(${strideHeight}, ${strideWidth});
      const ivec2 pads = ivec2(${padTop}, ${padLeft});
      const float neg_infinity = -3.4e38;

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.w;
        ivec2 outTopLeftCorner =
            coords.yz * strides - pads;
        int hBeg = outTopLeftCorner.x;
        int wBeg = outTopLeftCorner.y;

        float curVal = neg_infinity;
        for (int h = 0; h < ${filterHeight}; h++) {
          int hIn = hBeg + h * ${dilationHeight};

          if (hIn >= 0 && hIn < ${inHeight}) {
            for (int w = 0; w < ${filterWidth}; w++) {
              int wIn = wBeg + w * ${dilationWidth};

              if (wIn >= 0 && wIn < ${inWidth}) {
                float xVal = getX(batch, hIn, wIn, d1);
                float wVal = getW(h, w, d1);

                float val = xVal + wVal;
                if (val > curVal) {
                  curVal = val;
                }
              }
            }
          }
        }

        float result = curVal;
        setOutput(result);
      }
    `;
      }
    };
  }
});
function dilation2D(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter } = inputs;
  const { strides, pad: pad2, dilations } = attrs;
  const convInfo = backend_util_exports.computeDilation2DInfo(x.shape, filter.shape, strides, pad2, "NHWC", dilations);
  let out;
  const program = new Dilation2DProgram(convInfo);
  out = backend2.runWebGLProgram(program, [x, filter], "float32");
  const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: convInfo.outShape } });
  backend2.disposeIntermediateTensorInfo(out);
  return outReshaped;
}
var dilation2DConfig2;
var init_Dilation2D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Dilation2D.js"() {
    init_dist();
    init_dilation_gpu();
    init_Reshape2();
    dilation2DConfig2 = {
      kernelName: Dilation2D,
      backendName: "webgl",
      kernelFunc: dilation2D
    };
  }
});
function einsum2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { equation } = attrs;
  const tensors = inputs;
  const { allDims, summedDims, idDims } = backend_util_exports.decodeEinsumEquation(equation, tensors.length);
  backend_util_exports.checkEinsumDimSizes(allDims.length, idDims, tensors);
  const { path, steps } = backend_util_exports.getEinsumComputePath(summedDims, idDims);
  const nSteps = steps.length;
  let out = null;
  let numDimsRemaining = allDims.length;
  const tensorsToDispose = [];
  for (let i = 0; i < nSteps; ++i) {
    for (const idTerm of steps[i]) {
      const { permutationIndices: perm, expandDims: dimsToExpand } = backend_util_exports.getEinsumPermutation(numDimsRemaining, idDims[idTerm]);
      let x;
      if (backend_util_exports.isIdentityPermutation(perm)) {
        x = tensors[idTerm];
      } else {
        x = transpose3({ inputs: { x: tensors[idTerm] }, backend: backend2, attrs: { perm } });
        tensorsToDispose.push(x);
      }
      const targetShape = x.shape.slice();
      for (let k = 0; k < dimsToExpand.length; ++k) {
        targetShape.splice(dimsToExpand[k], 0, 1);
      }
      if (!util_exports.arraysEqual(x.shape, targetShape)) {
        x = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: targetShape } });
        tensorsToDispose.push(x);
      }
      if (out === null) {
        out = x;
      } else {
        out = multiply22({ inputs: { a: x, b: out }, backend: backend2 });
        tensorsToDispose.push(out);
      }
    }
    if (i < nSteps - 1) {
      if (path[i] >= 0) {
        out = sum4({
          inputs: { x: out },
          backend: backend2,
          attrs: {
            axis: path[i] - (allDims.length - numDimsRemaining),
            keepDims: false
          }
        });
        tensorsToDispose.push(out);
      }
      numDimsRemaining--;
    }
  }
  for (const tensorInfo of tensorsToDispose) {
    if (tensorInfo === out) {
      continue;
    }
    backend2.disposeIntermediateTensorInfo(tensorInfo);
  }
  return out;
}
var einsumConfig2;
var init_Einsum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Einsum.js"() {
    init_dist();
    init_Multiply2();
    init_Reshape2();
    init_Sum2();
    init_Transpose2();
    einsumConfig2 = {
      kernelName: Einsum,
      backendName: "webgl",
      kernelFunc: einsum2
    };
  }
});
var ELU4;
var ELU_PACKED;
var elu4;
var eluConfig2;
var init_Elu2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Elu.js"() {
    init_dist();
    init_kernel_funcs_utils();
    ELU4 = `return (x >= 0.0) ? x : (exp(x) - 1.0);`;
    ELU_PACKED = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
    elu4 = unaryKernelFunc2({ opSnippet: ELU4, packedOpSnippet: ELU_PACKED });
    eluConfig2 = {
      kernelName: Elu,
      backendName: "webgl",
      kernelFunc: elu4
    };
  }
});
var ELU_DER;
var ELU_DER_PACKED;
var eluGrad2;
var eluGradConfig3;
var init_EluGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/EluGrad.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    ELU_DER = `return (b >= 1.0) ? a : a * (b + 1.0);`;
    ELU_DER_PACKED = `
  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));
  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));
`;
    eluGrad2 = (args) => {
      const { inputs, backend: backend2 } = args;
      const { dy, y } = inputs;
      const program = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(ELU_DER_PACKED, dy.shape, y.shape) : new BinaryOpProgram(ELU_DER, dy.shape, y.shape);
      return backend2.runWebGLProgram(program, [dy, y], dy.dtype);
    };
    eluGradConfig3 = {
      kernelName: EluGrad,
      backendName: "webgl",
      kernelFunc: eluGrad2
    };
  }
});
var PACKED_EQUAL;
var EQUAL;
var equal3;
var equalConfig2;
var init_Equal2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Equal.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    PACKED_EQUAL = `
  return vec4(equal(a, b));
`;
    EQUAL = `return float(a == b);`;
    equal3 = binaryKernelFunc2({
      opSnippet: EQUAL,
      packedOpSnippet: PACKED_EQUAL,
      dtype: "bool",
      cpuKernelImpl: equalImplCPU
    });
    equalConfig2 = {
      kernelName: Equal,
      backendName: "webgl",
      kernelFunc: equal3
    };
  }
});
var ERF;
var erf3;
var erfConfig2;
var init_Erf2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Erf.js"() {
    init_dist();
    init_kernel_funcs_utils();
    ERF = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  float p = ${backend_util_exports.ERF_P};
  float a1 = ${backend_util_exports.ERF_A1};
  float a2 = ${backend_util_exports.ERF_A2};
  float a3 = ${backend_util_exports.ERF_A3};
  float a4 = ${backend_util_exports.ERF_A4};
  float a5 = ${backend_util_exports.ERF_A5};

  float sign = sign(x);
  x = abs(x);
  float t = 1.0 / (1.0 + p * x);
  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));
`;
    erf3 = unaryKernelFunc2({ opSnippet: ERF });
    erfConfig2 = {
      kernelName: Erf,
      backendName: "webgl",
      kernelFunc: erf3
    };
  }
});
var EXP;
var EXP_PACKED;
var exp3;
var expConfig2;
var init_Exp2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Exp.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    EXP = CHECK_NAN_SNIPPET_UNARY + `
  return exp(x);
`;
    EXP_PACKED = `
  vec4 result = exp(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    exp3 = unaryKernelFunc2({
      opSnippet: EXP,
      packedOpSnippet: EXP_PACKED,
      cpuKernelImpl: expImplCPU,
      dtype: "float32"
    });
    expConfig2 = {
      kernelName: Exp,
      backendName: "webgl",
      kernelFunc: exp3
    };
  }
});
function expandDims4(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { dim } = attrs;
  const { input: input2 } = inputs;
  const inputRank = input2.shape.length;
  const newShape = input2.shape.slice();
  let $dim = dim;
  if (dim < 0) {
    util_exports.assert(-(inputRank + 1) <= dim, () => `Axis must be in the interval [${-(inputRank + 1)}, ${inputRank}]`);
    $dim = inputRank + dim + 1;
  }
  newShape.splice($dim, 0, 1);
  return reshape3({ inputs: { x: input2 }, backend: backend2, attrs: { shape: newShape } });
}
var expandDimsConfig2;
var init_ExpandDims2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ExpandDims.js"() {
    init_dist();
    init_Reshape2();
    expandDimsConfig2 = {
      kernelName: ExpandDims,
      backendName: "webgl",
      kernelFunc: expandDims4
    };
  }
});
var EXPM1;
var expm13;
var expm1Config2;
var init_Expm12 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Expm1.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    EXPM1 = `return exp(x) - 1.0;`;
    expm13 = unaryKernelFunc2({ opSnippet: EXPM1, packedOpSnippet: EXPM1, cpuKernelImpl: expm1ImplCPU });
    expm1Config2 = {
      kernelName: Expm1,
      backendName: "webgl",
      kernelFunc: expm13
    };
  }
});
var FFTProgram;
var init_fft_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/fft_gpu.js"() {
    FFTProgram = class {
      constructor(component, inputShape, inverse2) {
        this.variableNames = ["real", "imag"];
        const innerDim = inputShape[1];
        this.outputShape = inputShape;
        const exponentMultiplierSnippet = inverse2 ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`;
        const resultDenominator = inverse2 ? `${innerDim}.0` : "1.0";
        let opString;
        if (component === "real") {
          opString = "return real * expR - imag * expI;";
        } else if (component === "imag") {
          opString = "return real * expI + imag * expR;";
        } else {
          throw new Error(`FFT component must be either "real" or "imag", got ${component}.`);
        }
        this.userCode = `
      const float exponentMultiplier = ${exponentMultiplierSnippet};

      float unaryOpComplex(float real, float expR, float imag, float expI) {
        ${opString}
      }

      float mulMatDFT(int batch, int index) {
        float indexRatio = float(index) / float(${innerDim});
        float exponentMultiplierTimesIndexRatio =
            exponentMultiplier * indexRatio;

        float result = 0.0;

        for (int i = 0; i < ${innerDim}; i++) {
          // x = (-2|2 * PI / N) * index * i;
          float x = exponentMultiplierTimesIndexRatio * float(i);
          float expR = cos(x);
          float expI = sin(x);
          float real = getReal(batch, i);
          float imag = getImag(batch, i);

          result +=
              unaryOpComplex(real, expR, imag, expI) / ${resultDenominator};
        }

        return result;
      }

      void main() {
        ivec2 coords = getOutputCoords();
        setOutput(mulMatDFT(coords[0], coords[1]));
      }
    `;
      }
    };
  }
});
function fftImpl2(x, inverse2, backend2) {
  const xData = backend2.texData.get(x.dataId);
  const inputSize = util_exports.sizeFromShape(x.shape);
  const innerDimensionSize = x.shape[x.shape.length - 1];
  const batch = inputSize / innerDimensionSize;
  const input2D = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: [batch, innerDimensionSize] } });
  const xShape = input2D.shape;
  const realProgram = new FFTProgram("real", xShape, inverse2);
  const imagProgram = new FFTProgram("imag", xShape, inverse2);
  const inputs = [
    {
      dataId: xData.complexTensorInfos.real.dataId,
      dtype: xData.complexTensorInfos.real.dtype,
      shape: xShape
    },
    {
      dataId: xData.complexTensorInfos.imag.dataId,
      dtype: xData.complexTensorInfos.imag.dtype,
      shape: xShape
    }
  ];
  const realPart = backend2.runWebGLProgram(realProgram, inputs, "float32");
  const imagPart = backend2.runWebGLProgram(imagProgram, inputs, "float32");
  const complexOutput = complex3({ inputs: { real: realPart, imag: imagPart }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(realPart);
  backend2.disposeIntermediateTensorInfo(imagPart);
  const complexOutputReshaped = reshape3({ inputs: { x: complexOutput }, backend: backend2, attrs: { shape: x.shape } });
  backend2.disposeIntermediateTensorInfo(input2D);
  backend2.disposeIntermediateTensorInfo(complexOutput);
  return complexOutputReshaped;
}
var init_FFT_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FFT_impl.js"() {
    init_dist();
    init_fft_gpu();
    init_Complex2();
    init_Reshape2();
  }
});
function fft3(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  return fftImpl2(input2, false, backend2);
}
var fftConfig2;
var init_FFT2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FFT.js"() {
    init_dist();
    init_FFT_impl();
    fftConfig2 = {
      kernelName: FFT,
      backendName: "webgl",
      kernelFunc: fft3
    };
  }
});
var FillProgram;
var init_fill_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/fill_gpu.js"() {
    FillProgram = class {
      constructor(shape, value) {
        this.outputShape = [];
        this.customUniforms = [{ name: "value", type: "float" }];
        this.variableNames = ["x"];
        this.outputShape = shape;
        this.userCode = `
      void main() {
        // Input can be obtained from uniform value.
        setOutput(value);
      }
    `;
      }
    };
  }
});
function fill3(args) {
  const { backend: backend2, attrs } = args;
  const { shape, value } = attrs;
  let { dtype } = attrs;
  dtype = dtype || util_exports.inferDtype(value);
  if (dtype === "string") {
    const values = util_exports.getArrayFromDType(dtype, util_exports.sizeFromShape(shape));
    values.fill(value);
    return backend2.makeTensorInfo(shape, dtype, values);
  } else {
    const program = new FillProgram(shape, value);
    const customValues = [[value]];
    return backend2.runWebGLProgram(program, [], dtype, customValues);
  }
}
var fillConfig2;
var init_Fill2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Fill.js"() {
    init_dist();
    init_fill_gpu();
    fillConfig2 = {
      kernelName: Fill,
      backendName: "webgl",
      kernelFunc: fill3
    };
  }
});
var FlipLeftRightProgram;
var init_flip_left_right_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/flip_left_right_gpu.js"() {
    FlipLeftRightProgram = class {
      constructor(imageShape) {
        this.variableNames = ["Image"];
        this.outputShape = [];
        const imageWidth = imageShape[2];
        this.outputShape = imageShape;
        this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];

          int coordX = ${imageWidth} - x - 1;
          float outputValue;
          if(coordX >= 0 && coordX < ${imageWidth}) {
            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);
          } else {
            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);
          }
          setOutput(outputValue);
        }
    `;
      }
    };
  }
});
var flipLeftRightConfig2;
var init_FlipLeftRight2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FlipLeftRight.js"() {
    init_dist();
    init_flip_left_right_gpu();
    flipLeftRightConfig2 = {
      kernelName: FlipLeftRight,
      backendName: "webgl",
      kernelFunc: ({ inputs, backend: backend2 }) => {
        const { image: image2 } = inputs;
        const webglBackend = backend2;
        const program = new FlipLeftRightProgram(image2.shape);
        const output = webglBackend.runWebGLProgram(program, [image2], image2.dtype);
        return output;
      }
    };
  }
});
var FLOOR;
var floor3;
var floorConfig2;
var init_Floor2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Floor.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    FLOOR = `return floor(x);`;
    floor3 = unaryKernelFunc2({ opSnippet: FLOOR, packedOpSnippet: FLOOR, cpuKernelImpl: floorImplCPU });
    floorConfig2 = {
      kernelName: Floor,
      backendName: "webgl",
      kernelFunc: floor3
    };
  }
});
var INT_DIV;
var INT_DIV_PACKED;
var floorDiv3;
var floorDivConfig2;
var init_FloorDiv2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FloorDiv.js"() {
    init_dist();
    init_kernel_funcs_utils();
    INT_DIV = `
  float s = sign(a) * sign(b);
  int ia = round(a);
  int ib = round(b);
  if (ib != 0) {
    // Windows (D3D) wants guaranteed non-zero int division at compile-time.
    return float(idiv(ia, ib, s));
  } else {
    return NAN;
  }
`;
    INT_DIV_PACKED = `
  ivec4 ia = round(a);
  ivec4 ib = round(b);
  bvec4 cond = notEqual(ib, ivec4(0));
  ivec4 result = ivec4(0);
  vec4 s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    result[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    result[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    result[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    result[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4(result);
`;
    floorDiv3 = binaryKernelFunc2({ opSnippet: INT_DIV, packedOpSnippet: INT_DIV_PACKED, dtype: "int32" });
    floorDivConfig2 = {
      kernelName: FloorDiv,
      backendName: "webgl",
      kernelFunc: floorDiv3
    };
  }
});
var FromPixelsProgram;
var init_from_pixels_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_gpu.js"() {
    init_glsl_version();
    FromPixelsProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        const glsl = getGlslDifferences();
        const [height, width] = outputShape;
        this.outputShape = outputShape;
        this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);

        vec4 values = ${glsl.texture2D}(A, uv);
        float value;
        if (depth == 0) {
          value = values.r;
        } else if (depth == 1) {
          value = values.g;
        } else if (depth == 2) {
          value = values.b;
        } else if (depth == 3) {
          value = values.a;
        }

        setOutput(floor(value * 255.0 + 0.5));
      }
    `;
      }
    };
  }
});
var FromPixelsPackedProgram;
var init_from_pixels_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_packed_gpu.js"() {
    init_glsl_version();
    FromPixelsPackedProgram = class {
      constructor(outputShape) {
        this.variableNames = ["A"];
        this.packedInputs = false;
        this.packedOutput = true;
        const glsl = getGlslDifferences();
        const [height, width] = outputShape;
        this.outputShape = outputShape;
        this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];

        vec4 result = vec4(0.);

        for(int row=0; row<=1; row++) {
          for(int col=0; col<=1; col++) {
            texC = coords[1] + row;
            depth = coords[2] + col;

            vec2 uv = (vec2(texC, texR) + halfCR) /
                       vec2(${width}.0, ${height}.0);
            vec4 values = ${glsl.texture2D}(A, uv);
            float value;
            if (depth == 0) {
              value = values.r;
            } else if (depth == 1) {
              value = values.g;
            } else if (depth == 2) {
              value = values.b;
            } else if (depth == 3) {
              value = values.a;
            }

            result[row * 2 + col] = floor(value * 255.0 + 0.5);
          }
        }

        ${glsl.output} = result;
      }
    `;
      }
    };
  }
});
function fromPixels2(args) {
  const { inputs, backend: backend2, attrs } = args;
  let { pixels } = inputs;
  const { numChannels } = attrs;
  const isVideo = typeof HTMLVideoElement !== "undefined" && pixels instanceof HTMLVideoElement;
  const isImage = typeof HTMLImageElement !== "undefined" && pixels instanceof HTMLImageElement;
  const [width, height] = isVideo ? [
    pixels.videoWidth,
    pixels.videoHeight
  ] : [pixels.width, pixels.height];
  const texShape = [height, width];
  const outShape = [height, width, numChannels];
  if (isImage || isVideo) {
    const newWillReadFrequently = env().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
    if (fromPixels2DContext2 == null || newWillReadFrequently !== willReadFrequently) {
      willReadFrequently = newWillReadFrequently;
      fromPixels2DContext2 = document.createElement("canvas").getContext("2d", { willReadFrequently });
    }
    fromPixels2DContext2.canvas.width = width;
    fromPixels2DContext2.canvas.height = height;
    fromPixels2DContext2.drawImage(pixels, 0, 0, width, height);
    pixels = fromPixels2DContext2.canvas;
  }
  const tempPixelHandle = backend2.makeTensorInfo(texShape, "int32");
  backend2.texData.get(tempPixelHandle.dataId).usage = TextureUsage.PIXELS;
  backend2.gpgpu.uploadPixelDataToTexture(backend2.getTexture(tempPixelHandle.dataId), pixels);
  const program = env().getBool("WEBGL_PACK") ? new FromPixelsPackedProgram(outShape) : new FromPixelsProgram(outShape);
  const res = backend2.runWebGLProgram(program, [tempPixelHandle], "int32");
  backend2.disposeData(tempPixelHandle.dataId);
  return res;
}
var fromPixelsConfig;
var fromPixels2DContext2;
var willReadFrequently;
var init_FromPixels = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels.js"() {
    init_dist();
    init_dist();
    init_tex_util();
    init_from_pixels_gpu();
    init_from_pixels_packed_gpu();
    fromPixelsConfig = {
      kernelName: FromPixels,
      backendName: "webgl",
      kernelFunc: fromPixels2
    };
    willReadFrequently = env().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
  }
});
function fusedConv2d(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad2, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
  const $dataFormat = backend_util_exports.convertConv2DDataFormat(dataFormat);
  const convInfo = backend_util_exports.computeConv2DInfo(x.shape, filter.shape, strides, dilations, pad2, dimRoundingMode, false, $dataFormat);
  let out;
  const intermediates = [];
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation === "leakyrelu";
  const prepareInputs = () => {
    const inputs2 = [x, filter];
    const alignInputWithDataFormat = (input2, dataFormat2) => {
      if (dataFormat2 === "NCHW" && input2.shape.length === 1 && input2.shape[0] !== 1) {
        const alignedInput = reshape3({
          inputs: { x: input2 },
          backend: backend2,
          attrs: { shape: [input2.shape[0], 1, 1] }
        });
        intermediates.push(alignedInput);
        return alignedInput;
      }
      return input2;
    };
    if (hasBias) {
      inputs2.push(alignInputWithDataFormat(bias, dataFormat));
    }
    if (hasPreluActivationWeights) {
      inputs2.push(alignInputWithDataFormat(preluActivationWeights, dataFormat));
    }
    if (hasLeakyreluAlpha) {
      const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
      inputs2.push($leakyreluAlpha);
      intermediates.push($leakyreluAlpha);
    }
    return inputs2;
  };
  if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === "SAME" || convInfo.padInfo.type === "VALID")) {
    out = conv2dByMatMul({
      x,
      filter,
      convInfo,
      backend: backend2,
      bias,
      activation,
      preluActivationWeights,
      leakyreluAlpha
    });
  } else if (convInfo.strideWidth <= 2 && $dataFormat === "channelsLast" && env().getBool("WEBGL_EXP_CONV")) {
    const fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;
    const program = new Conv2DPackedProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    const customValues = [
      [convInfo.padInfo.top, convInfo.padInfo.left],
      [convInfo.strideHeight, convInfo.strideWidth],
      [convInfo.dilationHeight, convInfo.dilationWidth],
      [convInfo.inHeight, convInfo.inWidth]
    ];
    const inputs2 = prepareInputs();
    out = backend2.runWebGLProgram(program, inputs2, "float32", customValues);
  } else if (env().getBool("WEBGL_CONV_IM2COL")) {
    out = conv2dWithIm2Row({
      x,
      filter,
      convInfo,
      backend: backend2,
      bias,
      activation,
      preluActivationWeights,
      leakyreluAlpha
    });
  } else {
    const fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;
    const program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
    const inputs2 = prepareInputs();
    out = backend2.runWebGLProgram(program, inputs2, "float32");
  }
  const outReshaped = reshape3({ inputs: { x: out }, backend: backend2, attrs: { shape: convInfo.outShape } });
  intermediates.push(out);
  intermediates.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return outReshaped;
}
var fusedConv2DConfig2;
var init_FusedConv2D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FusedConv2D.js"() {
    init_dist();
    init_conv_gpu();
    init_conv_packed_gpu();
    init_kernel_funcs_utils();
    init_Conv2D_impl();
    init_Reshape2();
    fusedConv2DConfig2 = {
      kernelName: FusedConv2D,
      backendName: "webgl",
      kernelFunc: fusedConv2d
    };
  }
});
function fusedDepthwiseConv2D2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, filter, bias, preluActivationWeights } = inputs;
  const { strides, pad: pad2, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;
  const intermediates = [];
  let $dilations = dilations;
  if ($dilations == null) {
    $dilations = [1, 1];
  }
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, $dilations), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${strides} and dilations '${$dilations}'`);
  const convInfo = backend_util_exports.computeConv2DInfo(
    x.shape,
    filter.shape,
    strides,
    $dilations,
    pad2,
    dimRoundingMode,
    true
    /* depthwise */
  );
  const shouldPackDepthwiseConv = env().getBool("WEBGL_PACK_DEPTHWISECONV") && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1;
  const fusedActivation = activation ? mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) : null;
  const programInputs = [x, filter];
  const hasBias = bias != null;
  const hasPreluActivationWeights = preluActivationWeights != null;
  const hasLeakyreluAlpha = activation === "leakyrelu";
  if (hasBias) {
    programInputs.push(bias);
  }
  if (hasPreluActivationWeights) {
    programInputs.push(preluActivationWeights);
  }
  if (hasLeakyreluAlpha) {
    const $leakyreluAlpha = backend2.makeTensorInfo([], "float32", util_exports.createScalarValue(leakyreluAlpha, "float32"));
    programInputs.push($leakyreluAlpha);
    intermediates.push($leakyreluAlpha);
  }
  let program;
  if (shouldPackDepthwiseConv) {
    program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
  } else {
    program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights, hasLeakyreluAlpha);
  }
  const customValues = [
    [convInfo.padInfo.top, convInfo.padInfo.left],
    [convInfo.strideHeight, convInfo.strideWidth],
    [convInfo.dilationHeight, convInfo.dilationWidth],
    [convInfo.inHeight, convInfo.inWidth]
  ];
  const result = backend2.runWebGLProgram(program, programInputs, "float32", customValues);
  intermediates.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return result;
}
var fusedDepthwiseConv2DConfig2;
var init_FusedDepthwiseConv2D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/FusedDepthwiseConv2D.js"() {
    init_dist();
    init_conv_gpu_depthwise();
    init_conv_packed_gpu_depthwise();
    init_kernel_funcs_utils();
    fusedDepthwiseConv2DConfig2 = {
      kernelName: FusedDepthwiseConv2D,
      backendName: "webgl",
      kernelFunc: fusedDepthwiseConv2D2
    };
  }
});
var GatherNDProgram;
var init_gather_nd_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/gather_nd_gpu.js"() {
    init_shader_compiler();
    GatherNDProgram = class {
      constructor(sliceDim, strides, shape, paramsShape) {
        this.sliceDim = sliceDim;
        this.strides = strides;
        this.paramsShape = paramsShape;
        this.variableNames = ["x", "indices"];
        this.outputShape = shape;
        const dtype = getCoordsDataType(shape.length);
        let mainLoop = `
    int index;`;
        for (let j = 0; j < this.sliceDim; j++) {
          mainLoop += `
          index = round(getIndices(coords[0], ${j}));
          out_of_bounds = out_of_bounds || index < 0;
          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[j]};
          flattenIndex += index * ${this.strides[j]};`;
        }
        this.userCode = `
         void main() {
          ${dtype} coords = getOutputCoords();
          int flattenIndex = 0;
          bool out_of_bounds = false;

          ${mainLoop}

          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));
        }
      `;
      }
    };
  }
});
function gatherNd2(args) {
  const { inputs, backend: backend2 } = args;
  const { params, indices } = inputs;
  const indicesShape = indices.shape;
  const sliceRank = indicesShape[indicesShape.length - 1];
  const paramsSize = util_exports.sizeFromShape(params.shape);
  const [resultShape, numSlices, sliceSize, strides] = backend_util_exports.prepareAndValidate(params, indices);
  const flattenIndices = reshape3({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numSlices, sliceRank] } });
  const flattenX = reshape3({
    inputs: { x: params },
    backend: backend2,
    attrs: { shape: [util_exports.sizeFromShape(params.shape) / sliceSize, sliceSize] }
  });
  if (backend2.shouldExecuteOnCPU([params, indices]) || params.dtype === "string") {
    const indicesData = backend2.readSync(indices.dataId);
    const paramsBuf = backend2.bufferSync(params);
    const outValue = gatherNdImplCPU(indicesData, paramsBuf, params.dtype, numSlices, sliceRank, sliceSize, strides, params.shape, paramsSize);
    return backend2.makeTensorInfo(resultShape, params.dtype, outValue.values);
  }
  const program = new GatherNDProgram(sliceRank, strides, [numSlices, sliceSize], params.shape);
  const res = backend2.runWebGLProgram(program, [flattenX, flattenIndices], flattenX.dtype);
  const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: resultShape } });
  backend2.disposeIntermediateTensorInfo(flattenIndices);
  backend2.disposeIntermediateTensorInfo(flattenX);
  backend2.disposeIntermediateTensorInfo(res);
  return reshaped;
}
var gatherNdConfig2;
var init_GatherNd2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GatherNd.js"() {
    init_dist();
    init_gather_nd_gpu();
    init_shared2();
    init_Reshape2();
    gatherNdConfig2 = {
      kernelName: GatherNd,
      backendName: "webgl",
      kernelFunc: gatherNd2
    };
  }
});
function getSourceCoords2(aShape, axis) {
  const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
  const sourceCoords = [];
  for (let i = 0; i < aShape.length; i++) {
    if (i === 2) {
      sourceCoords.push("index");
    } else {
      sourceCoords.push(`${currentCoords[i]}`);
    }
  }
  return sourceCoords.join();
}
var GatherProgram;
var init_gather_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/gather_gpu.js"() {
    init_shader_compiler();
    GatherProgram = class {
      constructor(aShape, outputShape) {
        this.variableNames = ["A", "indices"];
        this.outputShape = outputShape;
        this.rank = outputShape.length;
        const dtype = getCoordsDataType(this.rank);
        const sourceCoords = getSourceCoords2(aShape, 2);
        this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        int index = int(getIndices(resRC.x, resRC.z));
        float inBounds = (index >= 0) && (index < ${aShape[2]}) ? 1.0 : 0.0;
        setOutput(inBounds * getA(${sourceCoords}));
      }
    `;
      }
    };
  }
});
function gatherV22(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, indices } = inputs;
  const { axis, batchDims } = attrs;
  const parsedAxis = util_exports.parseAxisParam(axis, x.shape)[0];
  if (env().get("DEBUG")) {
    const indicesVals = backend2.readSync(indices.dataId);
    const axisDim = x.shape[parsedAxis];
    for (let i = 0; i < indicesVals.length; ++i) {
      const index = indicesVals[i];
      util_exports.assert(index <= axisDim - 1 && index >= 0, () => `GatherV2: the index value ${index} is not in [0, ${axisDim - 1}]`);
    }
  }
  const shapeInfo = backend_util_exports.segment_util.collectGatherOpShapeInfo(x, indices, parsedAxis, batchDims);
  const indicesSize = util_exports.sizeFromShape(indices.shape);
  const toDispose = [];
  const flattenX = reshape3({
    inputs: { x },
    backend: backend2,
    attrs: {
      shape: [
        shapeInfo.batchSize,
        shapeInfo.outerSize,
        shapeInfo.dimSize,
        shapeInfo.sliceSize
      ]
    }
  });
  const flattenIndex = reshape3({
    inputs: { x: indices },
    backend: backend2,
    attrs: { shape: [shapeInfo.batchSize, indicesSize / shapeInfo.batchSize] }
  });
  toDispose.push(flattenX);
  toDispose.push(flattenIndex);
  const flattenOutputShape = [
    shapeInfo.batchSize,
    shapeInfo.outerSize,
    indicesSize / shapeInfo.batchSize,
    shapeInfo.sliceSize
  ];
  if (backend2.shouldExecuteOnCPU([x, indices]) || x.dtype === "string") {
    const indicesBuf = backend2.bufferSync(flattenIndex);
    const xBuf = backend2.bufferSync(flattenX);
    const outBuf = gatherV2ImplCPU(xBuf, indicesBuf, flattenOutputShape);
    toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
    return backend2.makeTensorInfo(shapeInfo.outputShape, outBuf.dtype, outBuf.values);
  }
  const program = new GatherProgram(flattenX.shape, flattenOutputShape);
  const res = backend2.runWebGLProgram(program, [flattenX, flattenIndex], flattenX.dtype);
  toDispose.push(res);
  const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: shapeInfo.outputShape } });
  toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return reshaped;
}
var gatherV2Config2;
var init_GatherV22 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GatherV2.js"() {
    init_dist();
    init_gather_gpu();
    init_shared2();
    init_Reshape2();
    gatherV2Config2 = {
      kernelName: GatherV2,
      backendName: "webgl",
      kernelFunc: gatherV22
    };
  }
});
var GREATER;
var GREATER_PACKED;
var greater3;
var greaterConfig2;
var init_Greater2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Greater.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    GREATER = `return float(a > b);`;
    GREATER_PACKED = `
  return vec4(greaterThan(a, b));
`;
    greater3 = binaryKernelFunc2({
      opSnippet: GREATER,
      packedOpSnippet: GREATER_PACKED,
      cpuKernelImpl: greaterImplCPU,
      dtype: "bool"
    });
    greaterConfig2 = {
      kernelName: Greater,
      backendName: "webgl",
      kernelFunc: greater3
    };
  }
});
var GREATER_EQUAL;
var GREATER_EQUAL_PACKED;
var greaterEqual3;
var greaterEqualConfig2;
var init_GreaterEqual2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/GreaterEqual.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    GREATER_EQUAL = `return float(a >= b);`;
    GREATER_EQUAL_PACKED = `
  return vec4(greaterThanEqual(a, b));
`;
    greaterEqual3 = binaryKernelFunc2({
      opSnippet: GREATER_EQUAL,
      packedOpSnippet: GREATER_EQUAL_PACKED,
      dtype: "bool",
      cpuKernelImpl: greaterEqualImplCPU
    });
    greaterEqualConfig2 = {
      kernelName: GreaterEqual,
      backendName: "webgl",
      kernelFunc: greaterEqual3
    };
  }
});
function ifft3(args) {
  const { inputs, backend: backend2 } = args;
  const { input: input2 } = inputs;
  return fftImpl2(input2, true, backend2);
}
var ifftConfig2;
var init_IFFT2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IFFT.js"() {
    init_dist();
    init_FFT_impl();
    ifftConfig2 = {
      kernelName: IFFT,
      backendName: "webgl",
      kernelFunc: ifft3
    };
  }
});
var IS_FINITE;
var isFinite4;
var isFiniteConfig2;
var init_IsFinite2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsFinite.js"() {
    init_dist();
    init_kernel_funcs_utils();
    IS_FINITE = `return float(!isnan(x) && !isinf(x));`;
    isFinite4 = unaryKernelFunc2({ opSnippet: IS_FINITE, dtype: "bool" });
    isFiniteConfig2 = {
      kernelName: IsFinite,
      backendName: "webgl",
      kernelFunc: isFinite4
    };
  }
});
var IS_INF;
var isInf3;
var isInfConfig2;
var init_IsInf2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsInf.js"() {
    init_dist();
    init_kernel_funcs_utils();
    IS_INF = `return float(isinf(x));`;
    isInf3 = unaryKernelFunc2({ opSnippet: IS_INF, dtype: "bool" });
    isInfConfig2 = {
      kernelName: IsInf,
      backendName: "webgl",
      kernelFunc: isInf3
    };
  }
});
var IS_NAN;
var isNaN4;
var isNaNConfig2;
var init_IsNaN2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/IsNaN.js"() {
    init_dist();
    init_kernel_funcs_utils();
    IS_NAN = `return float(isnan(x));`;
    isNaN4 = unaryKernelFunc2({ opSnippet: IS_NAN, dtype: "bool" });
    isNaNConfig2 = {
      kernelName: IsNan,
      backendName: "webgl",
      kernelFunc: isNaN4
    };
  }
});
var LESS;
var LESS_PACKED;
var less3;
var lessConfig2;
var init_Less2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Less.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    LESS = `return float(a < b);`;
    LESS_PACKED = `
  return vec4(lessThan(a, b));
`;
    less3 = binaryKernelFunc2({
      opSnippet: LESS,
      packedOpSnippet: LESS_PACKED,
      cpuKernelImpl: lessImplCPU,
      dtype: "bool"
    });
    lessConfig2 = {
      kernelName: Less,
      backendName: "webgl",
      kernelFunc: less3
    };
  }
});
var LESS_EQUAL;
var LESS_EQUAL_PACKED;
var lessEqual3;
var lessEqualConfig2;
var init_LessEqual2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LessEqual.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    LESS_EQUAL = `return float(a <= b);`;
    LESS_EQUAL_PACKED = `
  return vec4(lessThanEqual(a, b));
`;
    lessEqual3 = binaryKernelFunc2({
      opSnippet: LESS_EQUAL,
      packedOpSnippet: LESS_EQUAL_PACKED,
      cpuKernelImpl: lessEqualImplCPU,
      dtype: "bool"
    });
    lessEqualConfig2 = {
      kernelName: LessEqual,
      backendName: "webgl",
      kernelFunc: lessEqual3
    };
  }
});
function linSpace2(args) {
  const { backend: backend2, attrs } = args;
  const { start, stop, num } = attrs;
  const outVals = linSpaceImplCPU(start, stop, num);
  return backend2.makeTensorInfo([outVals.length], "float32", outVals);
}
var linSpaceConfig2;
var init_LinSpace2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LinSpace.js"() {
    init_dist();
    init_shared2();
    linSpaceConfig2 = {
      kernelName: LinSpace,
      backendName: "webgl",
      kernelFunc: linSpace2
    };
  }
});
var LOG;
var LOG_PACKED;
var log4;
var logConfig2;
var init_Log2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Log.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    LOG = CHECK_NAN_SNIPPET_UNARY + `
  return x < 0.0 ? 0./0. : log(x);
`;
    LOG_PACKED = `
  vec4 result = log(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);
  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);
  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);
  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);
  return result;
`;
    log4 = unaryKernelFunc2({ opSnippet: LOG, packedOpSnippet: LOG_PACKED, cpuKernelImpl: logImplCPU });
    logConfig2 = {
      kernelName: Log,
      backendName: "webgl",
      kernelFunc: log4
    };
  }
});
var LOG1P;
var log1p3;
var log1pConfig2;
var init_Log1p2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Log1p.js"() {
    init_dist();
    init_kernel_funcs_utils();
    LOG1P = CHECK_NAN_SNIPPET_UNARY + `
  return log(1.0 + x);
`;
    log1p3 = unaryKernelFunc2({ opSnippet: LOG1P });
    log1pConfig2 = {
      kernelName: Log1p,
      backendName: "webgl",
      kernelFunc: log1p3
    };
  }
});
var LOGICAL_AND;
var LOGICAL_AND_PACKED;
var logicalAnd3;
var logicalAndConfig2;
var init_LogicalAnd2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalAnd.js"() {
    init_dist();
    init_kernel_funcs_utils();
    LOGICAL_AND = `return float(a >= 1.0 && b >= 1.0);`;
    LOGICAL_AND_PACKED = `
  return vec4(
    vec4(greaterThanEqual(a, vec4(1.0))) *
    vec4(greaterThanEqual(b, vec4(1.0))));
`;
    logicalAnd3 = binaryKernelFunc2({
      opSnippet: LOGICAL_AND,
      packedOpSnippet: LOGICAL_AND_PACKED,
      dtype: "bool"
    });
    logicalAndConfig2 = {
      kernelName: LogicalAnd,
      backendName: "webgl",
      kernelFunc: logicalAnd3
    };
  }
});
var LOGICAL_NOT;
var logicalNot3;
var logicalNotConfig2;
var init_LogicalNot2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalNot.js"() {
    init_dist();
    init_kernel_funcs_utils();
    LOGICAL_NOT = `return float(!(x >= 1.0));`;
    logicalNot3 = unaryKernelFunc2({ opSnippet: LOGICAL_NOT });
    logicalNotConfig2 = {
      kernelName: LogicalNot,
      backendName: "webgl",
      kernelFunc: logicalNot3
    };
  }
});
var LOGICAL_OR;
var LOGICAL_OR_PACKED;
var logicalOr3;
var logicalOrConfig2;
var init_LogicalOr2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalOr.js"() {
    init_dist();
    init_kernel_funcs_utils();
    LOGICAL_OR = `return float(a >= 1.0 || b >= 1.0);`;
    LOGICAL_OR_PACKED = `
  return min(
    vec4(greaterThanEqual(a, vec4(1.0))) +
    vec4(greaterThanEqual(b, vec4(1.0))),
    vec4(1.0));
`;
    logicalOr3 = binaryKernelFunc2({ opSnippet: LOGICAL_OR, packedOpSnippet: LOGICAL_OR_PACKED, dtype: "bool" });
    logicalOrConfig2 = {
      kernelName: LogicalOr,
      backendName: "webgl",
      kernelFunc: logicalOr3
    };
  }
});
var LRNProgram;
var init_lrn_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/lrn_gpu.js"() {
    LRNProgram = class {
      constructor(xShape, radius, bias, alpha, beta) {
        this.variableNames = ["x"];
        this.outputShape = [];
        const rad = radius;
        const maxD = xShape[3] - 1;
        this.outputShape = xShape;
        let powOperator;
        const basis = `float(${bias}) + float(${alpha}) * sum`;
        if (beta === 0.5) {
          powOperator = `inversesqrt(${basis})`;
        } else if (beta === 1) {
          powOperator = `1.0/(${basis})`;
        } else {
          powOperator = `exp(log(${basis}) * float(-${beta}));`;
        }
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];
        int d = coords[3];
        float x = getX(b, r, c, d);
        float sum = 0.0;
        for (int j = -${rad}; j <= ${rad}; j++) {
          int idx = d + j;
          if (idx >= 0 && idx <=  ${maxD}) {
            float z = getX(b, r, c, idx);
            sum += z * z;
          }
        }
        float val = x * ${powOperator};
        setOutput(val);
      }
    `;
      }
    };
  }
});
var LRNPackedProgram;
var init_lrn_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/lrn_packed_gpu.js"() {
    LRNPackedProgram = class {
      constructor(xShape, radius, bias, alpha, beta) {
        this.variableNames = ["x"];
        this.outputShape = [];
        this.packedInputs = true;
        this.packedOutput = true;
        const rad = radius;
        const maxD = xShape[3] - 1;
        this.outputShape = xShape;
        let powOperator;
        const basis = `float(${bias}) + float(${alpha}) * sum`;
        if (beta === 0.5) {
          powOperator = `inversesqrt(${basis})`;
        } else if (beta === 1) {
          powOperator = `1.0/(${basis})`;
        } else {
          powOperator = `exp(log(${basis}) * float(-${beta}));`;
        }
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords.x;
        int r = coords.y;
        int c = coords.z;
        int d = coords.w;

        bool hasNextCol = d < ${this.outputShape[3]};
        bool hasNextRow = c < ${this.outputShape[2]};

        vec4 sum = vec4(0.);
        vec4 xFragAtOutputCoords = getX(b, r, c, d);

        vec4 xAtOutputCoords = vec4(
          getChannel(xFragAtOutputCoords, vec2(c, d)),
          hasNextCol ?
            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,
          hasNextRow ?
            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,
          (hasNextRow && hasNextCol) ?
            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0
        );

        int firstChannel = d - ${rad};
        vec2 cache = vec2(0.);
        if(firstChannel >= 0){
          vec4 firstChannelFrag = getX(b, r, c, firstChannel);
          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));
            if(hasNextRow){
              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));
            }
        }

        ivec2 depth = ivec2(d, d + 1);
        for (int j = - ${rad}; j <= ${rad}; j++) {
          ivec2 idx = depth + j;
          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));
          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${maxD}));

          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;
          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;

          if(depthInRange || depthPlusOneInRange){
            vec4 z = vec4(0.);
            vec4 xFragAtCurrentDepth;
            z.xz = cache.xy;
            if(depthPlusOneInRange && hasNextCol){
              xFragAtCurrentDepth = idx.y != d ?
                getX(b, r, c, idx.y) : xFragAtOutputCoords;
              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));
              if(hasNextRow){
                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));
              }
            }
            cache.xy = z.yw;
            sum += z * z;
          }
        }
        vec4 result = xAtOutputCoords * ${powOperator};
        setOutput(result);
      }
    `;
      }
    };
  }
});
var lrn;
var LRNConfig2;
var init_LRN2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LRN.js"() {
    init_dist();
    init_lrn_gpu();
    init_lrn_packed_gpu();
    lrn = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { x } = inputs;
      const { depthRadius, bias, alpha, beta } = attrs;
      const program = env().getBool("WEBGL_PACK_NORMALIZATION") ? new LRNPackedProgram(x.shape, depthRadius, bias, alpha, beta) : new LRNProgram(x.shape, depthRadius, bias, alpha, beta);
      return backend2.runWebGLProgram(program, [x], x.dtype);
    };
    LRNConfig2 = {
      kernelName: LRN,
      backendName: "webgl",
      kernelFunc: lrn
    };
  }
});
var LRNGradProgram;
var init_lrn_grad_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/lrn_grad_gpu.js"() {
    LRNGradProgram = class {
      constructor(inputShape, depthRadius, bias, alpha, beta) {
        this.variableNames = ["inputImage", "outputImage", "dy"];
        this.outputShape = [];
        this.outputShape = inputShape;
        this.depth = inputShape[3];
        this.depthRadius = depthRadius;
        this.bias = bias;
        this.alpha = alpha;
        this.beta = beta;
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];

        float result = 0.0;
        for (int d = 0; d < ${this.depth}; ++d) {
          int depthBegin = int(max(0.0, float(d - ${depthRadius})));
          int depthEnd = int(min(float(${this.depth}),
              float(d + ${depthRadius} + 1)));

          const int MIN_DEPTH_BEGIN = 0;
          const int MAX_DEPTH_END = ${this.depth};

          float norm = 0.0;
          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            }
            else {
              break;
            }
          }

          norm = float(${alpha}) * norm + float(${bias});

          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd){
              float dyi = -2.0 * float(${alpha})
                * float(${beta})
                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)
                / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * ${beta});
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            }
            else {
              break;
            }
          }
      }
      setOutput(result);
      }
    `;
      }
    };
  }
});
var lrnGrad;
var LRNGradConfig2;
var init_LRNGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/LRNGrad.js"() {
    init_dist();
    init_lrn_grad_gpu();
    lrnGrad = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { x, y, dy } = inputs;
      const { depthRadius, bias, alpha, beta } = attrs;
      const program = new LRNGradProgram(x.shape, depthRadius, bias, alpha, beta);
      return backend2.runWebGLProgram(program, [x, y, dy], x.dtype);
    };
    LRNGradConfig2 = {
      kernelName: LRNGrad,
      backendName: "webgl",
      kernelFunc: lrnGrad
    };
  }
});
function maxImpl2(x, reduceShape, outShape, backend2) {
  const inSize = util_exports.sizeFromShape(reduceShape);
  const xSize = util_exports.sizeFromShape(x.shape);
  const batchSize = xSize / inSize;
  const reshapedInput = reshape3({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend: backend2 });
  const reduced = reduce(reshapedInput, x.dtype, "max", backend2);
  const reshapedOutput = reshape3({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(reshapedInput);
  backend2.disposeIntermediateTensorInfo(reduced);
  return reshapedOutput;
}
var init_Max_impl2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Max_impl.js"() {
    init_dist();
    init_reduce();
    init_Reshape2();
  }
});
function max4(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { reductionIndices, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports.parseAxisParam(reductionIndices, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  const maxInputIsTransposed = permutedAxes != null;
  const shouldExecuteOnCPU = backend2.shouldExecuteOnCPU([x]);
  let maxInput = x;
  if (maxInputIsTransposed) {
    if (shouldExecuteOnCPU) {
      const xTexData = backend2.texData.get(maxInput.dataId);
      const values = xTexData.values;
      const newShape = new Array(xRank);
      for (let i = 0; i < newShape.length; i++) {
        newShape[i] = x.shape[permutedAxes[i]];
      }
      const maxInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
      maxInput = backend2.makeTensorInfo(newShape, x.dtype);
      const maxInputData = backend2.texData.get(maxInput.dataId);
      maxInputData.values = maxInputValues;
    } else {
      maxInput = transposeImpl2(x, permutedAxes, backend2);
    }
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
  }
  backend_util_exports.assertAxesAreInnerMostDims("max", axes, xRank);
  const [maxOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(maxInput.shape, axes);
  let outShape = maxOutShape;
  if (keepDims) {
    outShape = backend_util_exports.expandShapeToKeepDim(maxOutShape, origAxes);
  }
  let out;
  if (shouldExecuteOnCPU) {
    const xTexData = backend2.texData.get(maxInput.dataId);
    const values = xTexData.values;
    const outValues = maxImplCPU(values, util_exports.sizeFromShape(reduceShape), outShape, x.dtype);
    out = backend2.makeTensorInfo(outShape, x.dtype);
    const outData = backend2.texData.get(out.dataId);
    outData.values = outValues;
  } else {
    out = maxImpl2(maxInput, reduceShape, outShape, backend2);
  }
  if (maxInputIsTransposed) {
    backend2.disposeIntermediateTensorInfo(maxInput);
  }
  return out;
}
var maxConfig2;
var init_Max2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Max.js"() {
    init_dist();
    init_dist();
    init_shared2();
    init_Max_impl2();
    init_Transpose_impl2();
    maxConfig2 = {
      kernelName: Max,
      backendName: "webgl",
      kernelFunc: max4
    };
  }
});
var MAXIMUM;
var MAXIMUM_PACKED;
var maximum3;
var maximumConfig2;
var init_Maximum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Maximum.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    init_kernel_funcs_utils();
    init_shared2();
    MAXIMUM = CHECK_NAN_SNIPPET2 + `
  return max(a, b);
`;
    MAXIMUM_PACKED = `
  vec4 result = vec4(max(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + CHECK_NAN_SNIPPET_PACKED + `
  return result;
`;
    maximum3 = binaryKernelFunc2({
      opSnippet: MAXIMUM,
      packedOpSnippet: MAXIMUM_PACKED,
      cpuKernelImpl: maximumImplCPU
    });
    maximumConfig2 = {
      kernelName: Maximum,
      backendName: "webgl",
      kernelFunc: maximum3
    };
  }
});
function maxPool3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  assertNotComplex2(x, "maxPool");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 && util_exports.arraysEqual(convInfo.inShape, convInfo.outShape)) {
    return identity22({ inputs: { x }, backend: backend2 });
  }
  const maxPoolProgram = new Pool2DProgram(convInfo, "max", false);
  return backend2.runWebGLProgram(maxPoolProgram, [x], x.dtype);
}
var maxPoolConfig2;
var init_MaxPool2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool.js"() {
    init_dist();
    init_pool_gpu();
    init_webgl_util();
    init_Identity2();
    maxPoolConfig2 = {
      kernelName: MaxPool,
      backendName: "webgl",
      kernelFunc: maxPool3
    };
  }
});
function maxPool3d2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { filterSize, strides, pad: pad2, dataFormat, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode, dataFormat);
  const maxPoolProgram = new Pool3DProgram(convInfo, "max", false);
  return backend2.runWebGLProgram(maxPoolProgram, [x], x.dtype);
}
var maxPool3DConfig2;
var init_MaxPool3D2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3D.js"() {
    init_dist();
    init_pool_gpu();
    maxPool3DConfig2 = {
      kernelName: MaxPool3D,
      backendName: "webgl",
      kernelFunc: maxPool3d2
    };
  }
});
var MaxPool2DBackpropProgram;
var MaxPool3DBackpropProgram;
var init_max_pool_backprop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/max_pool_backprop_gpu.js"() {
    MaxPool2DBackpropProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy", "maxPos"];
        this.outputShape = convInfo.inShape;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationHeight = convInfo.dilationHeight;
        const effectiveFilterHeight = convInfo.effectiveFilterHeight;
        const effectiveFilterWidth = convInfo.effectiveFilterWidth;
        const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
        const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
        const lastIndex = effectiveFilterHeight * effectiveFilterWidth - 1;
        this.userCode = `
      const ivec2 pads = ivec2(${padTop}, ${padLeft});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${effectiveFilterHeight};
          wR += ${dilationHeight}) {
          float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

          if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${effectiveFilterWidth}; wC++) {
            float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

            if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);
            int maxPosValue = ${lastIndex} - int(getMaxPos(b, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            int curPosValue = wR * ${effectiveFilterWidth} + wC;
            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

            dotProd += dyValue * mask;
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
    MaxPool3DBackpropProgram = class {
      constructor(convInfo) {
        this.variableNames = ["dy", "maxPos"];
        this.outputShape = convInfo.inShape;
        const strideDepth = convInfo.strideDepth;
        const strideHeight = convInfo.strideHeight;
        const strideWidth = convInfo.strideWidth;
        const dilationDepth = convInfo.dilationDepth;
        const dilationHeight = convInfo.dilationHeight;
        const dilationWidth = convInfo.dilationWidth;
        const effectiveFilterDepth = convInfo.effectiveFilterDepth;
        const effectiveFilterHeight = convInfo.effectiveFilterHeight;
        const effectiveFilterWidth = convInfo.effectiveFilterWidth;
        const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;
        const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;
        const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;
        const lastIndex = effectiveFilterDepth * effectiveFilterHeight * effectiveFilterWidth - 1;
        this.userCode = `
      const ivec3 pads = ivec3(${padFront}, ${padTop}, ${padLeft});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${effectiveFilterDepth};
           wD += ${dilationDepth}) {
          float dyD = float(dyDCorner + wD) / ${strideDepth}.0;

          if (dyD < 0.0 || dyD >= ${convInfo.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${effectiveFilterHeight};
              wR += ${dilationHeight}) {
            float dyR = float(dyRCorner + wR) / ${strideHeight}.0;

            if (dyR < 0.0 || dyR >= ${convInfo.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${effectiveFilterWidth};
                wC += ${dilationWidth}) {
              float dyC = float(dyCCorner + wC) / ${strideWidth}.0;

              if (dyC < 0.0 || dyC >= ${convInfo.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);
              int maxPosValue = ${lastIndex} -
                  int(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              int curPosValue =
                  wD * ${effectiveFilterHeight} * ${effectiveFilterWidth} +
                  wR * ${effectiveFilterWidth} + wC;
              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

              dotProd += dyValue * mask;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
      }
    };
  }
});
function maxPool3DGrad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2 } = inputs;
  const x = input2;
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const dilations = [1, 1, 1];
  const convInfo = backend_util_exports.computePool3DInfo(x.shape, filterSize, strides, dilations, pad2, dimRoundingMode);
  const maxPool3dPositionsProgram = new Pool3DProgram(
    convInfo,
    "max",
    true
    /* get positions */
  );
  const maxPool3dPositions2 = backend2.runWebGLProgram(maxPool3dPositionsProgram, [x], x.dtype);
  const maxPoolBackpropProgram = new MaxPool3DBackpropProgram(convInfo);
  const result = backend2.runWebGLProgram(maxPoolBackpropProgram, [dy, maxPool3dPositions2], x.dtype);
  backend2.disposeIntermediateTensorInfo(maxPool3dPositions2);
  return result;
}
var maxPool3DGradConfig3;
var init_MaxPool3DGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3DGrad.js"() {
    init_dist();
    init_max_pool_backprop_gpu();
    init_pool_gpu();
    maxPool3DGradConfig3 = {
      kernelName: MaxPool3DGrad,
      backendName: "webgl",
      kernelFunc: maxPool3DGrad2
    };
  }
});
function maxPoolGrad3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { dy, input: input2, output } = inputs;
  const x = input2;
  assertNotComplex2([input2, output], "maxPoolGrad");
  const { filterSize, strides, pad: pad2, dimRoundingMode } = attrs;
  const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, 1, pad2, dimRoundingMode);
  const getPositions = true;
  const maxPoolPositionsProgram = new Pool2DProgram(convInfo, "max", getPositions);
  const maxPoolPositions2 = backend2.runWebGLProgram(maxPoolPositionsProgram, [x], x.dtype);
  const maxPoolBackPropProgram = new MaxPool2DBackpropProgram(convInfo);
  const result = backend2.runWebGLProgram(maxPoolBackPropProgram, [dy, maxPoolPositions2], x.dtype);
  backend2.disposeIntermediateTensorInfo(maxPoolPositions2);
  return result;
}
var maxPoolGradConfig3;
var init_MaxPoolGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolGrad.js"() {
    init_dist();
    init_max_pool_backprop_gpu();
    init_pool_gpu();
    init_webgl_util();
    maxPoolGradConfig3 = {
      kernelName: MaxPoolGrad,
      backendName: "webgl",
      kernelFunc: maxPoolGrad3
    };
  }
});
function maxPoolWithArgmaxImpl2(x, includeBatchInIndex, convInfo, backend2) {
  let program = new Pool2DProgram(convInfo, "max", false);
  const poolOutput = backend2.runWebGLProgram(program, [x], "float32");
  program = new Pool2DProgram(convInfo, "max", true, true, includeBatchInIndex);
  const indexOutput = backend2.runWebGLProgram(program, [x], "float32");
  return [poolOutput, indexOutput];
}
var init_MaxPoolWithArgmax_impl2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax_impl.js"() {
    init_pool_gpu();
  }
});
var maxPoolWithArgmaxConfig2;
var init_MaxPoolWithArgmax2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax.js"() {
    init_dist();
    init_dist();
    init_MaxPoolWithArgmax_impl2();
    maxPoolWithArgmaxConfig2 = {
      kernelName: MaxPoolWithArgmax,
      backendName: "webgl",
      kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
        const { x } = inputs;
        const { filterSize, strides, pad: pad2, includeBatchInIndex } = attrs;
        const webglBackend = backend2;
        util_exports.assert(x.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${x.shape.length}.`);
        const dilations = [1, 1];
        util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(strides, dilations), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${strides} and dilations '${dilations}'`);
        const convInfo = backend_util_exports.computePool2DInfo(x.shape, filterSize, strides, dilations, pad2);
        const [result, indexes] = maxPoolWithArgmaxImpl2(x, includeBatchInIndex, convInfo, webglBackend);
        return [result, indexes];
      }
    };
  }
});
function meanImpl(x, reduceShape, outShape, backend2) {
  const inSize = util_exports.sizeFromShape(reduceShape);
  const xSize = util_exports.sizeFromShape(x.shape);
  const batchSize = xSize / inSize;
  const reshapedInput = reshape3({ inputs: { x }, attrs: { shape: [batchSize, inSize] }, backend: backend2 });
  const reduced = reduce(reshapedInput, "float32", "mean", backend2);
  const reshapedOutput = reshape3({ inputs: { x: reduced }, attrs: { shape: outShape }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(reshapedInput);
  backend2.disposeIntermediateTensorInfo(reduced);
  return reshapedOutput;
}
var init_Mean_impl = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mean_impl.js"() {
    init_dist();
    init_reduce();
    init_Reshape2();
  }
});
var meanConfig2;
var init_Mean2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mean.js"() {
    init_dist();
    init_Mean_impl();
    init_Transpose_impl2();
    meanConfig2 = {
      kernelName: Mean,
      backendName: "webgl",
      kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
        const { x } = inputs;
        const { keepDims, axis } = attrs;
        const webglBackend = backend2;
        const xRank = x.shape.length;
        const origAxes = util_exports.parseAxisParam(axis, x.shape);
        let axes = origAxes;
        const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
        const meanInputIsTransposed = permutedAxes != null;
        const shouldExecuteOnCPU = webglBackend.shouldExecuteOnCPU([x]);
        const intermediates = [];
        let meanInput = x;
        if (meanInputIsTransposed) {
          if (shouldExecuteOnCPU) {
            const xTexData = webglBackend.texData.get(meanInput.dataId);
            const values = xTexData.values;
            const newShape = new Array(xRank);
            for (let i = 0; i < newShape.length; i++) {
              newShape[i] = x.shape[permutedAxes[i]];
            }
            const meanInputValues = transposeImplCPU(values, x.shape, x.dtype, permutedAxes, newShape);
            meanInput = webglBackend.makeTensorInfo(newShape, x.dtype);
            const meanInputData = webglBackend.texData.get(meanInput.dataId);
            meanInputData.values = meanInputValues;
          } else {
            meanInput = transposeImpl2(x, permutedAxes, webglBackend);
          }
          intermediates.push(meanInput);
          axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
        }
        backend_util_exports.assertAxesAreInnerMostDims("sum", axes, xRank);
        const [meanOutShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(meanInput.shape, axes);
        let outShape = meanOutShape;
        if (keepDims) {
          outShape = backend_util_exports.expandShapeToKeepDim(meanOutShape, origAxes);
        }
        const out = meanImpl(meanInput, reduceShape, outShape, webglBackend);
        for (const i of intermediates) {
          webglBackend.disposeIntermediateTensorInfo(i);
        }
        return out;
      }
    };
  }
});
function min4(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, x.shape.length);
  }
  backend_util_exports.assertAxesAreInnerMostDims("min", axes, xRank);
  const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
  const inSize = util_exports.sizeFromShape(reduceShape);
  const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
  const reduced = reduce(a2D, a2D.dtype, "min", backend2);
  let res;
  if (keepDims) {
    const newShape = backend_util_exports.expandShapeToKeepDim(outShape, origAxes);
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: newShape } });
  } else {
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
  }
  backend2.disposeIntermediateTensorInfo(a2D);
  backend2.disposeIntermediateTensorInfo(reduced);
  if (permutedAxes != null) {
    backend2.disposeIntermediateTensorInfo(permutedX);
  }
  return res;
}
var minConfig2;
var init_Min2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Min.js"() {
    init_dist();
    init_reduce();
    init_Reshape2();
    init_Transpose2();
    minConfig2 = {
      kernelName: Min,
      backendName: "webgl",
      kernelFunc: min4
    };
  }
});
var MINIMUM;
var MINIMUM_PACKED;
var minimum3;
var minimumConfig2;
var init_Minimum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Minimum.js"() {
    init_dist();
    init_binaryop_gpu();
    init_binaryop_packed_gpu();
    init_kernel_funcs_utils();
    init_shared2();
    MINIMUM = CHECK_NAN_SNIPPET2 + `
  return min(a, b);
`;
    MINIMUM_PACKED = `
  vec4 result = vec4(min(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + CHECK_NAN_SNIPPET_PACKED + `
  return result;
`;
    minimum3 = binaryKernelFunc2({
      opSnippet: MINIMUM,
      packedOpSnippet: MINIMUM_PACKED,
      cpuKernelImpl: minimumImplCPU
    });
    minimumConfig2 = {
      kernelName: Minimum,
      backendName: "webgl",
      kernelFunc: minimum3
    };
  }
});
var MirrorPadProgram;
var init_mirror_pad_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/mirror_pad_gpu.js"() {
    init_shader_compiler();
    MirrorPadProgram = class {
      constructor(xShape, paddings, mode) {
        this.variableNames = ["x"];
        this.outputShape = paddings.map(
          (p2, i) => p2[0] + xShape[i] + p2[1]
          /* afterPad */
        );
        const rank = xShape.length;
        const dtype = getCoordsDataType(rank);
        const start = paddings.map((p2) => p2[0]).join(",");
        const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
        const unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
        const offset = mode === "reflect" ? 0 : 1;
        if (rank === 1) {
          this.userCode = `
        int start = ${start};
        int end = ${end};

        void main() {
          int outC = getOutputCoords();
          if (outC < start) {
            outC = start * 2 - outC - ${offset};
          } else if(outC >= end) {
            outC = (end - 1) * 2 - outC + ${offset};
          }
          setOutput(getX(outC - start));
        }
      `;
          return;
        }
        this.userCode = `
      ${dtype} start = ${dtype}(${start});
      ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outC = getOutputCoords();
        for (int i = 0; i < ${rank}; i++) {
          if (outC[i] < start[i]) {
            outC[i] = start[i] * 2 - outC[i] - ${offset};
          } else if(outC[i] >= end[i]) {
            outC[i] = (end[i] - 1) * 2 - outC[i] + ${offset};
          }
        }
        ${dtype} coords = outC - start;
        setOutput(getX(${unpackedCoords}));
      }
    `;
      }
    };
  }
});
var MirrorPadPackedProgram;
var init_mirror_pad_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/mirror_pad_packed_gpu.js"() {
    init_packing_util();
    init_shader_compiler();
    MirrorPadPackedProgram = class {
      constructor(xShape, paddings, mode) {
        this.variableNames = ["x"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = paddings.map(
          (p2, i) => p2[0] + xShape[i] + p2[1]
          /* afterPad */
        );
        const rank = xShape.length;
        const dtype = getCoordsDataType(rank);
        const start = paddings.map((p2) => p2[0]).join(",");
        const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
        const coords2 = getChannels("rc", rank);
        const source = getChannels("source", rank);
        const cLimit = `${coords2[rank - 1]} < ${this.outputShape[rank - 1]}`;
        const innerDims = rank === 1 ? "source" : `vec2(${source.slice(-2).join()})`;
        const offset = mode === "reflect" ? 0 : 1;
        let mainLoop = "";
        if (rank === 1) {
          const padSetup = `
        ${dtype} source = rc;
        if (source < start) {
          source = start * 2 - source - ${offset};
        } else if (source >= end) {
          source = (end - 1) * 2 - source + ${offset};
        }
        source -= start;
      `;
          mainLoop = `
        ${dtype} rc = outputLoc;
        ${padSetup}
        result[0] = getChannel(getX(${source.join()}), ${innerDims});
        ${coords2[rank - 1]} += 1;
        if(${cLimit}) {
          ${padSetup}
          result[1] = getChannel(getX(${source.join()}), ${innerDims});
        }
      `;
        } else {
          const padSetup = `
        ${dtype} source = rc;
        ${dtype} lt = ${dtype}(lessThan(source, start));
        ${dtype} gte = ${dtype}(greaterThanEqual(source, end));
        ${dtype} orig = 1 - (lt + gte);
        source = orig * source +
                lt * (start * 2 - source - ${offset}) +
                gte * ((end - 1) * 2 - source + ${offset});
        source -= start;
      `;
          mainLoop = `
        ${dtype} rc = outputLoc;
        ${padSetup}
        result[0] = getChannel(getX(${source.join()}), ${innerDims});
        ${coords2[rank - 1]} += 1;
        if(${cLimit}) {
          ${padSetup}
          result[1] = getChannel(getX(${source.join()}), ${innerDims});
        }
        rc = outputLoc;
        ${coords2[rank - 2]} += 1;
        if(${coords2[rank - 2]} < ${this.outputShape[rank - 2]}) {
          ${padSetup}
          result[2] = getChannel(getX(${source.join()}), ${innerDims});
          ${coords2[rank - 1]} += 1;
          if(${cLimit}) {
            ${padSetup}
            result[3] = getChannel(getX(${source.join()}), ${innerDims});
          }
        }
      `;
        }
        this.userCode = `
      const ${dtype} start = ${dtype}(${start});
      const ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${mainLoop}
        setOutput(result);
      }
    `;
      }
    };
  }
});
var mirrorPadKernelFunc;
var mirrorPadConfig2;
var init_MirrorPad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/MirrorPad.js"() {
    init_dist();
    init_mirror_pad_gpu();
    init_mirror_pad_packed_gpu();
    mirrorPadKernelFunc = ({ inputs, backend: backend2, attrs }) => {
      const { x } = inputs;
      const { paddings, mode } = attrs;
      const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new MirrorPadPackedProgram(x.shape, paddings, mode) : new MirrorPadProgram(x.shape, paddings, mode);
      const output = backend2.runWebGLProgram(program, [x], x.dtype);
      return output;
    };
    mirrorPadConfig2 = {
      kernelName: MirrorPad,
      backendName: "webgl",
      kernelFunc: mirrorPadKernelFunc
    };
  }
});
var MOD;
var MOD_PACKED;
var mod3;
var modConfig2;
var init_Mod2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Mod.js"() {
    init_dist();
    init_binaryop_packed_gpu();
    init_kernel_funcs_utils();
    MOD = `if (b == 0.0) return NAN;
  return mod(a, b);`;
    MOD_PACKED = `
  vec4 result = mod(a, b);
  bvec4 isNaN = equal(b, vec4(0.0));
  ` + CHECK_NAN_SNIPPET_PACKED + `
  return result;
`;
    mod3 = binaryKernelFunc2({
      opSnippet: MOD,
      packedOpSnippet: MOD_PACKED
    });
    modConfig2 = {
      kernelName: Mod,
      backendName: "webgl",
      kernelFunc: mod3
    };
  }
});
var MultinomialProgram;
var init_multinomial_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/multinomial_gpu.js"() {
    MultinomialProgram = class {
      constructor(batchSize, numOutcomes, numSamples) {
        this.variableNames = ["probs"];
        this.customUniforms = [{ name: "seed", type: "float" }];
        this.outputShape = [batchSize, numSamples];
        this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];

        float r = random(seed);
        float cdf = 0.0;

        for (int i = 0; i < ${numOutcomes - 1}; i++) {
          cdf += getProbs(batch, i);

          if (r < cdf) {
            setOutput(float(i));
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutput(float(${numOutcomes - 1}));
      }
    `;
      }
    };
  }
});
var DIV;
var DIV_PACKED;
var realDiv;
var realDivConfig2;
var init_RealDiv2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RealDiv.js"() {
    init_dist();
    init_kernel_funcs_utils();
    DIV = `
if (a == b) {
  return 1.0;
};
return a / b;`;
    DIV_PACKED = `
  // vec4 one = vec4(equal(a, b));
  // return one + (vec4(1.0) - one) * a / b;
  vec4 result = a / b;
  if(a.x == b.x) {
    result.x = 1.;
  }
  if(a.y == b.y) {
    result.y = 1.;
  }
  if(a.z == b.z) {
    result.z = 1.;
  }
  if(a.w == b.w) {
    result.w = 1.;
  }

  return result;
`;
    realDiv = binaryKernelFunc2({ opSnippet: DIV, packedOpSnippet: DIV_PACKED, checkOutOfBounds: true });
    realDivConfig2 = {
      kernelName: RealDiv,
      backendName: "webgl",
      kernelFunc: realDiv
    };
  }
});
var SUB;
var sub32;
var subConfig2;
var init_Sub2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sub.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    SUB = "return a - b;";
    sub32 = binaryKernelFunc2({
      opSnippet: SUB,
      packedOpSnippet: SUB,
      supportsComplex: true,
      cpuKernelImpl: subImplCPU
    });
    subConfig2 = {
      kernelName: Sub,
      backendName: "webgl",
      kernelFunc: sub32
    };
  }
});
function softmax3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { logits } = inputs;
  const { dim } = attrs;
  const axes = util_exports.parseAxisParam([dim], logits.shape);
  const maxLogit = max4({
    inputs: { x: logits },
    backend: backend2,
    attrs: { reductionIndices: axes, keepDims: false }
  });
  const expandedShape = backend_util_exports.expandShapeToKeepDim(maxLogit.shape, axes);
  const maxLogitsReshaped = reshape3({ inputs: { x: maxLogit }, backend: backend2, attrs: { shape: expandedShape } });
  const a = sub32({ inputs: { a: logits, b: maxLogitsReshaped }, backend: backend2 });
  const b = exp3({ inputs: { x: a }, backend: backend2 });
  const sumExp = sum4({ inputs: { x: b }, backend: backend2, attrs: { axis: axes, keepDims: false } });
  const sumExpReshaped = reshape3({ inputs: { x: sumExp }, backend: backend2, attrs: { shape: expandedShape } });
  const res = realDiv({ inputs: { a: b, b: sumExpReshaped }, backend: backend2 });
  backend2.disposeIntermediateTensorInfo(maxLogit);
  backend2.disposeIntermediateTensorInfo(maxLogitsReshaped);
  backend2.disposeIntermediateTensorInfo(a);
  backend2.disposeIntermediateTensorInfo(b);
  backend2.disposeIntermediateTensorInfo(sumExp);
  backend2.disposeIntermediateTensorInfo(sumExpReshaped);
  return res;
}
var softmaxConfig2;
var init_Softmax2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Softmax.js"() {
    init_dist();
    init_Exp2();
    init_Max2();
    init_RealDiv2();
    init_Reshape2();
    init_Sub2();
    init_Sum2();
    softmaxConfig2 = {
      kernelName: Softmax,
      backendName: "webgl",
      kernelFunc: softmax3
    };
  }
});
function multinomial2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { logits } = inputs;
  const { numSamples, seed, normalized } = attrs;
  const probs = normalized ? logits : softmax3({ inputs: { logits }, backend: backend2, attrs: { dim: logits.shape.length - 1 } });
  const batchSize = probs.shape[0];
  const numOutcomes = probs.shape[1];
  const program = new MultinomialProgram(batchSize, numOutcomes, numSamples);
  const customValues = [[seed]];
  const res = backend2.runWebGLProgram(program, [probs], "int32", customValues);
  if (!normalized) {
    backend2.disposeIntermediateTensorInfo(probs);
  }
  return res;
}
var multinomialConfig2;
var init_Multinomial2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Multinomial.js"() {
    init_dist();
    init_multinomial_gpu();
    init_Softmax2();
    multinomialConfig2 = {
      kernelName: Multinomial,
      backendName: "webgl",
      kernelFunc: multinomial2
    };
  }
});
function neg3(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (backend2.shouldExecuteOnCPU([x])) {
    const xData = backend2.texData.get(x.dataId);
    const [outValues, newShape] = negImplCPU(xData.values, x.shape, x.dtype);
    return backend2.makeTensorInfo(newShape, x.dtype, outValues);
  }
  let program;
  if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) {
    program = new UnaryOpPackedProgram(x.shape, NEG_PACKED);
  } else {
    program = new UnaryOpProgram(x.shape, NEG);
  }
  return backend2.runWebGLProgram(program, [x], x.dtype);
}
var NEG;
var NEG_PACKED;
var negConfig2;
var init_Neg2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Neg.js"() {
    init_dist();
    init_shared2();
    init_unaryop_gpu();
    init_unaryop_packed_gpu();
    NEG = CHECK_NAN_SNIPPET + `
  return -x;
`;
    NEG_PACKED = `
  vec4 result = -x;
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    negConfig2 = {
      kernelName: Neg,
      backendName: "webgl",
      kernelFunc: neg3
    };
  }
});
function nonMaxSuppressionV32(args) {
  backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold } = attrs;
  const boxesVals = backend2.readSync(boxes.dataId);
  const scoresVals = backend2.readSync(scores.dataId);
  const { selectedIndices } = nonMaxSuppressionV3Impl3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);
  return backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices));
}
var nonMaxSuppressionV3Impl3;
var nonMaxSuppressionV3Config2;
var init_NonMaxSuppressionV32 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV3.js"() {
    init_dist();
    nonMaxSuppressionV3Impl3 = kernel_impls_exports.nonMaxSuppressionV3Impl;
    nonMaxSuppressionV3Config2 = {
      kernelName: NonMaxSuppressionV3,
      backendName: "webgl",
      kernelFunc: nonMaxSuppressionV32
    };
  }
});
function nonMaxSuppressionV42(args) {
  backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize } = attrs;
  const boxesVals = backend2.readSync(boxes.dataId);
  const scoresVals = backend2.readSync(scores.dataId);
  const { selectedIndices, validOutputs } = nonMaxSuppressionV4Impl3(boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize);
  return [
    backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend2.makeTensorInfo([], "int32", new Int32Array([validOutputs]))
  ];
}
var nonMaxSuppressionV4Impl3;
var nonMaxSuppressionV4Config2;
var init_NonMaxSuppressionV42 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV4.js"() {
    init_dist();
    nonMaxSuppressionV4Impl3 = kernel_impls_exports.nonMaxSuppressionV4Impl;
    nonMaxSuppressionV4Config2 = {
      kernelName: NonMaxSuppressionV4,
      backendName: "webgl",
      kernelFunc: nonMaxSuppressionV42
    };
  }
});
function nonMaxSuppressionV52(args) {
  backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  const { inputs, backend: backend2, attrs } = args;
  const { boxes, scores } = inputs;
  const { maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma } = attrs;
  const boxesVals = backend2.readSync(boxes.dataId);
  const scoresVals = backend2.readSync(scores.dataId);
  const maxOutputSizeVal = maxOutputSize;
  const iouThresholdVal = iouThreshold;
  const scoreThresholdVal = scoreThreshold;
  const softNmsSigmaVal = softNmsSigma;
  const { selectedIndices, selectedScores } = nonMaxSuppressionV5Impl3(boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal, scoreThresholdVal, softNmsSigmaVal);
  return [
    backend2.makeTensorInfo([selectedIndices.length], "int32", new Int32Array(selectedIndices)),
    backend2.makeTensorInfo([selectedScores.length], "float32", new Float32Array(selectedScores))
  ];
}
var nonMaxSuppressionV5Impl3;
var nonMaxSuppressionV5Config2;
var init_NonMaxSuppressionV52 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV5.js"() {
    init_dist();
    nonMaxSuppressionV5Impl3 = kernel_impls_exports.nonMaxSuppressionV5Impl;
    nonMaxSuppressionV5Config2 = {
      kernelName: NonMaxSuppressionV5,
      backendName: "webgl",
      kernelFunc: nonMaxSuppressionV52
    };
  }
});
var OneHotProgram;
var init_onehot_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/onehot_gpu.js"() {
    OneHotProgram = class {
      constructor(numIndices, depth, onValue, offValue) {
        this.variableNames = ["indices"];
        this.outputShape = [numIndices, depth];
        this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int index = round(getIndices(coords.x));
        setOutput(mix(float(${offValue}), float(${onValue}),
                      float(index == coords.y)));
      }
    `;
      }
    };
  }
});
var oneHot3;
var oneHotConfig2;
var init_OneHot2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/OneHot.js"() {
    init_dist();
    init_onehot_gpu();
    init_Reshape2();
    oneHot3 = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { indices } = inputs;
      const { dtype, depth, onValue, offValue } = attrs;
      const indicesSize = util_exports.sizeFromShape(indices.shape);
      const program = new OneHotProgram(indicesSize, depth, onValue, offValue);
      const reshaped = reshape3({ inputs: { x: indices }, backend: backend2, attrs: { shape: [indicesSize] } });
      const result = backend2.runWebGLProgram(program, [reshaped], dtype);
      backend2.disposeIntermediateTensorInfo(reshaped);
      const outShape = [...indices.shape, depth];
      const out = reshape3({ inputs: { x: result }, backend: backend2, attrs: { shape: outShape } });
      backend2.disposeIntermediateTensorInfo(result);
      return out;
    };
    oneHotConfig2 = {
      kernelName: OneHot,
      backendName: "webgl",
      kernelFunc: oneHot3
    };
  }
});
function zerosLike3(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (x.dtype === "complex64") {
    const realPart = real3({ inputs: { input: x }, backend: backend2 });
    const r = zerosLike3({ inputs: { x: realPart }, backend: backend2 });
    const imagPart = imag3({ inputs: { input: x }, backend: backend2 });
    const i = zerosLike3({ inputs: { x: imagPart }, backend: backend2 });
    const result = complex3({ inputs: { real: r, imag: i }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(realPart);
    backend2.disposeIntermediateTensorInfo(r);
    backend2.disposeIntermediateTensorInfo(imagPart);
    backend2.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill3({
      attrs: {
        shape: x.shape,
        dtype: x.dtype,
        value: x.dtype === "string" ? "" : 0
      },
      backend: backend2
    });
  }
}
var zerosLikeConfig2;
var init_ZerosLike2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ZerosLike.js"() {
    init_dist();
    init_Complex2();
    init_Fill2();
    init_Imag2();
    init_Real2();
    zerosLikeConfig2 = {
      kernelName: ZerosLike,
      backendName: "webgl",
      kernelFunc: zerosLike3
    };
  }
});
function onesLike3(args) {
  const { inputs, backend: backend2 } = args;
  const { x } = inputs;
  if (x.dtype === "string") {
    throw new Error("onesLike is not supported under string dtype");
  } else if (x.dtype === "complex64") {
    const realPart = real3({ inputs: { input: x }, backend: backend2 });
    const r = onesLike3({ inputs: { x: realPart }, backend: backend2 });
    const imagPart = imag3({ inputs: { input: x }, backend: backend2 });
    const i = zerosLike3({ inputs: { x: imagPart }, backend: backend2 });
    const result = complex3({ inputs: { real: r, imag: i }, backend: backend2 });
    backend2.disposeIntermediateTensorInfo(realPart);
    backend2.disposeIntermediateTensorInfo(r);
    backend2.disposeIntermediateTensorInfo(imagPart);
    backend2.disposeIntermediateTensorInfo(i);
    return result;
  } else {
    return fill3({ attrs: { shape: x.shape, dtype: x.dtype, value: 1 }, backend: backend2 });
  }
}
var onesLikeConfig2;
var init_OnesLike2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/OnesLike.js"() {
    init_dist();
    init_Complex2();
    init_Fill2();
    init_Imag2();
    init_Real2();
    init_ZerosLike2();
    onesLikeConfig2 = {
      kernelName: OnesLike,
      backendName: "webgl",
      kernelFunc: onesLike3
    };
  }
});
function pack2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { axis } = attrs;
  if (inputs.length === 1) {
    return expandDims4({ inputs: { input: inputs[0] }, backend: backend2, attrs: { dim: axis } });
  }
  const shape = inputs[0].shape;
  const dtype = inputs[0].dtype;
  inputs.forEach((t) => {
    util_exports.assertShapesMatch(shape, t.shape, "All tensors passed to stack must have matching shapes");
    util_exports.assert(dtype === t.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  const intermediateTensorInfos = [];
  const expandedTensors = inputs.map((t) => {
    const expandedT = expandDims4({ inputs: { input: t }, backend: backend2, attrs: { dim: axis } });
    intermediateTensorInfos.push(expandedT);
    return expandedT;
  });
  const result = concat3({ inputs: expandedTensors, backend: backend2, attrs: { axis } });
  intermediateTensorInfos.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return result;
}
var packConfig2;
var init_Pack2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Pack.js"() {
    init_dist();
    init_Concat2();
    init_ExpandDims2();
    packConfig2 = {
      kernelName: Pack,
      backendName: "webgl",
      kernelFunc: pack2
    };
  }
});
var PadProgram;
var init_pad_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/pad_gpu.js"() {
    init_shader_compiler();
    PadProgram = class {
      constructor(xShape, paddings, constantValue) {
        this.variableNames = ["x"];
        this.customUniforms = [{ name: "value", type: "float" }];
        this.outputShape = paddings.map(
          (p2, i) => p2[0] + xShape[i] + p2[1]
          /* afterPad */
        );
        const rank = xShape.length;
        const type = getCoordsDataType(rank);
        const start = paddings.map((p2) => p2[0]).join(",");
        const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
        const unpackedCoords = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, rank);
        if (rank === 1) {
          this.userCode = `
        int start = ${start};
        int end = ${end};

        void main() {
          int outC = getOutputCoords();
          if (outC < start || outC >= end) {
            setOutput(value);
          } else {
            setOutput(getX(outC - start));
          }
        }
      `;
          return;
        }
        this.userCode = `
      ${type} start = ${type}(${start});
      ${type} end = ${type}(${end});

      void main() {
        ${type} outC = getOutputCoords();
        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {
          setOutput(value);
        } else {
          ${type} coords = outC - start;
          setOutput(getX(${unpackedCoords}));
        }
      }
    `;
      }
    };
  }
});
var PadPackedProgram;
var init_pad_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/pad_packed_gpu.js"() {
    init_packing_util();
    init_shader_compiler();
    PadPackedProgram = class {
      constructor(xShape, paddings, constantValue) {
        this.variableNames = ["x"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.customUniforms = [{ name: "value", type: "float" }];
        this.outputShape = paddings.map(
          (p2, i) => p2[0] + xShape[i] + p2[1]
          /* afterPad */
        );
        const rank = xShape.length;
        const dtype = getCoordsDataType(rank);
        const start = paddings.map((p2) => p2[0]).join(",");
        const end = paddings.map((p2, i) => p2[0] + xShape[i]).join(",");
        const coords2 = getChannels("rc", rank);
        const source = getChannels("source", rank);
        const cLimit = `${coords2[rank - 1]} < ${this.outputShape[rank - 1]}`;
        const innerDims = rank === 1 ? "source" : `vec2(${source.slice(-2).join()})`;
        const componentSetup = [
          `${dtype} rc = outputLoc;`,
          `${coords2[rank - 1]} += 1;
       if(${cLimit}) {
      `,
          rank === 1 ? "" : `}
       rc = outputLoc;
       ${coords2[rank - 2]} += 1;
       if(${coords2[rank - 2]} < ${this.outputShape[rank - 2]}) {`,
          rank === 1 ? "" : `  ${coords2[rank - 1]} += 1;
         if(${cLimit}) {`
        ];
        const paddingArea = rank === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
        let mainLoop = "";
        for (let i = 0, j = rank === 1 ? 2 : 4; i < j; i++) {
          mainLoop += `
        ${componentSetup[i]}
        if (${paddingArea}) {
          result[${i}] = float(value);
        } else {
          ${dtype} source = rc - start;
          result[${i}] = getChannel(getX(${source.join()}), ${innerDims});
        }
      `;
        }
        mainLoop += rank === 1 ? `} ` : `}}`;
        this.userCode = `
      const ${dtype} start = ${dtype}(${start});
      const ${dtype} end = ${dtype}(${end});

      void main() {
        ${dtype} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${mainLoop}
        setOutput(result);
      }
    `;
      }
    };
  }
});
var padV22;
var padV2Config2;
var init_PadV22 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/PadV2.js"() {
    init_dist();
    init_pad_gpu();
    init_pad_packed_gpu();
    init_Fill2();
    padV22 = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { x } = inputs;
      const { paddings, constantValue } = attrs;
      if (util_exports.sizeFromShape(x.shape) === 0) {
        const outputShape = paddings.map(
          (p2, i) => p2[0] + x.shape[i] + p2[1]
          /* afterPad */
        );
        return fill3({
          backend: backend2,
          attrs: { shape: outputShape, value: constantValue, dtype: x.dtype }
        });
      }
      const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new PadPackedProgram(x.shape, paddings, constantValue) : new PadProgram(x.shape, paddings, constantValue);
      const customValues = [[constantValue]];
      return backend2.runWebGLProgram(program, [x], x.dtype, customValues);
    };
    padV2Config2 = {
      kernelName: PadV2,
      backendName: "webgl",
      kernelFunc: padV22
    };
  }
});
var POW;
var POW_PACKED;
var pow3;
var powConfig2;
var init_Pow2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Pow.js"() {
    init_dist();
    init_binaryop_packed_gpu();
    init_kernel_funcs_utils();
    POW = `
  if(a < 0.0 && floor(b) < b){
    return NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  return (round(mod(b, 2.0)) != 1) ?
      pow(abs(a), b) : sign(a) * pow(abs(a), b);
`;
    POW_PACKED = `
  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.
  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));
  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);
  vec4 result = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  bvec4 isExpZero = equal(b, vec4(0.0));
  result.r = isExpZero.r ? 1.0 : result.r;
  result.g = isExpZero.g ? 1.0 : result.g;
  result.b = isExpZero.b ? 1.0 : result.b;
  result.a = isExpZero.a ? 1.0 : result.a;

  bvec4 isNaN1 = lessThan(a, vec4(0.0));
  bvec4 isNaN2 = lessThan(floor(b), b);
  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);
  ` + CHECK_NAN_SNIPPET_PACKED + `
  return result;
`;
    pow3 = binaryKernelFunc2({ opSnippet: POW, packedOpSnippet: POW_PACKED });
    powConfig2 = {
      kernelName: Pow,
      backendName: "webgl",
      kernelFunc: pow3
    };
  }
});
function prod3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { axis, keepDims } = attrs;
  const xRank = x.shape.length;
  const toDispose = [];
  const origAxes = util_exports.parseAxisParam(axis, x.shape);
  let axes = origAxes;
  const permutedAxes = backend_util_exports.getAxesPermutation(axes, xRank);
  let permutedX = x;
  if (permutedAxes != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutedAxes } });
    axes = backend_util_exports.getInnerMostAxes(axes.length, xRank);
    toDispose.push(permutedX);
  }
  backend_util_exports.assertAxesAreInnerMostDims("prod", axes, xRank);
  let res;
  if (backend2.shouldExecuteOnCPU([permutedX])) {
    const xVals = backend2.texData.get(permutedX.dataId).values;
    const { outVals, outShape, outDtype } = prodImplCPU(permutedX.shape, permutedX.dtype, xVals, axes);
    res = backend2.makeTensorInfo(outShape, outDtype, outVals);
  } else {
    const [outShape, reduceShape] = backend_util_exports.computeOutAndReduceShapes(permutedX.shape, axes);
    const inSize = util_exports.sizeFromShape(reduceShape);
    const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
    const outputDType = sumOutType(x.dtype);
    const reduced = reduce(a2D, outputDType, "prod", backend2);
    res = reshape3({ inputs: { x: reduced }, backend: backend2, attrs: { shape: outShape } });
    toDispose.push(a2D);
    toDispose.push(reduced);
  }
  if (keepDims) {
    toDispose.push(res);
    const newShape = backend_util_exports.expandShapeToKeepDim(res.shape, origAxes);
    res = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: newShape } });
  }
  toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return res;
}
var prodConfig2;
var init_Prod2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Prod.js"() {
    init_dist();
    init_reduce();
    init_shared2();
    init_Reshape2();
    init_Transpose2();
    prodConfig2 = {
      kernelName: Prod,
      backendName: "webgl",
      kernelFunc: prod3
    };
  }
});
function raggedGather2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { paramsNestedSplits, paramsDenseValues, indices } = inputs;
  const { outputRaggedRank } = attrs;
  const $paramsNestedSplits = paramsNestedSplits.map((t) => backend2.readSync(t.dataId));
  const $paramsNestedSplitsShapes = paramsNestedSplits.map((t) => t.shape);
  const $paramsDenseValues = backend2.readSync(paramsDenseValues.dataId);
  const $indices = backend2.readSync(indices.dataId);
  const [outputNestedSplits, outputDenseValues, outputDenseValuesShape] = raggedGatherImplCPU($paramsNestedSplits, $paramsNestedSplitsShapes, $paramsDenseValues, paramsDenseValues.shape, paramsDenseValues.dtype, $indices, indices.shape, outputRaggedRank);
  const outputNestedSplitsTensors = outputNestedSplits.map((splits) => backend2.makeTensorInfo([splits.length], "int32", splits));
  const outputDenseValuesTensor = backend2.makeTensorInfo(outputDenseValuesShape, paramsDenseValues.dtype, outputDenseValues);
  return outputNestedSplitsTensors.concat([outputDenseValuesTensor]);
}
var raggedGatherConfig2;
var init_RaggedGather2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RaggedGather.js"() {
    init_dist();
    init_shared2();
    raggedGatherConfig2 = {
      kernelName: RaggedGather,
      backendName: "webgl",
      kernelFunc: raggedGather2
    };
  }
});
function raggedRange2(args) {
  const { inputs, backend: backend2 } = args;
  const { starts, limits, deltas } = inputs;
  const $starts = backend2.readSync(starts.dataId);
  const $limits = backend2.readSync(limits.dataId);
  const $deltas = backend2.readSync(deltas.dataId);
  const [rtNestedSplitsData, rtDenseValuesData] = raggedRangeImplCPU($starts, starts.shape, starts.dtype, $limits, limits.shape, $deltas, deltas.shape);
  const rtNestedSplits = backend2.makeTensorInfo([rtNestedSplitsData.length], "int32", rtNestedSplitsData);
  const rtDenseValues = backend2.makeTensorInfo([rtDenseValuesData.length], starts.dtype, rtDenseValuesData);
  return [rtNestedSplits, rtDenseValues];
}
var raggedRangeConfig2;
var init_RaggedRange2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RaggedRange.js"() {
    init_dist();
    init_shared2();
    raggedRangeConfig2 = {
      kernelName: RaggedRange,
      backendName: "webgl",
      kernelFunc: raggedRange2
    };
  }
});
function raggedTensorToTensor2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { shape, values, defaultValue, rowPartitionTensors } = inputs;
  const { rowPartitionTypes } = attrs;
  const $shape = backend2.readSync(shape.dataId);
  const $values = backend2.readSync(values.dataId);
  const $defaultValue = backend2.readSync(defaultValue.dataId);
  const $rowPartitionValues = rowPartitionTensors.map((t) => backend2.readSync(t.dataId));
  const rowPartitionValuesShapes = rowPartitionTensors.map((t) => t.shape);
  const [outputShape, output] = raggedTensorToTensorImplCPU($shape, shape.shape, $values, values.shape, values.dtype, $defaultValue, defaultValue.shape, $rowPartitionValues, rowPartitionValuesShapes, rowPartitionTypes);
  return backend2.makeTensorInfo(outputShape, values.dtype, output);
}
var raggedTensorToTensorConfig2;
var init_RaggedTensorToTensor2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RaggedTensorToTensor.js"() {
    init_dist();
    init_shared2();
    raggedTensorToTensorConfig2 = {
      kernelName: RaggedTensorToTensor,
      backendName: "webgl",
      kernelFunc: raggedTensorToTensor2
    };
  }
});
var range4;
var rangeConfig2;
var init_Range2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Range.js"() {
    init_dist();
    init_shared2();
    range4 = (args) => {
      const { backend: backend2, attrs } = args;
      const { start, stop, step: step4, dtype } = attrs;
      const values = rangeImplCPU(start, stop, step4, dtype);
      return backend2.makeTensorInfo([values.length], dtype, values);
    };
    rangeConfig2 = {
      kernelName: Range,
      backendName: "webgl",
      kernelFunc: range4
    };
  }
});
var RECIPROCAL;
var reciprocal3;
var reciprocalConfig2;
var init_Reciprocal2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Reciprocal.js"() {
    init_dist();
    init_kernel_funcs_utils();
    RECIPROCAL = `return 1.0 / x;`;
    reciprocal3 = unaryKernelFunc2({ opSnippet: RECIPROCAL });
    reciprocalConfig2 = {
      kernelName: Reciprocal,
      backendName: "webgl",
      kernelFunc: reciprocal3
    };
  }
});
var RELU3;
var RELU_PACKED;
var relu3;
var reluConfig2;
var init_Relu2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Relu.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    RELU3 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : x;
`;
    RELU_PACKED = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    relu3 = unaryKernelFunc2({ opSnippet: RELU3, packedOpSnippet: RELU_PACKED });
    reluConfig2 = {
      kernelName: Relu,
      backendName: "webgl",
      kernelFunc: relu3
    };
  }
});
var RELU63;
var RELU6_PACKED;
var relu63;
var relu6Config2;
var init_Relu62 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Relu6.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_unaryop_gpu();
    RELU63 = CHECK_NAN_SNIPPET + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
    RELU6_PACKED = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    relu63 = unaryKernelFunc2({ opSnippet: RELU63, packedOpSnippet: RELU6_PACKED });
    relu6Config2 = {
      kernelName: Relu6,
      backendName: "webgl",
      kernelFunc: relu63
    };
  }
});
var ResizeBilinearProgram;
var init_resize_bilinear_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_gpu.js"() {
    ResizeBilinearProgram = class {
      constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
        this.variableNames = ["A"];
        this.outputShape = [];
        const [batch, oldHeight, oldWidth, depth] = inputShape;
        this.outputShape = [batch, newHeight, newWidth, depth];
        const effectiveInSize = [
          alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
          alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
        ];
        const effectiveOutSize = [
          alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
          alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
        ];
        let sourceFracIndexRC;
        if (halfPixelCenters) {
          sourceFracIndexRC = `(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)`;
        } else {
          sourceFracIndexRC = `vec2(yRC) * effectiveInputOverOutputRatioRC`;
        }
        this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the four integer indices.
        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));
        ivec2 sourceCeilRC = ivec2(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);
        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);
        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);
        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);

        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);

        float top = topLeft + (topRight - topLeft) * fracRC.y;
        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
        float newValue = top + (bottom - top) * fracRC.x;

        setOutput(newValue);
      }
    `;
      }
    };
  }
});
var ResizeBilinearPackedProgram;
var init_resize_bilinear_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_packed_gpu.js"() {
    ResizeBilinearPackedProgram = class {
      constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = [];
        const [batch, oldHeight, oldWidth, depth] = inputShape;
        this.outputShape = [batch, newHeight, newWidth, depth];
        const effectiveInSize = [
          alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
          alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
        ];
        const effectiveOutSize = [
          alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
          alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
        ];
        let sourceFracIndexRC;
        if (halfPixelCenters) {
          sourceFracIndexRC = `(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)`;
        } else {
          sourceFracIndexRC = `vec3(yRC) * effectiveInputOverOutputRatioRC`;
        }
        this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,
                                     ${oldWidth}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the four integer indices.
        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));
        ivec3 sourceCeilRC = ivec3(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${depth - 1};
        bool hasNextRow = coords.z < ${newWidth - 1};

        // In parallel, construct four corners for all four components in
        // packed 2x2 cell.
        vec4 topLeft = vec4(
          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 bottomLeft = vec4(
          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 topRight = vec4(
          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec4 bottomRight = vec4(
          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);

        vec4 top = mix(topLeft, topRight, fracRC.yyzz);
        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);
        vec4 newValue = mix(top, bottom, fracRC.x);

        setOutput(newValue);
      }
    `;
      }
    };
  }
});
function resizeBilinear4(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  const [newHeight, newWidth] = size;
  const program = env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeBilinearPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeBilinearProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
  return backend2.runWebGLProgram(program, [images], "float32");
}
var resizeBilinearConfig2;
var init_ResizeBilinear2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinear.js"() {
    init_dist();
    init_resize_bilinear_gpu();
    init_resize_bilinear_packed_gpu();
    resizeBilinearConfig2 = {
      kernelName: ResizeBilinear,
      backendName: "webgl",
      kernelFunc: resizeBilinear4
    };
  }
});
var ResizeBilinearBackpropProgram;
var init_resize_bilinear_backprop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_backprop_gpu.js"() {
    ResizeBilinearBackpropProgram = class {
      constructor(dyShape, inputShape, alignCorners) {
        this.variableNames = ["dy"];
        this.outputShape = [];
        this.outputShape = inputShape;
        const [, xHeight, xWidth] = inputShape;
        const [, yHeight, yWidth] = dyShape;
        const effectiveXSize = [
          alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
          alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
        ];
        const effectiveYSize = [
          alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
          alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
        ];
        const heightScale = effectiveXSize[0] / effectiveYSize[0];
        const widthScale = effectiveXSize[1] / effectiveYSize[1];
        const invHeightScale = 1 / heightScale;
        const invWidthScale = 1 / widthScale;
        const winHeight = Math.ceil(invHeightScale) * 2 + 2;
        const winWidth = Math.ceil(invWidthScale) * 2 + 2;
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${heightScale});
        const float widthScale = float(${widthScale});

        const float invHeightScale = float(${invHeightScale});
        const float invWidthScale = float(${invWidthScale});

        const int winHeight = int(${winHeight});
        const int winWidth = int(${winWidth});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(startRLerp - float(winHeight / 2));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(startCLerp - float(winWidth / 2));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${yHeight}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${yWidth}) {
              continue;
            }

            float dxR = float(dyR) * heightScale;
            int topDxRIndex = int(floor(dxR));
            int bottomDxRIndex = int(min(ceil(dxR), ${xHeight - 1}.0));
            float dxRLerp = dxR - float(topDxRIndex);
            float inverseDxRLerp = 1.0 - dxRLerp;

            float dxC = float(dyC) * widthScale;
            int leftDxCIndex = int(floor(dxC));
            int rightDxCIndex = int(min(ceil(dxC), ${xWidth - 1}.0));
            float dxCLerp = dxC - float(leftDxCIndex);
            float inverseDxCLerp = 1.0 - dxCLerp;

            if (r == topDxRIndex && c == leftDxCIndex) {
              // topLeft
              accumulator +=
                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
            }

            if (r == topDxRIndex && c == rightDxCIndex) {
              // topRight
              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
            }

            if (r == bottomDxRIndex && c == leftDxCIndex) {
              // bottomLeft
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
            }

            if (r == bottomDxRIndex && c == rightDxCIndex) {
              // bottomRight
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
      }
    };
  }
});
function resizeBilinearGrad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  const program = new ResizeBilinearBackpropProgram(dy.shape, images.shape, alignCorners);
  return backend2.runWebGLProgram(program, [dy], dy.dtype);
}
var resizeBilinearGradConfig3;
var init_ResizeBilinearGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinearGrad.js"() {
    init_dist();
    init_resize_bilinear_backprop_gpu();
    resizeBilinearGradConfig3 = {
      kernelName: ResizeBilinearGrad,
      backendName: "webgl",
      kernelFunc: resizeBilinearGrad2
    };
  }
});
var ResizeNearestNeighborProgram;
var init_resize_nearest_neighbor_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_gpu.js"() {
    ResizeNearestNeighborProgram = class {
      constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
        this.variableNames = ["A"];
        this.outputShape = [];
        const [batch, oldHeight, oldWidth, depth] = inputShape;
        this.outputShape = [batch, newHeight, newWidth, depth];
        const effectiveInSize = [
          alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
          alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
        ];
        const effectiveOutSize = [
          alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
          alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
        ];
        const roundBase = alignCorners ? "0.5" : "0.0";
        let sourceFracIndexRC;
        if (halfPixelCenters) {
          sourceFracIndexRC = `max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))`;
        } else {
          sourceFracIndexRC = `vec2(yRC) * effectiveInputOverOutputRatioRC`;
        }
        this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec2 inputShapeRC = vec2(${oldHeight}.0, ${oldWidth}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the coordinators of nearest neighbor point.
        ivec2 sourceNearestRC = ivec2(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));
        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);

        setOutput(newValue);
      }
    `;
      }
    };
  }
});
var ResizeNearestNeighborPackedProgram;
var init_resize_nearest_neighbor_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_packed_gpu.js"() {
    ResizeNearestNeighborPackedProgram = class {
      constructor(inputShape, newHeight, newWidth, alignCorners, halfPixelCenters) {
        this.variableNames = ["A"];
        this.packedInputs = true;
        this.packedOutput = true;
        this.outputShape = [];
        const [batch, oldHeight, oldWidth, depth] = inputShape;
        this.outputShape = [batch, newHeight, newWidth, depth];
        const effectiveInSize = [
          alignCorners && newHeight > 1 ? oldHeight - 1 : oldHeight,
          alignCorners && newWidth > 1 ? oldWidth - 1 : oldWidth
        ];
        const effectiveOutSize = [
          alignCorners && newHeight > 1 ? newHeight - 1 : newHeight,
          alignCorners && newWidth > 1 ? newWidth - 1 : newWidth
        ];
        const roundBase = alignCorners ? "0.5" : "0.0";
        let sourceFracIndexRC;
        if (halfPixelCenters) {
          sourceFracIndexRC = `max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))`;
        } else {
          sourceFracIndexRC = `vec3(yRC) * effectiveInputOverOutputRatioRC`;
        }
        this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${effectiveInSize[0] / effectiveOutSize[0]},
          ${effectiveInSize[1] / effectiveOutSize[1]},
          ${effectiveInSize[1] / effectiveOutSize[1]});
      const vec3 inputShapeRC = vec3(${oldHeight}.0, ${oldWidth}.0,
                                     ${oldWidth}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${sourceFracIndexRC};

        // Compute the coordinators of nearest neighbor point.
        ivec3 sourceNearestRC = ivec3(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${roundBase})));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${depth - 1};
        bool hasNextRow = coords.z < ${newWidth - 1};

        vec4 newValue = vec4(
          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),
          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);

        setOutput(newValue);
      }
    `;
      }
    };
  }
});
function resizeNearestNeighbor3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images } = inputs;
  const { alignCorners, halfPixelCenters, size } = attrs;
  const [newHeight, newWidth] = size;
  const program = env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeNearestNeighborPackedProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters) : new ResizeNearestNeighborProgram(images.shape, newHeight, newWidth, alignCorners, halfPixelCenters);
  return backend2.runWebGLProgram(program, [images], images.dtype);
}
var resizeNearestNeighborConfig2;
var init_ResizeNearestNeighbor2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighbor.js"() {
    init_dist();
    init_resize_nearest_neighbor_gpu();
    init_resize_nearest_neighbor_packed_gpu();
    resizeNearestNeighborConfig2 = {
      kernelName: ResizeNearestNeighbor,
      backendName: "webgl",
      kernelFunc: resizeNearestNeighbor3
    };
  }
});
var ResizeNearestNeigborBackpropProgram;
var init_resize_nearest_neighbor_backprop_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_backprop_gpu.js"() {
    ResizeNearestNeigborBackpropProgram = class {
      constructor(dyShape, inputShape, alignCorners) {
        this.variableNames = ["dy"];
        this.outputShape = [];
        this.outputShape = inputShape;
        const [, xHeight, xWidth] = inputShape;
        const [, yHeight, yWidth] = dyShape;
        const effectiveXSize = [
          alignCorners && yHeight > 1 ? xHeight - 1 : xHeight,
          alignCorners && yWidth > 1 ? xWidth - 1 : xWidth
        ];
        const effectiveYSize = [
          alignCorners && yHeight > 1 ? yHeight - 1 : yHeight,
          alignCorners && yWidth > 1 ? yWidth - 1 : yWidth
        ];
        const heightScale = effectiveXSize[0] / effectiveYSize[0];
        const widthScale = effectiveXSize[1] / effectiveYSize[1];
        const invHeightScale = 1 / heightScale;
        const invWidthScale = 1 / widthScale;
        const winHeight = Math.ceil(invHeightScale) * 2 + 2;
        const winWidth = Math.ceil(invWidthScale) * 2 + 2;
        this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${heightScale});
        const float widthScale = float(${widthScale});

        const float invHeightScale = float(${invHeightScale});
        const float invWidthScale = float(${invWidthScale});

        const int winHeight = int(${winHeight});
        const int winWidth = int(${winWidth});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(floor(startRLerp - float(winHeight / 2)));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(floor(startCLerp - float(winWidth / 2)));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${yHeight}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${yWidth}) {
              continue;
            }

            float sourceFracRow =
              float(${effectiveXSize[0]}) *
                (float(dyR) / float(${effectiveYSize[0]}));

            float sourceFracCol =
                float(${effectiveXSize[1]}) *
                  (float(dyC) / float(${effectiveYSize[1]}));

            int sourceNearestRow = int(min(
                float(int(${xHeight}) - 1),
                ${alignCorners} ? float(round(sourceFracRow)) :
                                  float(floor(sourceFracRow))));

            int sourceNearestCol = int(min(
                float(int(${xWidth}) - 1),
                ${alignCorners} ? float(round(sourceFracCol)) :
                                  float(floor(sourceFracCol))));

            if (r == sourceNearestRow && c == sourceNearestCol) {
              accumulator += getDy(b, dyR, dyC, d);
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
      }
    };
  }
});
function resizeNearestNeighborGrad2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { images, dy } = inputs;
  const { alignCorners } = attrs;
  const program = new ResizeNearestNeigborBackpropProgram(dy.shape, images.shape, alignCorners);
  return backend2.runWebGLProgram(program, [dy], dy.dtype);
}
var resizeNearestNeighborGradConfig3;
var init_ResizeNearestNeighborGrad2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighborGrad.js"() {
    init_dist();
    init_resize_nearest_neighbor_backprop_gpu();
    resizeNearestNeighborGradConfig3 = {
      kernelName: ResizeNearestNeighborGrad,
      backendName: "webgl",
      kernelFunc: resizeNearestNeighborGrad2
    };
  }
});
var ReverseProgram;
var init_reverse_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/reverse_gpu.js"() {
    init_shader_compiler();
    ReverseProgram = class {
      constructor(xShape, axis) {
        this.variableNames = ["x"];
        const rank = xShape.length;
        if (rank > 4) {
          throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);
        }
        this.outputShape = xShape;
        if (rank === 1) {
          this.userCode = `
        void main() {
          int coord = getOutputCoords();
          setOutput(getX(${xShape[0]} - coord - 1));
        }
      `;
          return;
        }
        const getInCoord = (i) => {
          if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
            return `${xShape[i]} - coords[${i}] - 1`;
          }
          return `coords[${i}]`;
        };
        const inCoords = xShape.map((_, i) => getInCoord(i)).join(",");
        const type = getCoordsDataType(rank);
        this.userCode = `
      void main() {
        ${type} coords = getOutputCoords();
        setOutput(getX(${inCoords}));
      }
    `;
      }
    };
  }
});
var ReversePackedProgram;
var init_reverse_packed_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/reverse_packed_gpu.js"() {
    init_packing_util();
    init_shader_compiler();
    ReversePackedProgram = class {
      constructor(xShape, axis) {
        this.variableNames = ["x"];
        this.packedInputs = true;
        this.packedOutput = true;
        const rank = xShape.length;
        if (rank > 4) {
          throw new Error(`WebGL backend: Reverse of rank-${rank} tensor is not yet supported`);
        }
        this.outputShape = xShape;
        const channels = getChannels("rc", rank);
        const nextColumn = `${channels[rank - 1]} + 1 < ${this.outputShape[rank - 1]}`;
        const nextRow = `${channels[rank - 2]} + 1 < ${this.outputShape[rank - 2]}`;
        const type = getCoordsDataType(rank);
        if (rank === 1) {
          this.userCode = `
        void main(){
          int rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = getChannel(getX(${xShape[0]} - rc - 1),
            ${xShape[0]} - rc - 1);
          if(${nextColumn}){
              result.g = getChannel(getX(${xShape[0]} - (rc  + 1) - 1),
                ${xShape[0]} - (rc  + 1) - 1);
          }
          setOutput(result);
        }
      `;
        } else {
          this.userCode = `
        void main() {
          ${type} rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = ${getR(channels.slice())};
          if(${nextColumn}){
            result.g = ${getG(channels.slice())};
          }
          if(${nextRow}) {
            result.b = ${getB(channels.slice())};
            if(${nextColumn}) {
              result.a = ${getA(channels.slice())};
            }
          }
          setOutput(result);
        }
    `;
        }
        function getR(channels2) {
          return getChannel(channels2);
        }
        function getG(channels2) {
          channels2[rank - 1] = "(" + channels2[rank - 1] + ` + 1)`;
          return getChannel(channels2);
        }
        function getB(channels2) {
          channels2[rank - 2] = "(" + channels2[rank - 2] + ` + 1)`;
          return getChannel(channels2);
        }
        function getA(channels2) {
          channels2[rank - 1] = "(" + channels2[rank - 1] + ` + 1)`;
          channels2[rank - 2] = "(" + channels2[rank - 2] + ` + 1)`;
          return getChannel(channels2);
        }
        function getChannel(channels2) {
          const inCoordsArray = xShape.map((_, i) => getInCoord(i, channels2));
          const inCoords = inCoordsArray.join(",");
          const innerDims = inCoordsArray.slice(-2).join(",");
          return `getChannel(getX(${inCoords}), vec2(${innerDims}))`;
        }
        function getInCoord(i, channels1) {
          if (axis.indexOf(i) !== -1 && xShape[i] !== 1) {
            return `${xShape[i]} - ${channels1[i]} - 1`;
          } else {
            return `${channels1[i]}`;
          }
        }
      }
    };
  }
});
function reverse3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { dims } = attrs;
  const xRank = x.shape.length;
  const $dims = util_exports.parseAxisParam(dims, x.shape);
  if (xRank === 0) {
    return identity22({ inputs: { x }, backend: backend2 });
  }
  const program = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new ReversePackedProgram(x.shape, $dims) : new ReverseProgram(x.shape, $dims);
  return backend2.runWebGLProgram(program, [x], x.dtype);
}
var reverseConfig2;
var init_Reverse2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Reverse.js"() {
    init_dist();
    init_reverse_gpu();
    init_reverse_packed_gpu();
    init_Identity2();
    reverseConfig2 = {
      kernelName: Reverse,
      backendName: "webgl",
      kernelFunc: reverse3
    };
  }
});
var RotateProgram;
var init_rotate_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/rotate_gpu.js"() {
    RotateProgram = class {
      constructor(imageShape, fillValue) {
        this.variableNames = ["Image"];
        this.outputShape = [];
        this.customUniforms = [{ name: "params", type: "vec4" }];
        const imageHeight = imageShape[1];
        const imageWidth = imageShape[2];
        this.outputShape = imageShape;
        let fillSnippet = "";
        if (typeof fillValue === "number") {
          fillSnippet = `float outputValue = ${fillValue.toFixed(2)};`;
        } else {
          fillSnippet = `
        vec3 fill = vec3(${fillValue.join(",")});
        float outputValue = fill[coords[3]];`;
        }
        this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];
          int y = coords[1];
          float coordXFloat = (float(x) - params[0]) * params[3] -
            (float(y) - params[1]) * params[2];
          float coordYFloat = (float(x) - params[0]) * params[2] +
            (float(y) - params[1]) * params[3];
          int coordX = int(round(coordXFloat + params[0]));
          int coordY = int(round(coordYFloat + params[1]));
          ${fillSnippet}
          if(coordX >= 0 && coordX < ${imageWidth} && coordY >= 0 && coordY < ${imageHeight}) {
            outputValue = getImage(coords[0], coordY, coordX, coords[3]);
          }
          setOutput(outputValue);
        }
    `;
      }
    };
  }
});
var rotateWithOffsetConfig2;
var init_RotateWithOffset2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/RotateWithOffset.js"() {
    init_dist();
    init_dist();
    init_rotate_gpu();
    rotateWithOffsetConfig2 = {
      kernelName: RotateWithOffset,
      backendName: "webgl",
      kernelFunc: ({ inputs, attrs, backend: backend2 }) => {
        const { image: image2 } = inputs;
        const { radians, fillValue, center } = attrs;
        const webglBackend = backend2;
        const program = new RotateProgram(image2.shape, fillValue);
        const [centerX, centerY] = backend_util_exports.getImageCenter(center, image2.shape[1], image2.shape[2]);
        const customValues = [[centerX, centerY, Math.sin(radians), Math.cos(radians)]];
        const output = webglBackend.runWebGLProgram(program, [image2], image2.dtype, customValues);
        return output;
      }
    };
  }
});
var ROUND;
var round4;
var roundConfig2;
var init_Round2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Round.js"() {
    init_dist();
    init_kernel_funcs_utils();
    ROUND = `
  // OpenGL ES does not support round function.
  // The algorithm is based on banker's rounding.
  float base = floor(x);
  if ((x - base) < 0.5) {
    return floor(x);
  } else if ((x - base) > 0.5) {
    return ceil(x);
  } else {
    if (mod(base, 2.0) == 0.0) {
      return base;
    } else {
      return base + 1.0;
    }
  }
`;
    round4 = unaryKernelFunc2({ opSnippet: ROUND });
    roundConfig2 = {
      kernelName: Round,
      backendName: "webgl",
      kernelFunc: round4
    };
  }
});
var RSQRT;
var rsqrt3;
var rsqrtConfig2;
var init_Rsqrt2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Rsqrt.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    RSQRT = `return inversesqrt(x);`;
    rsqrt3 = unaryKernelFunc2({ opSnippet: RSQRT, cpuKernelImpl: rsqrtImplCPU });
    rsqrtConfig2 = {
      kernelName: Rsqrt,
      backendName: "webgl",
      kernelFunc: rsqrt3
    };
  }
});
var ScatterProgram;
var init_scatter_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/scatter_gpu.js"() {
    init_shader_compiler();
    ScatterProgram = class {
      constructor(updateSize, sliceDim, indicesRank, updatesRank, strides, shape, summingDupeIndex = true) {
        this.variableNames = ["updates", "indices", "defaultValue"];
        this.outputShape = shape;
        const stridesType = getCoordsDataType(strides.length);
        const dtype = getCoordsDataType(shape.length);
        let indicesString = "";
        if (indicesRank === 1) {
          indicesString = "i";
        } else if (indicesRank === 2) {
          indicesString = "i, j";
        }
        const indicesSnippet = `getIndices(${indicesString})`;
        let updatesString = "";
        if (updatesRank === 1) {
          updatesString = "i";
        } else if (updatesRank === 2) {
          updatesString = "i, coords[1]";
        }
        const updatesSnippet = `getUpdates(${updatesString})`;
        const strideString = sliceDim > 1 ? "strides[j]" : "strides";
        this.userCode = `
        ${stridesType} strides = ${stridesType}(${strides});

        void main() {
          ${dtype} coords = getOutputCoords();
          float sum = 0.0;
          bool found = false;
          for (int i = 0; i < ${updateSize}; i++) {
            int flattenedIndex = 0;
            for (int j = 0; j < ${sliceDim}; j++) {
              int index = round(${indicesSnippet});
              flattenedIndex += index * ${strideString};
            }
            if (flattenedIndex == coords[0]) {
              sum += ${updatesSnippet};
              found = true;
            }
          }
          setOutput(mix(getDefaultValue(), sum, float(found)));
        }
      `;
      }
    };
  }
});
function scatterNd2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { indices, updates } = inputs;
  const { shape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(updates, indices, shape);
  const flattenShape = [outputSize / sliceSize, sliceSize];
  if (outputSize === 0) {
    return backend2.makeTensorInfo(shape, indices.dtype);
  }
  const flattenIndices = reshape3({ inputs: { x: indices }, backend: backend2, attrs: { shape: [numUpdates, sliceRank] } });
  const flattenX = reshape3({ inputs: { x: updates }, backend: backend2, attrs: { shape: [numUpdates, sliceSize] } });
  const defaultValue = backend2.makeTensorInfo([], "float32", new Float32Array([0]));
  const program = new ScatterProgram(numUpdates, sliceRank, flattenIndices.shape.length, flattenX.shape.length, strides, flattenShape);
  const res = backend2.runWebGLProgram(program, [flattenX, flattenIndices, defaultValue], flattenX.dtype);
  const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape } });
  backend2.disposeIntermediateTensorInfo(flattenIndices);
  backend2.disposeIntermediateTensorInfo(flattenX);
  backend2.disposeIntermediateTensorInfo(res);
  backend2.disposeIntermediateTensorInfo(defaultValue);
  return reshaped;
}
var scatterNdConfig2;
var init_ScatterNd2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/ScatterNd.js"() {
    init_dist();
    init_scatter_gpu();
    init_Reshape2();
    scatterNdConfig2 = {
      kernelName: ScatterNd,
      backendName: "webgl",
      kernelFunc: scatterNd2
    };
  }
});
var SearchSortedProgram;
var init_search_sorted_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/search_sorted_gpu.js"() {
    init_dist();
    SearchSortedProgram = class {
      constructor(batchSize, numInputs, numValues, side) {
        this.variableNames = ["sortedSequence", "values"];
        this.customUniforms = [{ name: "numInputs", type: "int" }];
        this.outputShape = [batchSize, numValues];
        const webGL2LoopHead = "while (left < right) {";
        const webGL1LoopHead = `for (int i = 0; i < ${Math.ceil(Math.log2(numInputs + 1))}; ++i) { if (left >= right) break;`;
        const loopHead = env().getNumber("WEBGL_VERSION") === 2 ? webGL2LoopHead : webGL1LoopHead;
        const boundComparator = side === "left" ? "<" : "<=";
        this.userCode = `
       int findBound(int batch, float value) {
         int left = 0;
         int right = numInputs;
         int mid;
         ${loopHead}
           mid = (left + right) / 2;
           if (getSortedSequence(batch, mid) ${boundComparator} value) {
             left = mid + 1;
           } else {
             right = mid;
           }
         }
         return right;
       }

       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int valueIndex = coords[1];

         float value = getValues(batch, valueIndex);

         setOutput(float(findBound(batch, value)));
       }
     `;
      }
    };
  }
});
function searchSorted2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { sortedSequence, values } = inputs;
  const { side } = attrs;
  const program = new SearchSortedProgram(sortedSequence.shape[0], sortedSequence.shape[1], values.shape[1], side);
  const customValues = [[sortedSequence.shape[1]]];
  return backend2.runWebGLProgram(program, [sortedSequence, values], "int32", customValues);
}
var searchSortedConfig2;
var init_SearchSorted2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SearchSorted.js"() {
    init_dist();
    init_search_sorted_gpu();
    searchSortedConfig2 = {
      kernelName: SearchSorted,
      backendName: "webgl",
      kernelFunc: searchSorted2
    };
  }
});
var SelectProgram;
var init_select_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/select_gpu.js"() {
    init_shader_compiler();
    SelectProgram = class {
      constructor(cRank, shape, rank) {
        this.variableNames = ["c", "a", "b"];
        this.outputShape = shape;
        let cCoords;
        let abCoords;
        if (rank > 4) {
          throw Error(`Where for rank ${rank} is not yet supported`);
        }
        if (rank === 1) {
          abCoords = `resRC`;
          cCoords = `resRC`;
        } else {
          const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"];
          const cCoordVars = [];
          const abCoordVars = [];
          for (let i = 0; i < shape.length; i++) {
            abCoordVars.push(`${currentCoords[i]}`);
            if (i < cRank) {
              cCoordVars.push(`${currentCoords[i]}`);
            }
          }
          cCoords = cCoordVars.join();
          abCoords = abCoordVars.join();
        }
        const dtype = getCoordsDataType(rank);
        this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        float cVal = getC(${cCoords});
        if (cVal >= 1.0) {
          setOutput(getA(${abCoords}));
        } else {
          setOutput(getB(${abCoords}));
        }
      }
    `;
      }
    };
  }
});
function select3(args) {
  const { inputs, backend: backend2 } = args;
  const { condition, t, e } = inputs;
  const program = new SelectProgram(condition.shape.length, t.shape, t.shape.length);
  return backend2.runWebGLProgram(program, [condition, t, e], upcastType(t.dtype, e.dtype));
}
var selectConfig2;
var init_Select2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Select.js"() {
    init_dist();
    init_select_gpu();
    selectConfig2 = {
      kernelName: Select,
      backendName: "webgl",
      kernelFunc: select3
    };
  }
});
var SELU;
var selu3;
var seluConfig2;
var init_Selu2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Selu.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SELU = `
  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
  // see: https://arxiv.org/abs/1706.02515
  float scaleAlpha = ${backend_util_exports.SELU_SCALEALPHA};
  float scale = ${backend_util_exports.SELU_SCALE};
  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);
`;
    selu3 = unaryKernelFunc2({ opSnippet: SELU });
    seluConfig2 = {
      kernelName: Selu,
      backendName: "webgl",
      kernelFunc: selu3
    };
  }
});
var SIGMOID3;
var SIGMOID_PACKED;
var sigmoid3;
var sigmoidConfig2;
var init_Sigmoid2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sigmoid.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    SIGMOID3 = CHECK_NAN_SNIPPET_UNARY + `
  return 1.0 / (1.0 + exp(-1.0 * x));
`;
    SIGMOID_PACKED = `
  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
    sigmoid3 = unaryKernelFunc2({
      opSnippet: SIGMOID3,
      packedOpSnippet: SIGMOID_PACKED,
      cpuKernelImpl: sigmoidImplCPU
    });
    sigmoidConfig2 = {
      kernelName: Sigmoid,
      backendName: "webgl",
      kernelFunc: sigmoid3
    };
  }
});
var SIGN;
var sign3;
var signConfig2;
var init_Sign2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sign.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SIGN = `
  if (isnan(x)) { return 0.0; }
  return sign(x);
`;
    sign3 = unaryKernelFunc2({ opSnippet: SIGN });
    signConfig2 = {
      kernelName: Sign,
      backendName: "webgl",
      kernelFunc: sign3
    };
  }
});
var SIN;
var sin3;
var sinConfig2;
var init_Sin2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sin.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SIN = CHECK_NAN_SNIPPET_UNARY + `
  return sin(x);
`;
    sin3 = unaryKernelFunc2({ opSnippet: SIN });
    sinConfig2 = {
      kernelName: Sin,
      backendName: "webgl",
      kernelFunc: sin3
    };
  }
});
var SINH;
var sinh3;
var sinhConfig2;
var init_Sinh2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sinh.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SINH = `
  float e2x = exp(x);
  return (e2x - 1.0 / e2x) / 2.0;
`;
    sinh3 = unaryKernelFunc2({ opSnippet: SINH });
    sinhConfig2 = {
      kernelName: Sinh,
      backendName: "webgl",
      kernelFunc: sinh3
    };
  }
});
var SOFTPLUS;
var softplus3;
var softplusConfig2;
var init_Softplus2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Softplus.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SOFTPLUS = `
  float epsilon = 1.1920928955078125e-7;
  float threshold = log(epsilon) + 2.0;

  bool too_large = x > -threshold;
  bool too_small = x < threshold;

  float result;
  float exp_x = exp(x);

  if (too_large){
    result = x;
  }
  else if (too_small){
    result = exp_x;
  }
  else{
    result = log(exp_x + 1.0);
  }
  return result;
`;
    softplus3 = unaryKernelFunc2({ opSnippet: SOFTPLUS });
    softplusConfig2 = {
      kernelName: Softplus,
      backendName: "webgl",
      kernelFunc: softplus3
    };
  }
});
var spaceToBatchND3;
var spaceToBatchNDConfig2;
var init_SpaceToBatchND2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SpaceToBatchND.js"() {
    init_dist();
    init_PadV22();
    init_Reshape2();
    init_Transpose2();
    spaceToBatchND3 = (args) => {
      const { inputs, backend: backend2, attrs } = args;
      const { x } = inputs;
      const { blockShape, paddings } = attrs;
      util_exports.assert(x.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
      const prod4 = blockShape.reduce((a, b) => a * b);
      const completePaddings = [[0, 0]];
      completePaddings.push(...paddings);
      for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {
        completePaddings.push([0, 0]);
      }
      const toDispose = [];
      const paddedX = padV22({
        inputs: { x },
        backend: backend2,
        attrs: { paddings: completePaddings, constantValue: 0 }
      });
      const reshapedPaddedShape = backend_util_exports.getReshaped(paddedX.shape, blockShape, prod4, false);
      const permutedReshapedPaddedPermutation = backend_util_exports.getPermuted(reshapedPaddedShape.length, blockShape.length, false);
      const flattenShape = backend_util_exports.getReshapedPermuted(paddedX.shape, blockShape, prod4, false);
      const reshapedPaddedX = reshape3({ inputs: { x: paddedX }, backend: backend2, attrs: { shape: reshapedPaddedShape } });
      const paddedXT = transpose3({
        inputs: { x: reshapedPaddedX },
        backend: backend2,
        attrs: { perm: permutedReshapedPaddedPermutation }
      });
      const result = reshape3({ inputs: { x: paddedXT }, backend: backend2, attrs: { shape: flattenShape } });
      toDispose.push(paddedX);
      toDispose.push(reshapedPaddedX);
      toDispose.push(paddedXT);
      toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
      return result;
    };
    spaceToBatchNDConfig2 = {
      kernelName: SpaceToBatchND,
      backendName: "webgl",
      kernelFunc: spaceToBatchND3
    };
  }
});
function sparseFillEmptyRows2(args) {
  const { inputs, backend: backend2 } = args;
  const { indices, values, denseShape, defaultValue } = inputs;
  if (denseShape.shape.length !== 1) {
    throw new Error(`Dense shape must be a vector, saw:
         ${denseShape.shape}`);
  }
  if (indices.shape.length !== 2) {
    throw new Error(`Indices must be a matrix, saw:
         ${indices.shape}`);
  }
  if (values.shape.length !== 1) {
    throw new Error(`Values must be a vector, saw:
         ${values.shape}`);
  }
  if (defaultValue.shape.length !== 0) {
    throw new Error(`Default value must be a scalar, saw:
        ${defaultValue.shape}`);
  }
  const $indices = backend2.readSync(indices.dataId);
  const $values = backend2.readSync(values.dataId);
  const $denseShape = backend2.readSync(denseShape.dataId);
  const $defaultValue = backend2.readSync(defaultValue.dataId)[0];
  const [outputIndices, outputIndicesShape, outputValues, emptyRowIndicator, reverseIndexMap] = sparseFillEmptyRowsImplCPU($indices, indices.shape, indices.dtype, $values, values.dtype, $denseShape, $defaultValue);
  return [
    backend2.makeTensorInfo(outputIndicesShape, indices.dtype, outputIndices),
    backend2.makeTensorInfo([outputIndicesShape[0]], values.dtype, outputValues),
    backend2.makeTensorInfo([emptyRowIndicator.length], "bool", new Uint8Array(emptyRowIndicator.map((value) => Number(value)))),
    backend2.makeTensorInfo([reverseIndexMap.length], indices.dtype, new Int32Array(reverseIndexMap))
  ];
}
var sparseFillEmptyRowsConfig2;
var init_SparseFillEmptyRows2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseFillEmptyRows.js"() {
    init_dist();
    init_shared2();
    sparseFillEmptyRowsConfig2 = {
      kernelName: SparseFillEmptyRows,
      backendName: "webgl",
      kernelFunc: sparseFillEmptyRows2
    };
  }
});
function sparseReshape2(args) {
  const { inputs, backend: backend2 } = args;
  const { inputIndices, inputShape, newShape } = inputs;
  if (inputIndices.shape.length !== 2) {
    throw new Error(`Input indices should be a matrix but received shape ${inputIndices.shape}`);
  }
  if (inputShape.shape.length !== 1) {
    throw new Error(`Input shape should be a vector but received shape ${inputShape.shape}`);
  }
  if (newShape.shape.length !== 1) {
    throw new Error(`Target shape should be a vector but received shape ${newShape.shape}`);
  }
  const $inputShape = Array.from(backend2.readSync(inputShape.dataId));
  const $inputIndices = backend2.readSync(inputIndices.dataId);
  const targetShape = Array.from(backend2.readSync(newShape.dataId));
  const [newIndices, indicesShape, outputShape] = sparseReshapeImplCPU($inputIndices, inputIndices.shape, inputIndices.dtype, $inputShape, targetShape);
  return [
    backend2.makeTensorInfo(indicesShape, inputIndices.dtype, newIndices),
    backend2.makeTensorInfo([outputShape.length], newShape.dtype, new Int32Array(outputShape))
  ];
}
var sparseReshapeConfig2;
var init_SparseReshape2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseReshape.js"() {
    init_dist();
    init_shared2();
    sparseReshapeConfig2 = {
      kernelName: SparseReshape,
      backendName: "webgl",
      kernelFunc: sparseReshape2
    };
  }
});
function sparseSegmentMean2(args) {
  const { inputs, backend: backend2 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
              ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
              ${segmentIds.shape}`);
  }
  const $data = backend2.readSync(data.dataId);
  const $indices = backend2.readSync(indices.dataId);
  const $segmentIds = backend2.readSync(segmentIds.dataId);
  const [outputData, outputDataShape] = sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds, true);
  return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentMeanConfig2;
var init_SparseSegmentMean2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentMean.js"() {
    init_dist();
    init_shared2();
    sparseSegmentMeanConfig2 = {
      kernelName: SparseSegmentMean,
      backendName: "webgl",
      kernelFunc: sparseSegmentMean2
    };
  }
});
function sparseSegmentSum2(args) {
  const { inputs, backend: backend2 } = args;
  const { data, indices, segmentIds } = inputs;
  if (data.shape.length < 1) {
    throw new Error(`Data should be at least 1 dimensional but received scalar`);
  }
  if (indices.shape.length !== 1) {
    throw new Error(`Indices should be a vector but received shape
             ${indices.shape}`);
  }
  if (segmentIds.shape.length !== 1) {
    throw new Error(`Segment ids should be a vector but received shape
             ${segmentIds.shape}`);
  }
  const $data = backend2.readSync(data.dataId);
  const $indices = backend2.readSync(indices.dataId);
  const $segmentIds = backend2.readSync(segmentIds.dataId);
  const [outputData, outputDataShape] = sparseSegmentReductionImplCPU($data, data.shape, data.dtype, $indices, $segmentIds);
  return backend2.makeTensorInfo(outputDataShape, data.dtype, outputData);
}
var sparseSegmentSumConfig2;
var init_SparseSegmentSum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentSum.js"() {
    init_dist();
    init_shared2();
    sparseSegmentSumConfig2 = {
      kernelName: SparseSegmentSum,
      backendName: "webgl",
      kernelFunc: sparseSegmentSum2
    };
  }
});
function sparseToDense2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { sparseIndices, sparseValues, defaultValue } = inputs;
  const { outputShape } = attrs;
  const { sliceRank, numUpdates, sliceSize, strides, outputSize } = backend_util_exports.calculateShapes(sparseValues, sparseIndices, outputShape);
  const sumDupeIndices = false;
  if (sparseValues.dtype === "string") {
    const indicesBuf = backend2.bufferSync(sparseIndices);
    const updatesBuf = backend2.bufferSync(sparseValues);
    const $defaultValue = util_exports.decodeString(backend2.readSync(defaultValue.dataId)[0]);
    const outBuf = scatterImplCPU(indicesBuf, updatesBuf, outputShape, outputSize, sliceSize, numUpdates, sliceRank, strides, $defaultValue, sumDupeIndices);
    return backend2.makeTensorInfo(outputShape, outBuf.dtype, outBuf.values);
  }
  const program = new ScatterProgram(numUpdates, sliceRank, sparseIndices.shape.length, sparseValues.shape.length, strides, [outputSize, 1], sumDupeIndices);
  const res = backend2.runWebGLProgram(program, [sparseValues, sparseIndices, defaultValue], sparseValues.dtype);
  const reshaped = reshape3({ inputs: { x: res }, backend: backend2, attrs: { shape: outputShape } });
  backend2.disposeIntermediateTensorInfo(res);
  return reshaped;
}
var sparseToDenseConfig2;
var init_SparseToDense2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SparseToDense.js"() {
    init_dist();
    init_shared2();
    init_scatter_gpu();
    init_Reshape2();
    sparseToDenseConfig2 = {
      kernelName: SparseToDense,
      backendName: "webgl",
      kernelFunc: sparseToDense2
    };
  }
});
function splitV2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { numOrSizeSplits, axis } = attrs;
  const $axis = util_exports.parseAxisParam(axis, x.shape)[0];
  const splitSizes = backend_util_exports.prepareSplitSize(x, numOrSizeSplits, $axis);
  const xRank = x.shape.length;
  const begin = new Array(xRank).fill(0);
  const size = x.shape.slice();
  return splitSizes.map((s) => {
    const sliceSize = [...size];
    sliceSize[$axis] = s;
    const sliceT = slice3({ inputs: { x }, backend: backend2, attrs: { begin, size: sliceSize } });
    begin[$axis] += s;
    return sliceT;
  });
}
var splitVConfig2;
var init_SplitV2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SplitV.js"() {
    init_dist();
    init_Slice2();
    splitVConfig2 = {
      kernelName: SplitV,
      backendName: "webgl",
      kernelFunc: splitV2
    };
  }
});
var SQRT;
var sqrt3;
var sqrtConfig2;
var init_Sqrt2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sqrt.js"() {
    init_dist();
    init_kernel_funcs_utils();
    init_shared2();
    SQRT = `return sqrt(x);`;
    sqrt3 = unaryKernelFunc2({ opSnippet: SQRT, packedOpSnippet: SQRT, cpuKernelImpl: sqrtImplCPU });
    sqrtConfig2 = {
      kernelName: Sqrt,
      backendName: "webgl",
      kernelFunc: sqrt3
    };
  }
});
var SQUARE;
var square3;
var squareConfig2;
var init_Square2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Square.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SQUARE = `return x * x;`;
    square3 = unaryKernelFunc2({ opSnippet: SQUARE });
    squareConfig2 = {
      kernelName: Square,
      backendName: "webgl",
      kernelFunc: square3
    };
  }
});
var SQUARED_DIFFERENCE;
var squaredDifference3;
var squaredDifferenceConfig2;
var init_SquaredDifference2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/SquaredDifference.js"() {
    init_dist();
    init_kernel_funcs_utils();
    SQUARED_DIFFERENCE = "return (a - b) * (a - b);";
    squaredDifference3 = binaryKernelFunc2({ opSnippet: SQUARED_DIFFERENCE, packedOpSnippet: SQUARED_DIFFERENCE });
    squaredDifferenceConfig2 = {
      kernelName: SquaredDifference,
      backendName: "webgl",
      kernelFunc: squaredDifference3
    };
  }
});
function step3({ inputs, attrs, backend: backend2 }) {
  const { x } = inputs;
  const opSnippet = CHECK_NAN_SNIPPET + `
    return x > 0.0 ? 1.0 : float(${attrs.alpha});
  `;
  const program = new UnaryOpProgram(x.shape, opSnippet);
  return backend2.runWebGLProgram(program, [x], x.dtype);
}
var stepConfig2;
var init_Step2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Step.js"() {
    init_dist();
    init_unaryop_gpu();
    stepConfig2 = {
      kernelName: Step,
      backendName: "webgl",
      kernelFunc: step3
    };
  }
});
var StridedSliceProgram;
var init_strided_slice_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/strided_slice_gpu.js"() {
    init_shader_compiler();
    StridedSliceProgram = class {
      constructor(begin, strides, size) {
        this.variableNames = ["x"];
        this.outputShape = size;
        const rank = size.length;
        const inputDtype = getCoordsDataType(size.length);
        const dtype = getCoordsDataType(size.length);
        let newCoords = "";
        if (rank === 1) {
          newCoords = "coords * strides + begin";
        } else {
          let outputAxis = 0;
          newCoords = size.map((_, i) => {
            outputAxis++;
            return size.length === 1 ? `coords * strides[${i}] + begin[${i}]` : `coords[${outputAxis - 1}] * strides[${i}] + begin[${i}]`;
          }).join(",");
        }
        this.userCode = `
      ${inputDtype} begin = ${inputDtype}(${begin});
      ${inputDtype} strides = ${inputDtype}(${strides});

      void main() {
        ${dtype} coords = getOutputCoords();
        setOutput(getX(${newCoords}));
      }
    `;
      }
    };
  }
});
function stridedSlice3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask } = attrs;
  const { finalShapeSparse, finalShape, isIdentity, sliceDim0, isSimpleSlice, begin: $begin, end: $end, strides: $strides } = slice_util_exports.sliceInfo(x.shape, begin, end, strides, beginMask, endMask, ellipsisMask, newAxisMask, shrinkAxisMask);
  let result;
  if (isIdentity) {
    result = reshape3({ inputs: { x }, backend: backend2, attrs: { shape: finalShape } });
  } else if (sliceDim0 || isSimpleSlice) {
    util_exports.assert(x.shape.length >= 1, () => `Input must have rank at least 1, got: ${x.shape.length}`);
    const size = slice_util_exports.computeOutShape($begin, $end, $strides);
    const sliced = slice3({ inputs: { x }, backend: backend2, attrs: { begin: $begin, size } });
    result = reshape3({ inputs: { x: sliced }, backend: backend2, attrs: { shape: finalShape } });
    backend2.disposeIntermediateTensorInfo(sliced);
  } else {
    const shouldExecuteOnCPU = backend2.shouldExecuteOnCPU([x]);
    if (shouldExecuteOnCPU) {
      const values = backend2.readSync(x.dataId);
      const xBuf = buffer(x.shape, x.dtype, values);
      const resultValues = stridedSliceImplCPU(finalShapeSparse, xBuf, $strides, $begin);
      result = backend2.makeTensorInfo(finalShape, x.dtype, resultValues.values);
    } else {
      const program = new StridedSliceProgram($begin, $strides, finalShapeSparse);
      result = backend2.runWebGLProgram(program, [x], x.dtype);
    }
  }
  const resultReshaped = reshape3({ inputs: { x: result }, backend: backend2, attrs: { shape: finalShape } });
  backend2.disposeIntermediateTensorInfo(result);
  return resultReshaped;
}
var stridedSliceConfig2;
var init_StridedSlice2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StridedSlice.js"() {
    init_dist();
    init_shared2();
    init_strided_slice_gpu();
    init_Reshape2();
    init_Slice2();
    stridedSliceConfig2 = {
      kernelName: StridedSlice,
      backendName: "webgl",
      kernelFunc: stridedSlice3
    };
  }
});
function stringNGrams2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { separator, nGramWidths, leftPad, rightPad: rightPad2, padWidth, preserveShortSequences } = attrs;
  const { data, dataSplits } = inputs;
  const $data = backend2.readSync(data.dataId);
  const $dataSplits = backend2.readSync(dataSplits.dataId);
  const [nGrams, nGramsSplits] = stringNGramsImplCPU($data, $dataSplits, separator, nGramWidths, leftPad, rightPad2, padWidth, preserveShortSequences);
  return [
    backend2.makeTensorInfo([nGrams.length], "string", nGrams),
    backend2.makeTensorInfo(dataSplits.shape, "int32", nGramsSplits)
  ];
}
var stringNGramsConfig2;
var init_StringNGrams2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StringNGrams.js"() {
    init_dist();
    init_shared2();
    stringNGramsConfig2 = {
      kernelName: StringNGrams,
      backendName: "webgl",
      kernelFunc: stringNGrams2
    };
  }
});
function stringSplit2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { skipEmpty } = attrs;
  const { input: input2, delimiter } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (input2.shape.length !== 1) {
    throw new Error(`Input must be a vector, got shape: ${input2.shape}`);
  }
  if (delimiter.shape.length !== 0) {
    throw new Error(`Delimiter must be a scalar, got shape: ${delimiter.shape}`);
  }
  const $input = backend2.readSync(input2.dataId);
  const $delimiter = backend2.readSync(delimiter.dataId)[0];
  const [indices, values, shape] = stringSplitImplCPU($input, $delimiter, skipEmpty);
  const outputSize = values.length;
  return [
    backend2.makeTensorInfo([outputSize, 2], "int32", indices),
    backend2.makeTensorInfo([outputSize], "string", values),
    backend2.makeTensorInfo([2], "int32", new Int32Array(shape))
  ];
}
var stringSplitConfig2;
var init_StringSplit2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StringSplit.js"() {
    init_dist();
    init_shared2();
    stringSplitConfig2 = {
      kernelName: StringSplit,
      backendName: "webgl",
      kernelFunc: stringSplit2
    };
  }
});
function stringToHashBucketFast2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { numBuckets } = attrs;
  const { input: input2 } = inputs;
  if (input2.dtype !== "string") {
    throw new Error("Input must be of datatype string");
  }
  if (numBuckets <= 0) {
    throw new Error(`Number of buckets must be at least 1`);
  }
  const $input = backend2.readSync(input2.dataId);
  const output = stringToHashBucketFastImplCPU($input, numBuckets);
  return backend2.makeTensorInfo(input2.shape, "int32", output);
}
var stringToHashBucketFastConfig2;
var init_StringToHashBucketFast2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/StringToHashBucketFast.js"() {
    init_dist();
    init_shared2();
    stringToHashBucketFastConfig2 = {
      kernelName: StringToHashBucketFast,
      backendName: "webgl",
      kernelFunc: stringToHashBucketFast2
    };
  }
});
var TAN;
var tan3;
var tanConfig2;
var init_Tan2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Tan.js"() {
    init_dist();
    init_kernel_funcs_utils();
    TAN = `return tan(x);`;
    tan3 = unaryKernelFunc2({ opSnippet: TAN });
    tanConfig2 = {
      kernelName: Tan,
      backendName: "webgl",
      kernelFunc: tan3
    };
  }
});
var TANH;
var tanh4;
var tanhConfig2;
var init_Tanh2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Tanh.js"() {
    init_dist();
    init_kernel_funcs_utils();
    TANH = `
  float e2x = exp(-2.0 * abs(x));
  return sign(x) * (1.0 - e2x) / (1.0 + e2x);
`;
    tanh4 = unaryKernelFunc2({ opSnippet: TANH });
    tanhConfig2 = {
      kernelName: Tanh,
      backendName: "webgl",
      kernelFunc: tanh4
    };
  }
});
function getSourceCoords3(aShape) {
  const rank = aShape.length;
  if (rank > 5) {
    throw Error(`Tile for rank ${rank} is not yet supported`);
  }
  if (rank === 1) {
    return `imod(resRC, ${aShape[0]})`;
  }
  const currentCoords = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"];
  const sourceCoords = [];
  for (let i = 0; i < aShape.length; i++) {
    sourceCoords.push(`imod(${currentCoords[i]}, ${aShape[i]})`);
  }
  return sourceCoords.join();
}
var TileProgram;
var init_tile_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/tile_gpu.js"() {
    init_shader_compiler();
    TileProgram = class {
      constructor(aShape, reps) {
        this.variableNames = ["A"];
        const outputShape = new Array(aShape.length);
        for (let i = 0; i < outputShape.length; i++) {
          outputShape[i] = aShape[i] * reps[i];
        }
        this.outputShape = outputShape;
        this.rank = outputShape.length;
        const dtype = getCoordsDataType(this.rank);
        const sourceCoords = getSourceCoords3(aShape);
        this.userCode = `
      void main() {
        ${dtype} resRC = getOutputCoords();
        setOutput(getA(${sourceCoords}));
      }
    `;
      }
    };
  }
});
function tile4(params) {
  const { inputs, backend: backend2, attrs } = params;
  const { x } = inputs;
  const { reps } = attrs;
  if (x.dtype === "string" || x.shape.length > 5) {
    const data = backend2.readSync(x.dataId);
    const value = x.dtype === "string" ? data.map((d) => util_exports.decodeString(d)) : data;
    const buf = buffer(x.shape, x.dtype, value);
    const outBuf = tileImplCPU(buf, reps);
    return backend2.makeTensorInfo(outBuf.shape, outBuf.dtype, outBuf.values);
  }
  const program = new TileProgram(x.shape, reps);
  const output = backend2.runWebGLProgram(program, [x], x.dtype);
  return output;
}
var tileConfig2;
var init_Tile2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Tile.js"() {
    init_dist();
    init_shared2();
    init_tile_gpu();
    tileConfig2 = {
      kernelName: Tile,
      backendName: "webgl",
      kernelFunc: tile4
    };
  }
});
var SwapProgram;
var MergeProgram;
var init_top_k_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/top_k_gpu.js"() {
    SwapProgram = class {
      /**
       * @param shape desired output shape (can be larger than input shape, output
       *                                    will be padded with -Infinity)
       */
      constructor(shape) {
        this.variableNames = ["x", "indices"];
        this.customUniforms = [
          { name: "n", type: "int" },
          { name: "firstPass", type: "int" },
          { name: "negativeInf", type: "float" },
          { name: "dir", type: "int" },
          { name: "inc", type: "int" }
        ];
        this.outputShape = shape;
        this.userCode = `
       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // We compare elements pair-wise within a group of size 2 * inc.
         // The comparing rule for each group alternates between ascending
         // and descending. Within each group, we compare each pair at
         // positions i and i+inc. To decide whether an element at position i
         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
         // inc, it is in the first half of the group, we denote it as x0,
         // otherwise we denote it as x1.
         // For example, as shown in the Bitonic top K paper referenced above,
         // Figure5(a) shows that element[1] is in the
         // second half of the group when group size is 2, but it is in the
         // first half of the group when group size is 4.

         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;
         int i = isFirstInPair ? elemIdx : elemIdx - inc;

         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));
         float x0 = i0 < n ? getX(batch, i0) : negativeInf;
         float x1 = i1 < n ? getX(batch, i1) : negativeInf;

         // Denotes which direction indices are in (ascending or descending).
         bool reverse = imod(elemIdx, 2 * dir) >= dir;
         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
         if (reverse == isGreater) { // Elements in opposite order of direction
           int iTemp = i0;
           i0 = i1;
           i1 = iTemp;
         }
         if (isFirstInPair) {
            setOutput(float(i0));
         } else {
            setOutput(float(i1));
         }
       }
     `;
      }
    };
    MergeProgram = class {
      /**
       * @param shape desired output shape (must be half of the input size)
       */
      constructor(shape) {
        this.variableNames = ["x", "indices"];
        this.customUniforms = [
          { name: "n", type: "int" },
          { name: "firstPass", type: "int" },
          { name: "k", type: "int" }
        ];
        this.outputShape = shape;
        this.userCode = `
    void main() {
         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // The output size is half of the previous size.
         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),
         // we only need to output the indices at positions |, the indices at
         // positions _ can be thrown away, see Figure5(b) After Phase 2
         // (Merge phase) in the Bitonic Top K paper referenced above.
         // For example, the paper shows we only need to output the orange bars.
         // The output sequence should look like this | | | | | | | |.
         // Because the sequence is halved, to map the output index back
         // to the previous sequence to find the corresponding value,
         // we need to double the index. When we double the index,
         // we basically interpolate a position, so 2i looks like
         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position
         // of each 2k positions by - elemIdx % k. E.g. for output at
         // index 4,5,6,7, we want to get the corresponding element at
         // original index 8,9,10,11, for output at index 8,9,10,11,
         // we want to get the corresponding element at original index
         // 16,17,18,19, so on and so forth.

         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));
         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));

         float x0 = getX(batch, i0);
         float x1 = i1 < n ? getX(batch, i1) : x0;

         setOutput(x0 >= x1 ? float(i0) : float(i1));
       }
     `;
      }
    };
  }
});
function disposeIntermediateTensorInfoOrNull(backend2, tensorInfo) {
  if (tensorInfo !== null) {
    backend2.disposeIntermediateTensorInfo(tensorInfo);
  }
}
function roundUpToPow2(num) {
  let pow222 = 1;
  while (pow222 < num) {
    pow222 *= 2;
  }
  return pow222;
}
function topK2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x } = inputs;
  const { k, sorted } = attrs;
  const TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD");
  const TOPK_K_CPU_HANDOFF_THRESHOLD = env().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD");
  const xShape = x.shape;
  const lastDim = xShape[xShape.length - 1];
  if (backend2.shouldExecuteOnCPU([x]) || lastDim < TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD || k > TOPK_K_CPU_HANDOFF_THRESHOLD) {
    const xVals = backend2.readSync(x.dataId);
    const [allTopKVals, allTopKIndices] = topKImplCPU(xVals, xShape, x.dtype, k, sorted);
    return [
      backend2.makeTensorInfo(allTopKVals.shape, allTopKVals.dtype, allTopKVals.values),
      backend2.makeTensorInfo(allTopKIndices.shape, allTopKIndices.dtype, allTopKIndices.values)
    ];
  }
  if (k === 0) {
    xShape[xShape.length - 1] = 0;
    return [
      backend2.makeTensorInfo(xShape, x.dtype, []),
      backend2.makeTensorInfo(xShape, "int32", [])
    ];
  }
  if (lastDim === 1) {
    return [
      x,
      fill3({ attrs: { shape: xShape, dtype: "int32", value: 0 }, backend: backend2 })
    ];
  }
  const xtexData = backend2.texData.get(x.dataId);
  const xIsPacked = xtexData !== null && xtexData.isPacked;
  const xUnPacked = xIsPacked ? backend2.unpackTensor(x) : x;
  const xSize = util_exports.sizeFromShape(xShape);
  const batch = xSize / lastDim;
  const x2D = reshape3({ inputs: { x: xUnPacked }, attrs: { shape: [batch, lastDim] }, backend: backend2 });
  if (xIsPacked) {
    disposeIntermediateTensorInfoOrNull(backend2, xUnPacked);
  }
  const kPow2 = roundUpToPow2(k);
  const lastDimPow2 = roundUpToPow2(lastDim);
  let indices = null;
  const getInputs = () => indices === null ? [x2D, x2D] : [x2D, indices];
  const runSwap = (dir, inc, shape) => {
    const inputs2 = getInputs();
    const program = new SwapProgram(shape);
    const fistPass = indices === null ? 1 : 0;
    const customValues = [[lastDim], [fistPass], [Number.NEGATIVE_INFINITY], [dir], [inc]];
    const prevIndices2 = indices;
    indices = backend2.runWebGLProgram(program, inputs2, "int32", customValues);
    disposeIntermediateTensorInfoOrNull(backend2, prevIndices2);
  };
  for (let len4 = 1; len4 < kPow2; len4 *= 2) {
    const dir = len4 * 2;
    for (let inc = len4; inc >= 1; inc /= 2) {
      runSwap(dir, inc, [batch, lastDimPow2]);
    }
  }
  for (let indicesSize = lastDimPow2; indicesSize > kPow2; indicesSize /= 2) {
    const inputs2 = getInputs();
    const mergeProgram = new MergeProgram([batch, indicesSize / 2]);
    const firstPass = indices === null ? 1 : 0;
    const customValues = [[lastDim], [firstPass], [kPow2]];
    const prevIndices2 = indices;
    indices = backend2.runWebGLProgram(mergeProgram, inputs2, "int32", customValues);
    disposeIntermediateTensorInfoOrNull(backend2, prevIndices2);
    const len4 = kPow2 / 2;
    const dir = len4 * 2;
    for (let inc = len4; inc >= 1; inc /= 2) {
      runSwap(dir, inc, indices.shape);
    }
  }
  let prevIndices = indices;
  indices = slice3({ inputs: { x: indices }, backend: backend2, attrs: { begin: 0, size: [batch, k] } });
  disposeIntermediateTensorInfoOrNull(backend2, prevIndices);
  let values = gatherV22({ inputs: { x: x2D, indices }, backend: backend2, attrs: { axis: 1, batchDims: 1 } });
  disposeIntermediateTensorInfoOrNull(backend2, x2D);
  const newShape = xShape.slice(0, -1);
  newShape.push(k);
  prevIndices = indices;
  indices = reshape3({ inputs: { x: indices }, attrs: { shape: newShape }, backend: backend2 });
  disposeIntermediateTensorInfoOrNull(backend2, prevIndices);
  const prevValues = values;
  values = reshape3({ inputs: { x: values }, attrs: { shape: newShape }, backend: backend2 });
  disposeIntermediateTensorInfoOrNull(backend2, prevValues);
  return [values, indices];
}
var topKConfig2;
var init_TopK2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/TopK.js"() {
    init_dist();
    init_shared2();
    init_top_k_gpu();
    init_Fill2();
    init_GatherV22();
    init_Reshape2();
    init_Slice2();
    topKConfig2 = {
      kernelName: TopK,
      backendName: "webgl",
      kernelFunc: topK2
    };
  }
});
var TransformProgram;
var init_transform_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/transform_gpu.js"() {
    TransformProgram = class {
      constructor(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape) {
        this.variableNames = ["Image", "Transforms"];
        this.outputShape = outShape;
        const interpolationModeId = interpolation === "nearest" ? 1 : 2;
        let fillModeId;
        switch (fillMode) {
          case "constant":
            fillModeId = 1;
            break;
          case "reflect":
            fillModeId = 2;
            break;
          case "wrap":
            fillModeId = 3;
            break;
          case "nearest":
            fillModeId = 4;
            break;
          default:
            fillModeId = 1;
            break;
        }
        this.userCode = `
            float mapCoord(float outCoord, float len) {
              float inCoord = outCoord;
              if(${fillModeId} == 2) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    if (inCoord < sz2) {
                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +
                      inCoord;
                    }
                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    inCoord -= sz2 * float(int(float(inCoord / sz2)));
                    if (inCoord >= len) {
                      inCoord = sz2 - inCoord - 1.0;
                    }
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${fillModeId} == 3) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord -= len * float(int(float(inCoord / sz)));
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${fillModeId} == 4) {
                return clamp(outCoord, 0.0, len - 1.0);
              } else {
                return outCoord;
              }
            }

            float readWithFillValue(int batch, int coordY, int coordX,
              int channel) {
              float outputValue;
              if (0 <= coordY && coordY < ${imageHeight} && 0 <= coordX && coordX < ${imageWidth}) {
                  outputValue = getImage(batch, coordY, coordX, channel);
              } else {
                outputValue = float(${fillValue});
              }
              return outputValue;
            }

            void main() {
              ivec4 coords = getOutputCoords();
              float outputValue;
              int batch = coords[0];
              int x = coords[2];
              int y = coords[1];
              int channel = coords[3];
              float xf = float(x);
              float yf = float(y);
              float a1 = getTransforms(batch, 0);
              float a2 = getTransforms(batch, 1);
              float a3 = getTransforms(batch, 2);
              float b1 = getTransforms(batch, 3);
              float b2 = getTransforms(batch, 4);
              float b3 = getTransforms(batch, 5);
              float c1 = getTransforms(batch, 6);
              float c2 = getTransforms(batch, 7);
              float projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = float(${fillValue});
              } else {
                float inX = (a1 * xf + a2 * yf + a3) / projection;
                float inY = (b1 * xf + b2 * yf + b3) / projection;
                float mapX = mapCoord(inX, float(${imageWidth}));
                float mapY = mapCoord(inY, float(${imageHeight}));

                if (${interpolationModeId} == 1) {
                  int coordY = int(round(mapY));
                  int coordX = int(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  float yFloor = floor(mapY);
                  float xFloor = floor(mapX);
                  float yCeil = yFloor + 1.0;
                  float xCeil = xFloor + 1.0;
                  float valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);
                  float valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutput(outputValue);
            }
        `;
      }
    };
  }
});
function transform3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { image: image2, transforms } = inputs;
  const { interpolation, fillMode, fillValue, outputShape } = attrs;
  const [batch, imageHeight, imageWidth, numChannels] = image2.shape;
  const [outHeight, outWidth] = outputShape != null ? outputShape : [imageHeight, imageWidth];
  const outShape = [
    batch,
    outHeight,
    outWidth,
    numChannels
  ];
  const program = new TransformProgram(imageHeight, imageWidth, interpolation, fillMode, fillValue, outShape);
  return backend2.runWebGLProgram(program, [image2, transforms], "float32");
}
var transformConfig2;
var init_Transform2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Transform.js"() {
    init_dist();
    init_transform_gpu();
    transformConfig2 = {
      kernelName: Transform,
      backendName: "webgl",
      kernelFunc: transform3
    };
  }
});
function unique4(args) {
  const { inputs, attrs, backend: backend2 } = args;
  const { axis } = attrs;
  const { x } = inputs;
  assertNotComplex2(x, "unique");
  console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  const values = backend2.readSync(x.dataId);
  const { outputValues, outputShape, indices } = uniqueImplCPU(values, axis, x.shape, x.dtype);
  return [
    backend2.makeTensorInfo(outputShape, x.dtype, outputValues),
    backend2.makeTensorInfo([indices.length], "int32", indices)
  ];
}
var uniqueConfig2;
var init_Unique2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Unique.js"() {
    init_dist();
    init_shared2();
    init_webgl_util();
    uniqueConfig2 = {
      kernelName: Unique,
      backendName: "webgl",
      kernelFunc: unique4
    };
  }
});
function unpack2(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { value } = inputs;
  let { axis } = attrs;
  if (axis < 0) {
    axis += value.shape.length;
  }
  const x = value;
  const xRank = x.shape.length;
  const num = value.shape[axis];
  const outShape = new Array(xRank - 1);
  let outIndex = 0;
  for (let i = 0; i < xRank; i++) {
    if (i !== axis) {
      outShape[outIndex++] = x.shape[i];
    }
  }
  const toDispose = [];
  const begin = new Array(xRank).fill(0);
  const size = x.shape.slice();
  size[axis] = 1;
  const res = new Array(num);
  for (let i = 0; i < res.length; i++) {
    begin[axis] = i;
    const sliced = slice3({ inputs: { x }, backend: backend2, attrs: { begin, size } });
    const reshaped = reshape3({ inputs: { x: sliced }, backend: backend2, attrs: { shape: outShape } });
    res[i] = reshaped;
    toDispose.push(sliced);
  }
  toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return res;
}
var unpackConfig2;
var init_Unpack2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Unpack.js"() {
    init_dist();
    init_Reshape2();
    init_Slice2();
    unpackConfig2 = {
      kernelName: Unpack,
      backendName: "webgl",
      kernelFunc: unpack2
    };
  }
});
var SegmentOpProgram;
var init_segment_gpu = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/segment_gpu.js"() {
    SegmentOpProgram = class {
      constructor(segOpInfo, segOpType) {
        this.variableNames = ["x", "segmentIds"];
        const windowSize = segOpInfo.windowSize;
        const batchSize = segOpInfo.batchSize;
        const inSize = segOpInfo.inSize;
        const numSegments = segOpInfo.numSegments;
        const outSize = numSegments * Math.ceil(inSize / windowSize);
        this.outputShape = [batchSize, outSize];
        const initializationValue = "0.0";
        const returnValue = `sumValue`;
        const windowSizeNearestVec4 = Math.floor(windowSize / 4) * 4;
        const windowSizeVec4Remainder = windowSize % 4;
        const updateSnippet = `
        sumValue += dot(values, segFilter);
    `;
        let checkValueOutOfBounds = "";
        if (inSize % windowSize > 0) {
          checkValueOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return initializationValue;
        }
      `;
        }
        let checkSegmentIdOutOfBounds = "";
        if (inSize % windowSize > 0) {
          checkSegmentIdOutOfBounds = `
        if (inIdx < 0 || inIdx >= ${inSize}) {
          return -1.0;
        }
      `;
        }
        this.userCode = `
      const float initializationValue = ${initializationValue};

      float getValue(int batch, int inIdx) {
        ${checkValueOutOfBounds}
        return getX(batch, inIdx);
      }

      float getSegmentIdAtIndex(int inIdx) {
        ${checkSegmentIdOutOfBounds}
        return getSegmentIds(inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = int(floor(float(outIdx) / float(
          ${numSegments})) * float(${windowSize}));
        int currentSeg = int(mod(float(outIdx), float(${numSegments})));

        float sumValue = 0.0;

        for (int i = 0; i < ${windowSizeNearestVec4}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0
          );

          ${updateSnippet}
        }

        int inIdx = inOffset + ${windowSizeNearestVec4};
        if (${windowSizeVec4Remainder === 1}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            0,
            0,
            0
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
              0,
              0
          );

          ${updateSnippet}
        } else if (${windowSizeVec4Remainder === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            0
          );

          ${updateSnippet}
        }
        setOutput(${returnValue});
      }
    `;
      }
    };
  }
});
function unsortedSegmentSum3(args) {
  const { inputs, backend: backend2, attrs } = args;
  const { x, segmentIds } = inputs;
  const { numSegments } = attrs;
  const xRank = x.shape.length;
  const toDispose = [];
  let axis = 0;
  const permutation = backend_util_exports.getAxesPermutation([axis], xRank);
  let permutedX = x;
  if (permutation != null) {
    permutedX = transpose3({ inputs: { x }, backend: backend2, attrs: { perm: permutation } });
    toDispose.push(permutedX);
    axis = backend_util_exports.getInnerMostAxes(1, xRank)[0];
  }
  const outShape = backend_util_exports.segment_util.computeOutShape(permutedX.shape, axis, numSegments);
  const inSize = util_exports.sizeFromShape([permutedX.shape[axis]]);
  const a2D = reshape3({ inputs: { x: permutedX }, backend: backend2, attrs: { shape: [-1, inSize] } });
  toDispose.push(a2D);
  const outputDType = sumOutType(x.dtype);
  const segOpCompute = (x2, segOpType, segmentIds2, dtype, numSegments2) => {
    const batchSize = x2.shape[0];
    const inSize2 = x2.shape[1];
    const windowSize = backend_util_exports.segment_util.segOpComputeOptimalWindowSize(inSize2, numSegments2);
    const segOpInfo = { windowSize, inSize: inSize2, batchSize, numSegments: numSegments2 };
    const program = new SegmentOpProgram(segOpInfo, segOpType);
    const output = backend2.compileAndRun(program, [x2, segmentIds2], dtype);
    toDispose.push(output);
    if (output.shape[1] === numSegments2) {
      return output;
    }
    const rangeInfo = range4({
      backend: backend2,
      attrs: { start: 0, stop: numSegments2, step: 1, dtype: "float32" }
    });
    const tileInfo = tile4({
      inputs: { x: rangeInfo },
      backend: backend2,
      attrs: { reps: [inSize2 / windowSize] }
    });
    toDispose.push(rangeInfo);
    toDispose.push(tileInfo);
    const result2 = segOpCompute(output, segOpType, tileInfo, dtype, numSegments2);
    return result2;
  };
  const segOpResult = segOpCompute(a2D, "unsortedSegmentSum", segmentIds, outputDType, numSegments);
  const reshaped = reshape3({ inputs: { x: segOpResult }, backend: backend2, attrs: { shape: outShape } });
  let result = reshaped;
  if (permutation != null) {
    toDispose.push(reshaped);
    const perm = backend_util_exports.getUndoAxesPermutation(permutation);
    result = transpose3({ inputs: { x: result }, backend: backend2, attrs: { perm } });
  }
  toDispose.forEach((t) => backend2.disposeIntermediateTensorInfo(t));
  return result;
}
var unsortedSegmentSumConfig2;
var init_UnsortedSegmentSum2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/UnsortedSegmentSum.js"() {
    init_dist();
    init_segment_gpu();
    init_Range2();
    init_Reshape2();
    init_Tile2();
    init_Transpose2();
    unsortedSegmentSumConfig2 = {
      kernelName: UnsortedSegmentSum,
      backendName: "webgl",
      kernelFunc: unsortedSegmentSum3
    };
  }
});
var kernelConfigs2;
var init_register_all_kernels2 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/register_all_kernels.js"() {
    init_dist();
    init_FusedMatMul2();
    init_Abs2();
    init_Acos2();
    init_Acosh2();
    init_Add2();
    init_AddN2();
    init_All2();
    init_Any2();
    init_ArgMax2();
    init_ArgMin2();
    init_Asin2();
    init_Asinh2();
    init_Atan3();
    init_Atan22();
    init_Atanh2();
    init_AvgPool2();
    init_AvgPool3D2();
    init_AvgPool3DGrad2();
    init_AvgPoolGrad2();
    init_BatchMatMul2();
    init_BatchNorm2();
    init_BatchToSpaceND2();
    init_Bincount2();
    init_BroadcastArgs2();
    init_Cast2();
    init_Ceil2();
    init_ClipByValue2();
    init_Complex2();
    init_ComplexAbs2();
    init_Concat2();
    init_Conv2D2();
    init_Conv2DBackpropFilter2();
    init_Conv2DBackpropInput2();
    init_Conv3D2();
    init_Conv3DBackpropFilterV22();
    init_Conv3DBackpropInputV22();
    init_Cos2();
    init_Cosh2();
    init_CropAndResize2();
    init_Cumprod2();
    init_Cumsum2();
    init_DenseBincount2();
    init_DepthToSpace2();
    init_DepthwiseConv2dNative2();
    init_DepthwiseConv2dNativeBackpropFilter2();
    init_DepthwiseConv2dNativeBackpropInput2();
    init_Diag2();
    init_Dilation2D2();
    init_Einsum2();
    init_Elu2();
    init_EluGrad2();
    init_Equal2();
    init_Erf2();
    init_Exp2();
    init_ExpandDims2();
    init_Expm12();
    init_FFT2();
    init_Fill2();
    init_FlipLeftRight2();
    init_Floor2();
    init_FloorDiv2();
    init_FromPixels();
    init_FusedConv2D2();
    init_FusedDepthwiseConv2D2();
    init_GatherNd2();
    init_GatherV22();
    init_Greater2();
    init_GreaterEqual2();
    init_Identity2();
    init_IFFT2();
    init_Imag2();
    init_IsFinite2();
    init_IsInf2();
    init_IsNaN2();
    init_LeakyRelu2();
    init_Less2();
    init_LessEqual2();
    init_LinSpace2();
    init_Log2();
    init_Log1p2();
    init_LogicalAnd2();
    init_LogicalNot2();
    init_LogicalOr2();
    init_LRN2();
    init_LRNGrad2();
    init_Max2();
    init_Maximum2();
    init_MaxPool2();
    init_MaxPool3D2();
    init_MaxPool3DGrad2();
    init_MaxPoolGrad2();
    init_MaxPoolWithArgmax2();
    init_Mean2();
    init_Min2();
    init_Minimum2();
    init_MirrorPad2();
    init_Mod2();
    init_Multinomial2();
    init_Multiply2();
    init_Neg2();
    init_NonMaxSuppressionV32();
    init_NonMaxSuppressionV42();
    init_NonMaxSuppressionV52();
    init_NotEqual2();
    init_OneHot2();
    init_OnesLike2();
    init_Pack2();
    init_PadV22();
    init_Pow2();
    init_Prelu2();
    init_Prod2();
    init_RaggedGather2();
    init_RaggedRange2();
    init_RaggedTensorToTensor2();
    init_Range2();
    init_Real2();
    init_RealDiv2();
    init_Reciprocal2();
    init_Relu2();
    init_Relu62();
    init_Reshape2();
    init_ResizeBilinear2();
    init_ResizeBilinearGrad2();
    init_ResizeNearestNeighbor2();
    init_ResizeNearestNeighborGrad2();
    init_Reverse2();
    init_RotateWithOffset2();
    init_Round2();
    init_Rsqrt2();
    init_ScatterNd2();
    init_SearchSorted2();
    init_Select2();
    init_Selu2();
    init_Sigmoid2();
    init_Sign2();
    init_Sin2();
    init_Sinh2();
    init_Slice2();
    init_Softmax2();
    init_Softplus2();
    init_SpaceToBatchND2();
    init_SparseFillEmptyRows2();
    init_SparseReshape2();
    init_SparseSegmentMean2();
    init_SparseSegmentSum2();
    init_SparseToDense2();
    init_SplitV2();
    init_Sqrt2();
    init_Square2();
    init_SquaredDifference2();
    init_Step2();
    init_StridedSlice2();
    init_StringNGrams2();
    init_StringSplit2();
    init_StringToHashBucketFast2();
    init_Sub2();
    init_Sum2();
    init_Tan2();
    init_Tanh2();
    init_Tile2();
    init_TopK2();
    init_Transform2();
    init_Transpose2();
    init_Unique2();
    init_Unpack2();
    init_UnsortedSegmentSum2();
    init_ZerosLike2();
    kernelConfigs2 = [
      _fusedMatMulConfig2,
      absConfig2,
      acosConfig2,
      acoshConfig2,
      addConfig2,
      addNConfig2,
      allConfig2,
      anyConfig2,
      argMaxConfig2,
      argMinConfig2,
      asinConfig2,
      asinhConfig2,
      atanConfig2,
      atan2Config2,
      atanhConfig2,
      avgPoolConfig2,
      avgPool3DConfig2,
      avgPool3DGradConfig3,
      avgPoolGradConfig3,
      batchMatMulConfig2,
      batchNormConfig2,
      batchToSpaceNDConfig2,
      bincountConfig2,
      broadcastArgsConfig2,
      castConfig2,
      ceilConfig2,
      clipByValueConfig2,
      complexConfig2,
      complexAbsConfig2,
      concatConfig2,
      conv2DConfig2,
      conv2DBackpropFilterConfig2,
      conv2DBackpropInputConfig2,
      conv3DConfig2,
      conv3DBackpropFilterV2Config2,
      conv3DBackpropInputConfig,
      cosConfig2,
      coshConfig2,
      cropAndResizeConfig2,
      cumprodConfig2,
      cumsumConfig2,
      denseBincountConfig2,
      depthToSpaceConfig2,
      depthwiseConv2dNativeConfig2,
      depthwiseConv2dNativeBackpropFilterConfig2,
      depthwiseConv2dNativeBackpropInputConfig2,
      diagConfig2,
      dilation2DConfig2,
      einsumConfig2,
      eluConfig2,
      eluGradConfig3,
      equalConfig2,
      erfConfig2,
      expConfig2,
      expandDimsConfig2,
      expm1Config2,
      fftConfig2,
      fillConfig2,
      flipLeftRightConfig2,
      floorConfig2,
      floorDivConfig2,
      fromPixelsConfig,
      fusedConv2DConfig2,
      fusedDepthwiseConv2DConfig2,
      gatherNdConfig2,
      gatherV2Config2,
      greaterConfig2,
      greaterEqualConfig2,
      identityConfig2,
      ifftConfig2,
      imagConfig2,
      isFiniteConfig2,
      isInfConfig2,
      isNaNConfig2,
      leakyReluConfig2,
      lessConfig2,
      lessEqualConfig2,
      linSpaceConfig2,
      logConfig2,
      log1pConfig2,
      logicalAndConfig2,
      logicalNotConfig2,
      logicalOrConfig2,
      LRNConfig2,
      LRNGradConfig2,
      maxConfig2,
      maximumConfig2,
      maxPoolConfig2,
      maxPool3DConfig2,
      maxPool3DGradConfig3,
      maxPoolGradConfig3,
      maxPoolWithArgmaxConfig2,
      meanConfig2,
      minConfig2,
      minimumConfig2,
      mirrorPadConfig2,
      modConfig2,
      multinomialConfig2,
      multiplyConfig2,
      negConfig2,
      nonMaxSuppressionV3Config2,
      nonMaxSuppressionV4Config2,
      nonMaxSuppressionV5Config2,
      notEqualConfig2,
      oneHotConfig2,
      onesLikeConfig2,
      packConfig2,
      padV2Config2,
      powConfig2,
      preluConfig2,
      prodConfig2,
      raggedGatherConfig2,
      raggedRangeConfig2,
      raggedTensorToTensorConfig2,
      rangeConfig2,
      realConfig2,
      realDivConfig2,
      reciprocalConfig2,
      reluConfig2,
      relu6Config2,
      reshapeConfig2,
      resizeBilinearConfig2,
      resizeBilinearGradConfig3,
      resizeNearestNeighborConfig2,
      resizeNearestNeighborGradConfig3,
      reverseConfig2,
      rotateWithOffsetConfig2,
      roundConfig2,
      rsqrtConfig2,
      scatterNdConfig2,
      searchSortedConfig2,
      selectConfig2,
      seluConfig2,
      sigmoidConfig2,
      signConfig2,
      sinConfig2,
      sinhConfig2,
      sliceConfig2,
      softmaxConfig2,
      softplusConfig2,
      spaceToBatchNDConfig2,
      sparseFillEmptyRowsConfig2,
      sparseReshapeConfig2,
      sparseSegmentMeanConfig2,
      sparseSegmentSumConfig2,
      sparseToDenseConfig2,
      splitVConfig2,
      sqrtConfig2,
      squareConfig2,
      squaredDifferenceConfig2,
      stepConfig2,
      stridedSliceConfig2,
      stringNGramsConfig2,
      stringSplitConfig2,
      stringToHashBucketFastConfig2,
      subConfig2,
      sumConfig2,
      tanConfig2,
      tanhConfig2,
      tileConfig2,
      topKConfig2,
      transformConfig2,
      transposeConfig2,
      uniqueConfig2,
      unpackConfig2,
      unsortedSegmentSumConfig2,
      zerosLikeConfig2
    ];
    for (const kernelConfig of kernelConfigs2) {
      registerKernel(kernelConfig);
    }
  }
});
var init_dist6 = __esm({
  "node_modules/@tensorflow/tfjs-backend-webgl/dist/index.js"() {
    init_base3();
    init_register_all_kernels2();
  }
});
var init_version4 = __esm({
  "node_modules/@tensorflow/tfjs/dist/version.js"() {
  }
});
var init_dist7 = __esm({
  "node_modules/@tensorflow/tfjs/dist/index.js"() {
    init_dist();
    init_register_all_gradients();
    init_register_all_chained_ops();
    init_dist();
    init_dist2();
    init_dist3();
    init_dist4();
    init_dist5();
    init_dist6();
    init_dist();
    init_dist5();
    init_dist6();
    init_dist4();
    init_dist2();
    init_dist3();
    init_version4();
  }
});
function inlineWorker(scriptText) {
  let blob = new Blob([scriptText], { type: "text/javascript" });
  let url = URL.createObjectURL(blob);
  let worker = new Worker(url);
  URL.revokeObjectURL(url);
  return worker;
}
var init_inline_worker = __esm({
  "inline-worker:__inline-worker"() {
  }
});
function Worker2() {
  return inlineWorker('var at=class{constructor(o=[],e=Ce){if(this.data=o,this.length=this.data.length,this.compare=e,this.length>0)for(let t=(this.length>>1)-1;t>=0;t--)this._down(t)}push(o){this.data.push(o),this.length++,this._up(this.length-1)}pop(){if(this.length===0)return;let o=this.data[0],e=this.data.pop();return this.length--,this.length>0&&(this.data[0]=e,this._down(0)),o}peek(){return this.data[0]}_up(o){let{data:e,compare:t}=this,n=e[o];for(;o>0;){let r=o-1>>1,i=e[r];if(t(n,i)>=0)break;e[o]=i,o=r}e[o]=n}_down(o){let{data:e,compare:t}=this,n=this.length>>1,r=e[o];for(;o<n;){let i=(o<<1)+1,h=e[i],l=i+1;if(l<this.length&&t(e[l],h)<0&&(i=l,h=e[l]),t(h,r)>=0)break;e[o]=h,o=i}e[o]=r}};function Ce(s,o){return s<o?-1:s>o?1:0}var Mt=s=>{let{v1:o,v2:e}=s,t=0;for(let n=0;n<o.length;n++){let r=(o[n]^e[n])>>>0;t+=Oe(r)}return t},Oe=s=>{var o=s-(s>>1&1431655765);return o=(o>>2&858993459)+(o&858993459),o=(o>>4)+o&252645135,o=(o>>8)+o&16711935,o=(o>>16)+o&65535,o};var zt=s=>{let{keywidth:o,keyheight:e,querywidth:t,queryheight:n,matches:r}=s,i=t*1.2,h=-i,l=n*1.2,u=-l,c=12,a=10,m=-1,j=1,y=1/Math.log(10),g=Math.max(o,e),M=Math.floor(o/2),q=Math.floor(e/2),E=[];for(let v=0;v<r.length;v++){let $=r[v].querypoint.scale,Y=r[v].keypoint.scale;Y==0&&console.log("ERROR divide zero");let J=$/Y;E.push(J*g)}E.sort((v,$)=>v-$);let R=.25*E[Math.floor(E.length/2)-(E.length%2==0?1:0)-1],_=Math.max(5,Math.ceil((i-h)/R)),b=Math.max(5,Math.ceil((l-u)/R)),z=_*b,C=z*c,T=[],f=[],w={};for(let v=0;v<r.length;v++){let $=r[v].querypoint,Y=r[v].keypoint,{x:J,y:x,scale:P,angle:V}=Xe({querypoint:$,keypoint:Y,keycenterX:M,keycenterY:q,scaleOneOverLogK:y});if(J<h||J>=i||x<u||x>=l||V<=-Math.PI||V>Math.PI||P<m||P>=j){T[v]=!1;continue}let K=_*(J-h)/(i-h),X=b*(x-u)/(l-u),dt=c*(V+Math.PI)/(2*Math.PI),yt=a*(P-m)/(j-m);f[v]={binX:K,binY:X,binAngle:dt,binScale:yt};let ht=Math.floor(K-.5),ut=Math.floor(X-.5),ft=Math.floor(yt-.5),vt=(Math.floor(dt-.5)+c)%c;if(ht<0||ht+1>=_||ut<0||ut+1>=b||ft<0||ft+1>=a){T[v]=!1;continue}for(let ct=0;ct<2;ct++){let Nt=ht+ct;for(let xt=0;xt<2;xt++){let De=ut+xt;for(let _t=0;_t<2;_t++){let Te=(vt+_t)%c;for(let qt=0;qt<2;qt++){let Pe=ft+qt,Ft=Nt+De*_+Te*z+Pe*C;w[Ft]===void 0&&(w[Ft]=0),w[Ft]+=1}}}}T[v]=!0}let S=0,d=-1;if(Object.keys(w).forEach(v=>{w[v]>S&&(S=w[v],d=v)}),S<3)return[];let O=Math.floor(d%C%z%_),D=Math.floor((d-O)%C%z/_),U=Math.floor((d-O-D*_)%C/z),F=Math.floor((d-O-D*_-U*z)/C),B=[];for(let v=0;v<r.length;v++){if(!T[v])continue;let $=f[v];if(Math.abs($.binX-(O+.5))>=1||Math.abs($.binY-(D+.5))>=1||Math.abs($.binScale-(F+.5))>=1)continue;let P=Math.abs($.binAngle-(U+.5));Math.min(P,c-P)>=1||B.push(r[v])}return B},Xe=({querypoint:s,keypoint:o,keycenterX:e,keycenterY:t,scaleOneOverLogK:n})=>{let r=s.angle-o.angle;r<=-Math.PI?r+=2*Math.PI:r>Math.PI&&(r-=2*Math.PI);let i=s.scale/o.scale,h=i*Math.cos(r),l=i*Math.sin(r),u=[h,-l,l,h],c=[u[0]*o.x+u[1]*o.y,u[2]*o.x+u[3]*o.y],a=s.x-c[0],m=s.y-c[1];return{x:u[0]*e+u[1]*t+a,y:u[2]*e+u[3]*t+m,angle:r,scale:Math.log(i)*n}};var Ue=Object.prototype.toString;function H(s){return Ue.call(s).endsWith("Array]")}function $t(s){var o=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(!H(s))throw new TypeError("input must be an array");if(s.length===0)throw new TypeError("input must not be empty");var e=o.fromIndex,t=e===void 0?0:e,n=o.toIndex,r=n===void 0?s.length:n;if(t<0||t>=s.length||!Number.isInteger(t))throw new Error("fromIndex must be a positive integer smaller than length");if(r<=t||r>s.length||!Number.isInteger(r))throw new Error("toIndex must be an integer greater than fromIndex and at most equal to length");for(var i=s[t],h=t+1;h<r;h++)s[h]>i&&(i=s[h]);return i}function Lt(s){var o=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(!H(s))throw new TypeError("input must be an array");if(s.length===0)throw new TypeError("input must not be empty");var e=o.fromIndex,t=e===void 0?0:e,n=o.toIndex,r=n===void 0?s.length:n;if(t<0||t>=s.length||!Number.isInteger(t))throw new Error("fromIndex must be a positive integer smaller than length");if(r<=t||r>s.length||!Number.isInteger(r))throw new Error("toIndex must be an integer greater than fromIndex and at most equal to length");for(var i=s[t],h=t+1;h<r;h++)s[h]<i&&(i=s[h]);return i}function Dt(s){var o=arguments.length>1&&arguments[1]!==void 0?arguments[1]:{};if(H(s)){if(s.length===0)throw new TypeError("input must not be empty")}else throw new TypeError("input must be an array");var e;if(o.output!==void 0){if(!H(o.output))throw new TypeError("output option must be an array if specified");e=o.output}else e=new Array(s.length);var t=Lt(s),n=$t(s);if(t===n)throw new RangeError("minimum and maximum input values are equal. Cannot rescale a constant array");var r=o.min,i=r===void 0?o.autoMinMax?t:0:r,h=o.max,l=h===void 0?o.autoMinMax?n:1:h;if(i>=l)throw new RangeError("min option must be smaller than max option");for(var u=(l-i)/(n-t),c=0;c<s.length;c++)e[c]=(s[c]-t)*u+i;return e}var Et=" ".repeat(2),Ht=" ".repeat(4);function Bt(){return Tt(this)}function Tt(s,o={}){let{maxRows:e=15,maxColumns:t=10,maxNumSize:n=8,padMinus:r="auto"}=o;return`${s.constructor.name} {\n${Et}[\n${Ht}${$e(s,e,t,n,r)}\n${Et}]\n${Et}rows: ${s.rows}\n${Et}columns: ${s.columns}\n}`}function $e(s,o,e,t,n){let{rows:r,columns:i}=s,h=Math.min(r,o),l=Math.min(i,e),u=[];if(n==="auto"){n=!1;t:for(let c=0;c<h;c++)for(let a=0;a<l;a++)if(s.get(c,a)<0){n=!0;break t}}for(let c=0;c<h;c++){let a=[];for(let m=0;m<l;m++)a.push(Le(s.get(c,m),t,n));u.push(`${a.join(" ")}`)}return l!==i&&(u[u.length-1]+=` ... ${i-e} more columns`),h!==r&&u.push(`... ${r-o} more rows`),u.join(`\n${Ht}`)}function Le(s,o,e){return(s>=0&&e?` ${Vt(s,o-1)}`:Vt(s,o)).padEnd(o)}function Vt(s,o){let e=s.toString();if(e.length<=o)return e;let t=s.toFixed(o);if(t.length>o&&(t=s.toFixed(Math.max(0,o-(t.length-o)))),t.length<=o&&!t.startsWith("0.000")&&!t.startsWith("-0.000"))return t;let n=s.toExponential(o);return n.length>o&&(n=s.toExponential(Math.max(0,o-(n.length-o)))),n.slice(0)}function Yt(s,o){s.prototype.add=function(t){return typeof t=="number"?this.addS(t):this.addM(t)},s.prototype.addS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)+t);return this},s.prototype.addM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)+t.get(n,r));return this},s.add=function(t,n){return new o(t).add(n)},s.prototype.sub=function(t){return typeof t=="number"?this.subS(t):this.subM(t)},s.prototype.subS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)-t);return this},s.prototype.subM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)-t.get(n,r));return this},s.sub=function(t,n){return new o(t).sub(n)},s.prototype.subtract=s.prototype.sub,s.prototype.subtractS=s.prototype.subS,s.prototype.subtractM=s.prototype.subM,s.subtract=s.sub,s.prototype.mul=function(t){return typeof t=="number"?this.mulS(t):this.mulM(t)},s.prototype.mulS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)*t);return this},s.prototype.mulM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)*t.get(n,r));return this},s.mul=function(t,n){return new o(t).mul(n)},s.prototype.multiply=s.prototype.mul,s.prototype.multiplyS=s.prototype.mulS,s.prototype.multiplyM=s.prototype.mulM,s.multiply=s.mul,s.prototype.div=function(t){return typeof t=="number"?this.divS(t):this.divM(t)},s.prototype.divS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)/t);return this},s.prototype.divM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)/t.get(n,r));return this},s.div=function(t,n){return new o(t).div(n)},s.prototype.divide=s.prototype.div,s.prototype.divideS=s.prototype.divS,s.prototype.divideM=s.prototype.divM,s.divide=s.div,s.prototype.mod=function(t){return typeof t=="number"?this.modS(t):this.modM(t)},s.prototype.modS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)%t);return this},s.prototype.modM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)%t.get(n,r));return this},s.mod=function(t,n){return new o(t).mod(n)},s.prototype.modulus=s.prototype.mod,s.prototype.modulusS=s.prototype.modS,s.prototype.modulusM=s.prototype.modM,s.modulus=s.mod,s.prototype.and=function(t){return typeof t=="number"?this.andS(t):this.andM(t)},s.prototype.andS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)&t);return this},s.prototype.andM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)&t.get(n,r));return this},s.and=function(t,n){return new o(t).and(n)},s.prototype.or=function(t){return typeof t=="number"?this.orS(t):this.orM(t)},s.prototype.orS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)|t);return this},s.prototype.orM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)|t.get(n,r));return this},s.or=function(t,n){return new o(t).or(n)},s.prototype.xor=function(t){return typeof t=="number"?this.xorS(t):this.xorM(t)},s.prototype.xorS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)^t);return this},s.prototype.xorM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)^t.get(n,r));return this},s.xor=function(t,n){return new o(t).xor(n)},s.prototype.leftShift=function(t){return typeof t=="number"?this.leftShiftS(t):this.leftShiftM(t)},s.prototype.leftShiftS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)<<t);return this},s.prototype.leftShiftM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)<<t.get(n,r));return this},s.leftShift=function(t,n){return new o(t).leftShift(n)},s.prototype.signPropagatingRightShift=function(t){return typeof t=="number"?this.signPropagatingRightShiftS(t):this.signPropagatingRightShiftM(t)},s.prototype.signPropagatingRightShiftS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)>>t);return this},s.prototype.signPropagatingRightShiftM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)>>t.get(n,r));return this},s.signPropagatingRightShift=function(t,n){return new o(t).signPropagatingRightShift(n)},s.prototype.rightShift=function(t){return typeof t=="number"?this.rightShiftS(t):this.rightShiftM(t)},s.prototype.rightShiftS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)>>>t);return this},s.prototype.rightShiftM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,this.get(n,r)>>>t.get(n,r));return this},s.rightShift=function(t,n){return new o(t).rightShift(n)},s.prototype.zeroFillRightShift=s.prototype.rightShift,s.prototype.zeroFillRightShiftS=s.prototype.rightShiftS,s.prototype.zeroFillRightShiftM=s.prototype.rightShiftM,s.zeroFillRightShift=s.rightShift,s.prototype.not=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,~this.get(t,n));return this},s.not=function(t){return new o(t).not()},s.prototype.abs=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.abs(this.get(t,n)));return this},s.abs=function(t){return new o(t).abs()},s.prototype.acos=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.acos(this.get(t,n)));return this},s.acos=function(t){return new o(t).acos()},s.prototype.acosh=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.acosh(this.get(t,n)));return this},s.acosh=function(t){return new o(t).acosh()},s.prototype.asin=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.asin(this.get(t,n)));return this},s.asin=function(t){return new o(t).asin()},s.prototype.asinh=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.asinh(this.get(t,n)));return this},s.asinh=function(t){return new o(t).asinh()},s.prototype.atan=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.atan(this.get(t,n)));return this},s.atan=function(t){return new o(t).atan()},s.prototype.atanh=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.atanh(this.get(t,n)));return this},s.atanh=function(t){return new o(t).atanh()},s.prototype.cbrt=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.cbrt(this.get(t,n)));return this},s.cbrt=function(t){return new o(t).cbrt()},s.prototype.ceil=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.ceil(this.get(t,n)));return this},s.ceil=function(t){return new o(t).ceil()},s.prototype.clz32=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.clz32(this.get(t,n)));return this},s.clz32=function(t){return new o(t).clz32()},s.prototype.cos=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.cos(this.get(t,n)));return this},s.cos=function(t){return new o(t).cos()},s.prototype.cosh=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.cosh(this.get(t,n)));return this},s.cosh=function(t){return new o(t).cosh()},s.prototype.exp=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.exp(this.get(t,n)));return this},s.exp=function(t){return new o(t).exp()},s.prototype.expm1=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.expm1(this.get(t,n)));return this},s.expm1=function(t){return new o(t).expm1()},s.prototype.floor=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.floor(this.get(t,n)));return this},s.floor=function(t){return new o(t).floor()},s.prototype.fround=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.fround(this.get(t,n)));return this},s.fround=function(t){return new o(t).fround()},s.prototype.log=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.log(this.get(t,n)));return this},s.log=function(t){return new o(t).log()},s.prototype.log1p=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.log1p(this.get(t,n)));return this},s.log1p=function(t){return new o(t).log1p()},s.prototype.log10=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.log10(this.get(t,n)));return this},s.log10=function(t){return new o(t).log10()},s.prototype.log2=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.log2(this.get(t,n)));return this},s.log2=function(t){return new o(t).log2()},s.prototype.round=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.round(this.get(t,n)));return this},s.round=function(t){return new o(t).round()},s.prototype.sign=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.sign(this.get(t,n)));return this},s.sign=function(t){return new o(t).sign()},s.prototype.sin=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.sin(this.get(t,n)));return this},s.sin=function(t){return new o(t).sin()},s.prototype.sinh=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.sinh(this.get(t,n)));return this},s.sinh=function(t){return new o(t).sinh()},s.prototype.sqrt=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.sqrt(this.get(t,n)));return this},s.sqrt=function(t){return new o(t).sqrt()},s.prototype.tan=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.tan(this.get(t,n)));return this},s.tan=function(t){return new o(t).tan()},s.prototype.tanh=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.tanh(this.get(t,n)));return this},s.tanh=function(t){return new o(t).tanh()},s.prototype.trunc=function(){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.set(t,n,Math.trunc(this.get(t,n)));return this},s.trunc=function(t){return new o(t).trunc()},s.pow=function(t,n){return new o(t).pow(n)},s.prototype.pow=function(t){return typeof t=="number"?this.powS(t):this.powM(t)},s.prototype.powS=function(t){for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,Math.pow(this.get(n,r),t));return this},s.prototype.powM=function(t){if(t=o.checkMatrix(t),this.rows!==t.rows||this.columns!==t.columns)throw new RangeError("Matrices dimensions must be equal");for(let n=0;n<this.rows;n++)for(let r=0;r<this.columns;r++)this.set(n,r,Math.pow(this.get(n,r),t.get(n,r)));return this}}function Z(s,o,e){let t=e?s.rows:s.rows-1;if(o<0||o>t)throw new RangeError("Row index out of range")}function A(s,o,e){let t=e?s.columns:s.columns-1;if(o<0||o>t)throw new RangeError("Column index out of range")}function et(s,o){if(o.to1DArray&&(o=o.to1DArray()),o.length!==s.columns)throw new RangeError("vector size must be the same as the number of columns");return o}function ot(s,o){if(o.to1DArray&&(o=o.to1DArray()),o.length!==s.rows)throw new RangeError("vector size must be the same as the number of rows");return o}function Kt(s,o){if(!H(o))throw new TypeError("row indices must be an array");for(let e=0;e<o.length;e++)if(o[e]<0||o[e]>=s.rows)throw new RangeError("row indices are out of range")}function Jt(s,o){if(!H(o))throw new TypeError("column indices must be an array");for(let e=0;e<o.length;e++)if(o[e]<0||o[e]>=s.columns)throw new RangeError("column indices are out of range")}function Pt(s,o,e,t,n){if(arguments.length!==5)throw new RangeError("expected 4 arguments");if(St("startRow",o),St("endRow",e),St("startColumn",t),St("endColumn",n),o>e||t>n||o<0||o>=s.rows||e<0||e>=s.rows||t<0||t>=s.columns||n<0||n>=s.columns)throw new RangeError("Submatrix indices are out of range")}function mt(s,o=0){let e=[];for(let t=0;t<s;t++)e.push(o);return e}function St(s,o){if(typeof o!="number")throw new TypeError(`${s} must be a number`)}function nt(s){if(s.isEmpty())throw new Error("Empty matrix has no elements to index")}function Wt(s){let o=mt(s.rows);for(let e=0;e<s.rows;++e)for(let t=0;t<s.columns;++t)o[e]+=s.get(e,t);return o}function Gt(s){let o=mt(s.columns);for(let e=0;e<s.rows;++e)for(let t=0;t<s.columns;++t)o[t]+=s.get(e,t);return o}function Qt(s){let o=0;for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)o+=s.get(e,t);return o}function Zt(s){let o=mt(s.rows,1);for(let e=0;e<s.rows;++e)for(let t=0;t<s.columns;++t)o[e]*=s.get(e,t);return o}function At(s){let o=mt(s.columns,1);for(let e=0;e<s.rows;++e)for(let t=0;t<s.columns;++t)o[t]*=s.get(e,t);return o}function te(s){let o=1;for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)o*=s.get(e,t);return o}function ee(s,o,e){let t=s.rows,n=s.columns,r=[];for(let i=0;i<t;i++){let h=0,l=0,u=0;for(let c=0;c<n;c++)u=s.get(i,c)-e[i],h+=u,l+=u*u;o?r.push((l-h*h/n)/(n-1)):r.push((l-h*h/n)/n)}return r}function oe(s,o,e){let t=s.rows,n=s.columns,r=[];for(let i=0;i<n;i++){let h=0,l=0,u=0;for(let c=0;c<t;c++)u=s.get(c,i)-e[i],h+=u,l+=u*u;o?r.push((l-h*h/t)/(t-1)):r.push((l-h*h/t)/t)}return r}function ne(s,o,e){let t=s.rows,n=s.columns,r=t*n,i=0,h=0,l=0;for(let u=0;u<t;u++)for(let c=0;c<n;c++)l=s.get(u,c)-e,i+=l,h+=l*l;return o?(h-i*i/r)/(r-1):(h-i*i/r)/r}function se(s,o){for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)s.set(e,t,s.get(e,t)-o[e])}function re(s,o){for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)s.set(e,t,s.get(e,t)-o[t])}function ie(s,o){for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)s.set(e,t,s.get(e,t)-o)}function le(s){let o=[];for(let e=0;e<s.rows;e++){let t=0;for(let n=0;n<s.columns;n++)t+=Math.pow(s.get(e,n),2)/(s.columns-1);o.push(Math.sqrt(t))}return o}function he(s,o){for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)s.set(e,t,s.get(e,t)/o[e])}function ue(s){let o=[];for(let e=0;e<s.columns;e++){let t=0;for(let n=0;n<s.rows;n++)t+=Math.pow(s.get(n,e),2)/(s.rows-1);o.push(Math.sqrt(t))}return o}function fe(s,o){for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)s.set(e,t,s.get(e,t)/o[t])}function ce(s){let o=s.size-1,e=0;for(let t=0;t<s.columns;t++)for(let n=0;n<s.rows;n++)e+=Math.pow(s.get(n,t),2)/o;return Math.sqrt(e)}function ae(s,o){for(let e=0;e<s.rows;e++)for(let t=0;t<s.columns;t++)s.set(e,t,s.get(e,t)/o)}var N=class{static from1DArray(o,e,t){if(o*e!==t.length)throw new RangeError("data length does not match given dimensions");let r=new k(o,e);for(let i=0;i<o;i++)for(let h=0;h<e;h++)r.set(i,h,t[i*e+h]);return r}static rowVector(o){let e=new k(1,o.length);for(let t=0;t<o.length;t++)e.set(0,t,o[t]);return e}static columnVector(o){let e=new k(o.length,1);for(let t=0;t<o.length;t++)e.set(t,0,o[t]);return e}static zeros(o,e){return new k(o,e)}static ones(o,e){return new k(o,e).fill(1)}static rand(o,e,t={}){if(typeof t!="object")throw new TypeError("options must be an object");let{random:n=Math.random}=t,r=new k(o,e);for(let i=0;i<o;i++)for(let h=0;h<e;h++)r.set(i,h,n());return r}static randInt(o,e,t={}){if(typeof t!="object")throw new TypeError("options must be an object");let{min:n=0,max:r=1e3,random:i=Math.random}=t;if(!Number.isInteger(n))throw new TypeError("min must be an integer");if(!Number.isInteger(r))throw new TypeError("max must be an integer");if(n>=r)throw new RangeError("min must be smaller than max");let h=r-n,l=new k(o,e);for(let u=0;u<o;u++)for(let c=0;c<e;c++){let a=n+Math.round(i()*h);l.set(u,c,a)}return l}static eye(o,e,t){e===void 0&&(e=o),t===void 0&&(t=1);let n=Math.min(o,e),r=this.zeros(o,e);for(let i=0;i<n;i++)r.set(i,i,t);return r}static diag(o,e,t){let n=o.length;e===void 0&&(e=n),t===void 0&&(t=e);let r=Math.min(n,e,t),i=this.zeros(e,t);for(let h=0;h<r;h++)i.set(h,h,o[h]);return i}static min(o,e){o=this.checkMatrix(o),e=this.checkMatrix(e);let t=o.rows,n=o.columns,r=new k(t,n);for(let i=0;i<t;i++)for(let h=0;h<n;h++)r.set(i,h,Math.min(o.get(i,h),e.get(i,h)));return r}static max(o,e){o=this.checkMatrix(o),e=this.checkMatrix(e);let t=o.rows,n=o.columns,r=new this(t,n);for(let i=0;i<t;i++)for(let h=0;h<n;h++)r.set(i,h,Math.max(o.get(i,h),e.get(i,h)));return r}static checkMatrix(o){return N.isMatrix(o)?o:new k(o)}static isMatrix(o){return o!=null&&o.klass==="Matrix"}get size(){return this.rows*this.columns}apply(o){if(typeof o!="function")throw new TypeError("callback must be a function");for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)o.call(this,e,t);return this}to1DArray(){let o=[];for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)o.push(this.get(e,t));return o}to2DArray(){let o=[];for(let e=0;e<this.rows;e++){o.push([]);for(let t=0;t<this.columns;t++)o[e].push(this.get(e,t))}return o}toJSON(){return this.to2DArray()}isRowVector(){return this.rows===1}isColumnVector(){return this.columns===1}isVector(){return this.rows===1||this.columns===1}isSquare(){return this.rows===this.columns}isEmpty(){return this.rows===0||this.columns===0}isSymmetric(){if(this.isSquare()){for(let o=0;o<this.rows;o++)for(let e=0;e<=o;e++)if(this.get(o,e)!==this.get(e,o))return!1;return!0}return!1}isEchelonForm(){let o=0,e=0,t=-1,n=!0,r=!1;for(;o<this.rows&&n;){for(e=0,r=!1;e<this.columns&&r===!1;)this.get(o,e)===0?e++:this.get(o,e)===1&&e>t?(r=!0,t=e):(n=!1,r=!0);o++}return n}isReducedEchelonForm(){let o=0,e=0,t=-1,n=!0,r=!1;for(;o<this.rows&&n;){for(e=0,r=!1;e<this.columns&&r===!1;)this.get(o,e)===0?e++:this.get(o,e)===1&&e>t?(r=!0,t=e):(n=!1,r=!0);for(let i=e+1;i<this.rows;i++)this.get(o,i)!==0&&(n=!1);o++}return n}echelonForm(){let o=this.clone(),e=0,t=0;for(;e<o.rows&&t<o.columns;){let n=e;for(let r=e;r<o.rows;r++)o.get(r,t)>o.get(n,t)&&(n=r);if(o.get(n,t)===0)t++;else{o.swapRows(e,n);let r=o.get(e,t);for(let i=t;i<o.columns;i++)o.set(e,i,o.get(e,i)/r);for(let i=e+1;i<o.rows;i++){let h=o.get(i,t)/o.get(e,t);o.set(i,t,0);for(let l=t+1;l<o.columns;l++)o.set(i,l,o.get(i,l)-o.get(e,l)*h)}e++,t++}}return o}reducedEchelonForm(){let o=this.echelonForm(),e=o.columns,t=o.rows,n=t-1;for(;n>=0;)if(o.maxRow(n)===0)n--;else{let r=0,i=!1;for(;r<t&&i===!1;)o.get(n,r)===1?i=!0:r++;for(let h=0;h<n;h++){let l=o.get(h,r);for(let u=r;u<e;u++){let c=o.get(h,u)-l*o.get(n,u);o.set(h,u,c)}}n--}return o}set(){throw new Error("set method is unimplemented")}get(){throw new Error("get method is unimplemented")}repeat(o={}){if(typeof o!="object")throw new TypeError("options must be an object");let{rows:e=1,columns:t=1}=o;if(!Number.isInteger(e)||e<=0)throw new TypeError("rows must be a positive integer");if(!Number.isInteger(t)||t<=0)throw new TypeError("columns must be a positive integer");let n=new k(this.rows*e,this.columns*t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)n.setSubMatrix(this,this.rows*r,this.columns*i);return n}fill(o){for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,o);return this}neg(){return this.mulS(-1)}getRow(o){Z(this,o);let e=[];for(let t=0;t<this.columns;t++)e.push(this.get(o,t));return e}getRowVector(o){return k.rowVector(this.getRow(o))}setRow(o,e){Z(this,o),e=et(this,e);for(let t=0;t<this.columns;t++)this.set(o,t,e[t]);return this}swapRows(o,e){Z(this,o),Z(this,e);for(let t=0;t<this.columns;t++){let n=this.get(o,t);this.set(o,t,this.get(e,t)),this.set(e,t,n)}return this}getColumn(o){A(this,o);let e=[];for(let t=0;t<this.rows;t++)e.push(this.get(t,o));return e}getColumnVector(o){return k.columnVector(this.getColumn(o))}setColumn(o,e){A(this,o),e=ot(this,e);for(let t=0;t<this.rows;t++)this.set(t,o,e[t]);return this}swapColumns(o,e){A(this,o),A(this,e);for(let t=0;t<this.rows;t++){let n=this.get(t,o);this.set(t,o,this.get(t,e)),this.set(t,e,n)}return this}addRowVector(o){o=et(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)+o[t]);return this}subRowVector(o){o=et(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)-o[t]);return this}mulRowVector(o){o=et(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)*o[t]);return this}divRowVector(o){o=et(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)/o[t]);return this}addColumnVector(o){o=ot(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)+o[e]);return this}subColumnVector(o){o=ot(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)-o[e]);return this}mulColumnVector(o){o=ot(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)*o[e]);return this}divColumnVector(o){o=ot(this,o);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)this.set(e,t,this.get(e,t)/o[e]);return this}mulRow(o,e){Z(this,o);for(let t=0;t<this.columns;t++)this.set(o,t,this.get(o,t)*e);return this}mulColumn(o,e){A(this,o);for(let t=0;t<this.rows;t++)this.set(t,o,this.get(t,o)*e);return this}max(o){if(this.isEmpty())return NaN;switch(o){case"row":{let e=new Array(this.rows).fill(Number.NEGATIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)>e[t]&&(e[t]=this.get(t,n));return e}case"column":{let e=new Array(this.columns).fill(Number.NEGATIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)>e[n]&&(e[n]=this.get(t,n));return e}case void 0:{let e=this.get(0,0);for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)>e&&(e=this.get(t,n));return e}default:throw new Error(`invalid option: ${o}`)}}maxIndex(){nt(this);let o=this.get(0,0),e=[0,0];for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)>o&&(o=this.get(t,n),e[0]=t,e[1]=n);return e}min(o){if(this.isEmpty())return NaN;switch(o){case"row":{let e=new Array(this.rows).fill(Number.POSITIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)<e[t]&&(e[t]=this.get(t,n));return e}case"column":{let e=new Array(this.columns).fill(Number.POSITIVE_INFINITY);for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)<e[n]&&(e[n]=this.get(t,n));return e}case void 0:{let e=this.get(0,0);for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)<e&&(e=this.get(t,n));return e}default:throw new Error(`invalid option: ${o}`)}}minIndex(){nt(this);let o=this.get(0,0),e=[0,0];for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)this.get(t,n)<o&&(o=this.get(t,n),e[0]=t,e[1]=n);return e}maxRow(o){if(Z(this,o),this.isEmpty())return NaN;let e=this.get(o,0);for(let t=1;t<this.columns;t++)this.get(o,t)>e&&(e=this.get(o,t));return e}maxRowIndex(o){Z(this,o),nt(this);let e=this.get(o,0),t=[o,0];for(let n=1;n<this.columns;n++)this.get(o,n)>e&&(e=this.get(o,n),t[1]=n);return t}minRow(o){if(Z(this,o),this.isEmpty())return NaN;let e=this.get(o,0);for(let t=1;t<this.columns;t++)this.get(o,t)<e&&(e=this.get(o,t));return e}minRowIndex(o){Z(this,o),nt(this);let e=this.get(o,0),t=[o,0];for(let n=1;n<this.columns;n++)this.get(o,n)<e&&(e=this.get(o,n),t[1]=n);return t}maxColumn(o){if(A(this,o),this.isEmpty())return NaN;let e=this.get(0,o);for(let t=1;t<this.rows;t++)this.get(t,o)>e&&(e=this.get(t,o));return e}maxColumnIndex(o){A(this,o),nt(this);let e=this.get(0,o),t=[0,o];for(let n=1;n<this.rows;n++)this.get(n,o)>e&&(e=this.get(n,o),t[0]=n);return t}minColumn(o){if(A(this,o),this.isEmpty())return NaN;let e=this.get(0,o);for(let t=1;t<this.rows;t++)this.get(t,o)<e&&(e=this.get(t,o));return e}minColumnIndex(o){A(this,o),nt(this);let e=this.get(0,o),t=[0,o];for(let n=1;n<this.rows;n++)this.get(n,o)<e&&(e=this.get(n,o),t[0]=n);return t}diag(){let o=Math.min(this.rows,this.columns),e=[];for(let t=0;t<o;t++)e.push(this.get(t,t));return e}norm(o="frobenius"){let e=0;if(o==="max")return this.max();if(o==="frobenius"){for(let t=0;t<this.rows;t++)for(let n=0;n<this.columns;n++)e=e+this.get(t,n)*this.get(t,n);return Math.sqrt(e)}else throw new RangeError(`unknown norm type: ${o}`)}cumulativeSum(){let o=0;for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)o+=this.get(e,t),this.set(e,t,o);return this}dot(o){N.isMatrix(o)&&(o=o.to1DArray());let e=this.to1DArray();if(e.length!==o.length)throw new RangeError("vectors do not have the same size");let t=0;for(let n=0;n<e.length;n++)t+=e[n]*o[n];return t}mmul(o){o=k.checkMatrix(o);let e=this.rows,t=this.columns,n=o.columns,r=new k(e,n),i=new Float64Array(t);for(let h=0;h<n;h++){for(let l=0;l<t;l++)i[l]=o.get(l,h);for(let l=0;l<e;l++){let u=0;for(let c=0;c<t;c++)u+=this.get(l,c)*i[c];r.set(l,h,u)}}return r}strassen2x2(o){o=k.checkMatrix(o);let e=new k(2,2),t=this.get(0,0),n=o.get(0,0),r=this.get(0,1),i=o.get(0,1),h=this.get(1,0),l=o.get(1,0),u=this.get(1,1),c=o.get(1,1),a=(t+u)*(n+c),m=(h+u)*n,j=t*(i-c),p=u*(l-n),y=(t+r)*c,g=(h-t)*(n+i),M=(r-u)*(l+c),q=a+p-y+M,E=j+y,I=m+p,R=a-m+j+g;return e.set(0,0,q),e.set(0,1,E),e.set(1,0,I),e.set(1,1,R),e}strassen3x3(o){o=k.checkMatrix(o);let e=new k(3,3),t=this.get(0,0),n=this.get(0,1),r=this.get(0,2),i=this.get(1,0),h=this.get(1,1),l=this.get(1,2),u=this.get(2,0),c=this.get(2,1),a=this.get(2,2),m=o.get(0,0),j=o.get(0,1),p=o.get(0,2),y=o.get(1,0),g=o.get(1,1),M=o.get(1,2),q=o.get(2,0),E=o.get(2,1),I=o.get(2,2),R=(t+n+r-i-h-c-a)*g,_=(t-i)*(-j+g),b=h*(-m+j+y-g-M-q+I),z=(-t+i+h)*(m-j+g),C=(i+h)*(-m+j),T=t*m,f=(-t+u+c)*(m-p+M),w=(-t+u)*(p-M),S=(u+c)*(-m+p),d=(t+n+r-h-l-u-c)*M,O=c*(-m+p+y-g-M-q+E),D=(-r+c+a)*(g+q-E),U=(r-a)*(g-E),F=r*q,B=(c+a)*(-q+E),v=(-r+h+l)*(M+q-I),$=(r-l)*(M-I),Y=(h+l)*(-q+I),J=n*y,x=l*E,P=i*p,V=u*j,K=a*I,X=T+F+J,dt=R+z+C+T+D+F+B,yt=T+f+S+d+F+v+Y,ht=_+b+z+T+F+v+$,ut=_+z+C+T+x,ft=F+v+$+Y+P,vt=T+f+w+O+D+U+F,ct=D+U+F+B+V,Nt=T+f+w+S+K;return e.set(0,0,X),e.set(0,1,dt),e.set(0,2,yt),e.set(1,0,ht),e.set(1,1,ut),e.set(1,2,ft),e.set(2,0,vt),e.set(2,1,ct),e.set(2,2,Nt),e}mmulStrassen(o){o=k.checkMatrix(o);let e=this.clone(),t=e.rows,n=e.columns,r=o.rows,i=o.columns;n!==r&&console.warn(`Multiplying ${t} x ${n} and ${r} x ${i} matrix: dimensions do not match.`);function h(a,m,j){let p=a.rows,y=a.columns;if(p===m&&y===j)return a;{let g=N.zeros(m,j);return g=g.setSubMatrix(a,0,0),g}}let l=Math.max(t,r),u=Math.max(n,i);e=h(e,l,u),o=h(o,l,u);function c(a,m,j,p){if(j<=512||p<=512)return a.mmul(m);j%2===1&&p%2===1?(a=h(a,j+1,p+1),m=h(m,j+1,p+1)):j%2===1?(a=h(a,j+1,p),m=h(m,j+1,p)):p%2===1&&(a=h(a,j,p+1),m=h(m,j,p+1));let y=parseInt(a.rows/2,10),g=parseInt(a.columns/2,10),M=a.subMatrix(0,y-1,0,g-1),q=m.subMatrix(0,y-1,0,g-1),E=a.subMatrix(0,y-1,g,a.columns-1),I=m.subMatrix(0,y-1,g,m.columns-1),R=a.subMatrix(y,a.rows-1,0,g-1),_=m.subMatrix(y,m.rows-1,0,g-1),b=a.subMatrix(y,a.rows-1,g,a.columns-1),z=m.subMatrix(y,m.rows-1,g,m.columns-1),C=c(N.add(M,b),N.add(q,z),y,g),T=c(N.add(R,b),q,y,g),f=c(M,N.sub(I,z),y,g),w=c(b,N.sub(_,q),y,g),S=c(N.add(M,E),z,y,g),d=c(N.sub(R,M),N.add(q,I),y,g),O=c(N.sub(E,b),N.add(_,z),y,g),D=N.add(C,w);D.sub(S),D.add(O);let U=N.add(f,S),F=N.add(T,w),B=N.sub(C,T);B.add(f),B.add(d);let v=N.zeros(2*D.rows,2*D.columns);return v=v.setSubMatrix(D,0,0),v=v.setSubMatrix(U,D.rows,0),v=v.setSubMatrix(F,0,D.columns),v=v.setSubMatrix(B,D.rows,D.columns),v.subMatrix(0,j-1,0,p-1)}return c(e,o,l,u)}scaleRows(o={}){if(typeof o!="object")throw new TypeError("options must be an object");let{min:e=0,max:t=1}=o;if(!Number.isFinite(e))throw new TypeError("min must be a number");if(!Number.isFinite(t))throw new TypeError("max must be a number");if(e>=t)throw new RangeError("min must be smaller than max");let n=new k(this.rows,this.columns);for(let r=0;r<this.rows;r++){let i=this.getRow(r);i.length>0&&Dt(i,{min:e,max:t,output:i}),n.setRow(r,i)}return n}scaleColumns(o={}){if(typeof o!="object")throw new TypeError("options must be an object");let{min:e=0,max:t=1}=o;if(!Number.isFinite(e))throw new TypeError("min must be a number");if(!Number.isFinite(t))throw new TypeError("max must be a number");if(e>=t)throw new RangeError("min must be smaller than max");let n=new k(this.rows,this.columns);for(let r=0;r<this.columns;r++){let i=this.getColumn(r);i.length&&Dt(i,{min:e,max:t,output:i}),n.setColumn(r,i)}return n}flipRows(){let o=Math.ceil(this.columns/2);for(let e=0;e<this.rows;e++)for(let t=0;t<o;t++){let n=this.get(e,t),r=this.get(e,this.columns-1-t);this.set(e,t,r),this.set(e,this.columns-1-t,n)}return this}flipColumns(){let o=Math.ceil(this.rows/2);for(let e=0;e<this.columns;e++)for(let t=0;t<o;t++){let n=this.get(t,e),r=this.get(this.rows-1-t,e);this.set(t,e,r),this.set(this.rows-1-t,e,n)}return this}kroneckerProduct(o){o=k.checkMatrix(o);let e=this.rows,t=this.columns,n=o.rows,r=o.columns,i=new k(e*n,t*r);for(let h=0;h<e;h++)for(let l=0;l<t;l++)for(let u=0;u<n;u++)for(let c=0;c<r;c++)i.set(n*h+u,r*l+c,this.get(h,l)*o.get(u,c));return i}kroneckerSum(o){if(o=k.checkMatrix(o),!this.isSquare()||!o.isSquare())throw new Error("Kronecker Sum needs two Square Matrices");let e=this.rows,t=o.rows,n=this.kroneckerProduct(k.eye(t,t)),r=k.eye(e,e).kroneckerProduct(o);return n.add(r)}transpose(){let o=new k(this.columns,this.rows);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)o.set(t,e,this.get(e,t));return o}sortRows(o=me){for(let e=0;e<this.rows;e++)this.setRow(e,this.getRow(e).sort(o));return this}sortColumns(o=me){for(let e=0;e<this.columns;e++)this.setColumn(e,this.getColumn(e).sort(o));return this}subMatrix(o,e,t,n){Pt(this,o,e,t,n);let r=new k(e-o+1,n-t+1);for(let i=o;i<=e;i++)for(let h=t;h<=n;h++)r.set(i-o,h-t,this.get(i,h));return r}subMatrixRow(o,e,t){if(e===void 0&&(e=0),t===void 0&&(t=this.columns-1),e>t||e<0||e>=this.columns||t<0||t>=this.columns)throw new RangeError("Argument out of range");let n=new k(o.length,t-e+1);for(let r=0;r<o.length;r++)for(let i=e;i<=t;i++){if(o[r]<0||o[r]>=this.rows)throw new RangeError(`Row index out of range: ${o[r]}`);n.set(r,i-e,this.get(o[r],i))}return n}subMatrixColumn(o,e,t){if(e===void 0&&(e=0),t===void 0&&(t=this.rows-1),e>t||e<0||e>=this.rows||t<0||t>=this.rows)throw new RangeError("Argument out of range");let n=new k(t-e+1,o.length);for(let r=0;r<o.length;r++)for(let i=e;i<=t;i++){if(o[r]<0||o[r]>=this.columns)throw new RangeError(`Column index out of range: ${o[r]}`);n.set(i-e,r,this.get(i,o[r]))}return n}setSubMatrix(o,e,t){if(o=k.checkMatrix(o),o.isEmpty())return this;let n=e+o.rows-1,r=t+o.columns-1;Pt(this,e,n,t,r);for(let i=0;i<o.rows;i++)for(let h=0;h<o.columns;h++)this.set(e+i,t+h,o.get(i,h));return this}selection(o,e){Kt(this,o),Jt(this,e);let t=new k(o.length,e.length);for(let n=0;n<o.length;n++){let r=o[n];for(let i=0;i<e.length;i++){let h=e[i];t.set(n,i,this.get(r,h))}}return t}trace(){let o=Math.min(this.rows,this.columns),e=0;for(let t=0;t<o;t++)e+=this.get(t,t);return e}clone(){let o=new k(this.rows,this.columns);for(let e=0;e<this.rows;e++)for(let t=0;t<this.columns;t++)o.set(e,t,this.get(e,t));return o}sum(o){switch(o){case"row":return Wt(this);case"column":return Gt(this);case void 0:return Qt(this);default:throw new Error(`invalid option: ${o}`)}}product(o){switch(o){case"row":return Zt(this);case"column":return At(this);case void 0:return te(this);default:throw new Error(`invalid option: ${o}`)}}mean(o){let e=this.sum(o);switch(o){case"row":{for(let t=0;t<this.rows;t++)e[t]/=this.columns;return e}case"column":{for(let t=0;t<this.columns;t++)e[t]/=this.rows;return e}case void 0:return e/this.size;default:throw new Error(`invalid option: ${o}`)}}variance(o,e={}){if(typeof o=="object"&&(e=o,o=void 0),typeof e!="object")throw new TypeError("options must be an object");let{unbiased:t=!0,mean:n=this.mean(o)}=e;if(typeof t!="boolean")throw new TypeError("unbiased must be a boolean");switch(o){case"row":{if(!H(n))throw new TypeError("mean must be an array");return ee(this,t,n)}case"column":{if(!H(n))throw new TypeError("mean must be an array");return oe(this,t,n)}case void 0:{if(typeof n!="number")throw new TypeError("mean must be a number");return ne(this,t,n)}default:throw new Error(`invalid option: ${o}`)}}standardDeviation(o,e){typeof o=="object"&&(e=o,o=void 0);let t=this.variance(o,e);if(o===void 0)return Math.sqrt(t);for(let n=0;n<t.length;n++)t[n]=Math.sqrt(t[n]);return t}center(o,e={}){if(typeof o=="object"&&(e=o,o=void 0),typeof e!="object")throw new TypeError("options must be an object");let{center:t=this.mean(o)}=e;switch(o){case"row":{if(!H(t))throw new TypeError("center must be an array");return se(this,t),this}case"column":{if(!H(t))throw new TypeError("center must be an array");return re(this,t),this}case void 0:{if(typeof t!="number")throw new TypeError("center must be a number");return ie(this,t),this}default:throw new Error(`invalid option: ${o}`)}}scale(o,e={}){if(typeof o=="object"&&(e=o,o=void 0),typeof e!="object")throw new TypeError("options must be an object");let t=e.scale;switch(o){case"row":{if(t===void 0)t=le(this);else if(!H(t))throw new TypeError("scale must be an array");return he(this,t),this}case"column":{if(t===void 0)t=ue(this);else if(!H(t))throw new TypeError("scale must be an array");return fe(this,t),this}case void 0:{if(t===void 0)t=ce(this);else if(typeof t!="number")throw new TypeError("scale must be a number");return ae(this,t),this}default:throw new Error(`invalid option: ${o}`)}}toString(o){return Tt(this,o)}};N.prototype.klass="Matrix";typeof Symbol!="undefined"&&(N.prototype[Symbol.for("nodejs.util.inspect.custom")]=Bt);function me(s,o){return s-o}function Ve(s){return s.every(o=>typeof o=="number")}N.random=N.rand;N.randomInt=N.randInt;N.diagonal=N.diag;N.prototype.diagonal=N.prototype.diag;N.identity=N.eye;N.prototype.negate=N.prototype.neg;N.prototype.tensorProduct=N.prototype.kroneckerProduct;var k=class extends N{constructor(o,e){if(super(),k.isMatrix(o))return o.clone();if(Number.isInteger(o)&&o>=0)if(this.data=[],Number.isInteger(e)&&e>=0)for(let t=0;t<o;t++)this.data.push(new Float64Array(e));else throw new TypeError("nColumns must be a positive integer");else if(H(o)){let t=o;if(o=t.length,e=o?t[0].length:0,typeof e!="number")throw new TypeError("Data must be a 2D array with at least one element");this.data=[];for(let n=0;n<o;n++){if(t[n].length!==e)throw new RangeError("Inconsistent array dimensions");if(!Ve(t[n]))throw new TypeError("Input data contains non-numeric values");this.data.push(Float64Array.from(t[n]))}}else throw new TypeError("First argument must be a positive number or an array");this.rows=o,this.columns=e}set(o,e,t){return this.data[o][e]=t,this}get(o,e){return this.data[o][e]}removeRow(o){return Z(this,o),this.data.splice(o,1),this.rows-=1,this}addRow(o,e){return e===void 0&&(e=o,o=this.rows),Z(this,o,!0),e=Float64Array.from(et(this,e)),this.data.splice(o,0,e),this.rows+=1,this}removeColumn(o){A(this,o);for(let e=0;e<this.rows;e++){let t=new Float64Array(this.columns-1);for(let n=0;n<o;n++)t[n]=this.data[e][n];for(let n=o+1;n<this.columns;n++)t[n-1]=this.data[e][n];this.data[e]=t}return this.columns-=1,this}addColumn(o,e){typeof e=="undefined"&&(e=o,o=this.columns),A(this,o,!0),e=ot(this,e);for(let t=0;t<this.rows;t++){let n=new Float64Array(this.columns+1),r=0;for(;r<o;r++)n[r]=this.data[t][r];for(n[r++]=e[t];r<this.columns+1;r++)n[r]=this.data[t][r-1];this.data[t]=n}return this.columns+=1,this}};Yt(N,k);var Q=class extends N{constructor(o){super(),this.data=o,this.rows=o.length,this.columns=o[0].length}set(o,e,t){return this.data[o][e]=t,this}get(o,e){return this.data[o][e]}};var gt=class{constructor(o){o=Q.checkMatrix(o);let e=o.clone(),t=e.rows,n=e.columns,r=new Float64Array(t),i=1,h,l,u,c,a,m,j,p,y;for(h=0;h<t;h++)r[h]=h;for(p=new Float64Array(t),l=0;l<n;l++){for(h=0;h<t;h++)p[h]=e.get(h,l);for(h=0;h<t;h++){for(y=Math.min(h,l),a=0,u=0;u<y;u++)a+=e.get(h,u)*p[u];p[h]-=a,e.set(h,l,p[h])}for(c=l,h=l+1;h<t;h++)Math.abs(p[h])>Math.abs(p[c])&&(c=h);if(c!==l){for(u=0;u<n;u++)m=e.get(c,u),e.set(c,u,e.get(l,u)),e.set(l,u,m);j=r[c],r[c]=r[l],r[l]=j,i=-i}if(l<t&&e.get(l,l)!==0)for(h=l+1;h<t;h++)e.set(h,l,e.get(h,l)/e.get(l,l))}this.LU=e,this.pivotVector=r,this.pivotSign=i}isSingular(){let o=this.LU,e=o.columns;for(let t=0;t<e;t++)if(o.get(t,t)===0)return!0;return!1}solve(o){o=k.checkMatrix(o);let e=this.LU;if(e.rows!==o.rows)throw new Error("Invalid matrix dimensions");if(this.isSingular())throw new Error("LU matrix is singular");let n=o.columns,r=o.subMatrixRow(this.pivotVector,0,n-1),i=e.columns,h,l,u;for(u=0;u<i;u++)for(h=u+1;h<i;h++)for(l=0;l<n;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u));for(u=i-1;u>=0;u--){for(l=0;l<n;l++)r.set(u,l,r.get(u,l)/e.get(u,u));for(h=0;h<u;h++)for(l=0;l<n;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u))}return r}get determinant(){let o=this.LU;if(!o.isSquare())throw new Error("Matrix must be square");let e=this.pivotSign,t=o.columns;for(let n=0;n<t;n++)e*=o.get(n,n);return e}get lowerTriangularMatrix(){let o=this.LU,e=o.rows,t=o.columns,n=new k(e,t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)r>i?n.set(r,i,o.get(r,i)):r===i?n.set(r,i,1):n.set(r,i,0);return n}get upperTriangularMatrix(){let o=this.LU,e=o.rows,t=o.columns,n=new k(e,t);for(let r=0;r<e;r++)for(let i=0;i<t;i++)r<=i?n.set(r,i,o.get(r,i)):n.set(r,i,0);return n}get pivotPermutationVector(){return Array.from(this.pivotVector)}};function tt(s,o){let e=0;return Math.abs(s)>Math.abs(o)?(e=o/s,Math.abs(s)*Math.sqrt(1+e*e)):o!==0?(e=s/o,Math.abs(o)*Math.sqrt(1+e*e)):0}var pt=class{constructor(o){o=Q.checkMatrix(o);let e=o.clone(),t=o.rows,n=o.columns,r=new Float64Array(n),i,h,l,u;for(l=0;l<n;l++){let c=0;for(i=l;i<t;i++)c=tt(c,e.get(i,l));if(c!==0){for(e.get(l,l)<0&&(c=-c),i=l;i<t;i++)e.set(i,l,e.get(i,l)/c);for(e.set(l,l,e.get(l,l)+1),h=l+1;h<n;h++){for(u=0,i=l;i<t;i++)u+=e.get(i,l)*e.get(i,h);for(u=-u/e.get(l,l),i=l;i<t;i++)e.set(i,h,e.get(i,h)+u*e.get(i,l))}}r[l]=-c}this.QR=e,this.Rdiag=r}solve(o){o=k.checkMatrix(o);let e=this.QR,t=e.rows;if(o.rows!==t)throw new Error("Matrix row dimensions must agree");if(!this.isFullRank())throw new Error("Matrix is rank deficient");let n=o.columns,r=o.clone(),i=e.columns,h,l,u,c;for(u=0;u<i;u++)for(l=0;l<n;l++){for(c=0,h=u;h<t;h++)c+=e.get(h,u)*r.get(h,l);for(c=-c/e.get(u,u),h=u;h<t;h++)r.set(h,l,r.get(h,l)+c*e.get(h,u))}for(u=i-1;u>=0;u--){for(l=0;l<n;l++)r.set(u,l,r.get(u,l)/this.Rdiag[u]);for(h=0;h<u;h++)for(l=0;l<n;l++)r.set(h,l,r.get(h,l)-r.get(u,l)*e.get(h,u))}return r.subMatrix(0,i-1,0,n-1)}isFullRank(){let o=this.QR.columns;for(let e=0;e<o;e++)if(this.Rdiag[e]===0)return!1;return!0}get upperTriangularMatrix(){let o=this.QR,e=o.columns,t=new k(e,e),n,r;for(n=0;n<e;n++)for(r=0;r<e;r++)n<r?t.set(n,r,o.get(n,r)):n===r?t.set(n,r,this.Rdiag[n]):t.set(n,r,0);return t}get orthogonalMatrix(){let o=this.QR,e=o.rows,t=o.columns,n=new k(e,t),r,i,h,l;for(h=t-1;h>=0;h--){for(r=0;r<e;r++)n.set(r,h,0);for(n.set(h,h,1),i=h;i<t;i++)if(o.get(h,h)!==0){for(l=0,r=h;r<e;r++)l+=o.get(r,h)*n.get(r,i);for(l=-l/o.get(h,h),r=h;r<e;r++)n.set(r,i,n.get(r,i)+l*o.get(r,h))}}return n}};var lt=class{constructor(o,e={}){if(o=Q.checkMatrix(o),o.isEmpty())throw new Error("Matrix must be non-empty");let t=o.rows,n=o.columns,{computeLeftSingularVectors:r=!0,computeRightSingularVectors:i=!0,autoTranspose:h=!1}=e,l=!!r,u=!!i,c=!1,a;if(t<n)if(!h)a=o.clone(),console.warn("Computing SVD on a matrix with more columns than rows. Consider enabling autoTranspose");else{a=o.transpose(),t=a.rows,n=a.columns,c=!0;let f=l;l=u,u=f}else a=o.clone();let m=Math.min(t,n),j=Math.min(t+1,n),p=new Float64Array(j),y=new k(t,m),g=new k(n,n),M=new Float64Array(n),q=new Float64Array(t),E=new Float64Array(j);for(let f=0;f<j;f++)E[f]=f;let I=Math.min(t-1,n),R=Math.max(0,Math.min(n-2,t)),_=Math.max(I,R);for(let f=0;f<_;f++){if(f<I){p[f]=0;for(let w=f;w<t;w++)p[f]=tt(p[f],a.get(w,f));if(p[f]!==0){a.get(f,f)<0&&(p[f]=-p[f]);for(let w=f;w<t;w++)a.set(w,f,a.get(w,f)/p[f]);a.set(f,f,a.get(f,f)+1)}p[f]=-p[f]}for(let w=f+1;w<n;w++){if(f<I&&p[f]!==0){let S=0;for(let d=f;d<t;d++)S+=a.get(d,f)*a.get(d,w);S=-S/a.get(f,f);for(let d=f;d<t;d++)a.set(d,w,a.get(d,w)+S*a.get(d,f))}M[w]=a.get(f,w)}if(l&&f<I)for(let w=f;w<t;w++)y.set(w,f,a.get(w,f));if(f<R){M[f]=0;for(let w=f+1;w<n;w++)M[f]=tt(M[f],M[w]);if(M[f]!==0){M[f+1]<0&&(M[f]=0-M[f]);for(let w=f+1;w<n;w++)M[w]/=M[f];M[f+1]+=1}if(M[f]=-M[f],f+1<t&&M[f]!==0){for(let w=f+1;w<t;w++)q[w]=0;for(let w=f+1;w<t;w++)for(let S=f+1;S<n;S++)q[w]+=M[S]*a.get(w,S);for(let w=f+1;w<n;w++){let S=-M[w]/M[f+1];for(let d=f+1;d<t;d++)a.set(d,w,a.get(d,w)+S*q[d])}}if(u)for(let w=f+1;w<n;w++)g.set(w,f,M[w])}}let b=Math.min(n,t+1);if(I<n&&(p[I]=a.get(I,I)),t<b&&(p[b-1]=0),R+1<b&&(M[R]=a.get(R,b-1)),M[b-1]=0,l){for(let f=I;f<m;f++){for(let w=0;w<t;w++)y.set(w,f,0);y.set(f,f,1)}for(let f=I-1;f>=0;f--)if(p[f]!==0){for(let w=f+1;w<m;w++){let S=0;for(let d=f;d<t;d++)S+=y.get(d,f)*y.get(d,w);S=-S/y.get(f,f);for(let d=f;d<t;d++)y.set(d,w,y.get(d,w)+S*y.get(d,f))}for(let w=f;w<t;w++)y.set(w,f,-y.get(w,f));y.set(f,f,1+y.get(f,f));for(let w=0;w<f-1;w++)y.set(w,f,0)}else{for(let w=0;w<t;w++)y.set(w,f,0);y.set(f,f,1)}}if(u)for(let f=n-1;f>=0;f--){if(f<R&&M[f]!==0)for(let w=f+1;w<n;w++){let S=0;for(let d=f+1;d<n;d++)S+=g.get(d,f)*g.get(d,w);S=-S/g.get(f+1,f);for(let d=f+1;d<n;d++)g.set(d,w,g.get(d,w)+S*g.get(d,f))}for(let w=0;w<n;w++)g.set(w,f,0);g.set(f,f,1)}let z=b-1,C=0,T=Number.EPSILON;for(;b>0;){let f,w;for(f=b-2;f>=-1&&f!==-1;f--){let S=Number.MIN_VALUE+T*Math.abs(p[f]+Math.abs(p[f+1]));if(Math.abs(M[f])<=S||Number.isNaN(M[f])){M[f]=0;break}}if(f===b-2)w=4;else{let S;for(S=b-1;S>=f&&S!==f;S--){let d=(S!==b?Math.abs(M[S]):0)+(S!==f+1?Math.abs(M[S-1]):0);if(Math.abs(p[S])<=T*d){p[S]=0;break}}S===f?w=3:S===b-1?w=1:(w=2,f=S)}switch(f++,w){case 1:{let S=M[b-2];M[b-2]=0;for(let d=b-2;d>=f;d--){let O=tt(p[d],S),D=p[d]/O,U=S/O;if(p[d]=O,d!==f&&(S=-U*M[d-1],M[d-1]=D*M[d-1]),u)for(let F=0;F<n;F++)O=D*g.get(F,d)+U*g.get(F,b-1),g.set(F,b-1,-U*g.get(F,d)+D*g.get(F,b-1)),g.set(F,d,O)}break}case 2:{let S=M[f-1];M[f-1]=0;for(let d=f;d<b;d++){let O=tt(p[d],S),D=p[d]/O,U=S/O;if(p[d]=O,S=-U*M[d],M[d]=D*M[d],l)for(let F=0;F<t;F++)O=D*y.get(F,d)+U*y.get(F,f-1),y.set(F,f-1,-U*y.get(F,d)+D*y.get(F,f-1)),y.set(F,d,O)}break}case 3:{let S=Math.max(Math.abs(p[b-1]),Math.abs(p[b-2]),Math.abs(M[b-2]),Math.abs(p[f]),Math.abs(M[f])),d=p[b-1]/S,O=p[b-2]/S,D=M[b-2]/S,U=p[f]/S,F=M[f]/S,B=((O+d)*(O-d)+D*D)/2,v=d*D*(d*D),$=0;(B!==0||v!==0)&&(B<0?$=0-Math.sqrt(B*B+v):$=Math.sqrt(B*B+v),$=v/(B+$));let Y=(U+d)*(U-d)+$,J=U*F;for(let x=f;x<b-1;x++){let P=tt(Y,J);P===0&&(P=Number.MIN_VALUE);let V=Y/P,K=J/P;if(x!==f&&(M[x-1]=P),Y=V*p[x]+K*M[x],M[x]=V*M[x]-K*p[x],J=K*p[x+1],p[x+1]=V*p[x+1],u)for(let X=0;X<n;X++)P=V*g.get(X,x)+K*g.get(X,x+1),g.set(X,x+1,-K*g.get(X,x)+V*g.get(X,x+1)),g.set(X,x,P);if(P=tt(Y,J),P===0&&(P=Number.MIN_VALUE),V=Y/P,K=J/P,p[x]=P,Y=V*M[x]+K*p[x+1],p[x+1]=-K*M[x]+V*p[x+1],J=K*M[x+1],M[x+1]=V*M[x+1],l&&x<t-1)for(let X=0;X<t;X++)P=V*y.get(X,x)+K*y.get(X,x+1),y.set(X,x+1,-K*y.get(X,x)+V*y.get(X,x+1)),y.set(X,x,P)}M[b-2]=Y,C=C+1;break}case 4:{if(p[f]<=0&&(p[f]=p[f]<0?-p[f]:0,u))for(let S=0;S<=z;S++)g.set(S,f,-g.get(S,f));for(;f<z&&!(p[f]>=p[f+1]);){let S=p[f];if(p[f]=p[f+1],p[f+1]=S,u&&f<n-1)for(let d=0;d<n;d++)S=g.get(d,f+1),g.set(d,f+1,g.get(d,f)),g.set(d,f,S);if(l&&f<t-1)for(let d=0;d<t;d++)S=y.get(d,f+1),y.set(d,f+1,y.get(d,f)),y.set(d,f,S);f++}C=0,b--;break}}}if(c){let f=g;g=y,y=f}this.m=t,this.n=n,this.s=p,this.U=y,this.V=g}solve(o){let e=o,t=this.threshold,n=this.s.length,r=k.zeros(n,n);for(let m=0;m<n;m++)Math.abs(this.s[m])<=t?r.set(m,m,0):r.set(m,m,1/this.s[m]);let i=this.U,h=this.rightSingularVectors,l=h.mmul(r),u=h.rows,c=i.rows,a=k.zeros(u,c);for(let m=0;m<u;m++)for(let j=0;j<c;j++){let p=0;for(let y=0;y<n;y++)p+=l.get(m,y)*i.get(j,y);a.set(m,j,p)}return a.mmul(e)}solveForDiagonal(o){return this.solve(k.diag(o))}inverse(){let o=this.V,e=this.threshold,t=o.rows,n=o.columns,r=new k(t,this.s.length);for(let c=0;c<t;c++)for(let a=0;a<n;a++)Math.abs(this.s[a])>e&&r.set(c,a,o.get(c,a)/this.s[a]);let i=this.U,h=i.rows,l=i.columns,u=new k(t,h);for(let c=0;c<t;c++)for(let a=0;a<h;a++){let m=0;for(let j=0;j<l;j++)m+=r.get(c,j)*i.get(a,j);u.set(c,a,m)}return u}get condition(){return this.s[0]/this.s[Math.min(this.m,this.n)-1]}get norm2(){return this.s[0]}get rank(){let o=Math.max(this.m,this.n)*this.s[0]*Number.EPSILON,e=0,t=this.s;for(let n=0,r=t.length;n<r;n++)t[n]>o&&e++;return e}get diagonal(){return Array.from(this.s)}get threshold(){return Number.EPSILON/2*Math.max(this.m,this.n)*this.s[0]}get leftSingularVectors(){return this.U}get rightSingularVectors(){return this.V}get diagonalMatrix(){return k.diag(this.s)}};function st(s,o=!1){return s=Q.checkMatrix(s),o?new lt(s).inverse():ge(s,k.eye(s.rows))}function ge(s,o,e=!1){return s=Q.checkMatrix(s),o=Q.checkMatrix(o),e?new lt(s).solve(o):s.isSquare()?new gt(s).solve(o):new pt(s).solve(o)}var pe=()=>({seed:1234,arrayShuffle(o){let{arr:e,sampleSize:t}=o;for(let n=0;n<t;n++){this.seed=(214013*this.seed+2531011)%-2147483648;let r=this.seed>>16&32767;r=r%e.length;let i=e[n];e[n]=e[r],e[r]=i}},nextInt(o){this.seed=(214013*this.seed+2531011)%-2147483648;let e=this.seed>>16&32767;return e=e%o,e}});var G=(s,o,e)=>(o[0]-s[0])*(e[1]-s[1])-(o[1]-s[1])*(e[0]-s[0]),we=(s,o,e,t,n,r,i,h)=>!(G(s,o,e)>0!=G(n,r,i)>0||G(o,e,t)>0!=G(r,i,h)>0||G(e,t,s)>0!=G(i,h,n)>0||G(t,s,o)>0!=G(h,n,r)>0),de=(s,o,e,t,n,r)=>G(s,o,e)>0==G(t,n,r)>0,He=s=>{let o=s[4]*s[8]-s[5]*s[7],e=s[3]*s[8]-s[5]*s[6],t=s[3]*s[7]-s[4]*s[6];return s[0]*o-s[1]*e+s[2]*t},jt=(s,o)=>{let e=He(s);if(Math.abs(e)<=o)return null;let t=1/e;return[(s[4]*s[8]-s[5]*s[7])*t,(s[2]*s[7]-s[1]*s[8])*t,(s[1]*s[5]-s[2]*s[4])*t,(s[5]*s[6]-s[3]*s[8])*t,(s[0]*s[8]-s[2]*s[6])*t,(s[2]*s[3]-s[0]*s[5])*t,(s[3]*s[7]-s[4]*s[6])*t,(s[1]*s[6]-s[0]*s[7])*t,(s[0]*s[4]-s[1]*s[3])*t]};var rt=(s,o)=>{let e=o[6]*s[0]+o[7]*s[1]+o[8],t=[];return t[0]=(o[0]*s[0]+o[1]*s[1]+o[2])/e,t[1]=(o[3]*s[0]+o[4]*s[1]+o[5])/e,t},ye=(s,o,e,t)=>{let n=wt(o,s),r=wt(e,s),i=wt(t,s),h=wt(o,e),l=wt(t,e),u=kt(n,r),c=kt(r,i),a=kt(n,i),m=kt(h,l);return Math.min(Math.min(Math.min(u,c),a),m)},Me=(s,o,e,t)=>{let n=G(s,o,e)<=0;return!(G(o,e,t)<=0!==n||G(e,t,s)<=0!==n||G(t,s,o)<=0!==n)},wt=(s,o)=>[s[0]-o[0],s[1]-o[1]],kt=(s,o)=>{let e=s[0]*o[1]-s[1]*o[0];return Math.abs(e)*.5};var It=(s,o)=>{let{normPoints:e,param:t}=Ee(s),{normPoints:n,param:r}=Ee(o),i=n.length,h=[],l=[];for(let u=0;u<i;u++){let c=[e[u][0],e[u][1],1,0,0,0,-(e[u][0]*n[u][0]),-(e[u][1]*n[u][0])],a=[0,0,0,e[u][0],e[u][1],1,-(e[u][0]*n[u][1]),-(e[u][1]*n[u][1])];h.push(c),h.push(a),l.push([n[u][0]]),l.push([n[u][1]])}try{let u=new k(h),c=new k(l),a=u.transpose(),m=a.mmul(u),j=a.mmul(c),y=st(m).mmul(j).to1DArray();return Be(y,t,r)}catch(u){return null}},Ee=s=>{let o=0,e=0;for(let l=0;l<s.length;l++)o+=s[l][0],e+=s[l][1];let t=o/s.length,n=e/s.length,r=0;for(let l=0;l<s.length;l++){let u=s[l][0]-t,c=s[l][1]-n;r+=Math.sqrt(u*u+c*c)}let i=Math.sqrt(2)*s.length/r,h=[];for(let l=0;l<s.length;l++)h.push([(s[l][0]-t)*i,(s[l][1]-n)*i]);return{normPoints:h,param:{meanX:t,meanY:n,s:i}}},Be=(s,o,e)=>{let t=e.s*e.meanX,n=e.s*e.meanY,r=[s[0]+t*s[6],s[1]+t*s[7],(s[0]+t*s[6])*-o.meanX+(s[1]+t*s[7])*-o.meanY+(s[2]+t)/o.s,s[3]+n*s[6],s[4]+n*s[7],(s[3]+n*s[6])*-o.meanX+(s[4]+n*s[7])*-o.meanY+(s[5]+n)/o.s,e.s*s[6],e.s*s[7],e.s*s[6]*-o.meanX+e.s*s[7]*-o.meanY+e.s/o.s];for(let i=0;i<9;i++)r[i]=r[i]/r[8];return r};var Ye=.01,Ke=10,Je=20,We=10,Ct=s=>{let{srcPoints:o,dstPoints:e,keyframe:t,quickMode:n}=s,r=[[0,0],[t.width,0],[t.width,t.height],[0,t.height]],i=4;if(o.length<i)return null;let h=Ye,l=1/(h*h),u=Math.min(Ke,o.length),c=pe(),a=[];for(let E=0;E<o.length;E++)a[E]=E;c.arrayShuffle({arr:a,sampleSize:a.length});let m=n?We:Je,j=m*2,p=0,y=[];for(;p<j&&y.length<m;){if(p+=1,c.arrayShuffle({arr:a,sampleSize:i}),!we(o[a[0]],o[a[1]],o[a[2]],o[a[3]],e[a[0]],e[a[1]],e[a[2]],e[a[3]]))continue;let E=It([o[a[0]],o[a[1]],o[a[2]],o[a[3]]],[e[a[0]],e[a[1]],e[a[2]],e[a[3]]]);E!==null&&Ae({H:E,testPoints:r})&&y.push(E)}if(y.length===0)return null;let g=[];for(let E=0;E<y.length;E++)g.push({H:y[E],cost:0});let M=u;for(let E=0;E<o.length&&g.length>2;E+=M){M=Math.min(u,o.length-E);let I=E+M;for(let R=0;R<g.length;R++)for(let _=E;_<I;_++){let b=Ze({H:g[R].H,srcPoint:o[_],dstPoint:e[_],oneOverScale2:l});g[R].cost+=b}g.sort((R,_)=>R.cost-_.cost),g.splice(-Math.floor((g.length+1)/2))}let q=null;for(let E=0;E<g.length;E++){let I=Qe({inH:g[E].H});if(Ge({H:I,testPoints:r,keyframe:t})){q=I;break}}return q},Ge=({H:s,testPoints:o,keyframe:e})=>{let t=jt(s,1e-5);if(t===null)return!1;let n=[];for(let i=0;i<o.length;i++)n.push(rt(o[i],t));return!(ye(n[0],n[1],n[2],n[3])<e.width*e.height*1e-4||!Me(n[0],n[1],n[2],n[3]))},Qe=({inH:s})=>{let o=1/s[8],e=[];for(let t=0;t<8;t++)e[t]=s[t]*o;return e[8]=1,e},Ze=({H:s,srcPoint:o,dstPoint:e,oneOverScale2:t})=>{let n=rt(o,s),r=[n[0]-e[0],n[1]-e[1]];return Math.log(1+(r[0]*r[0]+r[1]*r[1])*t)},Ae=({H:s,testPoints:o})=>{let e=[];for(let t=0;t<o.length;t++)e[t]=rt(o[t],s);for(let t=0;t<o.length;t++){let n=t,r=(t+1)%o.length,i=(t+2)%o.length;if(!de(o[n],o[r],o[i],e[n],e[r],e[i]))return!1}return!0};var Se=3,ke=6,to=8,je=.7,be=({keyframe:s,querypoints:o,querywidth:e,queryheight:t,debugMode:n})=>{let r={},i=[];for(let g=0;g<o.length;g++){let M=o[g],q=M.maxima?s.maximaPoints:s.minimaPoints;if(q.length===0)continue;let E=M.maxima?s.maximaPointsCluster.rootNode:s.minimaPointsCluster.rootNode,I=[],R=new at([],(C,T)=>C.d-T.d);Ot({node:E,keypoints:q,querypoint:M,queue:R,keypointIndexes:I,numPop:0});let _=-1,b=Number.MAX_SAFE_INTEGER,z=Number.MAX_SAFE_INTEGER;for(let C=0;C<I.length;C++){let T=q[I[C]],f=Mt({v1:T.descriptors,v2:M.descriptors});f<b?(z=b,b=f,_=I[C]):f<z&&(z=f)}_!==-1&&(z===Number.MAX_SAFE_INTEGER||1*b/z<je)&&i.push({querypoint:M,keypoint:q[_]})}if(n&&(r.matches=i),i.length<ke)return{debugExtra:r};let h=zt({keywidth:s.width,keyheight:s.height,querywidth:e,queryheight:t,matches:i});n&&(r.houghMatches=h);let l=Ct({srcPoints:h.map(g=>[g.keypoint.x,g.keypoint.y]),dstPoints:h.map(g=>[g.querypoint.x,g.querypoint.y]),keyframe:s});if(l===null)return{debugExtra:r};let u=Ie({H:l,matches:h,threshold:Se});if(n&&(r.inlierMatches=u),u.length<ke)return{debugExtra:r};let c=jt(l,1e-5),a=10*10,m=[];for(let g=0;g<o.length;g++){let M=o[g],q=rt([M.x,M.y],c),E=-1,I=Number.MAX_SAFE_INTEGER,R=Number.MAX_SAFE_INTEGER,_=M.maxima?s.maximaPoints:s.minimaPoints;for(let b=0;b<_.length;b++){let z=_[b];if((z.x-q[0])*(z.x-q[0])+(z.y-q[1])*(z.y-q[1])>a)continue;let T=Mt({v1:z.descriptors,v2:M.descriptors});T<I?(R=I,I=T,E=b):T<R&&(R=T)}E!==-1&&(R===Number.MAX_SAFE_INTEGER||1*I/R<je)&&m.push({querypoint:M,keypoint:_[E]})}n&&(r.matches2=m);let j=zt({keywidth:s.width,keyheight:s.height,querywidth:e,queryheight:t,matches:m});n&&(r.houghMatches2=j);let p=Ct({srcPoints:j.map(g=>[g.keypoint.x,g.keypoint.y]),dstPoints:j.map(g=>[g.querypoint.x,g.querypoint.y]),keyframe:s});if(p===null)return{debugExtra:r};let y=Ie({H:p,matches:j,threshold:Se});return n&&(r.inlierMatches2=y),{H:p,matches:y,debugExtra:r}},Ot=({node:s,keypoints:o,querypoint:e,queue:t,keypointIndexes:n,numPop:r})=>{if(s.leaf){for(let l=0;l<s.pointIndexes.length;l++)n.push(s.pointIndexes[l]);return}let i=[];for(let l=0;l<s.children.length;l++){let c=s.children[l].centerPointIndex,a=Mt({v1:o[c].descriptors,v2:e.descriptors});i.push(a)}let h=Number.MAX_SAFE_INTEGER;for(let l=0;l<s.children.length;l++)h=Math.min(h,i[l]);for(let l=0;l<s.children.length;l++)i[l]!==h&&t.push({node:s.children[l],d:i[l]});for(let l=0;l<s.children.length;l++)i[l]===h&&Ot({node:s.children[l],keypoints:o,querypoint:e,queue:t,keypointIndexes:n,numPop:r});if(r<to&&t.length>0){let{node:l,d:u}=t.pop();r+=1,Ot({node:l,keypoints:o,querypoint:e,queue:t,keypointIndexes:n,numPop:r})}},Ie=s=>{let{H:o,matches:e,threshold:t}=s,n=t*t,r=[];for(let i=0;i<e.length;i++){let h=e[i].querypoint,l=e[i].keypoint,u=rt([l.x,l.y],o);(u[0]-h.x)*(u[0]-h.x)+(u[1]-h.y)*(u[1]-h.y)<=n&&r.push(e[i])}return r};var bt=class{constructor(o,e,t=!1){this.queryWidth=o,this.queryHeight=e,this.debugMode=t}matchDetection(o,e){let t={frames:[]},n=null;for(let l=0;l<o.length;l++){let{H:u,matches:c,debugExtra:a}=be({keyframe:o[l],querypoints:e,querywidth:this.queryWidth,queryheight:this.queryHeight,debugMode:this.debugMode});t.frames.push(a),u&&(n===null||n.matches.length<c.length)&&(n={keyframeIndex:l,H:u,matches:c})}if(n===null)return{keyframeIndex:-1,debugExtra:t};let r=[],i=[],h=o[n.keyframeIndex];for(let l=0;l<n.matches.length;l++){let u=n.matches[l].querypoint,c=n.matches[l].keypoint;r.push({x:u.x,y:u.y}),i.push({x:(c.x+.5)/h.scale,y:(c.y+.5)/h.scale,z:0})}return{screenCoords:r,worldCoords:i,keyframeIndex:n.keyframeIndex,debugExtra:t}}};var Re=({screenCoords:s,worldCoords:o,projectionTransform:e})=>{let t=It(o.map(g=>[g.x,g.y]),s.map(g=>[g.x,g.y])),n=new k([[t[0],t[1],t[2]],[t[3],t[4],t[5]],[t[6],t[7],t[8]]]),r=new k(e),l=st(r).mmul(n).to1DArray(),u=Math.sqrt(l[0]*l[0]+l[3]*l[3]+l[6]*l[6]),c=Math.sqrt(l[1]*l[1]+l[4]*l[4]+l[7]*l[7]),a=(u+c)/2,m=[];m[0]=l[0]/u,m[3]=l[3]/u,m[6]=l[6]/u,m[1]=l[1]/c,m[4]=l[4]/c,m[7]=l[7]/c,m[2]=m[3]*m[7]-m[6]*m[4],m[5]=m[6]*m[1]-m[0]*m[7],m[8]=m[0]*m[4]-m[1]*m[3];let j=Math.sqrt(m[2]*m[2]+m[5]*m[5]+m[8]*m[8]);m[2]/=j,m[5]/=j,m[8]/=j;let p=[];return p[0]=l[2]/a,p[1]=l[5]/a,p[2]=l[8]/a,[[m[0],m[1],m[2],p[0]],[m[3],m[4],m[5],p[1]],[m[6],m[7],m[8],p[2]]]};var ve=(s,o)=>[[s[0][0]*o[0][0]+s[0][2]*o[2][0],s[0][0]*o[0][1]+s[0][2]*o[2][1],s[0][0]*o[0][2]+s[0][2]*o[2][2],s[0][0]*o[0][3]+s[0][2]*o[2][3]],[s[1][1]*o[1][0]+s[1][2]*o[2][0],s[1][1]*o[1][1]+s[1][2]*o[2][1],s[1][1]*o[1][2]+s[1][2]*o[2][2],s[1][1]*o[1][3]+s[1][2]*o[2][3]],[o[2][0],o[2][1],o[2][2],o[2][3]]],Xt=(s,o,e,t)=>{let n=s[0][0]*o+s[0][1]*e+s[0][3],r=s[1][0]*o+s[1][1]*e+s[1][3],i=s[2][0]*o+s[2][1]*e+s[2][3];return{x:n,y:r,z:i}},Ne=(s,o,e,t)=>{let{x:n,y:r,z:i}=Xt(s,o,e,t);return{x:n/i,y:r/i}};var eo=5,oo=4,xe=10,no=.1,so=.99;var W=[[],[],[]],it=[[],[]],L=[[],[],[]],_e=({initialModelViewTransform:s,projectionTransform:o,worldCoords:e,screenCoords:t})=>{let n=0,r=0;for(let a=0;a<e.length;a++)n+=e[a].x,r+=e[a].y;n/=e.length,r/=e.length;let i=[];for(let a=0;a<e.length;a++)i.push({x:e[a].x-n,y:e[a].y-r,z:e[a].z});let h=[[],[],[]];for(let a=0;a<3;a++)for(let m=0;m<3;m++)h[a][m]=s[a][m];h[0][3]=s[0][0]*n+s[0][1]*r+s[0][3],h[1][3]=s[1][0]*n+s[1][1]*r+s[1][3],h[2][3]=s[2][0]*n+s[2][1]*r+s[2][3];let l=[1,.8,.6,.4,0],u=h,c=null;for(let a=0;a<l.length;a++){let m=ro({initialModelViewTransform:u,projectionTransform:o,worldCoords:i,screenCoords:t,inlierProb:l[a]});if(u=m.modelViewTransform,m.err<eo){c=u;break}}return c===null?null:(c[0][3]=c[0][3]-c[0][0]*n-c[0][1]*r,c[1][3]=c[1][3]-c[1][0]*n-c[1][1]*r,c[2][3]=c[2][3]-c[2][0]*n-c[2][1]*r,c)},ro=({initialModelViewTransform:s,projectionTransform:o,worldCoords:e,screenCoords:t,inlierProb:n})=>{let r=n<1,i=s,h=0,l=0,u=new Array(e.length),c=new Array(e.length),a=new Array(e.length),m=new Array(e.length);for(let j=0;j<=xe;j++){let p=ve(o,i);for(let E=0;E<e.length;E++){let I=Ne(p,e[E].x,e[E].y,e[E].z),R=t[E].x-I.x,_=t[E].y-I.y;a[E]=R,m[E]=_,u[E]=R*R+_*_}let y;if(l=0,r){let E=Math.max(3,Math.floor(e.length*n)-1);for(let I=0;I<e.length;I++)c[I]=u[I];c.sort((I,R)=>I-R),y=Math.max(c[E]*oo,16);for(let I=0;I<e.length;I++)c[I]>y?l+=y/6:l+=y/6*(1-(1-c[I]/y)*(1-c[I]/y)*(1-c[I]/y))}else for(let E=0;E<e.length;E++)l+=u[E];if(l/=e.length,l<no||j>0&&l/h>so||j===xe)break;h=l;let g=[],M=[];for(let E=0;E<e.length;E++){if(r&&u[E]>y)continue;let I=ho({modelViewProjectionTransform:p,modelViewTransform:i,projectionTransform:o,worldCoord:e[E]});if(r){let R=(1-u[E]/y)*(1-u[E]/y);for(let _=0;_<2;_++)for(let b=0;b<6;b++)I[_][b]*=R;g.push([a[E]*R]),g.push([m[E]*R])}else g.push([a[E]]),g.push([m[E]]);for(let R=0;R<I.length;R++)M.push(I[R])}let q=lo({dU:g,J_U_S:M});if(q===null)break;i=io({modelViewTransform:i,dS:q})}return{modelViewTransform:i,err:l}},io=({modelViewTransform:s,dS:o})=>{let e=o[0]*o[0]+o[1]*o[1]+o[2]*o[2],t,n,r;e<1e-6?(t=1,n=0,r=0,e=0):(e=Math.sqrt(e),t=o[0]/e,n=o[1]/e,r=o[2]/e);let i=Math.cos(e),h=Math.sin(e),l=1-i;W[0][0]=t*t*l+i,W[0][1]=t*n*l-r*h,W[0][2]=t*r*l+n*h,W[0][3]=o[3],W[1][0]=n*t*l+r*h,W[1][1]=n*n*l+i,W[1][2]=n*r*l-t*h,W[1][3]=o[4],W[2][0]=r*t*l-n*h,W[2][1]=r*n*l+t*h,W[2][2]=r*r*l+i,W[2][3]=o[5];let u=[[],[],[]];for(let c=0;c<3;c++){for(let a=0;a<4;a++)u[c][a]=s[c][0]*W[0][a]+s[c][1]*W[1][a]+s[c][2]*W[2][a];u[c][3]+=s[c][3]}return u},lo=({dU:s,J_U_S:o})=>{let e=new k(o),t=new k(s),n=e.transpose(),r=n.mmul(e),i=n.mmul(t),h;try{h=st(r)}catch(u){return null}return h.mmul(i).to1DArray()},ho=({modelViewProjectionTransform:s,modelViewTransform:o,projectionTransform:e,worldCoord:t})=>{let n=o,{x:r,y:i,z:h}=t,l=Xt(s,r,i,h),u=l.z*l.z;it[0][0]=e[0][0]*l.z/u,it[0][1]=e[0][1]*l.z/u,it[0][2]=(e[0][2]*l.z-e[2][2]*l.x)/u,it[1][0]=e[1][0]*l.z/u,it[1][1]=e[1][1]*l.z/u,it[1][2]=(e[1][2]*l.z-e[2][2]*l.y)/u,L[0][0]=n[0][2]*i,L[0][1]=-n[0][2]*r,L[0][2]=n[0][1]*r-n[0][0]*i,L[0][3]=n[0][0],L[0][4]=n[0][1],L[0][5]=n[0][2],L[1][0]=n[1][2]*i,L[1][1]=-n[1][2]*r,L[1][2]=n[1][1]*r-n[1][0]*i,L[1][3]=n[1][0],L[1][4]=n[1][1],L[1][5]=n[1][2],L[2][0]=n[2][2]*i,L[2][1]=-n[2][2]*r,L[2][2]=n[2][1]*r-n[2][0]*i,L[2][3]=n[2][0],L[2][4]=n[2][1],L[2][5]=n[2][2];let c=[[],[]];for(let a=0;a<2;a++)for(let m=0;m<6;m++){c[a][m]=0;for(let j=0;j<3;j++)c[a][m]+=it[a][j]*L[j][m]}return c};var Rt=class{constructor(o){this.projectionTransform=o}estimate({screenCoords:o,worldCoords:e}){return Re({screenCoords:o,worldCoords:e,projectionTransform:this.projectionTransform})}refineEstimate({initialModelViewTransform:o,worldCoords:e,screenCoords:t}){return _e({initialModelViewTransform:o,worldCoords:e,screenCoords:t,projectionTransform:this.projectionTransform})}};var uo=null,qe=null,Fe=!1,ze=null,Ut=null;onmessage=s=>{let{data:o}=s;switch(o.type){case"setup":uo=o.projectionTransform,qe=o.matchingDataList,Fe=o.debugMode,ze=new bt(o.inputWidth,o.inputHeight,Fe),Ut=new Rt(o.projectionTransform);break;case"match":let e=o.targetIndexes,t=-1,n=null,r=null;for(let c=0;c<e.length;c++){let a=e[c],{keyframeIndex:m,screenCoords:j,worldCoords:p,debugExtra:y}=ze.matchDetection(qe[a],o.featurePoints);if(r=y,m!==-1){let g=Ut.estimate({screenCoords:j,worldCoords:p});g&&(t=a,n=g);break}}postMessage({type:"matchDone",targetIndex:t,modelViewTransform:n,debugExtra:r});break;case"trackUpdate":let{modelViewTransform:i,worldCoords:h,screenCoords:l}=o,u=Ut.refineEstimate({initialModelViewTransform:i,worldCoords:h,screenCoords:l});postMessage({type:"trackUpdateDone",modelViewTransform:u});break;case"dispose":close();break;default:throw new Error(`Invalid message type \'${o.type}\'`)}};\n');
}
var init_controller_worker = __esm({
  "node_modules/mind-ar/src/image-target/controller.worker.js?worker&inline"() {
    init_inline_worker();
  }
});
var buildModelViewProjectionTransform;
var applyModelViewProjectionTransform;
var computeScreenCoordiate;
var init_utils2 = __esm({
  "node_modules/mind-ar/src/image-target/estimation/utils.js"() {
    buildModelViewProjectionTransform = (projectionTransform, modelViewTransform) => {
      const modelViewProjectionTransform = [
        [
          projectionTransform[0][0] * modelViewTransform[0][0] + projectionTransform[0][2] * modelViewTransform[2][0],
          projectionTransform[0][0] * modelViewTransform[0][1] + projectionTransform[0][2] * modelViewTransform[2][1],
          projectionTransform[0][0] * modelViewTransform[0][2] + projectionTransform[0][2] * modelViewTransform[2][2],
          projectionTransform[0][0] * modelViewTransform[0][3] + projectionTransform[0][2] * modelViewTransform[2][3]
        ],
        [
          projectionTransform[1][1] * modelViewTransform[1][0] + projectionTransform[1][2] * modelViewTransform[2][0],
          projectionTransform[1][1] * modelViewTransform[1][1] + projectionTransform[1][2] * modelViewTransform[2][1],
          projectionTransform[1][1] * modelViewTransform[1][2] + projectionTransform[1][2] * modelViewTransform[2][2],
          projectionTransform[1][1] * modelViewTransform[1][3] + projectionTransform[1][2] * modelViewTransform[2][3]
        ],
        [
          modelViewTransform[2][0],
          modelViewTransform[2][1],
          modelViewTransform[2][2],
          modelViewTransform[2][3]
        ]
      ];
      return modelViewProjectionTransform;
    };
    applyModelViewProjectionTransform = (modelViewProjectionTransform, x, y, z) => {
      const ux = modelViewProjectionTransform[0][0] * x + modelViewProjectionTransform[0][1] * y + modelViewProjectionTransform[0][3];
      const uy = modelViewProjectionTransform[1][0] * x + modelViewProjectionTransform[1][1] * y + modelViewProjectionTransform[1][3];
      const uz = modelViewProjectionTransform[2][0] * x + modelViewProjectionTransform[2][1] * y + modelViewProjectionTransform[2][3];
      return { x: ux, y: uy, z: uz };
    };
    computeScreenCoordiate = (modelViewProjectionTransform, x, y, z) => {
      const { x: ux, y: uy, z: uz } = applyModelViewProjectionTransform(modelViewProjectionTransform, x, y, z);
      return { x: ux / uz, y: uy / uz };
    };
  }
});
var AR2_DEFAULT_TS;
var AR2_DEFAULT_TS_GAP;
var AR2_SEARCH_SIZE;
var AR2_SEARCH_GAP;
var AR2_SIM_THRESH;
var TRACKING_KEYFRAME;
var PRECISION_ADJUST;
var Tracker;
var init_tracker = __esm({
  "node_modules/mind-ar/src/image-target/tracker/tracker.js"() {
    init_dist7();
    init_utils2();
    AR2_DEFAULT_TS = 6;
    AR2_DEFAULT_TS_GAP = 1;
    AR2_SEARCH_SIZE = 10;
    AR2_SEARCH_GAP = 1;
    AR2_SIM_THRESH = 0.8;
    TRACKING_KEYFRAME = 1;
    PRECISION_ADJUST = 1e3;
    Tracker = class {
      constructor(markerDimensions, trackingDataList, projectionTransform, inputWidth, inputHeight, debugMode = false) {
        this.markerDimensions = markerDimensions;
        this.trackingDataList = trackingDataList;
        this.projectionTransform = projectionTransform;
        this.debugMode = debugMode;
        this.trackingKeyframeList = [];
        for (let i = 0; i < trackingDataList.length; i++) {
          this.trackingKeyframeList.push(trackingDataList[i][TRACKING_KEYFRAME]);
        }
        let maxCount = 0;
        for (let i = 0; i < this.trackingKeyframeList.length; i++) {
          maxCount = Math.max(maxCount, this.trackingKeyframeList[i].points.length);
        }
        this.featurePointsListT = [];
        this.imagePixelsListT = [];
        this.imagePropertiesListT = [];
        for (let i = 0; i < this.trackingKeyframeList.length; i++) {
          const { featurePoints, imagePixels, imageProperties } = this._prebuild(this.trackingKeyframeList[i], maxCount);
          this.featurePointsListT[i] = featurePoints;
          this.imagePixelsListT[i] = imagePixels;
          this.imagePropertiesListT[i] = imageProperties;
        }
        this.kernelCaches = {};
      }
      dummyRun(inputT) {
        let transform4 = [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]];
        for (let targetIndex = 0; targetIndex < this.featurePointsListT.length; targetIndex++) {
          this.track(inputT, transform4, targetIndex);
        }
      }
      track(inputImageT, lastModelViewTransform, targetIndex) {
        let debugExtra = {};
        const modelViewProjectionTransform = buildModelViewProjectionTransform(this.projectionTransform, lastModelViewTransform);
        const modelViewProjectionTransformT = this._buildAdjustedModelViewTransform(modelViewProjectionTransform);
        const markerWidth = this.markerDimensions[targetIndex][0];
        const markerHeight = this.markerDimensions[targetIndex][1];
        const keyframeWidth = this.trackingKeyframeList[targetIndex].width;
        const keyframeHeight = this.trackingKeyframeList[targetIndex].height;
        const featurePointsT = this.featurePointsListT[targetIndex];
        const imagePixelsT = this.imagePixelsListT[targetIndex];
        const imagePropertiesT = this.imagePropertiesListT[targetIndex];
        const projectedImageT = this._computeProjection(modelViewProjectionTransformT, inputImageT, targetIndex);
        const { matchingPointsT, simT } = this._computeMatching(featurePointsT, imagePixelsT, imagePropertiesT, projectedImageT);
        const matchingPoints = matchingPointsT.arraySync();
        const sim = simT.arraySync();
        const trackingFrame = this.trackingKeyframeList[targetIndex];
        const worldCoords = [];
        const screenCoords = [];
        const goodTrack = [];
        for (let i = 0; i < matchingPoints.length; i++) {
          if (sim[i] > AR2_SIM_THRESH && i < trackingFrame.points.length) {
            goodTrack.push(i);
            const point = computeScreenCoordiate(modelViewProjectionTransform, matchingPoints[i][0], matchingPoints[i][1]);
            screenCoords.push(point);
            worldCoords.push({ x: trackingFrame.points[i].x / trackingFrame.scale, y: trackingFrame.points[i].y / trackingFrame.scale, z: 0 });
          }
        }
        if (this.debugMode) {
          debugExtra = {
            projectedImage: projectedImageT.arraySync(),
            matchingPoints: matchingPointsT.arraySync(),
            goodTrack,
            trackedPoints: screenCoords
          };
        }
        modelViewProjectionTransformT.dispose();
        projectedImageT.dispose();
        matchingPointsT.dispose();
        simT.dispose();
        return { worldCoords, screenCoords, debugExtra };
      }
      _computeMatching(featurePointsT, imagePixelsT, imagePropertiesT, projectedImageT) {
        const templateOneSize = AR2_DEFAULT_TS;
        const templateSize = templateOneSize * 2 + 1;
        const templateGap = AR2_DEFAULT_TS_GAP;
        const searchOneSize = AR2_SEARCH_SIZE * templateGap;
        const searchGap = AR2_SEARCH_GAP;
        const searchSize = searchOneSize * 2 + 1;
        const targetHeight = projectedImageT.shape[0];
        const targetWidth = projectedImageT.shape[1];
        const featureCount = featurePointsT.shape[0];
        if (!this.kernelCaches.computeMatching) {
          const kernel1 = {
            variableNames: ["features", "markerPixels", "markerProperties", "targetPixels"],
            outputShape: [featureCount, searchSize * searchSize],
            userCode: `
	  void main() {
	    ivec2 coords = getOutputCoords();

	    int featureIndex = coords[0];
	    int searchOffsetIndex = coords[1];

	    int markerWidth = int(getMarkerProperties(0));
	    int markerHeight = int(getMarkerProperties(1));
	    float markerScale = getMarkerProperties(2);

	    int searchOffsetX = imod(searchOffsetIndex, ${searchSize}) * ${searchGap};
	    int searchOffsetY = searchOffsetIndex / ${searchSize} * ${searchGap};

	    int sCenterX = int(getFeatures(featureIndex, 0) * markerScale);
	    int sCenterY = int(getFeatures(featureIndex, 1) * markerScale);

	    int sx = sCenterX + searchOffsetX - ${searchOneSize};
	    int sy = sCenterY + searchOffsetY - ${searchOneSize};

	    if (sx < ${templateOneSize} || sx >= (${targetWidth} - ${templateOneSize}) || sy < ${templateOneSize} || sy >= (${targetHeight} - ${templateOneSize})) {
	      setOutput(-2.);
	    } 
	    else {
	      float sumPoint = 0.;
	      float sumPointSquare = 0.;
	      float sumTemplate = 0.;
	      float sumTemplateSquare = 0.;
	      float sumPointTemplate = 0.;

	      for (int templateOffsetY = 0; templateOffsetY < ${templateSize}; templateOffsetY++) {
		for (int templateOffsetX = 0; templateOffsetX < ${templateSize}; templateOffsetX++) {
		  int fx2 = sCenterX + templateOffsetX - ${templateOneSize};
		  int fy2 = sCenterY + templateOffsetY - ${templateOneSize};

		  int sx2 = sx + templateOffsetX - ${templateOneSize};
		  int sy2 = sy + templateOffsetY - ${templateOneSize};

		  int markerPixelIndex = fy2 * markerWidth + fx2;
		  float markerPixel = getMarkerPixels(markerPixelIndex);
		  float targetPixel = getTargetPixels(sy2, sx2);

		  sumTemplate += markerPixel;
		  sumTemplateSquare += markerPixel * markerPixel;
		  sumPoint += targetPixel;
		  sumPointSquare += targetPixel * targetPixel;
		  sumPointTemplate += targetPixel * markerPixel;
		}
	      }

	      // Normalized cross-correlation
	      // !important divide first avoid overflow (e.g. sumPoint / count * sumPoint)
	      float count = float(${templateSize} * ${templateSize});
	      float pointVariance = sqrt(sumPointSquare - sumPoint / count * sumPoint);
	      float templateVariance = sqrt(sumTemplateSquare - sumTemplate / count * sumTemplate);

	      if (pointVariance < 0.0000001) {
		setOutput(-3.);
	      } else if (templateVariance < 0.0000001) {
		//setOutput(sumTemplate);
		setOutput(-4.);
	      } else {
		sumPointTemplate -= sumPoint / count * sumTemplate;
		float sim = sumPointTemplate / pointVariance / templateVariance;  
		setOutput(sim);
	      }
	    }
	  }
	`
          };
          const kernel2 = {
            variableNames: ["featurePoints", "markerProperties", "maxIndex"],
            outputShape: [featureCount, 2],
            // [x, y]
            userCode: `
	  void main() {
	    ivec2 coords = getOutputCoords();

	    float markerScale = getMarkerProperties(2);

	    int featureIndex = coords[0];

	    int maxIndex = int(getMaxIndex(featureIndex));
	    int searchLocationIndex = maxIndex / ${searchSize * searchSize};
	    int searchOffsetIndex = imod(maxIndex, ${searchSize * searchSize});

	    if (coords[1] == 0) {
	      int searchOffsetX = imod(searchOffsetIndex, ${searchSize}) * ${searchGap};
	      setOutput(getFeaturePoints(featureIndex, 0) + float(searchOffsetX - ${searchOneSize}) / markerScale);
	    }
	    else if (coords[1] == 1) {
	      int searchOffsetY = searchOffsetIndex / ${searchSize} * ${searchGap};
	      setOutput(getFeaturePoints(featureIndex, 1) + float(searchOffsetY - ${searchOneSize}) / markerScale);
	    }
	  }
	`
          };
          const kernel3 = {
            variableNames: ["sims", "maxIndex"],
            outputShape: [featureCount],
            userCode: `
	  void main() {
	    int featureIndex = getOutputCoords();
	    int maxIndex = int(getMaxIndex(featureIndex));
	    setOutput(getSims(featureIndex, maxIndex));
	  }
	`
          };
          this.kernelCaches.computeMatching = [kernel1, kernel2, kernel3];
        }
        return tidy(() => {
          const programs = this.kernelCaches.computeMatching;
          const allSims = this._compileAndRun(programs[0], [featurePointsT, imagePixelsT, imagePropertiesT, projectedImageT]);
          const maxIndex = allSims.argMax(1);
          const matchingPointsT = this._compileAndRun(programs[1], [featurePointsT, imagePropertiesT, maxIndex]);
          const simT = this._compileAndRun(programs[2], [allSims, maxIndex]);
          return { matchingPointsT, simT };
        });
      }
      _computeProjection(modelViewProjectionTransformT, inputImageT, targetIndex) {
        const markerWidth = this.trackingKeyframeList[targetIndex].width;
        const markerHeight = this.trackingKeyframeList[targetIndex].height;
        const markerScale = this.trackingKeyframeList[targetIndex].scale;
        const kernelKey = markerWidth + "-" + markerHeight + "-" + markerScale;
        if (!this.kernelCaches.computeProjection) {
          this.kernelCaches.computeProjection = {};
        }
        if (!this.kernelCaches.computeProjection[kernelKey]) {
          const kernel = {
            variableNames: ["M", "pixel"],
            outputShape: [markerHeight, markerWidth],
            userCode: `
	  void main() {
	      ivec2 coords = getOutputCoords();

	      float m00 = getM(0, 0) * ${PRECISION_ADJUST}.;
	      float m01 = getM(0, 1) * ${PRECISION_ADJUST}.;
	      float m03 = getM(0, 3) * ${PRECISION_ADJUST}.;
	      float m10 = getM(1, 0) * ${PRECISION_ADJUST}.;
	      float m11 = getM(1, 1) * ${PRECISION_ADJUST}.;
	      float m13 = getM(1, 3) * ${PRECISION_ADJUST}.;
	      float m20 = getM(2, 0) * ${PRECISION_ADJUST}.;
	      float m21 = getM(2, 1) * ${PRECISION_ADJUST}.;
	      float m23 = getM(2, 3) * ${PRECISION_ADJUST}.;

	      float y = float(coords[0]) / float(${markerScale});
	      float x = float(coords[1]) / float(${markerScale});
	      float uz = (x * m20) + (y * m21) + m23;
	      float oneOverUz = 1. / uz;

	      float ux = (x * m00) + (y * m01) + m03;
	      float uy = (x * m10) + (y * m11) + m13;

	      ux = floor(ux * oneOverUz + 0.5);
	      uy = floor(uy * oneOverUz + 0.5);
	      setOutput(getPixel(int(uy), int(ux)));
	    }
	`
          };
          this.kernelCaches.computeProjection[kernelKey] = kernel;
        }
        return tidy(() => {
          const program = this.kernelCaches.computeProjection[kernelKey];
          const result = this._compileAndRun(program, [modelViewProjectionTransformT, inputImageT]);
          return result;
        });
      }
      _buildAdjustedModelViewTransform(modelViewProjectionTransform) {
        return tidy(() => {
          let modelViewProjectionTransformAdjusted = [];
          for (let i = 0; i < modelViewProjectionTransform.length; i++) {
            modelViewProjectionTransformAdjusted.push([]);
            for (let j = 0; j < modelViewProjectionTransform[i].length; j++) {
              modelViewProjectionTransformAdjusted[i].push(modelViewProjectionTransform[i][j] / PRECISION_ADJUST);
            }
          }
          const t = tensor(modelViewProjectionTransformAdjusted, [3, 4]);
          return t;
        });
      }
      _prebuild(trackingFrame, maxCount) {
        return tidy(() => {
          const scale22 = trackingFrame.scale;
          const p2 = [];
          for (let k = 0; k < maxCount; k++) {
            if (k < trackingFrame.points.length) {
              p2.push([trackingFrame.points[k].x / scale22, trackingFrame.points[k].y / scale22]);
            } else {
              p2.push([-1, -1]);
            }
          }
          const imagePixels = tensor(trackingFrame.data, [trackingFrame.width * trackingFrame.height]);
          const imageProperties = tensor([trackingFrame.width, trackingFrame.height, trackingFrame.scale], [3]);
          const featurePoints = tensor(p2, [p2.length, 2], "float32");
          return {
            featurePoints,
            imagePixels,
            imageProperties
          };
        });
      }
      _compileAndRun(program, inputs) {
        const outInfo = backend().compileAndRun(program, inputs);
        return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
      }
    };
  }
});
var FREAK_RINGS;
var FREAKPOINTS;
var init_freak = __esm({
  "node_modules/mind-ar/src/image-target/detector/freak.js"() {
    FREAK_RINGS = [
      // ring 5
      {
        sigma: 0.55,
        points: [
          [-1, 0],
          [-0.5, -0.866025],
          [0.5, -0.866025],
          [1, -0],
          [0.5, 0.866025],
          [-0.5, 0.866025]
        ]
      },
      // ring 4
      {
        sigma: 0.475,
        points: [
          [0, 0.930969],
          [-0.806243, 0.465485],
          [-0.806243, -0.465485],
          [-0, -0.930969],
          [0.806243, -0.465485],
          [0.806243, 0.465485]
        ]
      },
      // ring 3
      {
        sigma: 0.4,
        points: [
          [0.847306, -0],
          [0.423653, 0.733789],
          [-0.423653, 0.733789],
          [-0.847306, 0],
          [-0.423653, -0.733789],
          [0.423653, -0.733789]
        ]
      },
      // ring 2
      {
        sigma: 0.325,
        points: [
          [-0, -0.741094],
          [0.641806, -0.370547],
          [0.641806, 0.370547],
          [0, 0.741094],
          [-0.641806, 0.370547],
          [-0.641806, -0.370547]
        ]
      },
      // ring 1
      {
        sigma: 0.25,
        points: [
          [-0.595502, 0],
          [-0.297751, -0.51572],
          [0.297751, -0.51572],
          [0.595502, -0],
          [0.297751, 0.51572],
          [-0.297751, 0.51572]
        ]
      },
      // ring 0
      {
        sigma: 0.175,
        points: [
          [0, 0.362783],
          [-0.314179, 0.181391],
          [-0.314179, -0.181391],
          [-0, -0.362783],
          [0.314179, -0.181391],
          [0.314179, 0.181391]
        ]
      },
      // center
      {
        sigma: 0.1,
        points: [
          [0, 0]
        ]
      }
    ];
    FREAKPOINTS = [];
    for (let r = 0; r < FREAK_RINGS.length; r++) {
      const sigma = FREAK_RINGS[r].sigma;
      for (let i = 0; i < FREAK_RINGS[r].points.length; i++) {
        const point = FREAK_RINGS[r].points[i];
        FREAKPOINTS.push([sigma, point[0], point[1]]);
      }
    }
  }
});
function GetKernels(image2) {
  const imageWidth = image2.shape[1];
  const imageHeight = image2.shape[0];
  const key = "w" + imageWidth + "h" + imageHeight;
  if (!cache.hasOwnProperty(key)) {
    const kernel1 = {
      variableNames: ["p"],
      outputShape: [imageHeight, imageWidth],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();

          float sum = getP(coords[0], coords[1]-2);
          sum += getP(coords[0], coords[1]-1) * 4.;
          sum += getP(coords[0], coords[1]) * 6.;
          sum += getP(coords[0], coords[1]+1) * 4.;
          sum += getP(coords[0], coords[1]+2);
          setOutput(sum);
        }
      `
    };
    const kernel2 = {
      variableNames: ["p"],
      outputShape: [imageHeight, imageWidth],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();

          float sum = getP(coords[0]-2, coords[1]);
          sum += getP(coords[0]-1, coords[1]) * 4.;
          sum += getP(coords[0], coords[1]) * 6.;
          sum += getP(coords[0]+1, coords[1]) * 4.;
          sum += getP(coords[0]+2, coords[1]);
          sum /= 256.;
          setOutput(sum);
        }
      `
    };
    cache[key] = [kernel1, kernel2];
  }
  return cache[key];
}
var cache;
var binomialFilter;
var binomialFilterConfig;
var init_binomialFilter = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/binomialFilter.js"() {
    cache = {};
    binomialFilter = (args) => {
      const image2 = args.inputs.image;
      const backend2 = args.backend;
      const [kernel1, kernel2] = GetKernels(image2);
      const result1 = backend2.runWebGLProgram(kernel1, [image2], image2.dtype);
      const result2 = backend2.runWebGLProgram(kernel2, [result1], image2.dtype);
      backend2.disposeIntermediateTensorInfo(result1);
      return result2;
    };
    binomialFilterConfig = {
      //: KernelConfig
      kernelName: "BinomialFilter",
      backendName: "webgl",
      kernelFunc: binomialFilter
      // as {} as KernelFunc,
    };
  }
});
function GetProgram(image2) {
  const imageWidth = image2.shape[1];
  const imageHeight = image2.shape[0];
  const kernelKey = "w" + imageWidth + "h" + imageHeight;
  if (!cache2.hasOwnProperty(kernelKey)) {
    const kernel = {
      variableNames: ["image0", "image1", "image2"],
      outputShape: [imageHeight, imageWidth],
      userCode: `
        void main() {
          ivec2 coords = getOutputCoords();
    
          int y = coords[0];
          int x = coords[1];
    
          float value = getImage1(y, x);
    
          // Step 1: find local maxima/minima
          if (value * value < ${LAPLACIAN_SQR_THRESHOLD}.) {
            setOutput(0.);
            return;
          }
          if (y < ${FREAK_EXPANSION_FACTOR} || y > ${imageHeight - 1 - FREAK_EXPANSION_FACTOR}) {
            setOutput(0.);
            return;
          }
          if (x < ${FREAK_EXPANSION_FACTOR} || x > ${imageWidth - 1 - FREAK_EXPANSION_FACTOR}) {
            setOutput(0.);
            return;
          }
    
          bool isMax = true;
          bool isMin = true;
          for (int dy = -1; dy <= 1; dy++) {
            for (int dx = -1; dx <= 1; dx++) {
              float value0 = getImage0(y+dy, x+dx);
              float value1 = getImage1(y+dy, x+dx);
              float value2 = getImage2(y+dy, x+dx);
    
        if (value < value0 || value < value1 || value < value2) {
          isMax = false;
        }
        if (value > value0 || value > value1 || value > value2) {
          isMin = false;
        }
            }
          }
    
          if (!isMax && !isMin) {
            setOutput(0.);
            return;
          }
    
          // compute edge score and reject based on threshold
          float dxx = getImage1(y, x+1) + getImage1(y, x-1) - 2. * getImage1(y, x);
          float dyy = getImage1(y+1, x) + getImage1(y-1, x) - 2. * getImage1(y, x);
          float dxy = 0.25 * (getImage1(y-1,x-1) + getImage1(y+1,x+1) - getImage1(y-1,x+1) - getImage1(y+1,x-1));
    
          float det = (dxx * dyy) - (dxy * dxy);
    
          if (abs(det) < 0.0001) { // determinant undefined. no solution
            setOutput(0.);
            return;
          }
    
          float edgeScore = (dxx + dyy) * (dxx + dyy) / det;
    
          if (abs(edgeScore) >= ${EDGE_HESSIAN_THRESHOLD} ) {
            setOutput(0.);
            return;
          }
          setOutput(getImage1(y,x));
        }
      `
    };
    cache2[kernelKey] = kernel;
  }
  return cache2[kernelKey];
}
var FREAK_EXPANSION_FACTOR;
var LAPLACIAN_THRESHOLD;
var LAPLACIAN_SQR_THRESHOLD;
var EDGE_THRESHOLD;
var EDGE_HESSIAN_THRESHOLD;
var cache2;
var buildExtremas;
var buildExtremasConfig;
var init_buildExtremas = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/buildExtremas.js"() {
    init_dist7();
    FREAK_EXPANSION_FACTOR = 7;
    LAPLACIAN_THRESHOLD = 3;
    LAPLACIAN_SQR_THRESHOLD = LAPLACIAN_THRESHOLD * LAPLACIAN_THRESHOLD;
    EDGE_THRESHOLD = 4;
    EDGE_HESSIAN_THRESHOLD = (EDGE_THRESHOLD + 1) * (EDGE_THRESHOLD + 1) / EDGE_THRESHOLD;
    cache2 = {};
    buildExtremas = (args) => {
      let { image0, image1, image2 } = args.inputs;
      const backend2 = args.backend;
      const program = GetProgram(image1);
      image0 = engine().runKernel("DownsampleBilinear", { image: image0 });
      image2 = engine().runKernel("UpsampleBilinear", { image: image2, targetImage: image1 });
      return backend2.runWebGLProgram(program, [image0, image1, image2], image1.dtype);
    };
    buildExtremasConfig = {
      //: KernelConfig
      kernelName: "BuildExtremas",
      backendName: "webgl",
      kernelFunc: buildExtremas
      // as {} as KernelFunc,
    };
  }
});
function GetProgram2(histograms) {
  const key = histograms.shape[0];
  if (!cache3.hasOwnProperty(key)) {
    const kernel = {
      variableNames: ["histogram"],
      outputShape: [histograms.shape[0]],
      userCode: `
            void main() {
                int featureIndex = getOutputCoords();

                int maxIndex = 0;
                for (int i = 1; i < ${ORIENTATION_NUM_BINS}; i++) {
                    if (getHistogram(featureIndex, i) > getHistogram(featureIndex, maxIndex)) {
                        maxIndex = i;
                    }
                }

                int prev = imod(maxIndex - 1 + ${ORIENTATION_NUM_BINS}, ${ORIENTATION_NUM_BINS});
                int next = imod(maxIndex + 1, ${ORIENTATION_NUM_BINS});

                /**
                 * Fit a quatratic to 3 points. The system of equations is:
                 *
                 * y0 = A*x0^2 + B*x0 + C
                 * y1 = A*x1^2 + B*x1 + C
                 * y2 = A*x2^2 + B*x2 + C
                 *
                 * This system of equations is solved for A,B,C.
                 */
                float p10 = float(maxIndex - 1);
                float p11 = getHistogram(featureIndex, prev); 
                float p20 = float(maxIndex);
                float p21 = getHistogram(featureIndex, maxIndex); 
                float p30 = float(maxIndex + 1);
                float p31 = getHistogram(featureIndex, next); 

                float d1 = (p30-p20)*(p30-p10);
                float d2 = (p10-p20)*(p30-p10);
                float d3 = p10-p20;

                // If any of the denominators are zero then, just use maxIndex.
                    float fbin = float(maxIndex);
                if ( abs(d1) > 0.00001 && abs(d2) > 0.00001 && abs(d3) > 0.00001) {
                float a = p10*p10;
                float b = p20*p20;

                // Solve for the coefficients A,B,C
                float A = ((p31-p21)/d1)-((p11-p21)/d2);
                float B = ((p11-p21)+(A*(b-a)))/d3;
                float C = p11-(A*a)-(B*p10);
                fbin = -B / (2. * A);
                }

                float an = 2.0 *${Math.PI} * (fbin + 0.5) / ${ORIENTATION_NUM_BINS}. - ${Math.PI};
                setOutput(an);
            }
            `
    };
    cache3[key] = kernel;
  }
  return cache3[key];
}
var ORIENTATION_NUM_BINS;
var cache3;
var computeExtremaAngles;
var computeExtremaAnglesConfig;
var init_computeExtremaAngles = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/computeExtremaAngles.js"() {
    ORIENTATION_NUM_BINS = 36;
    cache3 = {};
    computeExtremaAngles = (args) => {
      const { histograms } = args.inputs;
      const backend2 = args.backend;
      const program = GetProgram2(histograms);
      return backend2.runWebGLProgram(program, [histograms], histograms.dtype);
    };
    computeExtremaAnglesConfig = {
      //: KernelConfig
      kernelName: "ComputeExtremaAngles",
      backendName: "webgl",
      kernelFunc: computeExtremaAngles
      // as {} as KernelFunc,
    };
  }
});
function GetProgram3(imageCount, prunedExtremas) {
  const key = `${imageCount}|${prunedExtremas.shape[0]}`;
  if (!cache4.hasOwnProperty(key)) {
    const imageVariableNames = [];
    for (let i = 1; i < imageCount; i++) {
      imageVariableNames.push("image" + i);
    }
    let pixelsSubCodes = `float getPixel(int octave, int y, int x) {`;
    for (let i = 1; i < imageCount; i++) {
      pixelsSubCodes += `
  if (octave == ${i}) {
	return getImage${i}(y, x);
  }
`;
    }
    pixelsSubCodes += `}`;
    const kernel = {
      variableNames: [...imageVariableNames, "extrema", "angles", "freakPoints"],
      outputShape: [prunedExtremas.shape[0], FREAKPOINTS.length],
      userCode: `
  ${pixelsSubCodes}
  void main() {
	ivec2 coords = getOutputCoords();
	int featureIndex = coords[0];
	int freakIndex = coords[1];

	float freakSigma = getFreakPoints(freakIndex, 0);
	float freakX = getFreakPoints(freakIndex, 1);
	float freakY = getFreakPoints(freakIndex, 2);

	int octave = int(getExtrema(featureIndex, 1));
	float inputY = getExtrema(featureIndex, 2);
	float inputX = getExtrema(featureIndex, 3);
	float inputAngle = getAngles(featureIndex);
	float cos = ${FREAK_EXPANSION_FACTOR2}. * cos(inputAngle);
	float sin = ${FREAK_EXPANSION_FACTOR2}. * sin(inputAngle);

	float yp = inputY + freakX * sin + freakY * cos;
	float xp = inputX + freakX * cos + freakY * -sin;

	int x0 = int(floor(xp));
	int x1 = x0 + 1;
	int y0 = int(floor(yp));
	int y1 = y0 + 1;

	float f1 = getPixel(octave, y0, x0);
	float f2 = getPixel(octave, y0, x1);
	float f3 = getPixel(octave, y1, x0);
	float f4 = getPixel(octave, y1, x1);

	float x1f = float(x1);
	float y1f = float(y1);
	float x0f = float(x0);
	float y0f = float(y0);

	// ratio for interpolation between four neighbouring points
	float value = (x1f - xp) * (y1f - yp) * f1
		+ (xp - x0f) * (y1f - yp) * f2
		+ (x1f - xp) * (yp - y0f) * f3
		+ (xp - x0f) * (yp - y0f) * f4;

	setOutput(value);
  }
`
    };
    cache4[key] = kernel;
  }
  return cache4[key];
}
var FREAK_EXPANSION_FACTOR2;
var cache4;
var computeExtremaFreak;
var computeExtremaFreakConfig;
var init_computeExtremaFreak = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/computeExtremaFreak.js"() {
    init_freak();
    FREAK_EXPANSION_FACTOR2 = 7;
    cache4 = {};
    computeExtremaFreak = (args) => {
      const { gaussianImagesT, prunedExtremas, prunedExtremasAngles, freakPointsT, pyramidImagesLength } = args.inputs;
      const backend2 = args.backend;
      const program = GetProgram3(pyramidImagesLength, prunedExtremas);
      return backend2.runWebGLProgram(program, [...gaussianImagesT, prunedExtremas, prunedExtremasAngles, freakPointsT], "float32");
    };
    computeExtremaFreakConfig = {
      //: KernelConfig
      kernelName: "ComputeExtremaFreak",
      backendName: "webgl",
      kernelFunc: computeExtremaFreak
      // as {} as KernelFunc,
    };
  }
});
function GetProgram4(extremaFreaks) {
  const key = `${extremaFreaks.shape[0]}`;
  if (!cache5.hasOwnProperty(key)) {
    const kernel = {
      variableNames: ["freak", "p"],
      outputShape: [extremaFreaks.shape[0], descriptorCount],
      userCode: `
  void main() {
    ivec2 coords = getOutputCoords();
    int featureIndex = coords[0];
    int descIndex = coords[1] * 8;

    int sum = 0;
    for (int i = 0; i < 8; i++) {
      if (descIndex + i >= ${FREAK_CONPARISON_COUNT}) {
        continue;
      }

      int p1 = int(getP(descIndex + i, 0));
      int p2 = int(getP(descIndex + i, 1));

      float v1 = getFreak(featureIndex, p1);
      float v2 = getFreak(featureIndex, p2);

      if (v1 < v2 + 0.01) {
        sum += int(pow(2.0, float(7 - i)));
      }
    }
    setOutput(float(sum));
  }
`
    };
    cache5[key] = kernel;
  }
  return cache5[key];
}
var FREAK_CONPARISON_COUNT;
var descriptorCount;
var cache5;
var computeFreakDescriptor;
var computeFreakDescriptorConfig;
var init_computeFreakDescriptors = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/computeFreakDescriptors.js"() {
    init_freak();
    FREAK_CONPARISON_COUNT = (FREAKPOINTS.length - 1) * FREAKPOINTS.length / 2;
    descriptorCount = Math.ceil(FREAK_CONPARISON_COUNT / 8);
    cache5 = {};
    computeFreakDescriptor = (args) => {
      const { extremaFreaks, positionT } = args.inputs;
      const { backend: backend2 } = args;
      const program = GetProgram4(extremaFreaks);
      return backend2.runWebGLProgram(program, [extremaFreaks, positionT], "int32");
    };
    computeFreakDescriptorConfig = {
      //: KernelConfig
      kernelName: "ComputeFreakDescriptors",
      backendName: "webgl",
      kernelFunc: computeFreakDescriptor
      // as {} as KernelFunc,
    };
  }
});
function GetProgram5(numDogPyramidImages, extremasListLength) {
  const kernelKey = `${numDogPyramidImages}|${extremasListLength}`;
  if (!cache6.hasOwnProperty(kernelKey)) {
    const dogVariableNames = [];
    let dogSubCodes = `float getPixel(int octave, int y, int x) {`;
    for (let i = 1; i < numDogPyramidImages; i++) {
      dogVariableNames.push("image" + i);
      dogSubCodes += `
				if (octave == ${i}) {
					return getImage${i}(y, x);
				}
			`;
    }
    dogSubCodes += `}`;
    cache6[kernelKey] = {
      variableNames: [...dogVariableNames, "extrema"],
      outputShape: [extremasListLength, 3, 3],
      // 3x3 pixels around the extrema
      userCode: `
			${dogSubCodes}
		
			void main() {
				ivec3 coords = getOutputCoords();
				int featureIndex = coords[0];
				float score = getExtrema(featureIndex, 0);
				if (score == 0.0) {
					return;
				}
		
				int dy = coords[1]-1;
				int dx = coords[2]-1;
				int octave = int(getExtrema(featureIndex, 1));
				int y = int(getExtrema(featureIndex, 2));
				int x = int(getExtrema(featureIndex, 3));
				setOutput(getPixel(octave, y+dy, x+dx));
			}
			`
    };
  }
  return cache6[kernelKey];
}
var cache6;
var computeLocalization;
var computeLocalizationConfig;
var init_computeLocalization = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/computeLocalization.js"() {
    init_dist7();
    cache6 = {};
    computeLocalization = (args) => {
      const { prunedExtremasList, dogPyramidImagesT } = args.inputs;
      const backend2 = args.backend;
      const program = GetProgram5(dogPyramidImagesT.length, prunedExtremasList.length);
      const prunedExtremasT = tensor(prunedExtremasList, [prunedExtremasList.length, prunedExtremasList[0].length], "int32");
      return backend2.runWebGLProgram(program, [...dogPyramidImagesT.slice(1), prunedExtremasT], dogPyramidImagesT[0].dtype);
    };
    computeLocalizationConfig = {
      //: KernelConfig
      kernelName: "ComputeLocalization",
      backendName: "webgl",
      kernelFunc: computeLocalization
      // as {} as KernelFunc,
    };
  }
});
function GetPrograms(prunedExtremasT, radialPropertiesT, pyramidImagesLength) {
  const key = `${pyramidImagesLength}|${prunedExtremasT.shape[0]}|${radialPropertiesT.shape[0]}`;
  if (!cache7.hasOwnProperty(key)) {
    const imageVariableNames = [];
    for (let i = 1; i < pyramidImagesLength; i++) {
      imageVariableNames.push("image" + i);
    }
    let kernel1SubCodes = `float getPixel(int octave, int y, int x) {`;
    for (let i = 1; i < pyramidImagesLength; i++) {
      kernel1SubCodes += `
            if (octave == ${i}) {
                return getImage${i}(y, x);
            }
            `;
    }
    kernel1SubCodes += `}`;
    const kernel1 = {
      variableNames: [...imageVariableNames, "extrema", "radial"],
      outputShape: [prunedExtremasT.shape[0], radialPropertiesT.shape[0], 2],
      // last dimension: [fbin, magnitude]
      userCode: `
                ${kernel1SubCodes}

                void main() {
                    ivec3 coords = getOutputCoords();
                    int featureIndex = coords[0];
                    int radialIndex = coords[1];
                    int propertyIndex = coords[2];

                    int radialY = int(getRadial(radialIndex, 0));
                    int radialX = int(getRadial(radialIndex, 1));
                    float radialW = getRadial(radialIndex, 2);

                    int octave = int(getExtrema(featureIndex, 1));
                    int y = int(getExtrema(featureIndex, 2));
                    int x = int(getExtrema(featureIndex, 3));

                    int xp = x + radialX;
                    int yp = y + radialY;

                    float dy = getPixel(octave, yp+1, xp) - getPixel(octave, yp-1, xp);
                    float dx = getPixel(octave, yp, xp+1) - getPixel(octave, yp, xp-1);

                    if (propertyIndex == 0) {
                    // be careful that atan(0, 0) gives 1.57 instead of 0 (different from js), but doesn't matter here, coz magnitude is 0
                    
                    float angle = atan(dy, dx) + ${Math.PI};
                    float fbin = angle * ${ORIENTATION_NUM_BINS2}. * ${oneOver2PI};
                    setOutput(fbin);
                    return;
                    }

                    if (propertyIndex == 1) {
                        float mag = sqrt(dx * dx + dy * dy);
                        float magnitude = radialW * mag;
                        setOutput(magnitude);
                        return;
                    }
                }

                `
    };
    const kernel2 = {
      variableNames: ["fbinMag"],
      outputShape: [prunedExtremasT.shape[0], ORIENTATION_NUM_BINS2],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();
                int featureIndex = coords[0];
                int binIndex = coords[1];

                float sum = 0.;
                for (int i = 0; i < ${radialPropertiesT.shape[0]}; i++) {
                    float fbin = getFbinMag(featureIndex, i, 0);
                    int bin = int(floor(fbin - 0.5));
                    int b1 = imod(bin + ${ORIENTATION_NUM_BINS2}, ${ORIENTATION_NUM_BINS2});
                    int b2 = imod(bin + 1 + ${ORIENTATION_NUM_BINS2}, ${ORIENTATION_NUM_BINS2});

                    if (b1 == binIndex || b2 == binIndex) {
                        float magnitude = getFbinMag(featureIndex, i, 1);
                        float w2 = fbin - float(bin) - 0.5;
                        float w1 = w2 * -1. + 1.;

                        if (b1 == binIndex) {
                            sum += w1 * magnitude;
                        }
                        if (b2 == binIndex) {
                            sum += w2 * magnitude;
                        }
                    }
                }
                setOutput(sum);
            }
            `
    };
    cache7[key] = [kernel1, kernel2];
  }
  return cache7[key];
}
var oneOver2PI;
var ORIENTATION_NUM_BINS2;
var cache7;
var computeOrientationHistograms;
var computeOrientationHistogramsConfig;
var init_computeOrientationHistograms = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/computeOrientationHistograms.js"() {
    oneOver2PI = 0.159154943091895;
    ORIENTATION_NUM_BINS2 = 36;
    cache7 = {};
    computeOrientationHistograms = (args) => {
      const { gaussianImagesT, prunedExtremasT, radialPropertiesT, pyramidImagesLength } = args.inputs;
      const backend2 = args.backend;
      const [program1, program2] = GetPrograms(prunedExtremasT, radialPropertiesT, pyramidImagesLength);
      const result1 = backend2.runWebGLProgram(program1, [...gaussianImagesT, prunedExtremasT, radialPropertiesT], radialPropertiesT.dtype);
      const result2 = backend2.runWebGLProgram(program2, [result1], radialPropertiesT.dtype);
      backend2.disposeIntermediateTensorInfo(result1);
      return result2;
    };
    computeOrientationHistogramsConfig = {
      kernelName: "ComputeOrientationHistograms",
      backendName: "webgl",
      kernelFunc: computeOrientationHistograms
      // as {} as KernelFunc,
    };
  }
});
function GetProgram6(image2) {
  const imageWidth = image2.shape[1];
  const imageHeight = image2.shape[0];
  const kernelKey = "w" + imageWidth + "h" + imageHeight;
  if (!cache8.hasOwnProperty(kernelKey)) {
    const kernel = {
      variableNames: ["p"],
      outputShape: [Math.floor(imageHeight / 2), Math.floor(imageWidth / 2)],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();
                int y = coords[0] * 2;
                int x = coords[1] * 2;
        
                float sum = getP(y, x) * 0.25;
                sum += getP(y+1,x) * 0.25; 
                sum += getP(y, x+1) * 0.25; 
                sum += getP(y+1,x+1) * 0.25;
                setOutput(sum);
            }
            `
    };
    cache8[kernelKey] = kernel;
  }
  return cache8[kernelKey];
}
var cache8;
var downsampleBilinear;
var downsampleBilinearConfig;
var init_downsampleBilinear = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/downsampleBilinear.js"() {
    cache8 = {};
    downsampleBilinear = (args) => {
      const image2 = args.inputs.image;
      const backend2 = args.backend;
      const program = GetProgram6(image2);
      return backend2.runWebGLProgram(program, [image2], image2.dtype);
    };
    downsampleBilinearConfig = {
      //: KernelConfig
      kernelName: "DownsampleBilinear",
      backendName: "webgl",
      kernelFunc: downsampleBilinear
      // as {} as KernelFunc,
    };
  }
});
var extremaReduction;
var extremaReductionConfig;
var init_extremaReduction = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/extremaReduction.js"() {
    extremaReduction = (args) => {
      const { extremasResultT } = args.inputs;
      const backend2 = args.backend;
      const extremaHeight = extremasResultT.shape[0];
      const extremaWidth = extremasResultT.shape[1];
      const kernel = {
        variableNames: ["extrema"],
        outputShape: [Math.floor(extremaHeight / 2), Math.floor(extremaWidth / 2)],
        userCode: `
		  void main() {
			ivec2 coords = getOutputCoords();
			int y = coords[0] * 2;
			int x = coords[1] * 2;
  
			float location = 0.0;
			float values = getExtrema(y, x);
  
			if (getExtrema(y+1, x) != 0.0) {
			  location = 1.0;
		  values = getExtrema(y+1, x);
			}
			else if (getExtrema(y, x+1) != 0.0) {
			  location = 2.0;
		  values = getExtrema(y, x+1);
			}
			else if (getExtrema(y+1, x+1) != 0.0) {
			  location = 3.0;
		  values = getExtrema(y+1, x+1);
			}
  
			if (values < 0.0) {
			  setOutput(location * -1000.0 + values);
			} else {
			  setOutput(location * 1000.0 + values);
			}
		  }
		`
      };
      return backend2.runWebGLProgram(kernel, [extremasResultT], extremasResultT.dtype);
    };
    extremaReductionConfig = {
      //: KernelConfig
      kernelName: "ExtremaReduction",
      backendName: "webgl",
      kernelFunc: extremaReduction
      // as {} as KernelFunc,
    };
  }
});
function GetProgram7(histograms) {
  const kernelKey = `h${histograms.shape[0]}`;
  if (!cache9.hasOwnProperty(kernelKey)) {
    const kernel = {
      variableNames: ["histogram"],
      outputShape: [histograms.shape[0], ORIENTATION_NUM_BINS3],
      userCode: `
            void main() {
                ivec2 coords = getOutputCoords();

                int featureIndex = coords[0];
                int binIndex = coords[1];

                int prevBin = imod(binIndex - 1 + ${ORIENTATION_NUM_BINS3}, ${ORIENTATION_NUM_BINS3});
                int nextBin = imod(binIndex + 1, ${ORIENTATION_NUM_BINS3});
                float result = 0.274068619061197 * getHistogram(featureIndex, prevBin) + 0.451862761877606 * getHistogram(featureIndex, binIndex) + 0.274068619061197 * getHistogram(featureIndex, nextBin);

                setOutput(result);
            }
            `
    };
    cache9[kernelKey] = kernel;
  }
  return cache9[kernelKey];
}
var ORIENTATION_NUM_BINS3;
var ORIENTATION_SMOOTHING_ITERATIONS;
var cache9;
var smoothHistograms;
var smoothHistogramsConfig;
var init_smoothHistograms = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/smoothHistograms.js"() {
    ORIENTATION_NUM_BINS3 = 36;
    ORIENTATION_SMOOTHING_ITERATIONS = 5;
    cache9 = {};
    smoothHistograms = (args) => {
      let { histograms } = args.inputs;
      const backend2 = args.backend;
      const program = GetProgram7(histograms);
      for (let i = 0; i < ORIENTATION_SMOOTHING_ITERATIONS; i++) {
        const _histograms = histograms;
        histograms = backend2.runWebGLProgram(program, [histograms], histograms.dtype);
        if (i > 0) {
          backend2.disposeIntermediateTensorInfo(_histograms);
        }
      }
      return histograms;
    };
    smoothHistogramsConfig = {
      //: KernelConfig
      kernelName: "SmoothHistograms",
      backendName: "webgl",
      kernelFunc: smoothHistograms
      // as {} as KernelFunc,
    };
  }
});
function GetProgram8(image2, targetImage) {
  const targetImageWidth = targetImage.shape[1];
  const targetImageHeight = targetImage.shape[0];
  const kernelKey = "w" + targetImageWidth + "h" + targetImageHeight;
  if (!cache10.hasOwnProperty(kernelKey)) {
    const kernel = {
      variableNames: ["p"],
      outputShape: [targetImageHeight, targetImageWidth],
      userCode: `
              void main() {
                ivec2 coords = getOutputCoords();
                int j = coords[0];
                int i = coords[1];
        
                float sj = 0.5 * float(j) - 0.25; 
                float si = 0.5 * float(i) - 0.25;
        
                float sj0 = floor(sj);
                float sj1 = ceil(sj);
                float si0 = floor(si);
                float si1 = ceil(si);
        
                int sj0I = int(sj0);
                int sj1I = int(sj1);
                int si0I = int(si0);
                int si1I = int(si1);
        
                float sum = 0.0;
                sum += getP(sj0I, si0I) * (si1 - si) * (sj1 - sj);
                sum += getP(sj1I, si0I) * (si1 - si) * (sj - sj0);
                sum += getP(sj0I, si1I) * (si - si0) * (sj1 - sj);
                sum += getP(sj1I, si1I) * (si - si0) * (sj - sj0);
                setOutput(sum);
              }
            `
    };
    cache10[kernelKey] = kernel;
  }
  return cache10[kernelKey];
}
var cache10;
var upsampleBilinear;
var upsampleBilinearConfig;
var init_upsampleBilinear = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/upsampleBilinear.js"() {
    init_dist6();
    cache10 = {};
    upsampleBilinear = (args) => {
      const { image: image2, targetImage } = args.inputs;
      const backend2 = args.backend;
      const program = GetProgram8(image2, targetImage);
      return backend2.runWebGLProgram(program, [image2], image2.dtype);
    };
    upsampleBilinearConfig = {
      //: KernelConfig
      kernelName: "UpsampleBilinear",
      backendName: "webgl",
      kernelFunc: upsampleBilinear
      // as {} as KernelFunc,
    };
  }
});
var init_webgl2 = __esm({
  "node_modules/mind-ar/src/image-target/detector/kernels/webgl/index.js"() {
    init_dist7();
    init_binomialFilter();
    init_buildExtremas();
    init_computeExtremaAngles();
    init_computeExtremaFreak();
    init_computeFreakDescriptors();
    init_computeLocalization();
    init_computeOrientationHistograms();
    init_downsampleBilinear();
    init_extremaReduction();
    init_smoothHistograms();
    init_upsampleBilinear();
    registerKernel(binomialFilterConfig);
    registerKernel(buildExtremasConfig);
    registerKernel(computeExtremaAnglesConfig);
    registerKernel(computeExtremaFreakConfig);
    registerKernel(computeFreakDescriptorConfig);
    registerKernel(computeLocalizationConfig);
    registerKernel(computeOrientationHistogramsConfig);
    registerKernel(downsampleBilinearConfig);
    registerKernel(extremaReductionConfig);
    registerKernel(smoothHistogramsConfig);
    registerKernel(upsampleBilinearConfig);
  }
});
var PYRAMID_MIN_SIZE;
var PYRAMID_MAX_OCTAVE;
var LAPLACIAN_THRESHOLD2;
var LAPLACIAN_SQR_THRESHOLD2;
var EDGE_THRESHOLD2;
var EDGE_HESSIAN_THRESHOLD2;
var NUM_BUCKETS_PER_DIMENSION;
var MAX_FEATURES_PER_BUCKET;
var NUM_BUCKETS;
var ORIENTATION_GAUSSIAN_EXPANSION_FACTOR;
var ORIENTATION_REGION_EXPANSION_FACTOR;
var FREAK_CONPARISON_COUNT2;
var Detector;
var init_detector = __esm({
  "node_modules/mind-ar/src/image-target/detector/detector.js"() {
    init_dist7();
    init_freak();
    init_webgl2();
    PYRAMID_MIN_SIZE = 8;
    PYRAMID_MAX_OCTAVE = 5;
    LAPLACIAN_THRESHOLD2 = 3;
    LAPLACIAN_SQR_THRESHOLD2 = LAPLACIAN_THRESHOLD2 * LAPLACIAN_THRESHOLD2;
    EDGE_THRESHOLD2 = 4;
    EDGE_HESSIAN_THRESHOLD2 = (EDGE_THRESHOLD2 + 1) * (EDGE_THRESHOLD2 + 1) / EDGE_THRESHOLD2;
    NUM_BUCKETS_PER_DIMENSION = 10;
    MAX_FEATURES_PER_BUCKET = 5;
    NUM_BUCKETS = NUM_BUCKETS_PER_DIMENSION * NUM_BUCKETS_PER_DIMENSION;
    ORIENTATION_GAUSSIAN_EXPANSION_FACTOR = 3;
    ORIENTATION_REGION_EXPANSION_FACTOR = 1.5;
    FREAK_CONPARISON_COUNT2 = (FREAKPOINTS.length - 1) * FREAKPOINTS.length / 2;
    Detector = class {
      constructor(width, height, debugMode = false) {
        this.debugMode = debugMode;
        this.width = width;
        this.height = height;
        let numOctaves = 0;
        while (width >= PYRAMID_MIN_SIZE && height >= PYRAMID_MIN_SIZE) {
          width /= 2;
          height /= 2;
          numOctaves++;
          if (numOctaves === PYRAMID_MAX_OCTAVE)
            break;
        }
        this.numOctaves = numOctaves;
        this.tensorCaches = {};
        this.kernelCaches = {};
      }
      // used in compiler
      detectImageData(imageData) {
        const arr = new Uint8ClampedArray(4 * imageData.length);
        for (let i = 0; i < imageData.length; i++) {
          arr[4 * i] = imageData[i];
          arr[4 * i + 1] = imageData[i];
          arr[4 * i + 2] = imageData[i];
          arr[4 * i + 3] = 255;
        }
        const img = new ImageData(arr, this.width, this.height);
        return this.detect(img);
      }
      /**
       * 
       * @param {tf.Tensor<tf.Rank>} inputImageT 
       * @returns 
       */
      detect(inputImageT) {
        let debugExtra = null;
        const pyramidImagesT = [];
        for (let i = 0; i < this.numOctaves; i++) {
          let image1T;
          let image2T;
          if (i === 0) {
            image1T = this._applyFilter(inputImageT);
          } else {
            image1T = this._downsampleBilinear(pyramidImagesT[i - 1][pyramidImagesT[i - 1].length - 1]);
          }
          image2T = this._applyFilter(image1T);
          pyramidImagesT.push([image1T, image2T]);
        }
        const dogPyramidImagesT = [];
        for (let i = 0; i < this.numOctaves; i++) {
          let dogImageT = this._differenceImageBinomial(pyramidImagesT[i][0], pyramidImagesT[i][1]);
          dogPyramidImagesT.push(dogImageT);
        }
        const extremasResultsT = [];
        for (let i = 1; i < this.numOctaves - 1; i++) {
          const extremasResultT = this._buildExtremas(dogPyramidImagesT[i - 1], dogPyramidImagesT[i], dogPyramidImagesT[i + 1]);
          extremasResultsT.push(extremasResultT);
        }
        const prunedExtremasList = this._applyPrune(extremasResultsT);
        const prunedExtremasT = this._computeLocalization(prunedExtremasList, dogPyramidImagesT);
        const extremaHistogramsT = this._computeOrientationHistograms(prunedExtremasT, pyramidImagesT);
        const smoothedHistogramsT = this._smoothHistograms(extremaHistogramsT);
        const extremaAnglesT = this._computeExtremaAngles(smoothedHistogramsT);
        const extremaFreaksT = this._computeExtremaFreak(pyramidImagesT, prunedExtremasT, extremaAnglesT);
        const freakDescriptorsT = this._computeFreakDescriptors(extremaFreaksT);
        const prunedExtremasArr = prunedExtremasT.arraySync();
        const extremaAnglesArr = extremaAnglesT.arraySync();
        const freakDescriptorsArr = freakDescriptorsT.arraySync();
        if (this.debugMode) {
          debugExtra = {
            pyramidImages: pyramidImagesT.map((ts) => ts.map((t) => t.arraySync())),
            dogPyramidImages: dogPyramidImagesT.map((t) => t ? t.arraySync() : null),
            extremasResults: extremasResultsT.map((t) => t.arraySync()),
            extremaAngles: extremaAnglesT.arraySync(),
            prunedExtremas: prunedExtremasList,
            localizedExtremas: prunedExtremasT.arraySync()
          };
        }
        pyramidImagesT.forEach((ts) => ts.forEach((t) => t.dispose()));
        dogPyramidImagesT.forEach((t) => t && t.dispose());
        extremasResultsT.forEach((t) => t.dispose());
        prunedExtremasT.dispose();
        extremaHistogramsT.dispose();
        smoothedHistogramsT.dispose();
        extremaAnglesT.dispose();
        extremaFreaksT.dispose();
        freakDescriptorsT.dispose();
        const featurePoints = [];
        for (let i = 0; i < prunedExtremasArr.length; i++) {
          if (prunedExtremasArr[i][0] == 0)
            continue;
          const descriptors = [];
          for (let m = 0; m < freakDescriptorsArr[i].length; m += 4) {
            const v1 = freakDescriptorsArr[i][m];
            const v2 = freakDescriptorsArr[i][m + 1];
            const v3 = freakDescriptorsArr[i][m + 2];
            const v4 = freakDescriptorsArr[i][m + 3];
            let combined = v1 * 16777216 + v2 * 65536 + v3 * 256 + v4;
            descriptors.push(combined);
          }
          const octave = prunedExtremasArr[i][1];
          const y = prunedExtremasArr[i][2];
          const x = prunedExtremasArr[i][3];
          const originalX = x * Math.pow(2, octave) + Math.pow(2, octave - 1) - 0.5;
          const originalY = y * Math.pow(2, octave) + Math.pow(2, octave - 1) - 0.5;
          const scale22 = Math.pow(2, octave);
          featurePoints.push({
            maxima: prunedExtremasArr[i][0] > 0,
            x: originalX,
            y: originalY,
            scale: scale22,
            angle: extremaAnglesArr[i],
            descriptors
          });
        }
        return { featurePoints, debugExtra };
      }
      _computeFreakDescriptors(extremaFreaks) {
        if (!this.tensorCaches.computeFreakDescriptors) {
          const in1Arr = [];
          const in2Arr = [];
          for (let k12 = 0; k12 < extremaFreaks.shape[1]; k12++) {
            for (let k22 = k12 + 1; k22 < extremaFreaks.shape[1]; k22++) {
              in1Arr.push(k12);
              in2Arr.push(k22);
            }
          }
          const in1 = tensor(in1Arr, [in1Arr.length]).cast("int32");
          const in2 = tensor(in2Arr, [in2Arr.length]).cast("int32");
          this.tensorCaches.computeFreakDescriptors = {
            positionT: keep(stack([in1, in2], 1))
          };
        }
        const { positionT } = this.tensorCaches.computeFreakDescriptors;
        const descriptorCount2 = Math.ceil(FREAK_CONPARISON_COUNT2 / 8);
        return tidy(() => {
          return engine().runKernel("ComputeFreakDescriptors", { extremaFreaks, positionT });
        });
      }
      _computeExtremaFreak(pyramidImagesT, prunedExtremas, prunedExtremasAngles) {
        if (!this.tensorCaches._computeExtremaFreak) {
          tidy(() => {
            const freakPoints = tensor(FREAKPOINTS);
            this.tensorCaches._computeExtremaFreak = {
              freakPointsT: keep(freakPoints)
            };
          });
        }
        const { freakPointsT } = this.tensorCaches._computeExtremaFreak;
        const gaussianImagesT = [];
        for (let i = 1; i < pyramidImagesT.length; i++) {
          gaussianImagesT.push(pyramidImagesT[i][1]);
        }
        return tidy(() => {
          return engine().runKernel("ComputeExtremaFreak", { gaussianImagesT, prunedExtremas, prunedExtremasAngles, freakPointsT, pyramidImagesLength: pyramidImagesT.length });
        });
      }
      /**
       * 
       * @param {tf.Tensor<tf.Rank>} histograms 
       * @returns 
       */
      _computeExtremaAngles(histograms) {
        return tidy(() => {
          return engine().runKernel("ComputeExtremaAngles", { histograms });
        });
      }
      // TODO: maybe can try just using average momentum, instead of histogram method. histogram might be overcomplicated
      /**
       * 
       * @param {tf.Tensor<tf.Rank>} prunedExtremasT 
       * @param {tf.Tensor<tf.Rank>[]} pyramidImagesT 
       * @returns 
       */
      _computeOrientationHistograms(prunedExtremasT, pyramidImagesT) {
        const oneOver2PI2 = 0.159154943091895;
        const gaussianImagesT = [];
        for (let i = 1; i < pyramidImagesT.length; i++) {
          gaussianImagesT.push(pyramidImagesT[i][1]);
        }
        if (!this.tensorCaches.orientationHistograms) {
          tidy(() => {
            const gwScale = -1 / (2 * ORIENTATION_GAUSSIAN_EXPANSION_FACTOR * ORIENTATION_GAUSSIAN_EXPANSION_FACTOR);
            const radius = ORIENTATION_GAUSSIAN_EXPANSION_FACTOR * ORIENTATION_REGION_EXPANSION_FACTOR;
            const radiusCeil = Math.ceil(radius);
            const radialProperties = [];
            for (let y = -radiusCeil; y <= radiusCeil; y++) {
              for (let x = -radiusCeil; x <= radiusCeil; x++) {
                const distanceSquare = x * x + y * y;
                if (distanceSquare <= radius * radius) {
                  const _x = distanceSquare * gwScale;
                  let w = (720 + _x * (720 + _x * (360 + _x * (120 + _x * (30 + _x * (6 + _x)))))) * 0.0013888888;
                  radialProperties.push([y, x, w]);
                }
              }
            }
            this.tensorCaches.orientationHistograms = {
              radialPropertiesT: keep(tensor(radialProperties, [radialProperties.length, 3]))
            };
          });
        }
        const { radialPropertiesT } = this.tensorCaches.orientationHistograms;
        return tidy(() => {
          return engine().runKernel("ComputeOrientationHistograms", { gaussianImagesT, prunedExtremasT, radialPropertiesT, pyramidImagesLength: pyramidImagesT.length });
        });
      }
      // The histogram is smoothed with a Gaussian, with sigma = 1
      _smoothHistograms(histograms) {
        return tidy(() => {
          return engine().runKernel("SmoothHistograms", { histograms });
        });
      }
      /**
       * 
       * @param {number[][]} prunedExtremasList 
       * @param {tf.Tensor<tf.Rank>[]} dogPyramidImagesT 
       * @returns 
       */
      _computeLocalization(prunedExtremasList, dogPyramidImagesT) {
        return tidy(() => {
          const pixelsT = engine().runKernel("ComputeLocalization", { prunedExtremasList, dogPyramidImagesT });
          const pixels = pixelsT.arraySync();
          const result = [];
          for (let i = 0; i < pixels.length; i++) {
            result.push([]);
            for (let j = 0; j < pixels[i].length; j++) {
              result[i].push([]);
            }
          }
          const localizedExtremas = [];
          for (let i = 0; i < prunedExtremasList.length; i++) {
            localizedExtremas[i] = [
              prunedExtremasList[i][0],
              prunedExtremasList[i][1],
              prunedExtremasList[i][2],
              prunedExtremasList[i][3]
            ];
          }
          for (let i = 0; i < localizedExtremas.length; i++) {
            if (localizedExtremas[i][0] === 0) {
              continue;
            }
            const pixel = pixels[i];
            const dx = 0.5 * (pixel[1][2] - pixel[1][0]);
            const dy = 0.5 * (pixel[2][1] - pixel[0][1]);
            const dxx = pixel[1][2] + pixel[1][0] - 2 * pixel[1][1];
            const dyy = pixel[2][1] + pixel[0][1] - 2 * pixel[1][1];
            const dxy = 0.25 * (pixel[0][0] + pixel[2][2] - pixel[0][2] - pixel[2][0]);
            const det = dxx * dyy - dxy * dxy;
            const ux = (dyy * -dx + -dxy * -dy) / det;
            const uy = (-dxy * -dx + dxx * -dy) / det;
            const newY = localizedExtremas[i][2] + uy;
            const newX = localizedExtremas[i][3] + ux;
            if (Math.abs(det) < 1e-4) {
              continue;
            }
            localizedExtremas[i][2] = newY;
            localizedExtremas[i][3] = newX;
          }
          return tensor(localizedExtremas, [localizedExtremas.length, localizedExtremas[0].length], "float32");
        });
      }
      // faster to do it in CPU
      // if we do in gpu, we probably need to use tf.topk(), which seems to be run in CPU anyway (no gpu operation for that)
      //  TODO: research adapative maximum supression method
      /**
       * 
       * @param {tf.Tensor<tf.Rank>[]} extremasResultsT 
       * @returns 
       */
      _applyPrune(extremasResultsT) {
        const nBuckets = NUM_BUCKETS_PER_DIMENSION * NUM_BUCKETS_PER_DIMENSION;
        const nFeatures = MAX_FEATURES_PER_BUCKET;
        const curAbsScores = [];
        const result = [];
        for (let i = 0; i < nBuckets; i++) {
          result.push([]);
          curAbsScores.push([]);
          for (let j = 0; j < nFeatures; j++) {
            result[i].push([0, 0, 0, 0]);
            curAbsScores[i].push(0);
          }
        }
        tidy(() => {
          for (let k = 0; k < extremasResultsT.length; k++) {
            const reducedT = engine().runKernel("ExtremaReduction", { extremasResultT: extremasResultsT[k] });
            const octave = k + 1;
            const reduced = reducedT.arraySync();
            const height = reducedT.shape[0];
            const width = reducedT.shape[1];
            const bucketWidth = width * 2 / NUM_BUCKETS_PER_DIMENSION;
            const bucketHeight = height * 2 / NUM_BUCKETS_PER_DIMENSION;
            for (let j = 0; j < height; j++) {
              for (let i = 0; i < width; i++) {
                const encoded = reduced[j][i];
                if (encoded == 0)
                  continue;
                const score = encoded % 1e3;
                const loc = Math.floor(Math.abs(encoded) / 1e3);
                const x = i * 2 + (loc === 2 || loc === 3 ? 1 : 0);
                const y = j * 2 + (loc === 1 || loc === 3 ? 1 : 0);
                const bucketX = Math.floor(x / bucketWidth);
                const bucketY = Math.floor(y / bucketHeight);
                const bucket = bucketY * NUM_BUCKETS_PER_DIMENSION + bucketX;
                const absScore = Math.abs(score);
                let tIndex = nFeatures;
                while (tIndex >= 1 && absScore > curAbsScores[bucket][tIndex - 1]) {
                  tIndex -= 1;
                }
                if (tIndex < nFeatures) {
                  for (let t = nFeatures - 1; t >= tIndex + 1; t--) {
                    curAbsScores[bucket][t] = curAbsScores[bucket][t - 1];
                    result[bucket][t][0] = result[bucket][t - 1][0];
                    result[bucket][t][1] = result[bucket][t - 1][1];
                    result[bucket][t][2] = result[bucket][t - 1][2];
                    result[bucket][t][3] = result[bucket][t - 1][3];
                  }
                  curAbsScores[bucket][tIndex] = absScore;
                  result[bucket][tIndex][0] = score;
                  result[bucket][tIndex][1] = octave;
                  result[bucket][tIndex][2] = y;
                  result[bucket][tIndex][3] = x;
                }
              }
            }
          }
        });
        const list = [];
        for (let i = 0; i < nBuckets; i++) {
          for (let j = 0; j < nFeatures; j++) {
            list.push(result[i][j]);
          }
        }
        return list;
      }
      _buildExtremas(image0, image1, image2) {
        return tidy(() => {
          return engine().runKernel("BuildExtremas", { image0, image1, image2 });
        });
      }
      /**
       * 
       * @param {tf.Tensor<tf.Rank>} image1 
       * @param {tf.Tensor<tf.Rank>} image2 
       * @returns 
       */
      _differenceImageBinomial(image1, image2) {
        return tidy(() => {
          return image1.sub(image2);
        });
      }
      // 4th order binomail filter [1,4,6,4,1] X [1,4,6,4,1]
      _applyFilter(image2) {
        return tidy(() => {
          return engine().runKernel("BinomialFilter", { image: image2 });
        });
      }
      /* _upsampleBilinear(image, targetImage) {
      		const imageHeight = image.shape[0];
      		const imageWidth = image.shape[1];
      
      		const kernelKey = 'w' + imageWidth;
      		if (!this.kernelCaches.upsampleBilinear) {
      			this.kernelCaches.upsampleBilinear = {};
      		}
      
      		if (!this.kernelCaches.upsampleBilinear[kernelKey]) {
      			const kernel = {
      				variableNames: ['p'],
      				outputShape: [targetImage.shape[0], targetImage.shape[1]],
      				userCode: `
      	  void main() {
      		ivec2 coords = getOutputCoords();
      		int j = coords[0];
      		int i = coords[1];
      
      		float sj = 0.5 * float(j) - 0.25; 
      		float si = 0.5 * float(i) - 0.25;
      
      		float sj0 = floor(sj);
      		float sj1 = ceil(sj);
      		float si0 = floor(si);
      		float si1 = ceil(si);
      
      		int sj0I = int(sj0);
      		int sj1I = int(sj1);
      		int si0I = int(si0);
      		int si1I = int(si1);
      
      		float sum = 0.0;
      		sum += getP(sj0I, si0I) * (si1 - si) * (sj1 - sj);
      		sum += getP(sj1I, si0I) * (si1 - si) * (sj - sj0);
      		sum += getP(sj0I, si1I) * (si - si0) * (sj1 - sj);
      		sum += getP(sj1I, si1I) * (si - si0) * (sj - sj0);
      		setOutput(sum);
      	  }
      	`
      			};
      			this.kernelCaches.upsampleBilinear[kernelKey] = kernel;
      		}
      
      		return tf.tidy(() => {
      			const program = this.kernelCaches.upsampleBilinear[kernelKey];
      			return tf.engine().runKernel("UpsampleBilinear", { x: image, width: image.shape[1], height: image.shape[0] });//this._compileAndRun(program, [image]);
      		});
      	} */
      _downsampleBilinear(image2) {
        return tidy(() => {
          return engine().runKernel("DownsampleBilinear", { image: image2 });
        });
      }
      /**
       * 
       * @param {tf.MathBackendWebGL.GPGPUProgram} program 
       * @param {*} inputs 
       * @returns 
       */
      _compileAndRun(program, inputs) {
        const outInfo = backend().compileAndRun(program, inputs);
        return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
      }
      _runWebGLProgram(program, inputs, outputType) {
        const outInfo = backend().runWebGLProgram(program, inputs, outputType);
        return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
      }
    };
  }
});
var CropDetector;
var init_crop_detector = __esm({
  "node_modules/mind-ar/src/image-target/detector/crop-detector.js"() {
    init_dist7();
    init_detector();
    init_utils2();
    CropDetector = class {
      constructor(width, height, debugMode = false) {
        this.debugMode = debugMode;
        this.width = width;
        this.height = height;
        let minDimension = Math.min(width, height) / 2;
        let cropSize = Math.pow(2, Math.round(Math.log(minDimension) / Math.log(2)));
        this.cropSize = cropSize;
        this.detector = new Detector(cropSize, cropSize, debugMode);
        this.kernelCaches = {};
        this.lastRandomIndex = 4;
      }
      detect(inputImageT) {
        const startY = Math.floor(this.height / 2 - this.cropSize / 2);
        const startX = Math.floor(this.width / 2 - this.cropSize / 2);
        const result = this._detect(inputImageT, startX, startY);
        if (this.debugMode) {
          result.debugExtra.crop = { startX, startY, cropSize: this.cropSize };
        }
        return result;
      }
      detectMoving(inputImageT) {
        const dx = this.lastRandomIndex % 3;
        const dy = Math.floor(this.lastRandomIndex / 3);
        let startY = Math.floor(this.height / 2 - this.cropSize + dy * this.cropSize / 2);
        let startX = Math.floor(this.width / 2 - this.cropSize + dx * this.cropSize / 2);
        if (startX < 0)
          startX = 0;
        if (startY < 0)
          startY = 0;
        if (startX >= this.width - this.cropSize)
          startX = this.width - this.cropSize - 1;
        if (startY >= this.height - this.cropSize)
          startY = this.height - this.cropSize - 1;
        this.lastRandomIndex = (this.lastRandomIndex + 1) % 9;
        const result = this._detect(inputImageT, startX, startY);
        return result;
      }
      _detect(inputImageT, startX, startY) {
        const cropInputImageT = inputImageT.slice([startY, startX], [this.cropSize, this.cropSize]);
        const { featurePoints, debugExtra } = this.detector.detect(cropInputImageT);
        featurePoints.forEach((p2) => {
          p2.x += startX;
          p2.y += startY;
        });
        if (this.debugMode) {
          debugExtra.projectedImage = cropInputImageT.arraySync();
        }
        cropInputImageT.dispose();
        return { featurePoints, debugExtra };
      }
    };
  }
});
var resize;
var init_images = __esm({
  "node_modules/mind-ar/src/image-target/utils/images.js"() {
    resize = ({ image: image2, ratio }) => {
      const width = Math.round(image2.width * ratio);
      const height = Math.round(image2.height * ratio);
      const imageData = new Uint8Array(width * height);
      for (let i = 0; i < width; i++) {
        let si1 = Math.round(1 * i / ratio);
        let si2 = Math.round(1 * (i + 1) / ratio) - 1;
        if (si2 >= image2.width)
          si2 = image2.width - 1;
        for (let j = 0; j < height; j++) {
          let sj1 = Math.round(1 * j / ratio);
          let sj2 = Math.round(1 * (j + 1) / ratio) - 1;
          if (sj2 >= image2.height)
            sj2 = image2.height - 1;
          let sum5 = 0;
          let count2 = 0;
          for (let ii = si1; ii <= si2; ii++) {
            for (let jj = sj1; jj <= sj2; jj++) {
              sum5 += 1 * image2.data[jj * image2.width + ii];
              count2 += 1;
            }
          }
          imageData[j * width + i] = Math.floor(sum5 / count2);
        }
      }
      return { data: imageData, width, height };
    };
  }
});
var MIN_IMAGE_PIXEL_SIZE;
var buildImageList;
var buildTrackingImageList;
var init_image_list = __esm({
  "node_modules/mind-ar/src/image-target/image-list.js"() {
    init_images();
    MIN_IMAGE_PIXEL_SIZE = 100;
    buildImageList = (inputImage) => {
      const minScale = MIN_IMAGE_PIXEL_SIZE / Math.min(inputImage.width, inputImage.height);
      const scaleList = [];
      let c = minScale;
      while (true) {
        scaleList.push(c);
        c *= Math.pow(2, 1 / 3);
        if (c >= 0.95) {
          c = 1;
          break;
        }
      }
      scaleList.push(c);
      scaleList.reverse();
      const imageList = [];
      for (let i = 0; i < scaleList.length; i++) {
        const w = inputImage.width * scaleList[i];
        const h = inputImage.height * scaleList[i];
        imageList.push(Object.assign(resize({ image: inputImage, ratio: scaleList[i] }), { scale: scaleList[i] }));
      }
      return imageList;
    };
    buildTrackingImageList = (inputImage) => {
      const minDimension = Math.min(inputImage.width, inputImage.height);
      const scaleList = [];
      const imageList = [];
      scaleList.push(256 / minDimension);
      scaleList.push(128 / minDimension);
      for (let i = 0; i < scaleList.length; i++) {
        imageList.push(Object.assign(resize({ image: inputImage, ratio: scaleList[i] }), { scale: scaleList[i] }));
      }
      return imageList;
    };
  }
});
var compute;
var bitCount;
var init_hamming_distance = __esm({
  "node_modules/mind-ar/src/image-target/matching/hamming-distance.js"() {
    compute = (options) => {
      const { v1, v2 } = options;
      let d = 0;
      for (let i = 0; i < v1.length; i++) {
        let x = (v1[i] ^ v2[i]) >>> 0;
        d += bitCount(x);
      }
      return d;
    };
    bitCount = (v) => {
      var c = v - (v >> 1 & 1431655765);
      c = (c >> 2 & 858993459) + (c & 858993459);
      c = (c >> 4) + c & 252645135;
      c = (c >> 8) + c & 16711935;
      c = (c >> 16) + c & 65535;
      return c;
    };
  }
});
var mRandSeed;
var createRandomizer;
var init_randomizer = __esm({
  "node_modules/mind-ar/src/image-target/utils/randomizer.js"() {
    mRandSeed = 1234;
    createRandomizer = () => {
      const randomizer = {
        seed: mRandSeed,
        arrayShuffle(options) {
          const { arr, sampleSize } = options;
          for (let i = 0; i < sampleSize; i++) {
            this.seed = (214013 * this.seed + 2531011) % (1 << 31);
            let k = this.seed >> 16 & 32767;
            k = k % arr.length;
            let tmp = arr[i];
            arr[i] = arr[k];
            arr[k] = tmp;
          }
        },
        nextInt(maxValue) {
          this.seed = (214013 * this.seed + 2531011) % (1 << 31);
          let k = this.seed >> 16 & 32767;
          k = k % maxValue;
          return k;
        }
      };
      return randomizer;
    };
  }
});
var MIN_FEATURE_PER_NODE;
var NUM_ASSIGNMENT_HYPOTHESES;
var NUM_CENTERS;
var _computeKMedoids;
var build;
var _build;
var init_hierarchical_clustering = __esm({
  "node_modules/mind-ar/src/image-target/matching/hierarchical-clustering.js"() {
    init_hamming_distance();
    init_randomizer();
    MIN_FEATURE_PER_NODE = 16;
    NUM_ASSIGNMENT_HYPOTHESES = 128;
    NUM_CENTERS = 8;
    _computeKMedoids = (options) => {
      const { points, pointIndexes, randomizer } = options;
      const randomPointIndexes = [];
      for (let i = 0; i < pointIndexes.length; i++) {
        randomPointIndexes.push(i);
      }
      let bestSumD = Number.MAX_SAFE_INTEGER;
      let bestAssignmentIndex = -1;
      const assignments = [];
      for (let i = 0; i < NUM_ASSIGNMENT_HYPOTHESES; i++) {
        randomizer.arrayShuffle({ arr: randomPointIndexes, sampleSize: NUM_CENTERS });
        let sumD = 0;
        const assignment = [];
        for (let j = 0; j < pointIndexes.length; j++) {
          let bestD = Number.MAX_SAFE_INTEGER;
          for (let k = 0; k < NUM_CENTERS; k++) {
            const centerIndex = pointIndexes[randomPointIndexes[k]];
            const d = compute({ v1: points[pointIndexes[j]].descriptors, v2: points[centerIndex].descriptors });
            if (d < bestD) {
              assignment[j] = randomPointIndexes[k];
              bestD = d;
            }
          }
          sumD += bestD;
        }
        assignments.push(assignment);
        if (sumD < bestSumD) {
          bestSumD = sumD;
          bestAssignmentIndex = i;
        }
      }
      return assignments[bestAssignmentIndex];
    };
    build = ({ points }) => {
      const pointIndexes = [];
      for (let i = 0; i < points.length; i++) {
        pointIndexes.push(i);
      }
      const randomizer = createRandomizer();
      const rootNode = _build({ points, pointIndexes, centerPointIndex: null, randomizer });
      return { rootNode };
    };
    _build = (options) => {
      const { points, pointIndexes, centerPointIndex, randomizer } = options;
      let isLeaf = false;
      if (pointIndexes.length <= NUM_CENTERS || pointIndexes.length <= MIN_FEATURE_PER_NODE) {
        isLeaf = true;
      }
      const clusters = {};
      if (!isLeaf) {
        const assignment = _computeKMedoids({ points, pointIndexes, randomizer });
        for (let i = 0; i < assignment.length; i++) {
          if (clusters[pointIndexes[assignment[i]]] === void 0) {
            clusters[pointIndexes[assignment[i]]] = [];
          }
          clusters[pointIndexes[assignment[i]]].push(pointIndexes[i]);
        }
      }
      if (Object.keys(clusters).length === 1) {
        isLeaf = true;
      }
      const node = {
        centerPointIndex
      };
      if (isLeaf) {
        node.leaf = true;
        node.pointIndexes = [];
        for (let i = 0; i < pointIndexes.length; i++) {
          node.pointIndexes.push(pointIndexes[i]);
        }
        return node;
      }
      node.leaf = false;
      node.children = [];
      Object.keys(clusters).forEach((centerIndex) => {
        node.children.push(_build({ points, pointIndexes: clusters[centerIndex], centerPointIndex: centerIndex, randomizer }));
      });
      return node;
    };
  }
});
function setUint64(view, offset, value) {
  var high = value / 4294967296;
  var low = value;
  view.setUint32(offset, high);
  view.setUint32(offset + 4, low);
}
function setInt64(view, offset, value) {
  var high = Math.floor(value / 4294967296);
  var low = value;
  view.setUint32(offset, high);
  view.setUint32(offset + 4, low);
}
function getInt64(view, offset) {
  var high = view.getInt32(offset);
  var low = view.getUint32(offset + 4);
  return high * 4294967296 + low;
}
function getUint64(view, offset) {
  var high = view.getUint32(offset);
  var low = view.getUint32(offset + 4);
  return high * 4294967296 + low;
}
var UINT32_MAX;
var init_int2 = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/utils/int.mjs"() {
    UINT32_MAX = 4294967295;
  }
});
function utf8Count(str5) {
  var strLength = str5.length;
  var byteLength = 0;
  var pos = 0;
  while (pos < strLength) {
    var value = str5.charCodeAt(pos++);
    if ((value & 4294967168) === 0) {
      byteLength++;
      continue;
    } else if ((value & 4294965248) === 0) {
      byteLength += 2;
    } else {
      if (value >= 55296 && value <= 56319) {
        if (pos < strLength) {
          var extra = str5.charCodeAt(pos);
          if ((extra & 64512) === 56320) {
            ++pos;
            value = ((value & 1023) << 10) + (extra & 1023) + 65536;
          }
        }
      }
      if ((value & 4294901760) === 0) {
        byteLength += 3;
      } else {
        byteLength += 4;
      }
    }
  }
  return byteLength;
}
function utf8EncodeJs(str5, output, outputOffset) {
  var strLength = str5.length;
  var offset = outputOffset;
  var pos = 0;
  while (pos < strLength) {
    var value = str5.charCodeAt(pos++);
    if ((value & 4294967168) === 0) {
      output[offset++] = value;
      continue;
    } else if ((value & 4294965248) === 0) {
      output[offset++] = value >> 6 & 31 | 192;
    } else {
      if (value >= 55296 && value <= 56319) {
        if (pos < strLength) {
          var extra = str5.charCodeAt(pos);
          if ((extra & 64512) === 56320) {
            ++pos;
            value = ((value & 1023) << 10) + (extra & 1023) + 65536;
          }
        }
      }
      if ((value & 4294901760) === 0) {
        output[offset++] = value >> 12 & 15 | 224;
        output[offset++] = value >> 6 & 63 | 128;
      } else {
        output[offset++] = value >> 18 & 7 | 240;
        output[offset++] = value >> 12 & 63 | 128;
        output[offset++] = value >> 6 & 63 | 128;
      }
    }
    output[offset++] = value & 63 | 128;
  }
}
function utf8EncodeTEencode(str5, output, outputOffset) {
  output.set(sharedTextEncoder.encode(str5), outputOffset);
}
function utf8EncodeTEencodeInto(str5, output, outputOffset) {
  sharedTextEncoder.encodeInto(str5, output.subarray(outputOffset));
}
function utf8DecodeJs(bytes, inputOffset, byteLength) {
  var offset = inputOffset;
  var end = offset + byteLength;
  var units = [];
  var result = "";
  while (offset < end) {
    var byte1 = bytes[offset++];
    if ((byte1 & 128) === 0) {
      units.push(byte1);
    } else if ((byte1 & 224) === 192) {
      var byte2 = bytes[offset++] & 63;
      units.push((byte1 & 31) << 6 | byte2);
    } else if ((byte1 & 240) === 224) {
      var byte2 = bytes[offset++] & 63;
      var byte3 = bytes[offset++] & 63;
      units.push((byte1 & 31) << 12 | byte2 << 6 | byte3);
    } else if ((byte1 & 248) === 240) {
      var byte2 = bytes[offset++] & 63;
      var byte3 = bytes[offset++] & 63;
      var byte4 = bytes[offset++] & 63;
      var unit = (byte1 & 7) << 18 | byte2 << 12 | byte3 << 6 | byte4;
      if (unit > 65535) {
        unit -= 65536;
        units.push(unit >>> 10 & 1023 | 55296);
        unit = 56320 | unit & 1023;
      }
      units.push(unit);
    } else {
      units.push(byte1);
    }
    if (units.length >= CHUNK_SIZE) {
      result += String.fromCharCode.apply(String, units);
      units.length = 0;
    }
  }
  if (units.length > 0) {
    result += String.fromCharCode.apply(String, units);
  }
  return result;
}
function utf8DecodeTD(bytes, inputOffset, byteLength) {
  var stringBytes = bytes.subarray(inputOffset, inputOffset + byteLength);
  return sharedTextDecoder.decode(stringBytes);
}
var _a;
var _b;
var _c;
var TEXT_ENCODING_AVAILABLE;
var sharedTextEncoder;
var TEXT_ENCODER_THRESHOLD;
var utf8EncodeTE;
var CHUNK_SIZE;
var sharedTextDecoder;
var TEXT_DECODER_THRESHOLD;
var init_utf8 = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/utils/utf8.mjs"() {
    init_int2();
    TEXT_ENCODING_AVAILABLE = (typeof process === "undefined" || ((_a = process === null || process === void 0 ? void 0 : process.env) === null || _a === void 0 ? void 0 : _a["TEXT_ENCODING"]) !== "never") && typeof TextEncoder !== "undefined" && typeof TextDecoder !== "undefined";
    sharedTextEncoder = TEXT_ENCODING_AVAILABLE ? new TextEncoder() : void 0;
    TEXT_ENCODER_THRESHOLD = !TEXT_ENCODING_AVAILABLE ? UINT32_MAX : typeof process !== "undefined" && ((_b = process === null || process === void 0 ? void 0 : process.env) === null || _b === void 0 ? void 0 : _b["TEXT_ENCODING"]) !== "force" ? 200 : 0;
    utf8EncodeTE = (sharedTextEncoder === null || sharedTextEncoder === void 0 ? void 0 : sharedTextEncoder.encodeInto) ? utf8EncodeTEencodeInto : utf8EncodeTEencode;
    CHUNK_SIZE = 4096;
    sharedTextDecoder = TEXT_ENCODING_AVAILABLE ? new TextDecoder() : null;
    TEXT_DECODER_THRESHOLD = !TEXT_ENCODING_AVAILABLE ? UINT32_MAX : typeof process !== "undefined" && ((_c = process === null || process === void 0 ? void 0 : process.env) === null || _c === void 0 ? void 0 : _c["TEXT_DECODER"]) !== "force" ? 200 : 0;
  }
});
var ExtData;
var init_ExtData = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/ExtData.mjs"() {
    ExtData = /** @class */
    function() {
      function ExtData2(type, data) {
        this.type = type;
        this.data = data;
      }
      return ExtData2;
    }();
  }
});
var __extends;
var DecodeError;
var init_DecodeError = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/DecodeError.mjs"() {
    __extends = function() {
      var extendStatics = function(d, b) {
        extendStatics = Object.setPrototypeOf || { __proto__: [] } instanceof Array && function(d2, b2) {
          d2.__proto__ = b2;
        } || function(d2, b2) {
          for (var p2 in b2)
            if (Object.prototype.hasOwnProperty.call(b2, p2))
              d2[p2] = b2[p2];
        };
        return extendStatics(d, b);
      };
      return function(d, b) {
        if (typeof b !== "function" && b !== null)
          throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
        extendStatics(d, b);
        function __() {
          this.constructor = d;
        }
        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
      };
    }();
    DecodeError = /** @class */
    function(_super) {
      __extends(DecodeError2, _super);
      function DecodeError2(message) {
        var _this = _super.call(this, message) || this;
        var proto = Object.create(DecodeError2.prototype);
        Object.setPrototypeOf(_this, proto);
        Object.defineProperty(_this, "name", {
          configurable: true,
          enumerable: false,
          value: DecodeError2.name
        });
        return _this;
      }
      return DecodeError2;
    }(Error);
  }
});
function encodeTimeSpecToTimestamp(_a2) {
  var sec = _a2.sec, nsec = _a2.nsec;
  if (sec >= 0 && nsec >= 0 && sec <= TIMESTAMP64_MAX_SEC) {
    if (nsec === 0 && sec <= TIMESTAMP32_MAX_SEC) {
      var rv = new Uint8Array(4);
      var view = new DataView(rv.buffer);
      view.setUint32(0, sec);
      return rv;
    } else {
      var secHigh = sec / 4294967296;
      var secLow = sec & 4294967295;
      var rv = new Uint8Array(8);
      var view = new DataView(rv.buffer);
      view.setUint32(0, nsec << 2 | secHigh & 3);
      view.setUint32(4, secLow);
      return rv;
    }
  } else {
    var rv = new Uint8Array(12);
    var view = new DataView(rv.buffer);
    view.setUint32(0, nsec);
    setInt64(view, 4, sec);
    return rv;
  }
}
function encodeDateToTimeSpec(date) {
  var msec = date.getTime();
  var sec = Math.floor(msec / 1e3);
  var nsec = (msec - sec * 1e3) * 1e6;
  var nsecInSec = Math.floor(nsec / 1e9);
  return {
    sec: sec + nsecInSec,
    nsec: nsec - nsecInSec * 1e9
  };
}
function encodeTimestampExtension(object) {
  if (object instanceof Date) {
    var timeSpec = encodeDateToTimeSpec(object);
    return encodeTimeSpecToTimestamp(timeSpec);
  } else {
    return null;
  }
}
function decodeTimestampToTimeSpec(data) {
  var view = new DataView(data.buffer, data.byteOffset, data.byteLength);
  switch (data.byteLength) {
    case 4: {
      var sec = view.getUint32(0);
      var nsec = 0;
      return { sec, nsec };
    }
    case 8: {
      var nsec30AndSecHigh2 = view.getUint32(0);
      var secLow32 = view.getUint32(4);
      var sec = (nsec30AndSecHigh2 & 3) * 4294967296 + secLow32;
      var nsec = nsec30AndSecHigh2 >>> 2;
      return { sec, nsec };
    }
    case 12: {
      var sec = getInt64(view, 4);
      var nsec = view.getUint32(0);
      return { sec, nsec };
    }
    default:
      throw new DecodeError("Unrecognized data size for timestamp (expected 4, 8, or 12): ".concat(data.length));
  }
}
function decodeTimestampExtension(data) {
  var timeSpec = decodeTimestampToTimeSpec(data);
  return new Date(timeSpec.sec * 1e3 + timeSpec.nsec / 1e6);
}
var EXT_TIMESTAMP;
var TIMESTAMP32_MAX_SEC;
var TIMESTAMP64_MAX_SEC;
var timestampExtension;
var init_timestamp = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/timestamp.mjs"() {
    init_DecodeError();
    init_int2();
    EXT_TIMESTAMP = -1;
    TIMESTAMP32_MAX_SEC = 4294967296 - 1;
    TIMESTAMP64_MAX_SEC = 17179869184 - 1;
    timestampExtension = {
      type: EXT_TIMESTAMP,
      encode: encodeTimestampExtension,
      decode: decodeTimestampExtension
    };
  }
});
var ExtensionCodec;
var init_ExtensionCodec = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/ExtensionCodec.mjs"() {
    init_ExtData();
    init_timestamp();
    ExtensionCodec = /** @class */
    function() {
      function ExtensionCodec2() {
        this.builtInEncoders = [];
        this.builtInDecoders = [];
        this.encoders = [];
        this.decoders = [];
        this.register(timestampExtension);
      }
      ExtensionCodec2.prototype.register = function(_a2) {
        var type = _a2.type, encode2 = _a2.encode, decode2 = _a2.decode;
        if (type >= 0) {
          this.encoders[type] = encode2;
          this.decoders[type] = decode2;
        } else {
          var index = 1 + type;
          this.builtInEncoders[index] = encode2;
          this.builtInDecoders[index] = decode2;
        }
      };
      ExtensionCodec2.prototype.tryToEncode = function(object, context) {
        for (var i = 0; i < this.builtInEncoders.length; i++) {
          var encodeExt = this.builtInEncoders[i];
          if (encodeExt != null) {
            var data = encodeExt(object, context);
            if (data != null) {
              var type = -1 - i;
              return new ExtData(type, data);
            }
          }
        }
        for (var i = 0; i < this.encoders.length; i++) {
          var encodeExt = this.encoders[i];
          if (encodeExt != null) {
            var data = encodeExt(object, context);
            if (data != null) {
              var type = i;
              return new ExtData(type, data);
            }
          }
        }
        if (object instanceof ExtData) {
          return object;
        }
        return null;
      };
      ExtensionCodec2.prototype.decode = function(data, type, context) {
        var decodeExt = type < 0 ? this.builtInDecoders[-1 - type] : this.decoders[type];
        if (decodeExt) {
          return decodeExt(data, type, context);
        } else {
          return new ExtData(type, data);
        }
      };
      ExtensionCodec2.defaultCodec = new ExtensionCodec2();
      return ExtensionCodec2;
    }();
  }
});
function ensureUint8Array(buffer2) {
  if (buffer2 instanceof Uint8Array) {
    return buffer2;
  } else if (ArrayBuffer.isView(buffer2)) {
    return new Uint8Array(buffer2.buffer, buffer2.byteOffset, buffer2.byteLength);
  } else if (buffer2 instanceof ArrayBuffer) {
    return new Uint8Array(buffer2);
  } else {
    return Uint8Array.from(buffer2);
  }
}
function createDataView(buffer2) {
  if (buffer2 instanceof ArrayBuffer) {
    return new DataView(buffer2);
  }
  var bufferView = ensureUint8Array(buffer2);
  return new DataView(bufferView.buffer, bufferView.byteOffset, bufferView.byteLength);
}
var init_typedArrays = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/utils/typedArrays.mjs"() {
  }
});
var DEFAULT_MAX_DEPTH;
var DEFAULT_INITIAL_BUFFER_SIZE;
var Encoder;
var init_Encoder = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/Encoder.mjs"() {
    init_utf8();
    init_ExtensionCodec();
    init_int2();
    init_typedArrays();
    DEFAULT_MAX_DEPTH = 100;
    DEFAULT_INITIAL_BUFFER_SIZE = 2048;
    Encoder = /** @class */
    function() {
      function Encoder2(extensionCodec, context, maxDepth, initialBufferSize, sortKeys, forceFloat32, ignoreUndefined, forceIntegerToFloat) {
        if (extensionCodec === void 0) {
          extensionCodec = ExtensionCodec.defaultCodec;
        }
        if (context === void 0) {
          context = void 0;
        }
        if (maxDepth === void 0) {
          maxDepth = DEFAULT_MAX_DEPTH;
        }
        if (initialBufferSize === void 0) {
          initialBufferSize = DEFAULT_INITIAL_BUFFER_SIZE;
        }
        if (sortKeys === void 0) {
          sortKeys = false;
        }
        if (forceFloat32 === void 0) {
          forceFloat32 = false;
        }
        if (ignoreUndefined === void 0) {
          ignoreUndefined = false;
        }
        if (forceIntegerToFloat === void 0) {
          forceIntegerToFloat = false;
        }
        this.extensionCodec = extensionCodec;
        this.context = context;
        this.maxDepth = maxDepth;
        this.initialBufferSize = initialBufferSize;
        this.sortKeys = sortKeys;
        this.forceFloat32 = forceFloat32;
        this.ignoreUndefined = ignoreUndefined;
        this.forceIntegerToFloat = forceIntegerToFloat;
        this.pos = 0;
        this.view = new DataView(new ArrayBuffer(this.initialBufferSize));
        this.bytes = new Uint8Array(this.view.buffer);
      }
      Encoder2.prototype.reinitializeState = function() {
        this.pos = 0;
      };
      Encoder2.prototype.encodeSharedRef = function(object) {
        this.reinitializeState();
        this.doEncode(object, 1);
        return this.bytes.subarray(0, this.pos);
      };
      Encoder2.prototype.encode = function(object) {
        this.reinitializeState();
        this.doEncode(object, 1);
        return this.bytes.slice(0, this.pos);
      };
      Encoder2.prototype.doEncode = function(object, depth) {
        if (depth > this.maxDepth) {
          throw new Error("Too deep objects in depth ".concat(depth));
        }
        if (object == null) {
          this.encodeNil();
        } else if (typeof object === "boolean") {
          this.encodeBoolean(object);
        } else if (typeof object === "number") {
          this.encodeNumber(object);
        } else if (typeof object === "string") {
          this.encodeString(object);
        } else {
          this.encodeObject(object, depth);
        }
      };
      Encoder2.prototype.ensureBufferSizeToWrite = function(sizeToWrite) {
        var requiredSize = this.pos + sizeToWrite;
        if (this.view.byteLength < requiredSize) {
          this.resizeBuffer(requiredSize * 2);
        }
      };
      Encoder2.prototype.resizeBuffer = function(newSize) {
        var newBuffer = new ArrayBuffer(newSize);
        var newBytes = new Uint8Array(newBuffer);
        var newView = new DataView(newBuffer);
        newBytes.set(this.bytes);
        this.view = newView;
        this.bytes = newBytes;
      };
      Encoder2.prototype.encodeNil = function() {
        this.writeU8(192);
      };
      Encoder2.prototype.encodeBoolean = function(object) {
        if (object === false) {
          this.writeU8(194);
        } else {
          this.writeU8(195);
        }
      };
      Encoder2.prototype.encodeNumber = function(object) {
        if (Number.isSafeInteger(object) && !this.forceIntegerToFloat) {
          if (object >= 0) {
            if (object < 128) {
              this.writeU8(object);
            } else if (object < 256) {
              this.writeU8(204);
              this.writeU8(object);
            } else if (object < 65536) {
              this.writeU8(205);
              this.writeU16(object);
            } else if (object < 4294967296) {
              this.writeU8(206);
              this.writeU32(object);
            } else {
              this.writeU8(207);
              this.writeU64(object);
            }
          } else {
            if (object >= -32) {
              this.writeU8(224 | object + 32);
            } else if (object >= -128) {
              this.writeU8(208);
              this.writeI8(object);
            } else if (object >= -32768) {
              this.writeU8(209);
              this.writeI16(object);
            } else if (object >= -2147483648) {
              this.writeU8(210);
              this.writeI32(object);
            } else {
              this.writeU8(211);
              this.writeI64(object);
            }
          }
        } else {
          if (this.forceFloat32) {
            this.writeU8(202);
            this.writeF32(object);
          } else {
            this.writeU8(203);
            this.writeF64(object);
          }
        }
      };
      Encoder2.prototype.writeStringHeader = function(byteLength) {
        if (byteLength < 32) {
          this.writeU8(160 + byteLength);
        } else if (byteLength < 256) {
          this.writeU8(217);
          this.writeU8(byteLength);
        } else if (byteLength < 65536) {
          this.writeU8(218);
          this.writeU16(byteLength);
        } else if (byteLength < 4294967296) {
          this.writeU8(219);
          this.writeU32(byteLength);
        } else {
          throw new Error("Too long string: ".concat(byteLength, " bytes in UTF-8"));
        }
      };
      Encoder2.prototype.encodeString = function(object) {
        var maxHeaderSize = 1 + 4;
        var strLength = object.length;
        if (strLength > TEXT_ENCODER_THRESHOLD) {
          var byteLength = utf8Count(object);
          this.ensureBufferSizeToWrite(maxHeaderSize + byteLength);
          this.writeStringHeader(byteLength);
          utf8EncodeTE(object, this.bytes, this.pos);
          this.pos += byteLength;
        } else {
          var byteLength = utf8Count(object);
          this.ensureBufferSizeToWrite(maxHeaderSize + byteLength);
          this.writeStringHeader(byteLength);
          utf8EncodeJs(object, this.bytes, this.pos);
          this.pos += byteLength;
        }
      };
      Encoder2.prototype.encodeObject = function(object, depth) {
        var ext = this.extensionCodec.tryToEncode(object, this.context);
        if (ext != null) {
          this.encodeExtension(ext);
        } else if (Array.isArray(object)) {
          this.encodeArray(object, depth);
        } else if (ArrayBuffer.isView(object)) {
          this.encodeBinary(object);
        } else if (typeof object === "object") {
          this.encodeMap(object, depth);
        } else {
          throw new Error("Unrecognized object: ".concat(Object.prototype.toString.apply(object)));
        }
      };
      Encoder2.prototype.encodeBinary = function(object) {
        var size = object.byteLength;
        if (size < 256) {
          this.writeU8(196);
          this.writeU8(size);
        } else if (size < 65536) {
          this.writeU8(197);
          this.writeU16(size);
        } else if (size < 4294967296) {
          this.writeU8(198);
          this.writeU32(size);
        } else {
          throw new Error("Too large binary: ".concat(size));
        }
        var bytes = ensureUint8Array(object);
        this.writeU8a(bytes);
      };
      Encoder2.prototype.encodeArray = function(object, depth) {
        var size = object.length;
        if (size < 16) {
          this.writeU8(144 + size);
        } else if (size < 65536) {
          this.writeU8(220);
          this.writeU16(size);
        } else if (size < 4294967296) {
          this.writeU8(221);
          this.writeU32(size);
        } else {
          throw new Error("Too large array: ".concat(size));
        }
        for (var _i = 0, object_1 = object; _i < object_1.length; _i++) {
          var item = object_1[_i];
          this.doEncode(item, depth + 1);
        }
      };
      Encoder2.prototype.countWithoutUndefined = function(object, keys) {
        var count2 = 0;
        for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {
          var key = keys_1[_i];
          if (object[key] !== void 0) {
            count2++;
          }
        }
        return count2;
      };
      Encoder2.prototype.encodeMap = function(object, depth) {
        var keys = Object.keys(object);
        if (this.sortKeys) {
          keys.sort();
        }
        var size = this.ignoreUndefined ? this.countWithoutUndefined(object, keys) : keys.length;
        if (size < 16) {
          this.writeU8(128 + size);
        } else if (size < 65536) {
          this.writeU8(222);
          this.writeU16(size);
        } else if (size < 4294967296) {
          this.writeU8(223);
          this.writeU32(size);
        } else {
          throw new Error("Too large map object: ".concat(size));
        }
        for (var _i = 0, keys_2 = keys; _i < keys_2.length; _i++) {
          var key = keys_2[_i];
          var value = object[key];
          if (!(this.ignoreUndefined && value === void 0)) {
            this.encodeString(key);
            this.doEncode(value, depth + 1);
          }
        }
      };
      Encoder2.prototype.encodeExtension = function(ext) {
        var size = ext.data.length;
        if (size === 1) {
          this.writeU8(212);
        } else if (size === 2) {
          this.writeU8(213);
        } else if (size === 4) {
          this.writeU8(214);
        } else if (size === 8) {
          this.writeU8(215);
        } else if (size === 16) {
          this.writeU8(216);
        } else if (size < 256) {
          this.writeU8(199);
          this.writeU8(size);
        } else if (size < 65536) {
          this.writeU8(200);
          this.writeU16(size);
        } else if (size < 4294967296) {
          this.writeU8(201);
          this.writeU32(size);
        } else {
          throw new Error("Too large extension object: ".concat(size));
        }
        this.writeI8(ext.type);
        this.writeU8a(ext.data);
      };
      Encoder2.prototype.writeU8 = function(value) {
        this.ensureBufferSizeToWrite(1);
        this.view.setUint8(this.pos, value);
        this.pos++;
      };
      Encoder2.prototype.writeU8a = function(values) {
        var size = values.length;
        this.ensureBufferSizeToWrite(size);
        this.bytes.set(values, this.pos);
        this.pos += size;
      };
      Encoder2.prototype.writeI8 = function(value) {
        this.ensureBufferSizeToWrite(1);
        this.view.setInt8(this.pos, value);
        this.pos++;
      };
      Encoder2.prototype.writeU16 = function(value) {
        this.ensureBufferSizeToWrite(2);
        this.view.setUint16(this.pos, value);
        this.pos += 2;
      };
      Encoder2.prototype.writeI16 = function(value) {
        this.ensureBufferSizeToWrite(2);
        this.view.setInt16(this.pos, value);
        this.pos += 2;
      };
      Encoder2.prototype.writeU32 = function(value) {
        this.ensureBufferSizeToWrite(4);
        this.view.setUint32(this.pos, value);
        this.pos += 4;
      };
      Encoder2.prototype.writeI32 = function(value) {
        this.ensureBufferSizeToWrite(4);
        this.view.setInt32(this.pos, value);
        this.pos += 4;
      };
      Encoder2.prototype.writeF32 = function(value) {
        this.ensureBufferSizeToWrite(4);
        this.view.setFloat32(this.pos, value);
        this.pos += 4;
      };
      Encoder2.prototype.writeF64 = function(value) {
        this.ensureBufferSizeToWrite(8);
        this.view.setFloat64(this.pos, value);
        this.pos += 8;
      };
      Encoder2.prototype.writeU64 = function(value) {
        this.ensureBufferSizeToWrite(8);
        setUint64(this.view, this.pos, value);
        this.pos += 8;
      };
      Encoder2.prototype.writeI64 = function(value) {
        this.ensureBufferSizeToWrite(8);
        setInt64(this.view, this.pos, value);
        this.pos += 8;
      };
      return Encoder2;
    }();
  }
});
function encode(value, options) {
  if (options === void 0) {
    options = defaultEncodeOptions;
  }
  var encoder = new Encoder(options.extensionCodec, options.context, options.maxDepth, options.initialBufferSize, options.sortKeys, options.forceFloat32, options.ignoreUndefined, options.forceIntegerToFloat);
  return encoder.encodeSharedRef(value);
}
var defaultEncodeOptions;
var init_encode = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/encode.mjs"() {
    init_Encoder();
    defaultEncodeOptions = {};
  }
});
function prettyByte(byte) {
  return "".concat(byte < 0 ? "-" : "", "0x").concat(Math.abs(byte).toString(16).padStart(2, "0"));
}
var init_prettyByte = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/utils/prettyByte.mjs"() {
  }
});
var DEFAULT_MAX_KEY_LENGTH;
var DEFAULT_MAX_LENGTH_PER_KEY;
var CachedKeyDecoder;
var init_CachedKeyDecoder = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/CachedKeyDecoder.mjs"() {
    init_utf8();
    DEFAULT_MAX_KEY_LENGTH = 16;
    DEFAULT_MAX_LENGTH_PER_KEY = 16;
    CachedKeyDecoder = /** @class */
    function() {
      function CachedKeyDecoder2(maxKeyLength, maxLengthPerKey) {
        if (maxKeyLength === void 0) {
          maxKeyLength = DEFAULT_MAX_KEY_LENGTH;
        }
        if (maxLengthPerKey === void 0) {
          maxLengthPerKey = DEFAULT_MAX_LENGTH_PER_KEY;
        }
        this.maxKeyLength = maxKeyLength;
        this.maxLengthPerKey = maxLengthPerKey;
        this.hit = 0;
        this.miss = 0;
        this.caches = [];
        for (var i = 0; i < this.maxKeyLength; i++) {
          this.caches.push([]);
        }
      }
      CachedKeyDecoder2.prototype.canBeCached = function(byteLength) {
        return byteLength > 0 && byteLength <= this.maxKeyLength;
      };
      CachedKeyDecoder2.prototype.find = function(bytes, inputOffset, byteLength) {
        var records = this.caches[byteLength - 1];
        FIND_CHUNK:
          for (var _i = 0, records_1 = records; _i < records_1.length; _i++) {
            var record = records_1[_i];
            var recordBytes = record.bytes;
            for (var j = 0; j < byteLength; j++) {
              if (recordBytes[j] !== bytes[inputOffset + j]) {
                continue FIND_CHUNK;
              }
            }
            return record.str;
          }
        return null;
      };
      CachedKeyDecoder2.prototype.store = function(bytes, value) {
        var records = this.caches[bytes.length - 1];
        var record = { bytes, str: value };
        if (records.length >= this.maxLengthPerKey) {
          records[Math.random() * records.length | 0] = record;
        } else {
          records.push(record);
        }
      };
      CachedKeyDecoder2.prototype.decode = function(bytes, inputOffset, byteLength) {
        var cachedValue = this.find(bytes, inputOffset, byteLength);
        if (cachedValue != null) {
          this.hit++;
          return cachedValue;
        }
        this.miss++;
        var str5 = utf8DecodeJs(bytes, inputOffset, byteLength);
        var slicedCopyOfBytes = Uint8Array.prototype.slice.call(bytes, inputOffset, inputOffset + byteLength);
        this.store(slicedCopyOfBytes, str5);
        return str5;
      };
      return CachedKeyDecoder2;
    }();
  }
});
var __awaiter;
var __generator;
var __asyncValues;
var __await;
var __asyncGenerator;
var isValidMapKeyType;
var HEAD_BYTE_REQUIRED;
var EMPTY_VIEW;
var EMPTY_BYTES;
var DataViewIndexOutOfBoundsError;
var MORE_DATA;
var sharedCachedKeyDecoder;
var Decoder;
var init_Decoder = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/Decoder.mjs"() {
    init_prettyByte();
    init_ExtensionCodec();
    init_int2();
    init_utf8();
    init_typedArrays();
    init_CachedKeyDecoder();
    init_DecodeError();
    __awaiter = function(thisArg, _arguments, P, generator2) {
      function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
          resolve(value);
        });
      }
      return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
          try {
            step4(generator2.next(value));
          } catch (e) {
            reject(e);
          }
        }
        function rejected(value) {
          try {
            step4(generator2["throw"](value));
          } catch (e) {
            reject(e);
          }
        }
        function step4(result) {
          result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step4((generator2 = generator2.apply(thisArg, _arguments || [])).next());
      });
    };
    __generator = function(thisArg, body) {
      var _ = { label: 0, sent: function() {
        if (t[0] & 1)
          throw t[1];
        return t[1];
      }, trys: [], ops: [] }, f, y, t, g;
      return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
      }), g;
      function verb(n) {
        return function(v) {
          return step4([n, v]);
        };
      }
      function step4(op2) {
        if (f)
          throw new TypeError("Generator is already executing.");
        while (_)
          try {
            if (f = 1, y && (t = op2[0] & 2 ? y["return"] : op2[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op2[1])).done)
              return t;
            if (y = 0, t)
              op2 = [op2[0] & 2, t.value];
            switch (op2[0]) {
              case 0:
              case 1:
                t = op2;
                break;
              case 4:
                _.label++;
                return { value: op2[1], done: false };
              case 5:
                _.label++;
                y = op2[1];
                op2 = [0];
                continue;
              case 7:
                op2 = _.ops.pop();
                _.trys.pop();
                continue;
              default:
                if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op2[0] === 6 || op2[0] === 2)) {
                  _ = 0;
                  continue;
                }
                if (op2[0] === 3 && (!t || op2[1] > t[0] && op2[1] < t[3])) {
                  _.label = op2[1];
                  break;
                }
                if (op2[0] === 6 && _.label < t[1]) {
                  _.label = t[1];
                  t = op2;
                  break;
                }
                if (t && _.label < t[2]) {
                  _.label = t[2];
                  _.ops.push(op2);
                  break;
                }
                if (t[2])
                  _.ops.pop();
                _.trys.pop();
                continue;
            }
            op2 = body.call(thisArg, _);
          } catch (e) {
            op2 = [6, e];
            y = 0;
          } finally {
            f = t = 0;
          }
        if (op2[0] & 5)
          throw op2[1];
        return { value: op2[0] ? op2[1] : void 0, done: true };
      }
    };
    __asyncValues = function(o) {
      if (!Symbol.asyncIterator)
        throw new TypeError("Symbol.asyncIterator is not defined.");
      var m = o[Symbol.asyncIterator], i;
      return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
      }, i);
      function verb(n) {
        i[n] = o[n] && function(v) {
          return new Promise(function(resolve, reject) {
            v = o[n](v), settle(resolve, reject, v.done, v.value);
          });
        };
      }
      function settle(resolve, reject, d, v) {
        Promise.resolve(v).then(function(v2) {
          resolve({ value: v2, done: d });
        }, reject);
      }
    };
    __await = function(v) {
      return this instanceof __await ? (this.v = v, this) : new __await(v);
    };
    __asyncGenerator = function(thisArg, _arguments, generator2) {
      if (!Symbol.asyncIterator)
        throw new TypeError("Symbol.asyncIterator is not defined.");
      var g = generator2.apply(thisArg, _arguments || []), i, q = [];
      return i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
      }, i;
      function verb(n) {
        if (g[n])
          i[n] = function(v) {
            return new Promise(function(a, b) {
              q.push([n, v, a, b]) > 1 || resume(n, v);
            });
          };
      }
      function resume(n, v) {
        try {
          step4(g[n](v));
        } catch (e) {
          settle(q[0][3], e);
        }
      }
      function step4(r) {
        r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
      }
      function fulfill(value) {
        resume("next", value);
      }
      function reject(value) {
        resume("throw", value);
      }
      function settle(f, v) {
        if (f(v), q.shift(), q.length)
          resume(q[0][0], q[0][1]);
      }
    };
    isValidMapKeyType = function(key) {
      var keyType = typeof key;
      return keyType === "string" || keyType === "number";
    };
    HEAD_BYTE_REQUIRED = -1;
    EMPTY_VIEW = new DataView(new ArrayBuffer(0));
    EMPTY_BYTES = new Uint8Array(EMPTY_VIEW.buffer);
    DataViewIndexOutOfBoundsError = function() {
      try {
        EMPTY_VIEW.getInt8(0);
      } catch (e) {
        return e.constructor;
      }
      throw new Error("never reached");
    }();
    MORE_DATA = new DataViewIndexOutOfBoundsError("Insufficient data");
    sharedCachedKeyDecoder = new CachedKeyDecoder();
    Decoder = /** @class */
    function() {
      function Decoder2(extensionCodec, context, maxStrLength, maxBinLength, maxArrayLength, maxMapLength, maxExtLength, keyDecoder) {
        if (extensionCodec === void 0) {
          extensionCodec = ExtensionCodec.defaultCodec;
        }
        if (context === void 0) {
          context = void 0;
        }
        if (maxStrLength === void 0) {
          maxStrLength = UINT32_MAX;
        }
        if (maxBinLength === void 0) {
          maxBinLength = UINT32_MAX;
        }
        if (maxArrayLength === void 0) {
          maxArrayLength = UINT32_MAX;
        }
        if (maxMapLength === void 0) {
          maxMapLength = UINT32_MAX;
        }
        if (maxExtLength === void 0) {
          maxExtLength = UINT32_MAX;
        }
        if (keyDecoder === void 0) {
          keyDecoder = sharedCachedKeyDecoder;
        }
        this.extensionCodec = extensionCodec;
        this.context = context;
        this.maxStrLength = maxStrLength;
        this.maxBinLength = maxBinLength;
        this.maxArrayLength = maxArrayLength;
        this.maxMapLength = maxMapLength;
        this.maxExtLength = maxExtLength;
        this.keyDecoder = keyDecoder;
        this.totalPos = 0;
        this.pos = 0;
        this.view = EMPTY_VIEW;
        this.bytes = EMPTY_BYTES;
        this.headByte = HEAD_BYTE_REQUIRED;
        this.stack = [];
      }
      Decoder2.prototype.reinitializeState = function() {
        this.totalPos = 0;
        this.headByte = HEAD_BYTE_REQUIRED;
        this.stack.length = 0;
      };
      Decoder2.prototype.setBuffer = function(buffer2) {
        this.bytes = ensureUint8Array(buffer2);
        this.view = createDataView(this.bytes);
        this.pos = 0;
      };
      Decoder2.prototype.appendBuffer = function(buffer2) {
        if (this.headByte === HEAD_BYTE_REQUIRED && !this.hasRemaining(1)) {
          this.setBuffer(buffer2);
        } else {
          var remainingData = this.bytes.subarray(this.pos);
          var newData = ensureUint8Array(buffer2);
          var newBuffer = new Uint8Array(remainingData.length + newData.length);
          newBuffer.set(remainingData);
          newBuffer.set(newData, remainingData.length);
          this.setBuffer(newBuffer);
        }
      };
      Decoder2.prototype.hasRemaining = function(size) {
        return this.view.byteLength - this.pos >= size;
      };
      Decoder2.prototype.createExtraByteError = function(posToShow) {
        var _a2 = this, view = _a2.view, pos = _a2.pos;
        return new RangeError("Extra ".concat(view.byteLength - pos, " of ").concat(view.byteLength, " byte(s) found at buffer[").concat(posToShow, "]"));
      };
      Decoder2.prototype.decode = function(buffer2) {
        this.reinitializeState();
        this.setBuffer(buffer2);
        var object = this.doDecodeSync();
        if (this.hasRemaining(1)) {
          throw this.createExtraByteError(this.pos);
        }
        return object;
      };
      Decoder2.prototype.decodeMulti = function(buffer2) {
        return __generator(this, function(_a2) {
          switch (_a2.label) {
            case 0:
              this.reinitializeState();
              this.setBuffer(buffer2);
              _a2.label = 1;
            case 1:
              if (!this.hasRemaining(1))
                return [3, 3];
              return [4, this.doDecodeSync()];
            case 2:
              _a2.sent();
              return [3, 1];
            case 3:
              return [
                2
                /*return*/
              ];
          }
        });
      };
      Decoder2.prototype.decodeAsync = function(stream) {
        var stream_1, stream_1_1;
        var e_1, _a2;
        return __awaiter(this, void 0, void 0, function() {
          var decoded, object, buffer2, e_1_1, _b2, headByte, pos, totalPos;
          return __generator(this, function(_c2) {
            switch (_c2.label) {
              case 0:
                decoded = false;
                _c2.label = 1;
              case 1:
                _c2.trys.push([1, 6, 7, 12]);
                stream_1 = __asyncValues(stream);
                _c2.label = 2;
              case 2:
                return [4, stream_1.next()];
              case 3:
                if (!(stream_1_1 = _c2.sent(), !stream_1_1.done))
                  return [3, 5];
                buffer2 = stream_1_1.value;
                if (decoded) {
                  throw this.createExtraByteError(this.totalPos);
                }
                this.appendBuffer(buffer2);
                try {
                  object = this.doDecodeSync();
                  decoded = true;
                } catch (e) {
                  if (!(e instanceof DataViewIndexOutOfBoundsError)) {
                    throw e;
                  }
                }
                this.totalPos += this.pos;
                _c2.label = 4;
              case 4:
                return [3, 2];
              case 5:
                return [3, 12];
              case 6:
                e_1_1 = _c2.sent();
                e_1 = { error: e_1_1 };
                return [3, 12];
              case 7:
                _c2.trys.push([7, , 10, 11]);
                if (!(stream_1_1 && !stream_1_1.done && (_a2 = stream_1.return)))
                  return [3, 9];
                return [4, _a2.call(stream_1)];
              case 8:
                _c2.sent();
                _c2.label = 9;
              case 9:
                return [3, 11];
              case 10:
                if (e_1)
                  throw e_1.error;
                return [
                  7
                  /*endfinally*/
                ];
              case 11:
                return [
                  7
                  /*endfinally*/
                ];
              case 12:
                if (decoded) {
                  if (this.hasRemaining(1)) {
                    throw this.createExtraByteError(this.totalPos);
                  }
                  return [2, object];
                }
                _b2 = this, headByte = _b2.headByte, pos = _b2.pos, totalPos = _b2.totalPos;
                throw new RangeError("Insufficient data in parsing ".concat(prettyByte(headByte), " at ").concat(totalPos, " (").concat(pos, " in the current buffer)"));
            }
          });
        });
      };
      Decoder2.prototype.decodeArrayStream = function(stream) {
        return this.decodeMultiAsync(stream, true);
      };
      Decoder2.prototype.decodeStream = function(stream) {
        return this.decodeMultiAsync(stream, false);
      };
      Decoder2.prototype.decodeMultiAsync = function(stream, isArray) {
        return __asyncGenerator(this, arguments, function decodeMultiAsync_1() {
          var isArrayHeaderRequired, arrayItemsLeft, stream_2, stream_2_1, buffer2, e_2, e_3_1;
          var e_3, _a2;
          return __generator(this, function(_b2) {
            switch (_b2.label) {
              case 0:
                isArrayHeaderRequired = isArray;
                arrayItemsLeft = -1;
                _b2.label = 1;
              case 1:
                _b2.trys.push([1, 13, 14, 19]);
                stream_2 = __asyncValues(stream);
                _b2.label = 2;
              case 2:
                return [4, __await(stream_2.next())];
              case 3:
                if (!(stream_2_1 = _b2.sent(), !stream_2_1.done))
                  return [3, 12];
                buffer2 = stream_2_1.value;
                if (isArray && arrayItemsLeft === 0) {
                  throw this.createExtraByteError(this.totalPos);
                }
                this.appendBuffer(buffer2);
                if (isArrayHeaderRequired) {
                  arrayItemsLeft = this.readArraySize();
                  isArrayHeaderRequired = false;
                  this.complete();
                }
                _b2.label = 4;
              case 4:
                _b2.trys.push([4, 9, , 10]);
                _b2.label = 5;
              case 5:
                if (false)
                  return [3, 8];
                return [4, __await(this.doDecodeSync())];
              case 6:
                return [4, _b2.sent()];
              case 7:
                _b2.sent();
                if (--arrayItemsLeft === 0) {
                  return [3, 8];
                }
                return [3, 5];
              case 8:
                return [3, 10];
              case 9:
                e_2 = _b2.sent();
                if (!(e_2 instanceof DataViewIndexOutOfBoundsError)) {
                  throw e_2;
                }
                return [3, 10];
              case 10:
                this.totalPos += this.pos;
                _b2.label = 11;
              case 11:
                return [3, 2];
              case 12:
                return [3, 19];
              case 13:
                e_3_1 = _b2.sent();
                e_3 = { error: e_3_1 };
                return [3, 19];
              case 14:
                _b2.trys.push([14, , 17, 18]);
                if (!(stream_2_1 && !stream_2_1.done && (_a2 = stream_2.return)))
                  return [3, 16];
                return [4, __await(_a2.call(stream_2))];
              case 15:
                _b2.sent();
                _b2.label = 16;
              case 16:
                return [3, 18];
              case 17:
                if (e_3)
                  throw e_3.error;
                return [
                  7
                  /*endfinally*/
                ];
              case 18:
                return [
                  7
                  /*endfinally*/
                ];
              case 19:
                return [
                  2
                  /*return*/
                ];
            }
          });
        });
      };
      Decoder2.prototype.doDecodeSync = function() {
        DECODE:
          while (true) {
            var headByte = this.readHeadByte();
            var object = void 0;
            if (headByte >= 224) {
              object = headByte - 256;
            } else if (headByte < 192) {
              if (headByte < 128) {
                object = headByte;
              } else if (headByte < 144) {
                var size = headByte - 128;
                if (size !== 0) {
                  this.pushMapState(size);
                  this.complete();
                  continue DECODE;
                } else {
                  object = {};
                }
              } else if (headByte < 160) {
                var size = headByte - 144;
                if (size !== 0) {
                  this.pushArrayState(size);
                  this.complete();
                  continue DECODE;
                } else {
                  object = [];
                }
              } else {
                var byteLength = headByte - 160;
                object = this.decodeUtf8String(byteLength, 0);
              }
            } else if (headByte === 192) {
              object = null;
            } else if (headByte === 194) {
              object = false;
            } else if (headByte === 195) {
              object = true;
            } else if (headByte === 202) {
              object = this.readF32();
            } else if (headByte === 203) {
              object = this.readF64();
            } else if (headByte === 204) {
              object = this.readU8();
            } else if (headByte === 205) {
              object = this.readU16();
            } else if (headByte === 206) {
              object = this.readU32();
            } else if (headByte === 207) {
              object = this.readU64();
            } else if (headByte === 208) {
              object = this.readI8();
            } else if (headByte === 209) {
              object = this.readI16();
            } else if (headByte === 210) {
              object = this.readI32();
            } else if (headByte === 211) {
              object = this.readI64();
            } else if (headByte === 217) {
              var byteLength = this.lookU8();
              object = this.decodeUtf8String(byteLength, 1);
            } else if (headByte === 218) {
              var byteLength = this.lookU16();
              object = this.decodeUtf8String(byteLength, 2);
            } else if (headByte === 219) {
              var byteLength = this.lookU32();
              object = this.decodeUtf8String(byteLength, 4);
            } else if (headByte === 220) {
              var size = this.readU16();
              if (size !== 0) {
                this.pushArrayState(size);
                this.complete();
                continue DECODE;
              } else {
                object = [];
              }
            } else if (headByte === 221) {
              var size = this.readU32();
              if (size !== 0) {
                this.pushArrayState(size);
                this.complete();
                continue DECODE;
              } else {
                object = [];
              }
            } else if (headByte === 222) {
              var size = this.readU16();
              if (size !== 0) {
                this.pushMapState(size);
                this.complete();
                continue DECODE;
              } else {
                object = {};
              }
            } else if (headByte === 223) {
              var size = this.readU32();
              if (size !== 0) {
                this.pushMapState(size);
                this.complete();
                continue DECODE;
              } else {
                object = {};
              }
            } else if (headByte === 196) {
              var size = this.lookU8();
              object = this.decodeBinary(size, 1);
            } else if (headByte === 197) {
              var size = this.lookU16();
              object = this.decodeBinary(size, 2);
            } else if (headByte === 198) {
              var size = this.lookU32();
              object = this.decodeBinary(size, 4);
            } else if (headByte === 212) {
              object = this.decodeExtension(1, 0);
            } else if (headByte === 213) {
              object = this.decodeExtension(2, 0);
            } else if (headByte === 214) {
              object = this.decodeExtension(4, 0);
            } else if (headByte === 215) {
              object = this.decodeExtension(8, 0);
            } else if (headByte === 216) {
              object = this.decodeExtension(16, 0);
            } else if (headByte === 199) {
              var size = this.lookU8();
              object = this.decodeExtension(size, 1);
            } else if (headByte === 200) {
              var size = this.lookU16();
              object = this.decodeExtension(size, 2);
            } else if (headByte === 201) {
              var size = this.lookU32();
              object = this.decodeExtension(size, 4);
            } else {
              throw new DecodeError("Unrecognized type byte: ".concat(prettyByte(headByte)));
            }
            this.complete();
            var stack2 = this.stack;
            while (stack2.length > 0) {
              var state = stack2[stack2.length - 1];
              if (state.type === 0) {
                state.array[state.position] = object;
                state.position++;
                if (state.position === state.size) {
                  stack2.pop();
                  object = state.array;
                } else {
                  continue DECODE;
                }
              } else if (state.type === 1) {
                if (!isValidMapKeyType(object)) {
                  throw new DecodeError("The type of key must be string or number but " + typeof object);
                }
                if (object === "__proto__") {
                  throw new DecodeError("The key __proto__ is not allowed");
                }
                state.key = object;
                state.type = 2;
                continue DECODE;
              } else {
                state.map[state.key] = object;
                state.readCount++;
                if (state.readCount === state.size) {
                  stack2.pop();
                  object = state.map;
                } else {
                  state.key = null;
                  state.type = 1;
                  continue DECODE;
                }
              }
            }
            return object;
          }
      };
      Decoder2.prototype.readHeadByte = function() {
        if (this.headByte === HEAD_BYTE_REQUIRED) {
          this.headByte = this.readU8();
        }
        return this.headByte;
      };
      Decoder2.prototype.complete = function() {
        this.headByte = HEAD_BYTE_REQUIRED;
      };
      Decoder2.prototype.readArraySize = function() {
        var headByte = this.readHeadByte();
        switch (headByte) {
          case 220:
            return this.readU16();
          case 221:
            return this.readU32();
          default: {
            if (headByte < 160) {
              return headByte - 144;
            } else {
              throw new DecodeError("Unrecognized array type byte: ".concat(prettyByte(headByte)));
            }
          }
        }
      };
      Decoder2.prototype.pushMapState = function(size) {
        if (size > this.maxMapLength) {
          throw new DecodeError("Max length exceeded: map length (".concat(size, ") > maxMapLengthLength (").concat(this.maxMapLength, ")"));
        }
        this.stack.push({
          type: 1,
          size,
          key: null,
          readCount: 0,
          map: {}
        });
      };
      Decoder2.prototype.pushArrayState = function(size) {
        if (size > this.maxArrayLength) {
          throw new DecodeError("Max length exceeded: array length (".concat(size, ") > maxArrayLength (").concat(this.maxArrayLength, ")"));
        }
        this.stack.push({
          type: 0,
          size,
          array: new Array(size),
          position: 0
        });
      };
      Decoder2.prototype.decodeUtf8String = function(byteLength, headerOffset) {
        var _a2;
        if (byteLength > this.maxStrLength) {
          throw new DecodeError("Max length exceeded: UTF-8 byte length (".concat(byteLength, ") > maxStrLength (").concat(this.maxStrLength, ")"));
        }
        if (this.bytes.byteLength < this.pos + headerOffset + byteLength) {
          throw MORE_DATA;
        }
        var offset = this.pos + headerOffset;
        var object;
        if (this.stateIsMapKey() && ((_a2 = this.keyDecoder) === null || _a2 === void 0 ? void 0 : _a2.canBeCached(byteLength))) {
          object = this.keyDecoder.decode(this.bytes, offset, byteLength);
        } else if (byteLength > TEXT_DECODER_THRESHOLD) {
          object = utf8DecodeTD(this.bytes, offset, byteLength);
        } else {
          object = utf8DecodeJs(this.bytes, offset, byteLength);
        }
        this.pos += headerOffset + byteLength;
        return object;
      };
      Decoder2.prototype.stateIsMapKey = function() {
        if (this.stack.length > 0) {
          var state = this.stack[this.stack.length - 1];
          return state.type === 1;
        }
        return false;
      };
      Decoder2.prototype.decodeBinary = function(byteLength, headOffset) {
        if (byteLength > this.maxBinLength) {
          throw new DecodeError("Max length exceeded: bin length (".concat(byteLength, ") > maxBinLength (").concat(this.maxBinLength, ")"));
        }
        if (!this.hasRemaining(byteLength + headOffset)) {
          throw MORE_DATA;
        }
        var offset = this.pos + headOffset;
        var object = this.bytes.subarray(offset, offset + byteLength);
        this.pos += headOffset + byteLength;
        return object;
      };
      Decoder2.prototype.decodeExtension = function(size, headOffset) {
        if (size > this.maxExtLength) {
          throw new DecodeError("Max length exceeded: ext length (".concat(size, ") > maxExtLength (").concat(this.maxExtLength, ")"));
        }
        var extType = this.view.getInt8(this.pos + headOffset);
        var data = this.decodeBinary(
          size,
          headOffset + 1
          /* extType */
        );
        return this.extensionCodec.decode(data, extType, this.context);
      };
      Decoder2.prototype.lookU8 = function() {
        return this.view.getUint8(this.pos);
      };
      Decoder2.prototype.lookU16 = function() {
        return this.view.getUint16(this.pos);
      };
      Decoder2.prototype.lookU32 = function() {
        return this.view.getUint32(this.pos);
      };
      Decoder2.prototype.readU8 = function() {
        var value = this.view.getUint8(this.pos);
        this.pos++;
        return value;
      };
      Decoder2.prototype.readI8 = function() {
        var value = this.view.getInt8(this.pos);
        this.pos++;
        return value;
      };
      Decoder2.prototype.readU16 = function() {
        var value = this.view.getUint16(this.pos);
        this.pos += 2;
        return value;
      };
      Decoder2.prototype.readI16 = function() {
        var value = this.view.getInt16(this.pos);
        this.pos += 2;
        return value;
      };
      Decoder2.prototype.readU32 = function() {
        var value = this.view.getUint32(this.pos);
        this.pos += 4;
        return value;
      };
      Decoder2.prototype.readI32 = function() {
        var value = this.view.getInt32(this.pos);
        this.pos += 4;
        return value;
      };
      Decoder2.prototype.readU64 = function() {
        var value = getUint64(this.view, this.pos);
        this.pos += 8;
        return value;
      };
      Decoder2.prototype.readI64 = function() {
        var value = getInt64(this.view, this.pos);
        this.pos += 8;
        return value;
      };
      Decoder2.prototype.readF32 = function() {
        var value = this.view.getFloat32(this.pos);
        this.pos += 4;
        return value;
      };
      Decoder2.prototype.readF64 = function() {
        var value = this.view.getFloat64(this.pos);
        this.pos += 8;
        return value;
      };
      return Decoder2;
    }();
  }
});
function decode(buffer2, options) {
  if (options === void 0) {
    options = defaultDecodeOptions;
  }
  var decoder = new Decoder(options.extensionCodec, options.context, options.maxStrLength, options.maxBinLength, options.maxArrayLength, options.maxMapLength, options.maxExtLength);
  return decoder.decode(buffer2);
}
var defaultDecodeOptions;
var init_decode = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/decode.mjs"() {
    init_Decoder();
    defaultDecodeOptions = {};
  }
});
var init_dist8 = __esm({
  "node_modules/@msgpack/msgpack/dist.es5+esm/index.mjs"() {
    init_encode();
    init_decode();
  }
});
var CURRENT_VERSION;
var CompilerBase;
var _extractMatchingFeatures;
var init_compiler_base = __esm({
  "node_modules/mind-ar/src/image-target/compiler-base.js"() {
    init_detector();
    init_image_list();
    init_hierarchical_clustering();
    init_dist8();
    init_dist7();
    CURRENT_VERSION = 2;
    CompilerBase = class {
      constructor() {
        this.data = null;
      }
      // input html Images
      compileImageTargets(images, progressCallback) {
        return new Promise(async (resolve, reject) => {
          const targetImages = [];
          for (let i = 0; i < images.length; i++) {
            const img = images[i];
            const processCanvas = this.createProcessCanvas(img);
            const processContext = processCanvas.getContext("2d");
            processContext.drawImage(img, 0, 0, img.width, img.height);
            const processData = processContext.getImageData(0, 0, img.width, img.height);
            const greyImageData = new Uint8Array(img.width * img.height);
            for (let i2 = 0; i2 < greyImageData.length; i2++) {
              const offset = i2 * 4;
              greyImageData[i2] = Math.floor((processData.data[offset] + processData.data[offset + 1] + processData.data[offset + 2]) / 3);
            }
            const targetImage = { data: greyImageData, height: img.height, width: img.width };
            targetImages.push(targetImage);
          }
          const percentPerImage = 50 / targetImages.length;
          let percent = 0;
          this.data = [];
          for (let i = 0; i < targetImages.length; i++) {
            const targetImage = targetImages[i];
            const imageList = buildImageList(targetImage);
            const percentPerAction = percentPerImage / imageList.length;
            const matchingData = await _extractMatchingFeatures(imageList, () => {
              percent += percentPerAction;
              progressCallback(percent);
            });
            this.data.push({
              targetImage,
              imageList,
              matchingData
            });
          }
          for (let i = 0; i < targetImages.length; i++) {
            const trackingImageList = buildTrackingImageList(targetImages[i]);
            this.data[i].trackingImageList = trackingImageList;
          }
          const trackingDataList = await this.compileTrack({ progressCallback, targetImages, basePercent: 50 });
          for (let i = 0; i < targetImages.length; i++) {
            this.data[i].trackingData = trackingDataList[i];
          }
          resolve(this.data);
        });
      }
      // not exporting imageList because too large. rebuild this using targetImage
      exportData() {
        const dataList = [];
        for (let i = 0; i < this.data.length; i++) {
          dataList.push({
            //targetImage: this.data[i].targetImage,
            targetImage: {
              width: this.data[i].targetImage.width,
              height: this.data[i].targetImage.height
            },
            trackingData: this.data[i].trackingData,
            matchingData: this.data[i].matchingData
          });
        }
        const buffer2 = encode({
          v: CURRENT_VERSION,
          dataList
        });
        return buffer2;
      }
      importData(buffer2) {
        const content = decode(new Uint8Array(buffer2));
        if (!content.v || content.v !== CURRENT_VERSION) {
          console.error("Your compiled .mind might be outdated. Please recompile");
          return [];
        }
        const { dataList } = content;
        this.data = [];
        for (let i = 0; i < dataList.length; i++) {
          this.data.push({
            targetImage: dataList[i].targetImage,
            trackingData: dataList[i].trackingData,
            matchingData: dataList[i].matchingData
          });
        }
        return this.data;
      }
      createProcessCanvas(img) {
        console.warn("missing createProcessCanvas implementation");
      }
      compileTrack({ progressCallback, targetImages, basePercent }) {
        console.warn("missing compileTrack implementation");
      }
    };
    _extractMatchingFeatures = async (imageList, doneCallback) => {
      const keyframes = [];
      for (let i = 0; i < imageList.length; i++) {
        const image2 = imageList[i];
        const detector = new Detector(image2.width, image2.height);
        await nextFrame();
        tidy(() => {
          const inputT = tensor(image2.data, [image2.data.length], "float32").reshape([image2.height, image2.width]);
          const { featurePoints: ps } = detector.detect(inputT);
          const maximaPoints = ps.filter((p2) => p2.maxima);
          const minimaPoints = ps.filter((p2) => !p2.maxima);
          const maximaPointsCluster = build({ points: maximaPoints });
          const minimaPointsCluster = build({ points: minimaPoints });
          keyframes.push({
            maximaPoints,
            minimaPoints,
            maximaPointsCluster,
            minimaPointsCluster,
            width: image2.width,
            height: image2.height,
            scale: image2.scale
          });
          doneCallback(i);
        });
      }
      return keyframes;
    };
  }
});
function Worker3() {
  return inlineWorker('var q=class{constructor(s,t,n){this.cumsum=[];for(let e=0;e<n;e++){this.cumsum.push([]);for(let i=0;i<t;i++)this.cumsum[e].push(0)}this.cumsum[0][0]=s[0];for(let e=1;e<t;e++)this.cumsum[0][e]=this.cumsum[0][e-1]+s[e];for(let e=1;e<n;e++)this.cumsum[e][0]=this.cumsum[e-1][0]+s[e*t];for(let e=1;e<n;e++)for(let i=1;i<t;i++)this.cumsum[e][i]=s[e*t+i]+this.cumsum[e-1][i]+this.cumsum[e][i-1]-this.cumsum[e-1][i-1]}query(s,t,n,e){let i=this.cumsum[e][n];return t>0&&(i-=this.cumsum[t-1][n]),s>0&&(i-=this.cumsum[e][s-1]),s>0&&t>0&&(i+=this.cumsum[t-1][s-1]),i}};var C=10,z=2,M=6,Z=5,F=.95,N=.9,B=.2,U=8,V=24*2/3,I=a=>{let{data:s,width:t,height:n,scale:e}=a,i=[t*n];for(let o=0;o<i.length;o++)i[o]=!1;let u=new Float32Array(s.length);for(let o=0;o<t;o++)u[o]=-1,u[t*(n-1)+o]=-1;for(let o=0;o<n;o++)u[o*t]=-1,u[o*t+t-1]=-1;for(let o=1;o<t-1;o++)for(let d=1;d<n-1;d++){let h=o+t*d,S=0,l=0;for(let c=-1;c<=1;c++)S+=s[h+t*c+1]-s[h+t*c-1],l+=s[h+t+c]-s[h-t+c];S/=3*256,l/=3*256,u[h]=Math.sqrt((S*S+l*l)/2)}let f=new Uint32Array(1e3);for(let o=0;o<1e3;o++)f[o]=0;let m=[-1,1,-t,t],w=0;for(let o=1;o<t-1;o++)for(let d=1;d<n-1;d++){let h=o+t*d,S=!0;for(let l=0;l<m.length;l++)if(u[h]<=u[h+m[l]]){S=!1;break}if(S){let l=Math.floor(u[h]*1e3);l>999&&(l=999),l<0&&(l=0),f[l]+=1,w+=1,i[h]=!0}}let y=.02*t*n,T=999,r=0;for(;T>=0&&(r+=f[T],!(r>y));)T--;for(let o=0;o<i.length;o++)i[o]&&u[o]*1e3<T&&(i[o]=!1);let p=[];for(let o=0;o<s.length;o++)p[o]=s[o]*s[o];let A=new q(s,t,n),_=new q(p,t,n),E=new Float32Array(s.length);for(let o=0;o<t;o++)for(let d=0;d<n;d++){let h=d*t+o;if(!i[h]){E[h]=1;continue}let S=L({image:a,cx:o,cy:d,sdThresh:Z,imageDataCumsum:A,imageDataSqrCumsum:_});if(S===null){E[h]=1;continue}let l=-1;for(let c=-C;c<=C;c++){for(let g=-C;g<=C;g++){if(g*g+c*c<=z*z)continue;let D=P({image:a,cx:o+g,cy:d+c,vlen:S,tx:o,ty:d,imageDataCumsum:A,imageDataSqrCumsum:_});if(D!==null&&D>l&&(l=D,l>F))break}if(l>F)break}E[h]=l}return X({image:a,featureMap:E,templateSize:M,searchSize:z,occSize:V,maxSimThresh:N,minSimThresh:B,sdThresh:U,imageDataCumsum:A,imageDataSqrCumsum:_})},X=a=>{let{image:s,featureMap:t,templateSize:n,searchSize:e,occSize:i,maxSimThresh:u,minSimThresh:f,sdThresh:m,imageDataCumsum:w,imageDataSqrCumsum:y}=a,{data:T,width:r,height:p,scale:A}=s;i=Math.floor(Math.min(s.width,s.height)/10);let _=(n*2+1)*3,E=Math.floor(r/_),H=Math.floor(p/_),o=Math.floor(r/i)*Math.floor(p/i)+E*H,d=[],h=new Float32Array(T.length);for(let l=0;l<h.length;l++)h[l]=t[l];let S=0;for(;S<o;){let l=u,c=-1,g=-1;for(let j=0;j<p;j++)for(let x=0;x<r;x++)h[j*r+x]<l&&(l=h[j*r+x],c=x,g=j);if(c===-1)break;let D=L({image:s,cx:c,cy:g,sdThresh:0,imageDataCumsum:w,imageDataSqrCumsum:y});if(D===null){h[g*r+c]=1;continue}if(D/(n*2+1)<m){h[g*r+c]=1;continue}let k=1,b=-1;for(let j=-e;j<=e;j++){for(let x=-e;x<=e;x++){if(x*x+j*j>e*e||x===0&&j===0)continue;let v=P({image:s,vlen:D,cx:c+x,cy:g+j,tx:c,ty:g,imageDataCumsum:w,imageDataSqrCumsum:y});if(v!==null&&(v<k&&(k=v,k<f&&k<l)||v>b&&(b=v,b>.99)))break}if(k<f&&k<l||b>.99)break}if(k<f&&k<l||b>.99){h[g*r+c]=1;continue}d.push({x:c,y:g}),S+=1;for(let j=-i;j<=i;j++)for(let x=-i;x<=i;x++)g+j<0||g+j>=p||c+x<0||c+x>=r||(h[(g+j)*r+(c+x)]=1)}return d},L=({image:a,cx:s,cy:t,sdThresh:n,imageDataCumsum:e,imageDataSqrCumsum:i})=>{if(s-M<0||s+M>=a.width||t-M<0||t+M>=a.height)return null;let u=2*M+1,f=u*u,m=e.query(s-M,t-M,s+M,t+M);m/=f;let w=i.query(s-M,t-M,s+M,t+M);return w-=2*m*e.query(s-M,t-M,s+M,t+M),w+=f*m*m,w/f<n*n?null:(w=Math.sqrt(w),w)},P=a=>{let{image:s,cx:t,cy:n,vlen:e,tx:i,ty:u,imageDataCumsum:f,imageDataSqrCumsum:m}=a,{data:w,width:y,height:T}=s,r=M;if(t-r<0||t+r>=y||n-r<0||n+r>=T)return null;let p=2*r+1,A=f.query(t-r,n-r,t+r,n+r),_=m.query(t-r,n-r,t+r,n+r),E=0,H=(n-r)*y+(t-r),o=(u-r)*y+(i-r),d=y-p;for(let c=0;c<p;c++){for(let g=0;g<p;g++)E+=w[H]*w[o],H+=1,o+=1;H+=d,o+=d}let h=f.query(i-r,u-r,i+r,u+r);h/=p*p,E-=h*A;let S=_-A*A/(p*p);return S==0?null:(S=Math.sqrt(S),1*E/(e*S))};var R=(a,s)=>{let t=[];for(let n=0;n<a.length;n++){let e=a[n],i=I(e),u={data:e.data,scale:e.scale,width:e.width,height:e.height,points:i};t.push(u),s(n)}return t};var O=({image:a,ratio:s})=>{let t=Math.round(a.width*s),n=Math.round(a.height*s),e=new Uint8Array(t*n);for(let i=0;i<t;i++){let u=Math.round(1*i/s),f=Math.round(1*(i+1)/s)-1;f>=a.width&&(f=a.width-1);for(let m=0;m<n;m++){let w=Math.round(1*m/s),y=Math.round(1*(m+1)/s)-1;y>=a.height&&(y=a.height-1);let T=0,r=0;for(let p=u;p<=f;p++)for(let A=w;A<=y;A++)T+=1*a.data[A*a.width+p],r+=1;e[m*t+i]=Math.floor(T/r)}}return{data:e,width:t,height:n}};var W=a=>{let s=Math.min(a.width,a.height),t=[],n=[];t.push(256/s),t.push(128/s);for(let e=0;e<t.length;e++)n.push(Object.assign(O({image:a,ratio:t[e]}),{scale:t[e]}));return n};onmessage=a=>{let{data:s}=a;if(s.type==="compile"){let{targetImages:t}=s,n=100/t.length,e=0,i=[];for(let u=0;u<t.length;u++){let f=t[u],m=W(f),w=n/m.length,y=R(m,T=>{e+=w,postMessage({type:"progress",percent:e})});i.push(y)}postMessage({type:"compileDone",list:i})}};\n');
}
var init_compiler_worker = __esm({
  "node_modules/mind-ar/src/image-target/compiler.worker.js?worker&inline"() {
    init_inline_worker();
  }
});
var Compiler;
var init_compiler = __esm({
  "node_modules/mind-ar/src/image-target/compiler.js"() {
    init_compiler_base();
    init_compiler_worker();
    Compiler = class extends CompilerBase {
      createProcessCanvas(img) {
        const processCanvas = document.createElement("canvas");
        processCanvas.width = img.width;
        processCanvas.height = img.height;
        return processCanvas;
      }
      compileTrack({ progressCallback, targetImages, basePercent }) {
        return new Promise((resolve, reject) => {
          const worker = new Worker3();
          worker.onmessage = (e) => {
            if (e.data.type === "progress") {
              progressCallback(basePercent + e.data.percent * basePercent / 100);
            } else if (e.data.type === "compileDone") {
              resolve(e.data.list);
            }
          };
          worker.postMessage({ type: "compile", targetImages });
        });
      }
    };
  }
});
var InputLoader;
var init_input_loader = __esm({
  "node_modules/mind-ar/src/image-target/input-loader.js"() {
    init_dist7();
    InputLoader = class {
      constructor(width, height) {
        this.width = width;
        this.height = height;
        this.texShape = [height, width];
        const context = document.createElement("canvas").getContext("2d");
        context.canvas.width = width;
        context.canvas.height = height;
        this.context = context;
        this.program = this.buildProgram(width, height);
        const backend2 = backend();
        this.tempPixelHandle = backend2.makeTensorInfo(this.texShape, "float32");
        backend2.texData.get(this.tempPixelHandle.dataId).usage = 2;
      }
      // old method
      _loadInput(input2) {
        return tidy(() => {
          let inputImage = browser_exports.fromPixels(input2);
          inputImage = inputImage.mean(2);
          return inputImage;
        });
      }
      // input is instance of HTMLVideoElement or HTMLImageElement
      loadInput(input2) {
        const context = this.context;
        context.clearRect(0, 0, this.context.canvas.width, this.context.canvas.height);
        const isInputRotated = input2.width === this.height && input2.height === this.width;
        if (isInputRotated) {
          let x = this.context.canvas.width / 2;
          let y = this.context.canvas.height / 2;
          let angleInDegrees = 90;
          context.save();
          context.translate(x, y);
          context.rotate(angleInDegrees * Math.PI / 180);
          context.drawImage(input2, -input2.width / 2, -input2.height / 2);
          context.restore();
        } else {
          this.context.drawImage(input2, 0, 0, input2.width, input2.height);
        }
        const backend2 = backend();
        backend2.gpgpu.uploadPixelDataToTexture(backend2.getTexture(this.tempPixelHandle.dataId), this.context.canvas);
        const res = this._compileAndRun(this.program, [this.tempPixelHandle]);
        return res;
      }
      buildProgram(width, height) {
        const textureMethod = env().getNumber("WEBGL_VERSION") === 2 ? "texture" : "texture2D";
        const program = {
          variableNames: ["A"],
          outputShape: this.texShape,
          userCode: `
	void main() {
	  ivec2 coords = getOutputCoords();
	  int texR = coords[0];
	  int texC = coords[1];
	  vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${width}.0, ${height}.0);

	  vec4 values = ${textureMethod}(A, uv);
	  setOutput((0.299 * values.r + 0.587 * values.g + 0.114 * values.b) * 255.0);
	}
      `
        };
        return program;
      }
      _compileAndRun(program, inputs) {
        const outInfo = backend().compileAndRun(program, inputs);
        return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
      }
      _runWebGLProgram(program, inputs, outputType) {
        const outInfo = backend().runWebGLProgram(program, inputs, outputType);
        return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);
      }
    };
  }
});
var smoothingFactor;
var exponentialSmoothing;
var OneEuroFilter;
var init_one_euro_filter = __esm({
  "node_modules/mind-ar/src/libs/one-euro-filter.js"() {
    smoothingFactor = (te, cutoff) => {
      const r = 2 * Math.PI * cutoff * te;
      return r / (r + 1);
    };
    exponentialSmoothing = (a, x, xPrev) => {
      return a * x + (1 - a) * xPrev;
    };
    OneEuroFilter = class {
      constructor({ minCutOff, beta }) {
        this.minCutOff = minCutOff;
        this.beta = beta;
        this.dCutOff = 1e-3;
        this.xPrev = null;
        this.dxPrev = null;
        this.tPrev = null;
        this.initialized = false;
      }
      reset() {
        this.initialized = false;
      }
      filter(t, x) {
        if (!this.initialized) {
          this.initialized = true;
          this.xPrev = x;
          this.dxPrev = x.map(() => 0);
          this.tPrev = t;
          return x;
        }
        const { xPrev, tPrev, dxPrev } = this;
        const te = t - tPrev;
        const ad = smoothingFactor(te, this.dCutOff);
        const dx = [];
        const dxHat = [];
        const xHat = [];
        for (let i = 0; i < x.length; i++) {
          dx[i] = (x[i] - xPrev[i]) / te;
          dxHat[i] = exponentialSmoothing(ad, dx[i], dxPrev[i]);
          const cutOff = this.minCutOff + this.beta * Math.abs(dxHat[i]);
          const a = smoothingFactor(te, cutOff);
          xHat[i] = exponentialSmoothing(a, x[i], xPrev[i]);
        }
        this.xPrev = xHat;
        this.dxPrev = dxHat;
        this.tPrev = t;
        return xHat;
      }
    };
  }
});
var controller_exports = {};
__export2(controller_exports, {
  Controller: () => Controller
});
var tf;
var DEFAULT_FILTER_CUTOFF;
var DEFAULT_FILTER_BETA;
var DEFAULT_WARMUP_TOLERANCE;
var DEFAULT_MISS_TOLERANCE;
var Controller;
var init_controller = __esm({
  "node_modules/mind-ar/src/image-target/controller.js"() {
    init_dist7();
    init_controller_worker();
    init_tracker();
    init_crop_detector();
    init_compiler();
    init_input_loader();
    init_one_euro_filter();
    tf = { memory, nextFrame };
    DEFAULT_FILTER_CUTOFF = 1e-3;
    DEFAULT_FILTER_BETA = 1e3;
    DEFAULT_WARMUP_TOLERANCE = 5;
    DEFAULT_MISS_TOLERANCE = 5;
    Controller = class {
      constructor({
        inputWidth,
        inputHeight,
        onUpdate = null,
        debugMode = false,
        maxTrack = 1,
        warmupTolerance = null,
        missTolerance = null,
        filterMinCF = null,
        filterBeta = null
      }) {
        this.inputWidth = inputWidth;
        this.inputHeight = inputHeight;
        this.maxTrack = maxTrack;
        this.filterMinCF = filterMinCF === null ? DEFAULT_FILTER_CUTOFF : filterMinCF;
        this.filterBeta = filterBeta === null ? DEFAULT_FILTER_BETA : filterBeta;
        this.warmupTolerance = warmupTolerance === null ? DEFAULT_WARMUP_TOLERANCE : warmupTolerance;
        this.missTolerance = missTolerance === null ? DEFAULT_MISS_TOLERANCE : missTolerance;
        this.cropDetector = new CropDetector(this.inputWidth, this.inputHeight, debugMode);
        this.inputLoader = new InputLoader(this.inputWidth, this.inputHeight);
        this.markerDimensions = null;
        this.onUpdate = onUpdate;
        this.debugMode = debugMode;
        this.processingVideo = false;
        this.interestedTargetIndex = -1;
        this.trackingStates = [];
        const near = 10;
        const far = 1e5;
        const fovy = 45 * Math.PI / 180;
        const f = this.inputHeight / 2 / Math.tan(fovy / 2);
        this.projectionTransform = [
          [f, 0, this.inputWidth / 2],
          [0, f, this.inputHeight / 2],
          [0, 0, 1]
        ];
        this.projectionMatrix = this._glProjectionMatrix({
          projectionTransform: this.projectionTransform,
          width: this.inputWidth,
          height: this.inputHeight,
          near,
          far
        });
        this.worker = new Worker2();
        this.workerMatchDone = null;
        this.workerTrackDone = null;
        this.worker.onmessage = (e) => {
          if (e.data.type === "matchDone" && this.workerMatchDone !== null) {
            this.workerMatchDone(e.data);
          }
          if (e.data.type === "trackUpdateDone" && this.workerTrackDone !== null) {
            this.workerTrackDone(e.data);
          }
        };
      }
      showTFStats() {
        console.log(tf.memory().numTensors);
        console.table(tf.memory());
      }
      addImageTargets(fileURL) {
        return new Promise(async (resolve, reject) => {
          const content = await fetch(fileURL);
          const buffer2 = await content.arrayBuffer();
          const result = this.addImageTargetsFromBuffer(buffer2);
          resolve(result);
        });
      }
      addImageTargetsFromBuffer(buffer2) {
        const compiler = new Compiler();
        const dataList = compiler.importData(buffer2);
        const trackingDataList = [];
        const matchingDataList = [];
        const imageListList = [];
        const dimensions = [];
        for (let i = 0; i < dataList.length; i++) {
          matchingDataList.push(dataList[i].matchingData);
          trackingDataList.push(dataList[i].trackingData);
          dimensions.push([dataList[i].targetImage.width, dataList[i].targetImage.height]);
        }
        this.tracker = new Tracker(dimensions, trackingDataList, this.projectionTransform, this.inputWidth, this.inputHeight, this.debugMode);
        this.worker.postMessage({
          type: "setup",
          inputWidth: this.inputWidth,
          inputHeight: this.inputHeight,
          projectionTransform: this.projectionTransform,
          debugMode: this.debugMode,
          matchingDataList
        });
        this.markerDimensions = dimensions;
        return { dimensions, matchingDataList, trackingDataList };
      }
      dispose() {
        this.stopProcessVideo();
        this.worker.postMessage({
          type: "dispose"
        });
      }
      // warm up gpu - build kernels is slow
      dummyRun(input2) {
        const inputT = this.inputLoader.loadInput(input2);
        this.cropDetector.detect(inputT);
        this.tracker.dummyRun(inputT);
        inputT.dispose();
      }
      getProjectionMatrix() {
        return this.projectionMatrix;
      }
      getRotatedZ90Matrix(m) {
        const rotatedMatrix = [
          -m[1],
          m[0],
          m[2],
          m[3],
          -m[5],
          m[4],
          m[6],
          m[7],
          -m[9],
          m[8],
          m[10],
          m[11],
          -m[13],
          m[12],
          m[14],
          m[15]
        ];
        return rotatedMatrix;
      }
      getWorldMatrix(modelViewTransform, targetIndex) {
        return this._glModelViewMatrix(modelViewTransform, targetIndex);
      }
      async _detectAndMatch(inputT, targetIndexes) {
        const { featurePoints } = this.cropDetector.detectMoving(inputT);
        const { targetIndex: matchedTargetIndex, modelViewTransform } = await this._workerMatch(featurePoints, targetIndexes);
        return { targetIndex: matchedTargetIndex, modelViewTransform };
      }
      async _trackAndUpdate(inputT, lastModelViewTransform, targetIndex) {
        const { worldCoords, screenCoords } = this.tracker.track(inputT, lastModelViewTransform, targetIndex);
        if (worldCoords.length < 4)
          return null;
        const modelViewTransform = await this._workerTrackUpdate(lastModelViewTransform, { worldCoords, screenCoords });
        return modelViewTransform;
      }
      processVideo(input2) {
        if (this.processingVideo)
          return;
        this.processingVideo = true;
        this.trackingStates = [];
        for (let i = 0; i < this.markerDimensions.length; i++) {
          this.trackingStates.push({
            showing: false,
            isTracking: false,
            currentModelViewTransform: null,
            trackCount: 0,
            trackMiss: 0,
            filter: new OneEuroFilter({ minCutOff: this.filterMinCF, beta: this.filterBeta })
          });
        }
        const startProcessing = async () => {
          while (true) {
            if (!this.processingVideo)
              break;
            const inputT = this.inputLoader.loadInput(input2);
            const nTracking = this.trackingStates.reduce((acc, s) => {
              return acc + (!!s.isTracking ? 1 : 0);
            }, 0);
            if (nTracking < this.maxTrack) {
              const matchingIndexes = [];
              for (let i = 0; i < this.trackingStates.length; i++) {
                const trackingState = this.trackingStates[i];
                if (trackingState.isTracking === true)
                  continue;
                if (this.interestedTargetIndex !== -1 && this.interestedTargetIndex !== i)
                  continue;
                matchingIndexes.push(i);
              }
              const { targetIndex: matchedTargetIndex, modelViewTransform } = await this._detectAndMatch(inputT, matchingIndexes);
              if (matchedTargetIndex !== -1) {
                this.trackingStates[matchedTargetIndex].isTracking = true;
                this.trackingStates[matchedTargetIndex].currentModelViewTransform = modelViewTransform;
              }
            }
            for (let i = 0; i < this.trackingStates.length; i++) {
              const trackingState = this.trackingStates[i];
              if (trackingState.isTracking) {
                let modelViewTransform = await this._trackAndUpdate(inputT, trackingState.currentModelViewTransform, i);
                if (modelViewTransform === null) {
                  trackingState.isTracking = false;
                } else {
                  trackingState.currentModelViewTransform = modelViewTransform;
                }
              }
              if (!trackingState.showing) {
                if (trackingState.isTracking) {
                  trackingState.trackMiss = 0;
                  trackingState.trackCount += 1;
                  if (trackingState.trackCount > this.warmupTolerance) {
                    trackingState.showing = true;
                    trackingState.trackingMatrix = null;
                    trackingState.filter.reset();
                  }
                }
              }
              if (trackingState.showing) {
                if (!trackingState.isTracking) {
                  trackingState.trackCount = 0;
                  trackingState.trackMiss += 1;
                  if (trackingState.trackMiss > this.missTolerance) {
                    trackingState.showing = false;
                    trackingState.trackingMatrix = null;
                    this.onUpdate && this.onUpdate({ type: "updateMatrix", targetIndex: i, worldMatrix: null });
                  }
                } else {
                  trackingState.trackMiss = 0;
                }
              }
              if (trackingState.showing) {
                const worldMatrix = this._glModelViewMatrix(trackingState.currentModelViewTransform, i);
                trackingState.trackingMatrix = trackingState.filter.filter(Date.now(), worldMatrix);
                let clone22 = [];
                for (let j = 0; j < trackingState.trackingMatrix.length; j++) {
                  clone22[j] = trackingState.trackingMatrix[j];
                }
                const isInputRotated = input2.width === this.inputHeight && input2.height === this.inputWidth;
                if (isInputRotated) {
                  clone22 = this.getRotatedZ90Matrix(clone22);
                }
                this.onUpdate && this.onUpdate({ type: "updateMatrix", targetIndex: i, worldMatrix: clone22 });
              }
            }
            inputT.dispose();
            this.onUpdate && this.onUpdate({ type: "processDone" });
            await tf.nextFrame();
          }
        };
        startProcessing();
      }
      stopProcessVideo() {
        this.processingVideo = false;
      }
      async detect(input2) {
        const inputT = this.inputLoader.loadInput(input2);
        const { featurePoints, debugExtra } = await this.cropDetector.detect(inputT);
        inputT.dispose();
        return { featurePoints, debugExtra };
      }
      async match(featurePoints, targetIndex) {
        const { modelViewTransform, debugExtra } = await this._workerMatch(featurePoints, [targetIndex]);
        return { modelViewTransform, debugExtra };
      }
      async track(input2, modelViewTransform, targetIndex) {
        const inputT = this.inputLoader.loadInput(input2);
        const result = this.tracker.track(inputT, modelViewTransform, targetIndex);
        inputT.dispose();
        return result;
      }
      async trackUpdate(modelViewTransform, trackFeatures) {
        if (trackFeatures.worldCoords.length < 4)
          return null;
        const modelViewTransform2 = await this._workerTrackUpdate(modelViewTransform, trackFeatures);
        return modelViewTransform2;
      }
      _workerMatch(featurePoints, targetIndexes) {
        return new Promise(async (resolve, reject) => {
          this.workerMatchDone = (data) => {
            resolve({ targetIndex: data.targetIndex, modelViewTransform: data.modelViewTransform, debugExtra: data.debugExtra });
          };
          this.worker.postMessage({ type: "match", featurePoints, targetIndexes });
        });
      }
      _workerTrackUpdate(modelViewTransform, trackingFeatures) {
        return new Promise(async (resolve, reject) => {
          this.workerTrackDone = (data) => {
            resolve(data.modelViewTransform);
          };
          const { worldCoords, screenCoords } = trackingFeatures;
          this.worker.postMessage({ type: "trackUpdate", modelViewTransform, worldCoords, screenCoords });
        });
      }
      _glModelViewMatrix(modelViewTransform, targetIndex) {
        const height = this.markerDimensions[targetIndex][1];
        const openGLWorldMatrix = [
          modelViewTransform[0][0],
          -modelViewTransform[1][0],
          -modelViewTransform[2][0],
          0,
          -modelViewTransform[0][1],
          modelViewTransform[1][1],
          modelViewTransform[2][1],
          0,
          -modelViewTransform[0][2],
          modelViewTransform[1][2],
          modelViewTransform[2][2],
          0,
          modelViewTransform[0][1] * height + modelViewTransform[0][3],
          -(modelViewTransform[1][1] * height + modelViewTransform[1][3]),
          -(modelViewTransform[2][1] * height + modelViewTransform[2][3]),
          1
        ];
        return openGLWorldMatrix;
      }
      // build openGL projection matrix
      // ref: https://strawlab.org/2011/11/05/augmented-reality-with-OpenGL/
      _glProjectionMatrix({ projectionTransform, width, height, near, far }) {
        const proj = [
          [2 * projectionTransform[0][0] / width, 0, -(2 * projectionTransform[0][2] / width - 1), 0],
          [0, 2 * projectionTransform[1][1] / height, -(2 * projectionTransform[1][2] / height - 1), 0],
          [0, 0, -(far + near) / (far - near), -2 * far * near / (far - near)],
          [0, 0, -1, 0]
        ];
        const projMatrix = [];
        for (let i = 0; i < 4; i++) {
          for (let j = 0; j < 4; j++) {
            projMatrix.push(proj[j][i]);
          }
        }
        return projMatrix;
      }
    };
  }
});
var FacingModes = ["environment", "user"];
if (true) {
  Controller2 = (init_controller(), __toCommonJS(controller_exports)).Controller;
} else {
}
var Controller2;
var ImageTracking = class extends Component {
  init() {
    if (!navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      console.error("No media devices found.");
      this.active = false;
    }
    this.trackingTargets = [];
  }
  start() {
    this.view = this.object.getComponent("view");
    navigator.mediaDevices.getUserMedia({ audio: false, video: { facingMode: FacingModes[this.facingMode] } }).then((stream) => {
      this.video = document.createElement("video");
      this.video.playsInline = true;
      this.video.srcObject = stream;
      this.video.addEventListener("loadedmetadata", () => {
        this.video.play();
        this.video.width = this.video.videoWidth;
        this.video.height = this.video.videoHeight;
        this._setupAR(this.video);
      });
    });
  }
  /** Register an 'image-tracking-target' component to follow a marker */
  registerTarget(targetIndex, target) {
    this.trackingTargets.push({ targetIndex, target });
  }
  // start AR. input can be HTML image or video
  async _setupAR(input2) {
    const controller = new Controller2({
      inputWidth: input2.width,
      inputHeight: input2.height,
      maxTrack: this.maxTrack,
      filterMinCF: this.filterMinCF,
      filterBeta: this.filterBeta,
      missTolerance: this.missTolerance,
      warmupTolerance: this.warmupTolerance,
      onUpdate: (data) => {
        if (this.videoTexture)
          this.videoTexture.update();
        this.engine.scene.colorClearEnabled = false;
        this._updateCameraProjection();
        if (data.type === "updateMatrix") {
          const { targetIndex, worldMatrix } = data;
          this.trackingTargets.forEach((t) => {
            if (targetIndex === t.targetIndex) {
              const [markerWidth, markerHeight] = this.markerDimensions[targetIndex];
              t.target.updateTrack(worldMatrix, markerWidth, markerHeight);
            }
          });
        }
      }
    });
    const { dimensions } = await controller.addImageTargets(this.mindPath);
    const texture = new Texture(this.engine, this.video);
    this.input = input2;
    this.controller = controller;
    this.markerDimensions = dimensions;
    this.videoTexture = texture;
    if (this.videoPane) {
      const videoPaneMesh = this.videoPane.getComponent("mesh");
      videoPaneMesh.material = videoPaneMesh.material.clone();
      videoPaneMesh.material.flatTexture = texture;
    } else if (this.engine.scene.skyMaterial) {
      this.engine.scene.skyMaterial.texture = texture;
    } else {
      console.warn("No videoPane or sky material set, cannot show video feed.");
    }
    this.controller.processVideo(input2);
  }
  /* Update camera projection matrix and background video plane */
  _updateCameraProjection() {
    const { input: input2, controller } = this;
    if (!input2 || !controller) {
      return;
    }
    if (this.lastProjectionCanvasWidth === this.engine.canvas.width && this.lastProjectionCanvasHeight === this.engine.canvas.height) {
      return;
    }
    const controllerProjectionMatrix = controller.getProjectionMatrix();
    const projectionMatrix = [...controllerProjectionMatrix];
    const canvasAspect = this.engine.canvas.width / this.engine.canvas.height;
    const inputAspect = input2.width / input2.height;
    if (canvasAspect < inputAspect) {
      projectionMatrix[0] *= inputAspect / canvasAspect;
    }
    this.view.fov = 2 * Math.atan(1 / projectionMatrix[0]) * 180 / Math.PI;
    this.lastProjectionCanvasWidth = this.engine.canvas.width;
    this.lastProjectionCanvasHeight = this.engine.canvas.height;
    if (!this.videoPane)
      return;
    const invProjectionMatrix = new Float32Array(16);
    mat4_exports.invert(invProjectionMatrix, this.view.projectionMatrix);
    const corner = new Float32Array(3);
    vec3_exports.transformMat4(corner, [1, 1, 0], invProjectionMatrix);
    let videoScaleX, videoScaleY;
    if (inputAspect < canvasAspect) {
      videoScaleX = corner[0];
      videoScaleY = videoScaleX * input2.height / input2.width;
    } else {
      videoScaleY = corner[1];
      videoScaleX = videoScaleY * input2.width / input2.height;
    }
    const far = projectionMatrix[14] / (projectionMatrix[10] + 1);
    const videoTranslateZ = -far * 0.999;
    this.videoPane.scalingLocal = [
      videoScaleX / corner[2] * videoTranslateZ,
      videoScaleY / corner[2] * videoTranslateZ,
      1
    ];
    this.videoPane.setTranslationLocal([0, 0, videoTranslateZ]);
  }
};
__publicField2(ImageTracking, "TypeName", "image-tracking");
__publicField2(ImageTracking, "Properties", {
  /** Object with plane mesh for the background video */
  videoPane: Property.object(),
  /** Path to the .mind file containing the marker information */
  mindPath: Property.string(),
  /** Maximum amount of markers to use */
  maxTrack: Property.int(1),
  /** Facing mode of the user camera to get the video feed from */
  facingMode: Property.enum(FacingModes),
  /* OneEuroFilter, min cutoff frequency. default is 0.001 */
  filterMinCF: Property.float(1e-3),
  /* OneEuroFilter, beta. */
  filterBeta: Property.float(1),
  /* number of miss before considered target lost. */
  missTolerance: Property.int(5),
  /* number of track before considered target found. */
  warmupTolerance: Property.int(5)
});
var ZERO = [0, 0, 0];
var tempQuat = quat_exports.create();
var tempQuat2 = quat2_exports.create();
var tempVec3 = vec3_exports.create();
var ImageTrackingTarget = class extends Component {
  constructor() {
    super(...arguments);
    __publicField2(this, "originalScaling", vec3_exports.create());
  }
  init() {
    this.arCamera.getComponent("image-tracking").registerTarget(this.targetIndex, this);
  }
  start() {
    this.onTrackingLost();
  }
  onTrackingLost() {
    this.object.getScalingLocal(this.originalScaling);
    this.object.setScalingLocal(ZERO);
  }
  /* Update tracking target transformation */
  updateTrack(worldMatrix, markerWidth, _) {
    if (!worldMatrix) {
      this.onTrackingLost();
      return;
    }
    const mw = markerWidth / window.devicePixelRatio;
    mat4_exports.getRotation(tempQuat, worldMatrix);
    quat_exports.normalize(tempQuat, tempQuat);
    mat4_exports.getTranslation(tempVec3, worldMatrix);
    vec3_exports.scale(tempVec3, tempVec3, 1 / mw);
    quat2_exports.fromRotationTranslation(tempQuat2, tempQuat, tempVec3);
    this.object.setTransformLocal(tempQuat2);
    const c = window.devicePixelRatio / 2;
    this.object.translateObject([c, c, 0]);
    this.object.setScalingLocal(this.originalScaling);
  }
};
__publicField2(ImageTrackingTarget, "TypeName", "image-tracking-target");
__publicField2(ImageTrackingTarget, "Properties", {
  /** Index of the marker in the 'image-tracking' marker file */
  targetIndex: { type: Type.Int },
  /** Object that holds an 'image-tracking' component to register at */
  arCamera: { type: Type.Object }
});

// js/index.js
var RuntimeOptions = {
  physx: false,
  loader: false,
  xrFramebufferScaleFactor: 1,
  canvas: "canvas"
};
var Constants = {
  ProjectName: "multiple-targets",
  RuntimeBaseName: "WonderlandRuntime",
  WebXRRequiredFeatures: ["local"],
  WebXROptionalFeatures: ["local", "hand-tracking", "hit-test"]
};
var engine2 = await loadRuntime(Constants.RuntimeBaseName, RuntimeOptions);
Object.assign(engine2, dist_exports);
window.WL = engine2;
engine2.onSceneLoaded.once(() => {
  const el = document.getElementById("version");
  if (el)
    setTimeout(() => el.remove(), 2e3);
});
function requestSession(mode) {
  engine2.requestXRSession(
    mode,
    Constants.WebXRRequiredFeatures,
    Constants.WebXROptionalFeatures
  ).catch((e) => console.error(e));
}
function setupButtonsXR() {
  const arButton = document.getElementById("ar-button");
  if (arButton) {
    arButton.dataset.supported = engine2.arSupported;
    arButton.addEventListener("click", () => requestSession("immersive-ar"));
  }
  const vrButton = document.getElementById("vr-button");
  if (vrButton) {
    vrButton.dataset.supported = engine2.vrSupported;
    vrButton.addEventListener("click", () => requestSession("immersive-vr"));
  }
}
if (document.readyState === "loading") {
  window.addEventListener("load", setupButtonsXR);
} else {
  setupButtonsXR();
}
engine2.registerComponent(ImageTracking);
engine2.registerComponent(ImageTrackingTarget);
engine2.scene.load(`${Constants.ProjectName}.bin`);
/*! Bundled license information:

@wonderlandengine/mind-ar-tracking/dist/index.js:
  (*! Bundled license information:
  
  @tensorflow/tfjs-core/dist/backends/backend.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/util_base.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/environment.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/global_util.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/log.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/kernel_registry.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/hash_util.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/profiler.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/tape.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/tensor_format.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/tensor.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/types.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/tensor_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/engine.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/device_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/flags.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/tensor_util_env.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/operation.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/complex.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tensor_ops_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tensor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/types.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/io_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/router_registry.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/indexed_db.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/local_storage.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/model_management.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/platforms/platform_browser.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/platforms/platform_node.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/buffer.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/cast.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/clone.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/print.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/base_side_effects.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/globals.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/add.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/floorDiv.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/div.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/mul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/abs.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/acos.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/acosh.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/all.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/any.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/arg_max.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/arg_min.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/asin.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/asinh.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/atan.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/atan2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/atanh.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv_util.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/reshape.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/avg_pool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/avg_pool_3d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/concat.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/mat_mul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sigmoid.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/slice.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tanh.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/batchnorm.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/bincount.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/broadcast_to.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/ceil.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fill.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/clip_by_value.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv3d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/cos.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/cosh.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/cumprod.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the 'License');
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an 'AS IS' BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/cumsum.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/dense_bincount.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/depth_to_space.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/dilation2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/broadcast_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/where.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/zeros_like.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/div_no_nan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/dot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/elu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/erf.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/axis_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/max.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/min.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/pow.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/scalar.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sqrt.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/square.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sum.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/norm.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/euclidean_norm.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/exp.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/expand_dims.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/expm1.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tile.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/eye.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/floor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/gather.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/greater.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/greater_equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/imag.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/is_finite.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/is_inf.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/is_nan.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/leaky_relu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/less.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/less_equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/local_response_normalization.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/log.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/log1p.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/neg.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/softplus.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/log_sigmoid.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sub.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/log_softmax.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/log_sum_exp.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/logical_and.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/logical_not.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/logical_or.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/logical_xor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/search_sorted.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/max_pool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/max_pool_3d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/maximum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/mean.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/zeros.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/ones.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/minimum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/mirror_pad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/mod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/moments.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/not_equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/one_hot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/ones_like.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/pad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/pool.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/prelu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/prod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/rand_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/random_normal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/random_uniform.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/range.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/real.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/reciprocal.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/relu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/relu6.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/reverse.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/round.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/rsqrt.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/selu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sign.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sin.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sinh.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/slice1d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/slice2d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/slice3d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/slice4d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/softmax.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/spectral/fft.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/spectral/ifft.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/spectral/irfft.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/split.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/spectral/rfft.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/squared_difference.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/squeeze.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/stack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/step.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/strided_slice.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tan.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tensor1d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tensor2d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/tensor3d.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/topk.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/truncated_normal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/unique.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/unstack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/variable.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/where_impl.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/boolean_mask.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/transpose.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/moving_average.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/scatter_nd.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sparse_to_dense.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/gather_nd.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/dropout_util.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/dropout.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/signal_ops_util.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/in_top_k.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fused_util.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fused/conv2d.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fused/mat_mul.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fused_ops.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/flip_left_right.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/nonmax_util.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/threshold.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * https://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/image/transform.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/linalg/band_part.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/linalg/qr.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/ops.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/serialization.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/register_optimizers.js:
    (**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/browser_files.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/progress.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/weights_loader.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/http.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/passthrough.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/io/io.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/browser.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/slice_util.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/train.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/browser_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/concat_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/fused_types.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/reduce_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/rotate_util.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/array_ops_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/selu_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/erf_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/complex_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/einsum_util.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/segment_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/backend_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/backends/kernel_impls.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/base.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/index.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Abs_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Acos_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Acosh_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Add_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/AddN_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ArgMax_grad.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ArgMin_grad.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Asin_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Asinh_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Atan2_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Atan_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Atanh_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/AvgPool3D_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/avg_pool_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/AvgPool_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/BatchMatMul_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/BatchToSpaceND_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/BroadcastTo_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Cast_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Ceil_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ClipByValue_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ComplexAbs_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Concat_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Conv2D_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Conv2DBackpropInput_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Conv3D_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Cos_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Cosh_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Cumsum_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/DepthwiseConv2dNative_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Dilation2D_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Elu_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Erf_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Exp_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ExpandDims_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Expm1_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Floor_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/FloorDiv_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/FusedBatchNorm_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/GatherV2_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/GreaterEqual_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Identity_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/IsFinite_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/IsInf_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/IsNan_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/LeakyRelu_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Log1p_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Log_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/LogSoftmax_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/local_response_normalization_backprop.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/LRN_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/min_max_grad_util.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Max_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Maximum_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/max_pool_3d_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/MaxPool3D_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/ops/max_pool_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/MaxPool_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Mean_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Min_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Minimum_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/MirrorPad_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Mod_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Multiply_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Neg_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/OneHot_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/OnesLike_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Pack_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/PadV2_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Pow_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Prelu_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Prod_grad.js:
    (**
     * @license
     * Copyright 2022 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/RealDiv_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Reciprocal_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Relu6_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Relu_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Reshape_grad.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ResizeBilinear_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ResizeNearestNeighbor_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Reverse_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Round_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Rsqrt_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Select_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Selu_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sigmoid_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sign_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sin_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sinh_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Slice_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Softmax_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Softplus_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/SpaceToBatchND_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/SplitV_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sqrt_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Square_grad.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Step_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sub_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Sum_grad.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Tan_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Tanh_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Tile_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Transpose_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/Unpack_grad.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/UnsortedSegmentSum_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/gradients/ZerosLike_grad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/register_all_gradients.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/abs.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/acos.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/acosh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/add.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/all.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/any.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/arg_max.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/arg_min.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as_scalar.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as_type.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as1d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as3d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as4d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/as5d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/asin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/asinh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/atan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/atan2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/atanh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/batch_to_space_nd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/batchnorm.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/broadcast_to.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/cast.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/ceil.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/clip_by_value.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/concat.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/conv1d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/conv2d_transpose.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/conv2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/cos.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/cosh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/cumprod.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the 'License');
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an 'AS IS' BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/cumsum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/depth_to_space.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/depthwise_conv2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/dilation2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/div_no_nan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/div.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/dot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/elu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/erf.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/euclidean_norm.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/exp.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/expand_dims.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/expm1.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/fft.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/flatten.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/floor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/floorDiv.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/gather.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/greater_equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/greater.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/ifft.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/irfft.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/is_finite.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/is_inf.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/is_nan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/leaky_relu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/less_equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/less.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/local_response_normalization.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/log_sigmoid.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/log_softmax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/log_sum_exp.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/log.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/log1p.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/logical_and.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/logical_not.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/logical_or.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/logical_xor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/mat_mul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/max.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/maximum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/mean.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/min.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/minimum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/mirror_pad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/mod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/mul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/neg.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/norm.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/not_equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/one_hot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/ones_like.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/pad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/pow.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/prelu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/prod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/reciprocal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/relu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/relu6.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/reshape_as.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/reshape.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/resize_bilinear.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/resize_nearest_neighbor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/reverse.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/rfft.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/round.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/rsqrt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/selu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/separable_conv2d.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sigmoid.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sign.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sinh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/slice.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/softmax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/softplus.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/space_to_batch_nd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/split.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sqrt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/square.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/squeeze.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/stack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/step.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/strided_slice.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sub.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/sum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/tan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/tanh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/tile.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/to_bool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/to_float.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/to_int.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/topk.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/transpose.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/unique.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/unsorted_segment_sum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/unstack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/where.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/zeros_like.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/errors.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/executor_utils.js:
    (**
     * @license
     * Copyright 2022 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/generic_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/backend/state.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/keras_format/common.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/common.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/math_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/backend/common.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/backend/tfjs_backend.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/keras_format/initializer_config.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/initializers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/types_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/variable_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/variables.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/topology.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/input_layer.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/flags_layers.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/constraints.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/exports_constraints.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/exports_initializers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/logs.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/base_callbacks.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/serialization.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/losses.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/metrics.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/optimizers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/user_defined_metadata.js:
    (**
     * @license
     * Copyright 2019 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/layer_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/serialization_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/version.js:
    (** @license See the LICENSE file. *)
  
  @tensorflow/tfjs-layers/dist/engine/container.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/training_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/training_dataset.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/training_tensors.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/engine/training.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/models.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/exports.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/activations.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/regularizers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/advanced_activations.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/utils/conv_utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/convolutional.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/convolutional_depthwise.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/recurrent.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/convolutional_recurrent.js:
    (**
     * @license
     * Copyright 2020 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/core.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/embeddings.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/merge.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/noise.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/normalization.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/padding.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/pooling.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/wrappers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/preprocessing/image_preprocessing.js:
    (**
     * @license
     * Copyright 2022 CodeSmith LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/preprocessing/center_crop.js:
    (**
     * @license
     * Copyright 2022 CodeSmith LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/preprocessing/preprocessing_utils.js:
    (**
     * @license
     * Copyright 2022 CodeSmith LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/preprocessing/category_encoding.js:
    (**
     * @license
     * Copyright 2022 CodeSmith LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/layers/preprocessing/image_resizing.js:
    (**
     * @license
     * Copyright 2022 CodeSmith LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/exports_layers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/exports_models.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/exports_regularizers.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/callbacks.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-layers/dist/index.js:
    (**
     * @license
     * Copyright 2018 Google LLC
     *
     * Use of this source code is governed by an MIT-style
     * license that can be found in the LICENSE file or at
     * https://opensource.org/licenses/MIT.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/flags.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/data/compiled_api.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/custom_op/register.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/utils.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/control.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/convolution.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/creation.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/graph.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/image.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/logical.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/matrices.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/normalization.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/reduction.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/sparse.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/spectral.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/string.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/op_list/transformation.js:
    (**
     * @license
     * Copyright 2023 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/operation_mapper.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/tensor_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/tensor_array.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/tensor_list.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/control_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/hash_table.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/image_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/string_executor.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/operations/operation_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/model_analysis.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/graph_executor.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/executor/graph_model.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-converter/dist/version.js:
    (** @license See the LICENSE file. *)
  
  @tensorflow/tfjs-converter/dist/index.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/util/deep_map.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/util/deep_clone.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/util/ring_buffer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/util/growing_ring_buffer.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/lazy_iterator.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/dataset.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/datasets/text_line_dataset.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/datasets/csv_dataset.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/microphone_iterator.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/webcam_iterator.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/datasource.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/string_iterator.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/byte_chunk_iterator.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/file_chunk_iterator.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/iterators/url_chunk_iterator.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/util/source_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/sources/file_data_source.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/sources/url_data_source.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/readers.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     *
     * =============================================================================
     *)
  
  @tensorflow/tfjs-data/dist/version.js:
    (** @license See the LICENSE file. *)
  
  @tensorflow/tfjs-data/dist/index.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/cpu_util.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/backend_cpu.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Real.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Add.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Less.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Log.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js:
    (**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/shared.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/base.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/All.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Any.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ClipByValue.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Cumprod.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Max.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Min.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange.js:
    (**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Range.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Round.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted_impl.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Select.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Square.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Step.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-cpu/dist/index.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/canvas_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/tex_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/webgl_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/flags_webgl.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/glsl_version.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/shader_compiler_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/shader_compiler.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/gpgpu_math.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/decode_matrix_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/decode_matrix_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/encode_float_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/encode_float_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/encode_matrix_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/encode_matrix_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/gpgpu_util.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/gpgpu_context.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernel_utils/shared.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/packing_util.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/pack_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/reshape_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/texture_manager.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/unaryop_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/unaryop_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/unpack_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/backend_webgl.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/webgl.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/base.js:
    (**
     * @license
     * Copyright 2020 Google Inc. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/binaryop_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/binaryop_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Identity.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Complex.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LeakyRelu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Prelu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernel_utils/kernel_funcs_utils.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/mulmat_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/binaryop_complex_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Multiply.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernel_utils/reshape.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Reshape.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/mean_gpu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/reduce_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernel_utils/reduce.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/transpose_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/transpose_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Transpose_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sum_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Transpose.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/_FusedMatMul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Abs.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Acos.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Acosh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Add.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/addn_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/addn_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/AddN.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/All.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Any.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/argminmax_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/argminmax_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernel_utils/arg_min_max.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ArgMax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ArgMin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Asin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Asinh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Atan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Atan2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Atanh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/pool_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/avg_pool_backprop_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3DGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/AvgPoolGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/batchnorm_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/batchnorm_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/BatchNorm.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/slice_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/slice_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Slice.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/BatchToSpaceND.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Bincount.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/BroadcastArgs.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/NotEqual.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Real.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernel_utils/int.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Cast.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Ceil.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/clip_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/clip_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ClipByValue.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/complex_abs_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ComplexAbs.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/concat_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/concat_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Imag.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Concat_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Concat.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/conv_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/im2col_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropFilter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropInput.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv3D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropFilterV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropInputV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Cos.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Cosh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/crop_and_resize_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/CropAndResize.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Cum_impl.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Cumprod.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Cumsum.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/DenseBincount.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/depth_to_space_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/DepthToSpace.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/conv_gpu_depthwise.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu_depthwise.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNative.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu_depthwise.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropInput.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/diag_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Diag.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/dilation_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Dilation2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Einsum.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Elu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/EluGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Equal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Erf.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Exp.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ExpandDims.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Expm1.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/fft_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FFT_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FFT.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/fill_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Fill.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/flip_left_right_gpu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FlipLeftRight.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Floor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FloorDiv.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_packed_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FusedConv2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/FusedDepthwiseConv2D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/GatherNd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/gather_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/GatherV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Greater.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/GreaterEqual.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/IFFT.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/IsFinite.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/IsInf.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/IsNaN.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Less.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LessEqual.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LinSpace.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Log.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Log1p.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LogicalAnd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LogicalNot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LogicalOr.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/lrn_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/lrn_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LRN.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/lrn_grad_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/LRNGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Max_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Max.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Maximum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3D.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/max_pool_backprop_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3DGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Mean_impl.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Mean.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Min.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Minimum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/mirror_pad_gpu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/mirror_pad_packed_gpu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/MirrorPad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Mod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/multinomial_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/RealDiv.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sub.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Softmax.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Multinomial.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Neg.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV3.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV4.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV5.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/onehot_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/OneHot.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ZerosLike.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/OnesLike.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Pack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/pad_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/pad_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/PadV2.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Pow.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Prod.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/RaggedGather.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/RaggedRange.js:
    (**
     * @license
     * Copyright 2022 Google LLC.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/RaggedTensorToTensor.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Range.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Reciprocal.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Relu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Relu6.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/resize_bilinear_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/resize_bilinear_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinear.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/resize_bilinear_backprop_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinearGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighbor.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_backprop_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighborGrad.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/reverse_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/reverse_packed_gpu.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Reverse.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/rotate_gpu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/RotateWithOffset.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Round.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Rsqrt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/scatter_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/ScatterNd.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/search_sorted_gpu.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SearchSorted.js:
    (**
     * @license
     * Copyright 2022 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/select_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Select.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Selu.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sigmoid.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sign.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sin.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sinh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Softplus.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SpaceToBatchND.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SparseFillEmptyRows.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SparseReshape.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentMean.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentSum.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SparseToDense.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SplitV.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Sqrt.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Square.js:
    (**
     * @license
     * Copyright 2019 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/SquaredDifference.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Step.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/strided_slice_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/StridedSlice.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/StringNGrams.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/StringSplit.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/StringToHashBucketFast.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Tan.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Tanh.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/tile_gpu.js:
    (**
     * @license
     * Copyright 2017 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Tile.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/TopK.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/transform_gpu.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Transform.js:
    (**
     * @license
     * Copyright 2021 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Unique.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the License);
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an AS IS BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/Unpack.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/segment_gpu.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/kernels/UnsortedSegmentSum.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/register_all_kernels.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs-backend-webgl/dist/index.js:
    (**
     * @license
     * Copyright 2020 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  
  @tensorflow/tfjs/dist/version.js:
    (** @license See the LICENSE file. *)
  
  @tensorflow/tfjs/dist/index.js:
    (**
     * @license
     * Copyright 2018 Google LLC. All Rights Reserved.
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     * http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     * =============================================================================
     *)
  *)
*/
//# sourceMappingURL=multiple-targets-bundle.js.map
